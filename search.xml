<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>BloomFilter</title>
    <url>/2021/11/29/BloomFilter/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>布隆过滤器原理</li>
<li>布隆过滤器使用案例</li>
</ul>
<a id="more"></a>


<h2 id="布隆过滤器原理"><a href="#布隆过滤器原理" class="headerlink" title="布隆过滤器原理"></a>布隆过滤器原理</h2><p>布隆过滤器（Bloom Filter）是1970年由布隆提出的，它实际上是由一个很长的二进制向量和一系列随意映射函数组成。<br>它是一种基于概率的数据结构，主要用来判断某个元素是否在集合内，它具有运行速度快（时间效率），占用内存小的优点（空间效率），但是有一定的误识别率和删除困难的问题。它能够告诉你某个元素一定不在集合内或可能在集合内。</p>
<h3 id="算法："><a href="#算法：" class="headerlink" title="算法："></a>算法：</h3><ol>
<li>首先需要k个hash函数，每个函数可以把key散列成为1个整数</li>
<li>初始化时，需要一个长度为n比特的数组，每个比特位初始化为0</li>
<li>某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1</li>
<li>判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。</li>
</ol>
<h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><p>不需要存储key，节省空间</p>
<h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ol>
<li>算法判断key在集合中时，有一定的概率key其实不在集合中</li>
<li>无法删除</li>
</ol>
<h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><ul>
<li><p>False Position<br>集合里没有某元素，查找结果是有该元素。<br>也就是误判，这种情况在布隆过滤器中可能会出现。</p>
</li>
<li><p>False Negative<br>集合里有某元素，查找结果是没有该元素。<br>也就是少判，这种情况在布隆过滤器中一定不会出现</p>
</li>
</ul>
<blockquote>
<p>布隆过滤器只会多判不会少判。宁可错杀不可放过<br>想用布隆过滤器判断元素不存在，这个概率不是100%，<br>布隆过滤器认为不存在的情况， 确实是一定不会存在，但是，还有可能原本本身不存在，但是它会认为它存在的，比实际的要少</p>
</blockquote>
<p>Bloom Filter不会动态增长，运行过程中维护的始终只是m位的bitset，所以空间复杂度只有O(m);<br>Bloom Filter的插入与属于操作主要都是在计算k个hash，所以都是O(k)。</p>
<h2 id="个人感悟："><a href="#个人感悟：" class="headerlink" title="个人感悟："></a>个人感悟：</h2><h3 id="为什么布隆过滤器需要多个hash函数？"><a href="#为什么布隆过滤器需要多个hash函数？" class="headerlink" title="为什么布隆过滤器需要多个hash函数？"></a>为什么布隆过滤器需要多个hash函数？</h3><p>因为不同的key的hash值有可能会一样，这样误判的概率会很大，但是如果通过多个hash函数来计算，那么数据误判的概率就会低很多了</p>
<h3 id="为什么布隆过滤器不可以删除？"><a href="#为什么布隆过滤器不可以删除？" class="headerlink" title="为什么布隆过滤器不可以删除？"></a>为什么布隆过滤器不可以删除？</h3><p>如果布隆过滤器把其中一个key的值删除了，也就是把数组的值置为0了，另一个key的hash值有可能也被删除了。所以不可以删除</p>
<p>具体可以参考<a href="https://blog.csdn.net/CrankZ/article/details/84928562">布隆过滤器，原理+案例+代码实现</a></p>
<h2 id="测试案例："><a href="#测试案例：" class="headerlink" title="测试案例："></a>测试案例：</h2><ul>
<li><p>手写java代码，测试布隆过滤器误判情况</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> BF_CARDINAL_THRESHOLD <span class="token operator">=</span> <span class="token number">100000</span><span class="token punctuation">;</span>
        <span class="token keyword">double</span> BF_FALSE_POSITIVE_RATE <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">;</span>
        <span class="token class-name">BloomFilter</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> subOrderFilter <span class="token operator">=</span> <span class="token class-name">BloomFilter</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token class-name">Funnels</span><span class="token punctuation">.</span><span class="token function">integerFunnel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> BF_CARDINAL_THRESHOLD<span class="token punctuation">,</span> BF_FALSE_POSITIVE_RATE<span class="token punctuation">)</span><span class="token punctuation">;</span>
        
        <span class="token class-name">HashSet</span> st <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> BF_CARDINAL_THRESHOLD<span class="token punctuation">;</span> i <span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>subOrderFilter<span class="token punctuation">.</span><span class="token function">mightContain</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                st<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">//其实不存在，但是布隆过滤器认为它存在，这就是误判了</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                subOrderFilter<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"一共误判了："</span> <span class="token operator">+</span> st<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果使用这种方式来过滤，就会导致有一部分数据其实没有出现过，但是也会被过滤掉</p>
</li>
<li><p>在flink程序中使用布隆过滤器实时过滤</p>
<blockquote>
<p>这种情况下，会丢数据，其实感觉没啥意义。。。</p>
</blockquote>
</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>shaded<span class="token punctuation">.</span>guava18<span class="token punctuation">.</span>com<span class="token punctuation">.</span>google<span class="token punctuation">.</span>common<span class="token punctuation">.</span>hash<span class="token punctuation">.</span></span><span class="token class-name">BloomFilter</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>shaded<span class="token punctuation">.</span>guava18<span class="token punctuation">.</span>com<span class="token punctuation">.</span>google<span class="token punctuation">.</span>common<span class="token punctuation">.</span>hash<span class="token punctuation">.</span></span><span class="token class-name">Funnels</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">SingleOutputStreamOperator</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">ProcessFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span></span><span class="token class-name">StandardCharsets</span><span class="token punctuation">;</span>

<span class="token comment">/**
 * 使用布隆过滤器实时去重
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkBloomFilterDemo</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream1 <span class="token operator">=</span> source<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token class-name">String</span> str <span class="token operator">:</span> arr<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>x <span class="token operator">-></span> x<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">SubOrderDeduplicateProcessFunc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">;</span>
        stream1<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token comment">// 去重用的ProcessFunction</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">SubOrderDeduplicateProcessFunc</span> <span class="token keyword">extends</span> <span class="token class-name">ProcessFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> <span class="token number">1L</span><span class="token punctuation">;</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> BF_CARDINAL_THRESHOLD <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">double</span> BF_FALSE_POSITIVE_RATE <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">;</span>

        <span class="token keyword">private</span> <span class="token keyword">volatile</span> <span class="token class-name">BloomFilter</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> subOrderFilter<span class="token punctuation">;</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
            subOrderFilter <span class="token operator">=</span> <span class="token class-name">BloomFilter</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token class-name">Funnels</span><span class="token punctuation">.</span><span class="token function">stringFunnel</span><span class="token punctuation">(</span><span class="token class-name">StandardCharsets</span><span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">,</span> BF_CARDINAL_THRESHOLD<span class="token punctuation">,</span> BF_FALSE_POSITIVE_RATE<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>


        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processElement</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">String</span> subOrderId <span class="token operator">=</span> s<span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>subOrderFilter<span class="token punctuation">.</span><span class="token function">mightContain</span><span class="token punctuation">(</span>subOrderId<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                subOrderFilter<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>subOrderId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>


        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
            subOrderFilter <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>使用布隆过滤器防止缓存击穿</li>
<li>*不在布隆过滤器中的元素一定不存在数据库中。**<br>利用布隆过滤器的这个特点可以解决缓存穿透的问题，在服务启动的时候先把数据的查询条件，例如数据的 ID 映射到布隆过滤器上，当然如果新增数据时，除了写入到数据库中之外，也需要将数据的ID存入到布隆过滤器中。<br>我们在查询某条数据时，先判断这个查询的 ID 是否存在布隆过滤器中，如果不存在就直接返回空值，而不需要继续查询数据库和缓存，存在布隆过滤器中才继续查询数据库和缓存，这样就解决缓存穿透的问题。</li>
</ul>
]]></content>
      <categories>
        <category>Algorithm</category>
        <category>BloomFilter</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>CM宕机问题调查与修复</title>
    <url>/2022/03/17/CM%E5%AE%95%E6%9C%BA%E9%97%AE%E9%A2%98%E8%B0%83%E6%9F%A5%E4%B8%8E%E4%BF%AE%E5%A4%8D/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>CM宕机问题调查与修复</li>
</ul>
<a id="more"></a>

<h2 id="CM宕机问题调查与修复"><a href="#CM宕机问题调查与修复" class="headerlink" title="CM宕机问题调查与修复"></a>CM宕机问题调查与修复</h2><p>公司的Cloudera Manager宕机了，重启服务启动不起来<br>报错如下：<br><img src="/uploads/202203/CM%E5%AE%95%E6%9C%BA%E8%B0%83%E6%9F%A5%E4%B8%8E%E4%BF%AE%E5%A4%8D1.png" alt="CM宕机调查与修复1"></p>
<h3 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h3><p>首先还是先重启服务，然后出现如上图的报错，然后点击<code>完整日志文件</code>，提示去<code>/var/log/cloudera-scm-eventserver/mgmt-cmf-mgmt-EVENTSERVER-ddp1.log.out</code>查看<br>查看日志，报错如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2022-03-17 08:14:35,438 ERROR com.cloudera.cmon.pipeline.PipelineStage: tagger-writer stage encountered error
com.cloudera.cmon.pipeline.ItemRejectedException: java.io.FileNotFoundException: &#x2F;var&#x2F;lib&#x2F;cloudera-scm-eventserver&#x2F;v3&#x2F;_b03j.fdt (No space left on device)
        at com.cloudera.cmf.eventcatcher.server.EventIngester$TaggerWriterReceiver.receiveItem(EventIngester.java:71)
        at com.cloudera.cmf.eventcatcher.server.EventIngester$TaggerWriterReceiver.receiveItem(EventIngester.java:50)
        at com.cloudera.cmon.pipeline.PipelineStage.driver(PipelineStage.java:273)
        at com.cloudera.cmon.pipeline.PipelineStage$2.run(PipelineStage.java:149)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: &#x2F;var&#x2F;lib&#x2F;cloudera-scm-eventserver&#x2F;v3&#x2F;_b03j.fdt (No space left on device)
        at java.io.RandomAccessFile.open0(Native Method)
        at java.io.RandomAccessFile.open(RandomAccessFile.java:316)
        at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:243)
        at org.apache.lucene.store.FSDirectory$FSIndexOutput.&lt;init&gt;(FSDirectory.java:441)
        at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:306)
        at org.apache.lucene.index.FieldsWriter.&lt;init&gt;(FieldsWriter.java:83)
        at org.apache.lucene.index.StoredFieldsWriter.initFieldsWriter(StoredF2022-03-17 08:15:36,333 INFO com.cloudera.cmf.eventcatcher.server.EventCatcherService: Starting EventCatcherService. JVM Args: [-XX:+UseConcMarkSweepGC, -XX:+UseParNewGC, -Dmgmt.log.file&#x3D;mgmt-cmf-mgmt-EVENTSERVER-ddp1.log.out, -Djava.awt.headless&#x3D;true, -Djava.net.preferIPv4Stack&#x3D;true, -Xms1073741824, -Xmx1073741824, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath&#x3D;&#x2F;tmp&#x2F;mgmt_mgmt-EVENTSERVER-3c8d72dc1ca356c08341427a2af41630_pid12858.hprof, -XX:OnOutOfMemoryError&#x3D;&#x2F;opt&#x2F;cloudera&#x2F;cm-agent&#x2F;service&#x2F;common&#x2F;killparent.sh], Args: [], Version: 6.2.0 (#968826 built by jenkins on 20190314-1704 git: 16bbe6211555460a860cf22d811680b35755ea81)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>很明显，报错是因为磁盘空间不足，然后清理磁盘<br>但是，清理磁盘过后，发现重启还是启动不起来。<br>在网上找了很多解决方法，其中一个是</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mv &#x2F;var&#x2F;lib&#x2F;cloudera-scm-eventserver &#x2F;var&#x2F;lib&#x2F;cloudera-scm-eventserver-old<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>经过测试，这种方法对我的情况不适用，还是启动不起来</p>
<p>查看服务器进程，发现没有<code>cloudera-scm-agent</code>进程，只有<code>cloudera-scm-server</code>进程<br>查看status：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@ddp1 ~]# systemctl status cloudera-scm-agent
● cloudera-scm-agent.service - Cloudera Manager Agent Service
   Loaded: loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;cloudera-scm-agent.service; enabled; vendor preset: disabled)
   Active: inactive (dead) since Thu 2022-03-17 08:16:02 CST; 2h 40min ago
  Process: 20187 ExecStart&#x3D;&#x2F;opt&#x2F;cloudera&#x2F;cm-agent&#x2F;bin&#x2F;cm agent (code&#x3D;exited, status&#x3D;0&#x2F;SUCCESS)
 Main PID: 20187 (code&#x3D;exited, status&#x3D;0&#x2F;SUCCESS)

Mar 17 08:16:01 ddp1 cm[20187]: self.stream.flush()
Mar 17 08:16:01 ddp1 cm[20187]: IOError: [Errno 28] No space left on device
Mar 17 08:16:01 ddp1 cm[20187]: Logged from file cgroups.py, line 482
Mar 17 08:16:01 ddp1 cm[20187]: Traceback (most recent call last):
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 875, in emit
Mar 17 08:16:01 ddp1 cm[20187]: self.flush()
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 835, in flush
Mar 17 08:16:01 ddp1 cm[20187]: self.stream.flush()
Mar 17 08:16:01 ddp1 cm[20187]: IOError: [Errno 28] No space left on device
Mar 17 08:16:01 ddp1 cm[20187]: Logged from file main.py, line 109<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过<code>journalctl -u cloudera-scm-agent</code>查看执行日志</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Mar 17 08:16:01 ddp1 cm[20187]: IOError: [Errno 28] No space left on device
Mar 17 08:16:01 ddp1 cm[20187]: Logged from file agent.py, line 636
Mar 17 08:16:01 ddp1 cm[20187]: Traceback (most recent call last):
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 875, in emit
Mar 17 08:16:01 ddp1 cm[20187]: self.flush()
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 835, in flush
Mar 17 08:16:01 ddp1 cm[20187]: self.stream.flush()
Mar 17 08:16:01 ddp1 cm[20187]: IOError: [Errno 28] No space left on device
Mar 17 08:16:01 ddp1 cm[20187]: Logged from file cgroups.py, line 482
Mar 17 08:16:01 ddp1 cm[20187]: Traceback (most recent call last):
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 875, in emit
Mar 17 08:16:01 ddp1 cm[20187]: self.flush()
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 835, in flush
Mar 17 08:16:01 ddp1 cm[20187]: self.stream.flush()
Mar 17 08:16:01 ddp1 cm[20187]: IOError: [Errno 28] No space left on device
Mar 17 08:16:01 ddp1 cm[20187]: Logged from file cgroups.py, line 482
Mar 17 08:16:01 ddp1 cm[20187]: Traceback (most recent call last):
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 875, in emit
Mar 17 08:16:01 ddp1 cm[20187]: self.flush()
Mar 17 08:16:01 ddp1 cm[20187]: File &quot;&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;logging&#x2F;__init__.py&quot;, line 835, in flush
Mar 17 08:16:01 ddp1 cm[20187]: self.stream.flush()
Mar 17 08:16:01 ddp1 cm[20187]: IOError: [Errno 28] No space left on device<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意：我这里不断的重启CM，讲道理，agent服务应该启动很多次了，但是时间还是停留在早晨8点，就说明，后面的重启操作，其实还没有走到重启agent操作<br>应该还是在检查ddp1服务器的磁盘空间，但是ddp1上的agent进程已经没有了，所以server进程收不到ddp1磁盘已经正常的反馈。</p>
<p>解决办法：<br>手动在ddp1服务器上启动<code>cloudera-scm-agent</code>进程：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">systemctl start cloudera-scm-agent<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>之后在CM页面上重启<code>Cloudera Manager Service</code>服务。问题到此解决</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>CM</category>
      </categories>
      <tags>
        <tag>CM</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos安装Mysql</title>
    <url>/2022/03/11/Centos%E5%AE%89%E8%A3%85Mysql/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Centos安装Mysql</li>
</ul>
<a id="more"></a>

<h2 id="Centos安装Mysql"><a href="#Centos安装Mysql" class="headerlink" title="Centos安装Mysql"></a>Centos安装Mysql</h2><p>本文讲述Centos通过yum安装Mysql,yum本身没有mysql源，需要自己去官网下载</p>
<ol>
<li>去官网下载yum仓库文件<br>官网下载连接：<a href="https://dev.mysql.com/downloads/repo/yum/">https://dev.mysql.com/downloads/repo/yum/</a><br><img src="/uploads/202203/mysql-yum%E6%BA%90%E9%80%89%E6%8B%A9.png" alt="mysql-yum源选择"></li>
</ol>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#将复制的连接地址下载
[root@localhost ~]# wget https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql80-community-release-el7-3.noarch.rpm

[root@localhost ~]# ls
anaconda-ks.cfg  mysql80-community-release-el7-3.noarch.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>安装yum仓库文件<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#可是使用rpm -ivh或者是yum localinstall 去安装，两者实质是一样的
[root@localhost ~]# rpm -ivh mysql80-community-release-el7-3.noarch.rpm
warning: mysql80-community-release-el7-3.noarch.rpm: Header V3 DSA&#x2F;SHA1 Signature, key ID 5072e1f5: NOKEY
Preparing...                          ################################# [100%]
Updating &#x2F; installing...
   1:mysql80-community-release-el7-3  ################################# [100%]

#安装完成后可以看到mysql的repo文件
[root@localhost ~]# ls &#x2F;etc&#x2F;yum.repos.d&#x2F;
CentOS-Base.repo  epel.repo  mysql-community.repo  mysql-community-source.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>版本选择<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 安装 YUM 管理工具包，此包提供了 yum-config-manager 命令工具
[root@localhost ~]# yum -y install yum-utils

[root@localhost ~]# yum-config-manager --disable mysql80-community
[root@localhost ~]# yum-config-manager --enable mysql57-community
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
查看默认启动的仓库<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@localhost ~]# yum repolist enabled | grep mysql
mysql-connectors-community&#x2F;x86_64 MySQL Connectors Community                 185
mysql-tools-community&#x2F;x86_64      MySQL Tools Community                      123
mysql57-community&#x2F;x86_64          MySQL 5.7 Community Server                 484<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>安装<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yum install -y  mysql-community-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里会报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Downloading packages:
warning: &#x2F;var&#x2F;cache&#x2F;yum&#x2F;x86_64&#x2F;7&#x2F;mysql57-community&#x2F;packages&#x2F;mysql-community-devel-5.7.37-1.el7.x86_64.rpm: Header V4 RSA&#x2F;SHA256 Signature, key ID 3a79bd29: NOKEY
Retrieving key from file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysql


The GPG keys listed for the &quot;MySQL 5.7 Community Server&quot; repository are already installed but they are not correct for this package.
Check that the correct key URLs are configured for this repository.


Failing package is: mysql-community-devel-5.7.37-1.el7.x86_64
GPG Keys are configured as: file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
报错原因：官方 MySQL 存储库的 GPG 密钥已过期，无法安装或更新 MySQL 包<br>相关报错案例可以在mysql官网查看：<a href="https://bugs.mysql.com/bug.php?id=106188">https://bugs.mysql.com/bug.php?id=106188</a><br>可以在运行安装程序之前导入密钥：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#Centos
rpm --import https:&#x2F;&#x2F;repo.mysql.com&#x2F;RPM-GPG-KEY-mysql-2022
#Ubuntu：
wget -q -O - https:&#x2F;&#x2F;repo.mysql.com&#x2F;RPM-GPG-KEY-mysql-2022 | apt-key add -<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
之后再执行<code>yum install -y  mysql-community-server</code>就over了</li>
</ol>
<ol start="5">
<li><p>设置默认配置<br>在/etc/my.cnf的文件中设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[mysqld]
#配置文件根据环境自行配置，或者保持默认
#例如添加下面几行，设置默认引擎编码和排序规则(根据情况设置合适的)
default-storage-engine&#x3D;INNODB
character-set-server &#x3D; utf8mb4
collation-server &#x3D; utf8mb4_general_ci
skip-character-set-client-handshake
secure_file_priv&#x3D;&#39;&#39;


[client]
default-character-set&#x3D;utf8mb4
[mysql]
default-character-set&#x3D;utf8mb4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>启动服务</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 启动
systemctl start mysqld

# 查看状态
systemctl status mysqld

# 开机自启动
systemctl enable mysqld

# 查看监听端口，默认 3306
ss -natl |grep 3306<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>初始化<br>MySQL服务器初始化（从MySQL 5.7开始）：<br>在 MySQL 服务器初始启动时，如果服务器的数据目录为空，则会发生以下情况：<br>MySQL 服务器已初始化。<br>在数据目录中生成SSL证书和密钥文件。<br>安装并启用该 validate_password 插件。<br>将创建一个超级用户 帐户‘root’@’localhost’。并会设置超级用户的密码，将其存储在错误日志文件/var/log/mysqld.log中。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@localhost ~]# grep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log
2021-01-25T04:26:33.010077Z 1 [Note] A temporary password is generated for root@localhost: *sH2qhGeN(eB

#本地登录的root密码: *sH2qhGeN(eB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>修改初始密码</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mysql&gt; alter user   root@localhost   identified  by  &#39;123456&#39;;
ERROR 1819 (HY000): Your password does not satisfy the current policy requirements

#太过简单的密码会失败，因为不满足密码复杂度的要求

mysql&gt; alter user   root@localhost   identified  by  &#39;Gjc123!@#&#39;;
Query OK, 0 rows affected (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>要设置比较简单的密码就需要取消密码复杂度<br>编辑 my.cnf配置文件, 在 [mysqld]配置块儿中添加如下内容</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">plugin-load&#x3D;validate_password.so
validate-password&#x3D;OFF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>保存退出后，重启服务, 修改密码</p>
</li>
<li><p>远程连接<br>远程登录还需要授权远程登录<br>Mysql默认不允许远程登录，我们需要设置关闭selinux或者防火墙，不关防火墙就开放3306端口；</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mysql&gt; grant all privileges on *.* to root@localhost identified by &#39;Gjc123!@#&#39;;
 Query OK, 0 rows affected, 1 warning (0.00 sec)

#允许任意IP连接
 mysql&gt; grant all privileges on *.* to root@&#39;%&#39; identified by &#39;Gjc123!@#&#39;;
 Query OK, 0 rows affected, 1 warning (0.00 sec)
flush privileges;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>%：匹配任意长度的任意字符，常用于设置允许从任何主机登录<br>_：匹配任意单个字符</p>
</li>
</ol>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#放开3306端口
firewall-cmd --zone&#x3D;public --add-port&#x3D;3306&#x2F;tcp --permanent
firewall-cmd --reload

#关闭防火墙和selinux一劳永逸<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="binlog开启步骤"><a href="#binlog开启步骤" class="headerlink" title="binlog开启步骤"></a>binlog开启步骤</h3><p>检查binlog开启状态：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 如果log_bin显示为ON，则代表已开启。</span>
<span class="token keyword">show</span> variables <span class="token operator">like</span> <span class="token string">'log_%'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>首先找到<code>my.cnf</code>:</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@ddp5 tmp]# mysql --help | grep &#39;Default options&#39; -A 1
Default options are read from the following files in the given order:
&#x2F;etc&#x2F;my.cnf &#x2F;etc&#x2F;mysql&#x2F;my.cnf &#x2F;usr&#x2F;etc&#x2F;my.cnf ~&#x2F;.my.cnf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>可以看到mysql优先加载/etc/my.cnf中的配置。<br>所以需要在/etc/my.cnf中<code>mysqld</code>节添加开启binlog的配置：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[mysqld]
#设置日志路径，注意路经需要mysql用户有权限写
## &#x2F;data&#x2F;mysql&#x2F;logs&#x2F;是binlog存储路径，mysql-bin是文件名
## 在该文件夹下会生成 mysql-bin.000001、 mysql-bin.index文件
log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;logs&#x2F;mysql-bin
#选择row模式
binlog_format&#x3D;ROW
##配置serverid
server_id&#x3D;1
#设置binlog清理时间
expire_logs_days &#x3D; 7
##binlog每个日志文件大小
max_binlog_size &#x3D; 100m
##binlog缓存大小
binlog_cache_size &#x3D; 4m
##最大binlog缓存大小
max_binlog_cache_size &#x3D; 512m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>修改完配置后，重启mysql。执行SHOW VARIABLES LIKE ‘log_bin’; Value 值为 ON即可</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">service mysqld restart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>注意：需要在[mysqld]节点下添加如上参数，否则会报错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mysql: [ERROR] unknown variable &#39;log-bin&#x3D;&#x2F;data&#x2F;mysql&#x2F;logs&#x2F;mysql-bin&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Cloudera Manager CDH离线安装</title>
    <url>/2022/03/11/Cloudera-Manager-CDH%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>CM离线安装<a id="more"></a>

</li>
</ul>
<h2 id="CM离线安装"><a href="#CM离线安装" class="headerlink" title="CM离线安装"></a>CM离线安装</h2><h3 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h3><p>准备3台虚拟机<br>golden-01<br>golden-02<br>golden-03<br>并设置免秘钥登录，这里忽略</p>
<p>下载cdh6.2.0，在百度网盘下载：<br><a href="https://pan.baidu.com/s/1QlWyMRSRJNcaStsZMSdmLg">https://pan.baidu.com/s/1QlWyMRSRJNcaStsZMSdmLg</a>  提取码：ietj</p>
<h3 id="关闭防火墙与关闭-SELINUX"><a href="#关闭防火墙与关闭-SELINUX" class="headerlink" title="关闭防火墙与关闭 SELINUX"></a>关闭防火墙与关闭 SELINUX</h3><ol>
<li>关闭防火墙<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">systemctl stop firewalld  ## 关闭防火墙
systemctl disable firewalld ###禁止防火墙开机自启<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>关闭SELINUX，只需要关闭一个需要配置http文件服务的虚拟机就可以<br>vim /etc/selinux/config —&gt; SELINUX=disabled (修改)<br>这里改完了需要重启虚拟机<br>这里如果不关闭SELINUX，下面视同httpd访问文件的时候，会报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">You don&#39;t have permission to access upload&#x2F; on this server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


</li>
</ol>
<h3 id="配置NTP服务（所有节点）"><a href="#配置NTP服务（所有节点）" class="headerlink" title="配置NTP服务（所有节点）"></a>配置NTP服务（所有节点）</h3><p>修改时区（改为中国标准时区）</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime
## 安装ntp
yum -y install ntp <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>ntp主机配置 vi /etc/ntp.conf<br>在文件里新增server ntp.aliyun.com，并把原始的server给注释掉<br>重启<code>service ntpd restart</code></p>
<h3 id="配置本地服务器（选定任意一台主机即可）"><a href="#配置本地服务器（选定任意一台主机即可）" class="headerlink" title="配置本地服务器（选定任意一台主机即可）"></a>配置本地服务器（选定任意一台主机即可）</h3><p>配置的本地文件服务器的目的是为了，让之后其他节点可以从这直接下载</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum install -y httpd  ##安装httpd
service httpd start 启用htttpd
cd &#x2F;var&#x2F;www&#x2F;html&#x2F;  &amp;&amp; mkdir cdh6  &amp;&amp; mkdir cm6
## 把下载的rpm放到文件服务cm6里
cp &#x2F;home&#x2F;golden&#x2F;cdh6.2.0&#x2F;cm6&#x2F;* &#x2F;var&#x2F;www&#x2F;html&#x2F;cm6&#x2F;
cp &#x2F;home&#x2F;golden&#x2F;cdh6.2.0&#x2F;oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm &#x2F;var&#x2F;www&#x2F;html&#x2F;cm6&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里注意，启用httpd服务以后，防火墙和selinux必须都关闭，否则，就会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">You don&#39;t have permission to access upload&#x2F; on this server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>生成yum源的描述的目录信息 可以让其他节点知道到这里下载</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum install -y createrepo  ##下载createrepo命令
## 进入到cm6安装包的httpd资源位置
cd &#x2F;var&#x2F;www&#x2F;html&#x2F;cm6
##创建yum源的描述meta
createrepo .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在<strong>所有节点上</strong>添加yum源的配置文件</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cat &gt;&gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;cm6.repo &lt;&lt; EOF
[cm6-local]
name&#x3D;cm6-local
baseurl&#x3D;http:&#x2F;&#x2F;192.168.233.133&#x2F;cm6&#x2F;
enabled&#x3D;1
gpgcheck&#x3D;0
EOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>查看yum配置源是否生效</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum clean all
yum repolist
yum makecache<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h3><p>前面安装了2次，都是使用自己配置JAVA_HOME的方式，都没问题，但是，最后一次使用了CentOS7精简版的，还是使用自己配置JAVA_HOME的方式，发现cloudera-manager-server启动不成功<br>通过<code>journalctl -u cloudera-manager-server</code>以及<code>journalctl -xe</code>来查看启动日志，发现，报找不到java。但是java安装没有问题<br>最后使用了yum安装了jdk问题解决了</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yum install -y oracle-j2sdk1.8-1.8.0+update181-1.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="clouder-server-与agent安装"><a href="#clouder-server-与agent安装" class="headerlink" title="clouder server 与agent安装"></a>clouder server 与agent安装</h3><h4 id="安装cm6相关依赖（所有节点）"><a href="#安装cm6相关依赖（所有节点）" class="headerlink" title="安装cm6相关依赖（所有节点）"></a>安装cm6相关依赖（所有节点）</h4><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum -y install chkconfig python bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse fuse-libs redhat-lsb httpd mod_ssl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="安装Cloudera-Manager-Server"><a href="#安装Cloudera-Manager-Server" class="headerlink" title="安装Cloudera Manager Server"></a>安装Cloudera Manager Server</h4><p>这一步只需要在CM Server节点上操作。<br>执行下面的命令：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 安装openjdk8
yum install oracle-j2sdk1.8   ##这里不知道需不需要安装，因为我本机已经安装了java了。这里先不安装，如果报错再重来
# 安装 cm manager(只需在server节点安装)
yum install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="配置本地Parcel存储库"><a href="#配置本地Parcel存储库" class="headerlink" title="配置本地Parcel存储库"></a>配置本地Parcel存储库</h3><p>Cloudera Manager Server安装完成后，进入到本地Parcel存储库目录：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cd &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo  ## Cloudera Manager Server完成以后，该目录就已经生成了<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>将第一部分下载的CDH parcels文件上传至该目录下，然后执行修改sha文件：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">mv &#x2F;data6&#x2F;upload&#x2F;parcels&#x2F;* &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F;
mv CDH-6.3.0-1.cdh6.3.0.p0.1279813-el7.parcel.sha1 CDH-6.3.0-1.cdh6.3.0.p0.1279813-el7.parcel.sha<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="配置mysql-jdbc驱动"><a href="#配置mysql-jdbc驱动" class="headerlink" title="配置mysql jdbc驱动"></a>配置mysql jdbc驱动</h3><p>从前面下载好的mysql-connector-java-5.1.47.tar.gz包中解压出mysql-connector-java-5.1.47-bin.jar文件，将mysql-connector-java-5.1.47-bin.jar文件上传至CM Server节点上的/usr/share/java/目录下并重命名为mysql-connector-java.jar（如果/usr/share/java/目录不存在，需要手动创建）：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cd &#x2F;usr&#x2F;share&#x2F;java  &amp;&amp; mv &#x2F;home&#x2F;golden&#x2F;mysql-connector-java-5.1.47.jar .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="创建CDH所需要的数据库"><a href="#创建CDH所需要的数据库" class="headerlink" title="创建CDH所需要的数据库"></a>创建CDH所需要的数据库</h3><p>根据所需要安装的服务参照下表创建对应的数据库以及数据库用户，数据库必须使用utf8编码，创建数据库时要记录好用户名及对应密码：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- scm</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> scm <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> scm<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'scm'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'scm'</span><span class="token punctuation">;</span>

<span class="token comment">-- amon</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> amon <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> amon<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'amon'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'amon'</span><span class="token punctuation">;</span>

<span class="token comment">-- rman</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> rman <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> rman<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'rman'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'rman'</span><span class="token punctuation">;</span>

<span class="token comment">-- hue</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> hue <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span> 
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> hue<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hue'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'hue'</span><span class="token punctuation">;</span>

<span class="token comment">-- hive</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> metastore <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> metastore<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hive'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'hive'</span><span class="token punctuation">;</span>

<span class="token comment">-- sentry</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> sentry <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>   
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> sentry<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'sentry'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'sentry'</span><span class="token punctuation">;</span>

<span class="token comment">-- nav</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> nav <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>      
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> nav<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'nav'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'nav'</span><span class="token punctuation">;</span>

<span class="token comment">-- navms</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> navms <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> navms<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'navms'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'navms'</span><span class="token punctuation">;</span>

<span class="token comment">-- oozie</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> oozie <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> oozie<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'oozie'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'oozie'</span><span class="token punctuation">;</span>

<span class="token comment">-- hive</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> hive <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> hive<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hive'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'hive'</span><span class="token punctuation">;</span>
<span class="token comment">-- flush</span>
FLUSH <span class="token keyword">PRIVILEGES</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="设置Cloudera-Manager-数据库"><a href="#设置Cloudera-Manager-数据库" class="headerlink" title="设置Cloudera Manager 数据库"></a>设置Cloudera Manager 数据库</h3><p>Cloudera Manager Server包含一个配置数据库的脚本。</p>
<ul>
<li>mysql数据库与CM Server是同一台主机<br>执行命令：<code>/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm</code></li>
<li>mysql数据库与CM Server不在同一台主机上<br>执行命令：<code>/opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h &lt;mysql-host-ip&gt; --scm-host &lt;cm-server-ip&gt; scm scm</code><br>执行如下命令：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&#x2F;opt&#x2F;cloudera&#x2F;cm&#x2F;schema&#x2F;scm_prepare_database.sh mysql -uroot -h golden-02 -p&#39;Gjc123!@#&#39; --scm-host golden-01 scm scm scm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里卡了很久，报了如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ERROR Exception when creating&#x2F;dropping database with user &#39;root&#39; and jdbc url &#39;jdbc:mysql:&#x2F;&#x2F;golden-02&#x2F;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&#39;
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet successfully received from the server was 202 milliseconds ago.  The last packet sent successfully to the server was 197 milliseconds ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)[:1.8.0_321]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)[:1.8.0_321]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)[:1.8.0_321]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)[:1.8.0_321]
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
找了很久的问题，首先是安装的mysql不支持远程连接，需要做如下配置：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">grant</span> <span class="token keyword">all</span> <span class="token keyword">privileges</span> <span class="token keyword">on</span> <span class="token operator">*</span><span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">to</span> root<span class="token variable">@'%'</span> identified <span class="token keyword">by</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">;</span>
flush <span class="token keyword">privileges</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
配置了以后，还是报错，找了很久，最终找到原因，是因为下载的<code>mysql-connector-java-5.1.47-bin.jar</code>有问题，重新下载了一个，问题解决</li>
</ul>
<h3 id="安装CDH节点"><a href="#安装CDH节点" class="headerlink" title="安装CDH节点"></a>安装CDH节点</h3><h4 id="启动Cloudera-Manager-Server服务"><a href="#启动Cloudera-Manager-Server服务" class="headerlink" title="启动Cloudera Manager Server服务"></a>启动Cloudera Manager Server服务</h4><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">systemctl start cloudera-scm-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>然后等待Cloudera Manager Server启动，可能需要稍等一会儿，可以通过命令<code>tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</code>去监控服务启动状态。<br>当看到<code>INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server.</code>日志打印出来后，说明服务启动成功，可以通过浏览器访问<code>Cloudera Manager WEB</code>界面了。</p>
<h4 id="访问Cloudera-Manager-WEB界面"><a href="#访问Cloudera-Manager-WEB界面" class="headerlink" title="访问Cloudera Manager WEB界面"></a>访问Cloudera Manager WEB界面</h4><ul>
<li>打开浏览器，访问地址：http://<server_host>:7180，默认账号和密码都为admin：</li>
<li>首先是Cloudera Manager的欢迎页面，点击页面右下角的【继续】按钮进行下一步</li>
<li>勾选接受条款，点击【继续】进行下一步：</li>
<li>版本选择,这里我就选择免费版了：</li>
<li>选择版本以后会出现第二个欢迎界面，不过这个是安装集群的欢迎页：</li>
<li>选择主机,这一步是要搜索并选择用于安装CDH集群的主机，在主机名称后面的输入框中输入各个节点的hostname，中间使用英文逗号分隔开，然后点击搜索，在结果列表中勾选要安装CDH的节点即可：<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E9%85%8D%E7%BD%AE%E4%B8%BB%E6%9C%BA.png" alt="CM离线安装_配置主机"></li>
<li>指定存储库<code>Cloudera Manager Agent</code>这里选择自定义，填写上面使用httpd搭建好的Cloudera Manager YUM 库URL：</li>
<li>CDH and other software 如果我们之前的【配置本地Parcel存储库】步骤操作无误的话，这里会自动选择【使用Parcel】，并加载出CDH版本，但是这里一直没有识别出来，还报了如下错误：<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E8%AF%86%E5%88%AB%E4%B8%8D%E5%88%B0parcel-repo.png" alt="CM离线安装_识别不到parcel-repo"><br>找到问题原因：是因为parcel文件的<code>.sha1</code>需要改成<code>.sha</code>，修改完以后，就能识别出来了<br>这里一开始还跟着教程先用yum安装了<code>cloudera-manager-agent</code>，安装完了更报错，这里不要安装<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E6%AD%A3%E5%B8%B8%E8%AF%86%E5%88%AB%E5%88%B0parcel-repo.png" alt="CM离线安装_正常识别到parcel-repo"></li>
<li>JDK安装选项，这里jdk已经安装了，不要勾选</li>
<li>SSH登录配置，用于配置集群主机之间的SSH登录，填写root用户的密码，根据集群配置填写合适的【同时安装数量】值即可：<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E6%8F%90%E4%BE%9BSSH%E7%99%BB%E5%BD%95%E5%87%AD%E6%8D%AE.png" alt="CM离线安装_提供SSH登录凭据"></li>
<li>安装Agent</li>
<li>安装Parcels</li>
<li>主机检查，<code>Inspect Network Performance </code>和<code>Inspect Network Performance</code>需要点击的，一开始以为是自动检查，一直等着<br>然后标黄了几个选项：<br>Cloudera 建议将 /proc/sys/vm/swappiness 设置为最大值 10。当前设置为 30。使用 sysctl 命令在运行时更改该设置并编辑 /etc/sysctl.conf，以在重启后保存该设置。您可以继续进行安装，但 Cloudera Manager 可能会报告您的主机由于交换而运行状况不良。<br>已启用透明大页面压缩，可能会导致重大性能问题。请运行echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag和echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled以禁用此设置，然后将同一命令添加到 /etc/rc.local 等初始化脚本中，以便在系统重启时予以设置。<br>安装上面的提示执行即可；<br>但是有一点，报找不到java，这个有点不知道怎么解决了，这里先跳过了，点击<code>I understand this risks</code></li>
</ul>
<h3 id="安装CDH集群"><a href="#安装CDH集群" class="headerlink" title="安装CDH集群"></a>安装CDH集群</h3><h4 id="选择服务类型"><a href="#选择服务类型" class="headerlink" title="选择服务类型"></a>选择服务类型</h4><p>这里我选择自定义服务，然后选择很多组件，hdfs、zk、yarn、hbase、kafka等等</p>
<h4 id="角色分配"><a href="#角色分配" class="headerlink" title="角色分配"></a>角色分配</h4><p>这里会有默认设置，然后把需要手动设置的手动设置一下，点击继续</p>
<h4 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h4><p>这里根据要求设置即可<br>后面的步骤就没有什么问题了，可以参考下面的两篇文章。</p>
<p>这里参考了<br><a href="https://segmentfault.com/a/1190000021809645">CentOS7 Cloudera Manager6 完全离线安装 CDH6 集群</a><br><a href="https://blog.csdn.net/weixin_45682234/article/details/105844209">cdh6.2离线安装（傻瓜式安装教程）</a></p>
<h2 id="CDH日志清理"><a href="#CDH日志清理" class="headerlink" title="CDH日志清理"></a>CDH日志清理</h2><p>随着CM运行的时间越来越长，它所产生的日志文件也越来越大，需要定期去清理这些日志文件<br>在网上找了一个博客，用了他的自动化脚本，然后CM的监控页面都出问题了，无语了<br>以下是脚本：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;bin&#x2F;bash

# 清理日志
cd &#x2F;var&#x2F;log&#x2F;hadoop-mapreduce
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;hadoop-hdfs
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;zookeeper
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;hive
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;cloudera-scm-agent
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;audit
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;hadoop-yarn
rm -rf *.out.* 
rm -rf *.log.*

cd &#x2F;var&#x2F;log&#x2F;hue-httpd
rm -rf *.out.* 
rm -rf *.log.*

# 清理监控日志
cd &#x2F;var&#x2F;lib&#x2F;cloudera-host-monitor&#x2F;ts&#x2F;type&#x2F;partitions
rm -rf type*
cd &#x2F;var&#x2F;lib&#x2F;cloudera-host-monitor&#x2F;ts&#x2F;stream&#x2F;partitions
rm -rf stream*
cd &#x2F;var&#x2F;lib&#x2F;cloudera-host-monitor&#x2F;ts&#x2F;ts_stream_rollup_PT600S&#x2F;partitions&#x2F;
rm -rf ts_stream*
cd &#x2F;var&#x2F;lib&#x2F;cloudera-host-monitor&#x2F;ts&#x2F;ts_type_rollup_PT600S&#x2F;partitions&#x2F;
rm -rf ts_type*

cd &#x2F;var&#x2F;lib&#x2F;cloudera-service-monitor&#x2F;ts&#x2F;stream&#x2F;partitions&#x2F;
rm -rf stream*
cd &#x2F;var&#x2F;lib&#x2F;cloudera-service-monitor&#x2F;ts&#x2F;type&#x2F;partitions&#x2F;
rm -rf type*
cd &#x2F;var&#x2F;lib&#x2F;cloudera-service-monitor&#x2F;ts&#x2F;ts_stream_rollup_PT600S&#x2F;partitions&#x2F;
rm -rf ts_stream*
cd &#x2F;var&#x2F;lib&#x2F;cloudera-service-monitor&#x2F;ts&#x2F;ts_type_rollup_PT600S&#x2F;partitions&#x2F;
rm -rf ts_type*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>执行完成之后，监控页面如下图：<br><img src="/uploads/202203/CM%E7%9B%91%E6%8E%A7%E9%A1%B5%E9%9D%A2%E6%95%85%E9%9A%9C.png" alt="CM监控页面故障"></p>
<p>解决办法：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mv cloudera-host-monitor&#x2F; cloudera-host-monitor_BAK
mv  cloudera-service-monitor  cloudera-service-monitor_BAK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>然后重启Cloudera Management Service，然后就不报错了，但是，都是无数据了，也好理解，都删除了嘛<br><img src="/uploads/202203/CM%E7%9B%91%E6%8E%A7%E9%A1%B5%E9%9D%A2%E6%97%A0%E6%95%B0%E6%8D%AE.png" alt="CM监控页面无数据"><br>等待了一会，页面现实正常：<br><img src="/uploads/202203/CM%E7%9B%91%E6%8E%A7%E9%A1%B5%E9%9D%A2%E6%81%A2%E5%A4%8D%E6%AD%A3%E5%B8%B8.png" alt="CM监控页面恢复正常"></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>CM</category>
      </categories>
      <tags>
        <tag>CM</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker学习笔记</title>
    <url>/2022/03/30/Docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Mac下Docker安装</li>
<li>Docker常用命令</li>
</ul>
<a id="more"></a>

<h2 id="Mac下Docker安装"><a href="#Mac下Docker安装" class="headerlink" title="Mac下Docker安装"></a>Mac下Docker安装</h2><p>安装docker很简单，直接到官网下载即可：<br><a href="https://docs.docker.com/desktop/mac/install/">Docker下载地址</a><br>然后使用dmg包安装即可</p>
<h2 id="Docker常用命令"><a href="#Docker常用命令" class="headerlink" title="Docker常用命令"></a>Docker常用命令</h2><ol>
<li>启动任务<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker run -e MKL_SERVICE_FORCE_INTEL&#x3D;1 -p 47334:47334 -p 47335:47335 mindsdb&#x2F;mindsdb<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>停止任务<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 查看容器ID
docker ps | grep mindsdb
#c6d6476faa30        mindsdb&#x2F;mindsdb     &quot;&#x2F;bin&#x2F;sh -c &#39;bash ...&quot;   39 minutes ago      Up 39 minutes       0.0.0.0:47334-47335-&gt;47334-47335&#x2F;tcp, 47336&#x2F;tcp   jovial_lovelace
docker stop c6d6476faa30<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>删除image<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 查看images
docker images
#REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
#docker.io&#x2F;mindsdb&#x2F;mindsdb   latest              2df288cf59e0        8 days ago          11.6 GB
docker rmi 2df288cf59e0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>上传/下载文件到容器<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 上传文件
docker cp &#x2F;home&#x2F;temp.txt c6d6476faa30:&#x2F;data&#x2F;  #表示上传主机目录为 &#x2F;home&#x2F;temp.txt 的文件到 redis 容器的 &#x2F;data&#x2F; 路径下
## 下载文件
docker cp c6d6476faa30:&#x2F;data&#x2F;temp.txt &#x2F;home&#x2F;  #表示下载 redis 容器中路径为 &#x2F;data&#x2F;temp.txt 的文件到主键目录 &#x2F;home&#x2F; 中<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>进入容器中执行命令<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker exec -it c6d6476faa30 &#x2F;bin&#x2F;bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




</li>
</ol>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch学习笔记</title>
    <url>/2021/06/25/Elasticsearch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Elasticsearch简介</li>
</ul>
<a id="more"></a>


<h2 id="Elasticsearch简介"><a href="#Elasticsearch简介" class="headerlink" title="Elasticsearch简介"></a>Elasticsearch简介</h2><p>Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎，有以下几个特点：</p>
<ul>
<li>一个分布式的实时文档存储，每个字段都可被索引</li>
<li>一个分布式实时搜索引擎</li>
<li>强大的横向扩展能力，并支持大数据集的结构化/非结构化数据</li>
<li>Elasticsearch是<code>面向文档</code>的，意味着它存储整个对象或文档(使用<code>JSON</code>作为文档的序列化格式)</li>
</ul>
<p>Elasticsearch 是一个开源的搜索引擎，建立在一个全文搜索引擎库 Apache Lucene™ 基础之上。 Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库—​无论是开源还是私有。</p>
<p>Elasticsearch的安装很简单，直接解压就行，访问使用restAPI，也可以使用kibana<br>kibana的安装也很简单，直接解压，配置一下ES的相关属性就可以<br>安装好后，访问<code>http://localhost:5601/</code>即可使用kibana操作ES</p>
<h2 id="Elasticsearch使用"><a href="#Elasticsearch使用" class="headerlink" title="Elasticsearch使用"></a>Elasticsearch使用</h2><h3 id="直接通过Curl操作ES"><a href="#直接通过Curl操作ES" class="headerlink" title="直接通过Curl操作ES"></a>直接通过Curl操作ES</h3><p>这种方式，是直接使用 RESTful API 通过端口 9200 和 Elasticsearch 进行通信，不过不太常用，一般都是通过kibana来操作ES</p>
<ul>
<li>操作索引<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 创建一个名称为 alibaba 的 Index（索引库）
curl -X PUT localhost:9200&#x2F;alibaba
# 删除索引
curl -X DELETE localhost:9200&#x2F;alibaba
# 列出每个 Index 包含的 Type
curl &quot;localhost:9200&#x2F;_mapping?pretty&#x3D;true&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>操作Document 文档</li>
<li><ul>
<li>新增文档<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 在 alibaba&#x2F;user 中，新增一条记录（文档），记录的 id 为 1
curl -X PUT localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1 -d &#123;\&quot;name\&quot;:\&quot;rose\&quot;&#125;
#  或者
curl -X PUT localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1 -H &quot;Content-Type: application&#x2F;json&quot; -d &#123;\&quot;name\&quot;:\&quot;rose\&quot;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
上述示例中，alibaba 代表 Index，user 代表 Type，如果它们不存在，会自动创建。1 代表记录的 id。<br>新增记录时，也可以不指定 id，这时服务器会自动生成一个随机字符串作为该记录的 id。</li>
</ul>
</li>
</ul>
<p>** 查看记录</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">
# 查看 alibaba&#x2F;user&#x2F;1 记录
curl localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1
# 查看 alibaba&#x2F;user&#x2F;1 记录（会对结果进行格式化）
curl localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1?pretty
# 查看 alibaba&#x2F;user 中的所有记录
curl localhost:9200&#x2F;alibaba&#x2F;user&#x2F;_search<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>?pretty 表示对返回结果进行格式化，以便更易于阅读。</p>
<p>** 删除记录</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">curl -X DELETE localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1?pretty<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="通过kibana操作ES"><a href="#通过kibana操作ES" class="headerlink" title="通过kibana操作ES"></a>通过kibana操作ES</h3><p>kibana的访问地址：<a href="http://localhost:5601/">http://localhost:5601/</a><br>在kibana侧边栏找到Management -&gt; Dev Tool ,在Dev Tool里就可以操作ES了</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Filco圣手二代双模蓝牙机械键盘的连接方法</title>
    <url>/2021/01/18/Filco%E5%9C%A3%E6%89%8B%E4%BA%8C%E4%BB%A3%E5%8F%8C%E6%A8%A1%E8%93%9D%E7%89%99%E6%9C%BA%E6%A2%B0%E9%94%AE%E7%9B%98%E7%9A%84%E8%BF%9E%E6%8E%A5%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="常规方法"><a href="#常规方法" class="headerlink" title="常规方法"></a>常规方法</h2><ol>
<li>确认键盘的电源接通。 </li>
<li>同时按下「Ctrl」+「Alt」+「Fn」执行装置切换模式。配对LED灯（蓝）和低电量显示LED灯（红）约同时亮10秒左右。</li>
<li>想移除已登录的装置时，请从「蓝牙装置登录／切换键」①～④按下任一键</li>
</ol>
<h2 id="新添加的电脑"><a href="#新添加的电脑" class="headerlink" title="新添加的电脑"></a>新添加的电脑</h2><p>如果是新添加的电脑，会在首次配置的时候输入验证码，这时候，需要快速在键盘上按下验证码，输入后就可正常连接了<br>注意，如果失败的次数过多，那么就会提示输入PIN码</p>
<h2 id="输入PIN码的方式（亲测可用）"><a href="#输入PIN码的方式（亲测可用）" class="headerlink" title="输入PIN码的方式（亲测可用）"></a>输入PIN码的方式（亲测可用）</h2><ol>
<li>当你要连接蓝牙键盘的时电脑端出现输入PIN</li>
<li>此时先在本机键盘上输入任意六位PIN</li>
<li>接下来电脑开始验证时，迅速在你的蓝牙设备上输入刚才的六位PIN，然后回车，成功！</li>
</ol>
<h2 id="想要清楚以前绑定的设备（亲测可用）"><a href="#想要清楚以前绑定的设备（亲测可用）" class="headerlink" title="想要清楚以前绑定的设备（亲测可用）"></a>想要清楚以前绑定的设备（亲测可用）</h2><p>如果被绑定的①～④有某个想重新绑定新的电脑，可以按如下步骤：</p>
<ol>
<li>同时按下crtl+alt+Fn，红蓝灯闪烁4秒。</li>
<li>键盘背面的清除键，拿笔点住2秒。</li>
<li>再按数字键1-4的任意一个想清除配置的数字。</li>
<li>然后从想连接的设备蓝牙列表中选择键盘，点击连接。</li>
<li>该设备屏幕出现4或6位的配对码。在键盘上依次按下配对码，回车。OK，该设备与filco蓝牙键盘连接成功。</li>
</ol>
<p>这里只是为了记录一下，省的下次还要继续查度娘</p>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
  </entry>
  <entry>
    <title>FlinkCDC原理</title>
    <url>/2022/03/23/FlinkCDC%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>FlinkCDC概述</li>
</ul>
<a id="more"></a>


<h2 id="FlinkCDC概述"><a href="#FlinkCDC概述" class="headerlink" title="FlinkCDC概述"></a>FlinkCDC概述</h2><p>支持 currentFetchEventTimeLag，currentEmitEventTimeLag，sourceIdleTime 监控指标<br>这些指标遵循 FLIP-33 [1] 的连接器指标规范，可以查看 FLIP-33 获取每个指标的含义。其中，<br>currentEmitEventTimeLag 指标记录的是 Source 发送一条记录到下游节点的时间点和该记录<br>在 DB 里产生时间点差值，用于衡量数据从 DB 产生到离开 Source 节点的延迟。用户可以通<br>过该指标判断 source 是否进入了 binlog 读取阶段：</p>
<ul>
<li>即当该指标为 0 时，代表还在全量历史读取阶段；</li>
<li>当大于 0 时，则代表进入了 binlog 读取阶段。</li>
</ul>
]]></content>
      <categories>
        <category>Flink</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（二）</title>
    <url>/2021/01/29/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink任务案例</li>
<li>Flink的slot和并行度理解<a id="more"></a>
<h2 id="Flink任务案例"><a href="#Flink任务案例" class="headerlink" title="Flink任务案例"></a>Flink任务案例</h2><h3 id="Flink消费Kafka-自定义KafkaDeserializationSchema"><a href="#Flink消费Kafka-自定义KafkaDeserializationSchema" class="headerlink" title="Flink消费Kafka:自定义KafkaDeserializationSchema"></a>Flink消费Kafka:自定义KafkaDeserializationSchema</h3>Flink已经定义好的反序列化shema:</li>
<li>SimpleStringSchema：返回的结果只有Kafka的value，没有其它信息：</li>
<li>TypeInformationKeyValueSerializationSchema：返回的结果只有Kafka的key,value，没有其它信息</li>
</ul>
<p>如果需要获得Kafka的topic或者其它信息，就需要通过实现KafkaDeserializationSchema接口来自定义返回数据的结构</p>
<ul>
<li>自定义KafkaDeserializationSchema：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">TypeHint</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">TypeInformation</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">KafkaDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span></span><span class="token class-name">Charset</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyKafkaDeserializationSchema</span> <span class="token keyword">implements</span> <span class="token class-name">KafkaDeserializationSchema</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Charset</span> UTF_8 <span class="token operator">=</span> <span class="token class-name">Charset</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span><span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isEndOfStream</span><span class="token punctuation">(</span><span class="token class-name">String</span> nextElement<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">deserialize</span><span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token operator">&lt;</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">></span> consumerRecord<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">String</span> value <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>consumerRecord<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> UTF_8<span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">long</span> offset <span class="token operator">=</span> consumerRecord<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">int</span> partition <span class="token operator">=</span> consumerRecord<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%s,%s,%s"</span><span class="token punctuation">,</span>value<span class="token punctuation">,</span>offset<span class="token punctuation">,</span>partition<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%s,%s,%s"</span><span class="token punctuation">,</span>value<span class="token punctuation">,</span>offset<span class="token punctuation">,</span>partition<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">TypeInformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token function">getProducedType</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token class-name">TypeInformation</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TypeHint</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//return null; //会报错</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
如果不重写，会报如下错误：<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">Exception in thread &quot;main&quot; org.apache.flink.api.common.functions.InvalidTypesException: The return type of function &#39;Custom Source&#39; could not be determined automatically, due to type erasure. You can give type information hints by using the returns(...) method on the result of the transformation call, or by letting your function implement the &#39;ResultTypeQueryable&#39; interface.
	at org.apache.flink.api.dag.Transformation.getOutputType(Transformation.java:479)
	at org.apache.flink.streaming.api.datastream.DataStream.getType(DataStream.java:193)
	at org.apache.flink.streaming.api.datastream.DataStream.flatMap(DataStream.java:613)
	at com.hzw.bigdata.flinkstudy.FlinkConsumerKafka.main(FlinkConsumerKafka.java:60)
Caused by: org.apache.flink.api.common.functions.InvalidTypesException: Type of TypeVariable &#39;OUT&#39; in &#39;interface org.apache.flink.streaming.api.functions.source.ParallelSourceFunction&#39; could not be determined. This is most likely a type erasure problem. The type extraction currently supports types with generic variables only in cases where all variables in the return type can be deduced from the input type(s). Otherwise the type has to be specified explicitly using type information.
	at org.apache.flink.api.java.typeutils.TypeExtractor.createTypeInfoWithTypeHierarchy(TypeExtractor.java:923)
	at org.apache.flink.api.java.typeutils.TypeExtractor.privateCreateTypeInfo(TypeExtractor.java:828)
	at org.apache.flink.api.java.typeutils.TypeExtractor.createTypeInfo(TypeExtractor.java:787)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getTypeInfo(StreamExecutionEnvironment.java:2287)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1681)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1668)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1637)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1623)
	at com.hzw.bigdata.flinkstudy.FlinkConsumerKafka.main(FlinkConsumerKafka.java:58)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>主类调用：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">Types</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">TimeCharacteristic</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer011</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Kafka参数</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">MyKafkaDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        consumer<span class="token punctuation">.</span><span class="token function">setStartFromEarliest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> wordCount <span class="token operator">=</span> stream
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
                    collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>INT<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>key <span class="token operator">-></span> key<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>key <span class="token operator">-></span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>f0 <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> key<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        wordCount<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka streaming word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
具体的可以参考<br><a href="https://my.oschina.net/u/2380815/blog/4453531">Flink实战：自定义KafkaDeserializationSchema(Java/Scala)</a></li>
</ul>
<h2 id="Flink的slot和并行度理解"><a href="#Flink的slot和并行度理解" class="headerlink" title="Flink的slot和并行度理解"></a>Flink的slot和并行度理解</h2><h3 id="Flink的Slot是什么？和Spark的Excutor有什么区别？"><a href="#Flink的Slot是什么？和Spark的Excutor有什么区别？" class="headerlink" title="Flink的Slot是什么？和Spark的Excutor有什么区别？"></a>Flink的Slot是什么？和Spark的Excutor有什么区别？</h3><h3 id="Slot和并行度之间有什么关系？"><a href="#Slot和并行度之间有什么关系？" class="headerlink" title="Slot和并行度之间有什么关系？"></a>Slot和并行度之间有什么关系？</h3><p>是每个slot都有几个并行度，还是说，并行度是整体任务的并行度，和每个slot没什么关系？</p>
<h3 id="假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据"><a href="#假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据" class="headerlink" title="假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据"></a>假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据</h3>]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（四）</title>
    <url>/2021/08/12/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink时间语义与窗口<a id="more"></a>


</li>
</ul>
<h2 id="Flink时间语义与Watermark"><a href="#Flink时间语义与Watermark" class="headerlink" title="Flink时间语义与Watermark"></a>Flink时间语义与Watermark</h2><p>Event Time：事件创建的时间<br>Ingestion Time：数据进入Flink的时间<br>Processing Time：执行操作算子的本地系统时间，与机器相关</p>
<p>WaterMark是用来处理乱序数据的</p>
<ul>
<li>Watermark是一种衡量Event Time进展的机制们可以设定延迟触发</li>
<li>Watermark是用于处理乱序事件的吗，而正确的处理乱序事件，通常用Watermark机制集合window来实现</li>
<li>数据流重的Watermark用于表示timesamp小于Watermark的数据，都已经到达了，因此，window的执行也是由Watermark触发的</li>
<li>Watermark用来让程序自己平衡延迟和结果正确性</li>
</ul>
<h3 id="Watermark的特点："><a href="#Watermark的特点：" class="headerlink" title="Watermark的特点："></a>Watermark的特点：</h3><ul>
<li>Watermark是一条特殊的数据记录</li>
<li>Watermark必须单调递增，以确保任务的事件事件始终在向前推进，而不是在后退</li>
<li>Watermark与数据的时间戳相关</li>
</ul>
<blockquote>
<p>每条数据都会计算出一个watermark，每个watermark都会和之前的watermark做比较，取更大的一个，确保watermark是向前推进的<br>多个分区的watermark，会取当前window下，所有分区重最小的一个，为了防止数据丢失<br>每个watermark都会和window的结束时间（window.getEnd()）做比较，如果时间大于等于window结束时间，window就会被触发，处理的数据会小于window结束时间的，等于window结束时间的会放到下一个window<br>程序运行以后，会一直获取Watermark（执行getCurrentWatermark()函数），不管有没有数据进来</p>
</blockquote>
<p>具体的可以看之前写的demo<br><a href="https://github.com/gujincheng/FlinkStudy/blob/main/src/main/java/com/hzw/bigdata/flinkstudy/WaterMarkDemo.java">WaterMarkDemo</a></p>
<p>当Flink 用来跟踪事件时间进度的水印已经超过了元素所属窗口的结束时间戳时，<br>即数据延迟的时候，默认情况下，数据会丢失，为了防止这种情况可以使用以下两种方式来避免：</p>
<ul>
<li>可以通过设置allowedLateness来避免<blockquote>
<p>当数据晚于Watermark后，为了防止数据丢失，可以通过设置allowedLateness来避免，<br>Allowed lateness 指定元素在被丢弃之前可以延迟多长时间，其默认值为 0。</p>
</blockquote>
</li>
<li>获取延迟数据作为副输出（把延迟的数据放到另外一个流单独处理）<br>具体可以参考<br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#allowed-lateness">Flink官网-Allowed Lateness</a></li>
</ul>
<h2 id="Flink窗口"><a href="#Flink窗口" class="headerlink" title="Flink窗口"></a>Flink窗口</h2><p>一般真实的数据流都是无界的，但是window可以把无限的数据流切分，得到有限的数据集进行处理<br>window就是将无限流切割为有限流的一种方式，它会将流数据分发到有限大小的桶重进行分析</p>
<p>窗口化的Flink程序的一般结构如下，第一个代码段中是分组的流，而第二段是非分组的流。正如我们所见，唯一的区别是分组的<code>stream</code>调用<code>keyBy(…)</code>和<code>window(…)</code>，而非分组的<code>stream</code>中<code>window()</code>换成了<code>windowAll(…)</code>，这些也将贯穿都这一页的其他部分中。</p>
<h3 id="Keyed-Windows"><a href="#Keyed-Windows" class="headerlink" title="Keyed Windows"></a>Keyed Windows</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">stream
       <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>               <span class="token operator">&lt;</span><span class="token operator">-</span>  keyed versus non<span class="token operator">-</span>keyed windows
       <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>              <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"assigner"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">trigger</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"trigger"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> <span class="token keyword">default</span> trigger<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">evictor</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"evictor"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no evictor<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">allowedLateness</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"lateness"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> zero<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">sideOutputLateData</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no side output <span class="token keyword">for</span> late data<span class="token punctuation">)</span>
       <span class="token punctuation">.</span>reduce<span class="token operator">/</span>aggregate<span class="token operator">/</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"function"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Non-Keyed-Windows"><a href="#Non-Keyed-Windows" class="headerlink" title="Non-Keyed Windows"></a>Non-Keyed Windows</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">stream
       <span class="token punctuation">.</span><span class="token function">windowAll</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>           <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"assigner"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">trigger</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"trigger"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> <span class="token keyword">default</span> trigger<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">evictor</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"evictor"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no evictor<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">allowedLateness</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"lateness"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> zero<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">sideOutputLateData</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no side output <span class="token keyword">for</span> late data<span class="token punctuation">)</span>
       <span class="token punctuation">.</span>reduce<span class="token operator">/</span>aggregate<span class="token operator">/</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"function"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>方括号[]内的命令是可选的</p>
<h3 id="WindowAssigner"><a href="#WindowAssigner" class="headerlink" title="WindowAssigner"></a>WindowAssigner</h3><p>WindowAssigner是负责将每一个到来的元素分配给一个或者多个窗口(window),Flink 提供了一些常用的预定义窗口分配器，即:滚动窗口、滑动窗口、会话窗口和全局窗口。<br>你也可以通过继承WindowAssigner类来自定义自己的窗口。所有的内置窗口分配器(除了全局窗口 global window)都是通过时间来分配元素到窗口中的，这个时间要么是处理的时间，要么是事件发生的时间</p>
<h3 id="window分类："><a href="#window分类：" class="headerlink" title="window分类："></a>window分类：</h3><ul>
<li>时间窗口（Time Window）<br>  ** 滚动时间窗口<br>  ** 滑动时间窗口<br>  ** 会话窗口</li>
<li>计数窗口（Count Window）<br>  ** 滚动计数窗口<br>  ** 滑动计数窗口<br>窗口是滚动还是滑动，是根据<code>WindowAssigner</code>来区分的<h4 id="滚动窗口（Tumbling-Windows）"><a href="#滚动窗口（Tumbling-Windows）" class="headerlink" title="滚动窗口（Tumbling Windows）"></a>滚动窗口（Tumbling Windows）</h4></li>
<li>将数据依据固定的窗口长度对数据进行切分</li>
<li>时间对其，窗口长度固定，没有重叠         <blockquote>
<p>TumblingEventTimeWindows,这个WindowAssigner必须要结合watermark使用，否则，window不会触发<br>TumblingProcessingTimeWindows，这个WindowAssigner不需要watermark</p>
</blockquote>
<h4 id="滑动窗口（Sliding-Windows）"><a href="#滑动窗口（Sliding-Windows）" class="headerlink" title="滑动窗口（Sliding Windows）"></a>滑动窗口（Sliding Windows）</h4></li>
<li>滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成</li>
<li>窗口长度固定，可以有重叠</li>
</ul>
<h4 id="会话窗口（Session-Windows）"><a href="#会话窗口（Session-Windows）" class="headerlink" title="会话窗口（Session Windows）"></a>会话窗口（Session Windows）</h4><ul>
<li>由一系列事件组合一个指定时间长度的timeout间隙组成，也就是一段时间没有接收到新数据就会生成新的窗口</li>
<li>特点：时间无对齐</li>
</ul>
<h3 id="window的生命周期"><a href="#window的生命周期" class="headerlink" title="window的生命周期"></a>window的生命周期</h3><p>当第一个应该属于该窗口的元素到达时，就会创建一个窗口，当时间（事件或处理时间）超过其结束时间戳加上用户指定的时间时，该窗口将被完全删除，<br>Flink 确保了只清除基于时间的window，其他类型的window不清除</p>
<p>此外，每个窗口都有一个触发器（请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#triggers">触发器</a>）和一个函数（ProcessWindowFunction、ReduceFunction 或 AggregateFunction）（请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#window-functions">窗口函数</a>）。<br>该函数将包含要应用于窗口内容的计算，而触发器指定窗口被认为准备好应用该函数的条件。触发策略可能类似于“当窗口中的元素数量超过 4 时”，或“当水印通过窗口末尾时”。<br>触发器还可以决定在创建和删除窗口之间的任何时间清除窗口的内容。在这种情况下，清除仅指窗口中的元素，而不是窗口元数据。这意味着新数据仍然可以添加到该窗口。<br>除了上述之外，您还可以指定一个 Evictor（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#evictors">Evictors</a>），它能够在触发器触发之后和之前从窗口中删除元素</p>
<h3 id="Window-Functions"><a href="#Window-Functions" class="headerlink" title="Window Functions"></a>Window Functions</h3><p>在定义了窗口分配器之后，我们需要指定我们想要在这些窗口中的每一个上执行的计算。这是窗口函数的职责，<br>它用于在系统确定窗口已准备好处理时处理每个（可能是键控的）窗口的元素。窗口函数可以是<code>ReduceFunction</code>、<code>AggregateFunction</code>或<code>ProcessWindowFunction</code>之一。<br>前两个可以更有效地执行（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#useful-state-size-considerations">状态大小</a>部分），因为 Flink 可以在每个窗口的元素到达时增量聚合它们。<br><code>ProcessWindowFunction</code>获取包含在窗口中的所有元素的<code>Iterable</code>以及有关元素所属窗口的附加元信息。<br>带有<code>ProcessWindowFunction</code>的窗口转换不能像其他情况一样有效地执行，因为 Flink 在调用函数之前必须在内部缓冲窗口的所有元素。<br>这可以通过将 <code>ProcessWindowFunction</code> 与 <code>ReduceFunction</code> 或 <code>AggregateFunction</code> 结合来获得窗口元素的增量聚合和 <code>ProcessWindowFunction</code> 接收的附加窗口元数据来缓解。</p>
<h4 id="ReduceFunction"><a href="#ReduceFunction" class="headerlink" title="ReduceFunction"></a>ReduceFunction</h4><p>ReduceFunction 指定如何组合来自输入的两个元素以生成相同类型的输出元素。 Flink 使用 ReduceFunction 来增量聚合窗口的元素。<br>ReduceFunction 有多种实现方式<br>第一种是直接窗口内聚合，不能对窗口外的数据做聚合，这个是最基本的reduce<br>第二种，先执行窗口内的聚合，然后，可以执行窗口外的，代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> <span class="token function">reduce</span><span class="token punctuation">(</span>
            <span class="token class-name">ReduceFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> reduceFunction<span class="token punctuation">,</span> <span class="token class-name">ProcessWindowFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">,</span> <span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">W</span><span class="token punctuation">></span></span> function<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">TypeInformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> resultType <span class="token operator">=</span>
                <span class="token function">getProcessWindowFunctionReturnType</span><span class="token punctuation">(</span>function<span class="token punctuation">,</span> input<span class="token punctuation">.</span><span class="token function">getType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> <span class="token function">reduce</span><span class="token punctuation">(</span>reduceFunction<span class="token punctuation">,</span> function<span class="token punctuation">,</span> resultType<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ReduceFunction 处理玩的结果，会当成输入写入到ProcessWindowFunction<br>这种适合处理，先用reduce预聚合，然后再通过ProcessWindowFunction整体聚合<br>AggregateFunction同样有这种功能，可能传入ProcessWindowFunction</p>
<h4 id="AggregateFunction"><a href="#AggregateFunction" class="headerlink" title="AggregateFunction"></a>AggregateFunction</h4><p>AggregateFunction 是 ReduceFunction 的通用版本，它具有三种类型：输入类型 (IN)、累加器类型 (ACC) 和输出类型 (OUT)。<br>输入类型是输入流中元素的类型，AggregateFunction 有一种方法可以将一个输入元素添加到累加器中。<br>该接口还具有用于创建初始累加器、将两个累加器合并为一个累加器以及从累加器中提取输出（OUT 类型）的方法。 我们将在下面的示例中看到它是如何工作的。<br>与 ReduceFunction 相同，Flink 将在窗口的输入元素到达时增量地聚合它们。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/**
 * The accumulator is used to keep a running sum and a count. The &#123;@code getResult&#125; method
 * computes the average.
 */</span>
<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">AverageAggregate</span>
    <span class="token keyword">implements</span> <span class="token class-name">AggregateFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Double</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>
  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> accumulator<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>accumulator<span class="token punctuation">.</span>f0 <span class="token operator">+</span> value<span class="token punctuation">.</span>f1<span class="token punctuation">,</span> accumulator<span class="token punctuation">.</span>f1 <span class="token operator">+</span> <span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Double</span> <span class="token function">getResult</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> accumulator<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span> accumulator<span class="token punctuation">.</span>f0<span class="token punctuation">)</span> <span class="token operator">/</span> accumulator<span class="token punctuation">.</span>f1<span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> <span class="token function">merge</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> a<span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> b<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>f0 <span class="token operator">+</span> b<span class="token punctuation">.</span>f0<span class="token punctuation">,</span> a<span class="token punctuation">.</span>f1 <span class="token operator">+</span> b<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

input
    <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>key selector<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>window assigner<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">AverageAggregate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>上面的示例计算窗口中元素的第二个字段的平均值。</p>
<h4 id="ProcessWindowFunction"><a href="#ProcessWindowFunction" class="headerlink" title="ProcessWindowFunction"></a>ProcessWindowFunction</h4><p>ProcessWindowFunction 获得一个包含窗口所有元素的 Iterable 和一个可以访问时间和状态信息的 Context 对象，这使其能够提供比其他窗口函数更大的灵活性。<br>这是以性能和资源消耗为代价的，因为元素不能增量聚合，而是需要在内部缓冲，直到窗口被认为准备好进行处理。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

input
  <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>t <span class="token operator">-></span> t<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingEventTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">minutes</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyProcessWindowFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* ... */</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyProcessWindowFunction</span> 
    <span class="token keyword">extends</span> <span class="token class-name">ProcessWindowFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span><span class="token class-name">String</span> key<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">long</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> in<span class="token operator">:</span> input<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      count<span class="token operator">++</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token string">"Window: "</span> <span class="token operator">+</span> context<span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"count: "</span> <span class="token operator">+</span> count<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>该示例显示了一个 ProcessWindowFunction，它对窗口中的元素进行计数。此外，窗口函数将有关窗口的信息添加到输出中。</p>
<blockquote>
<p>请注意，将 ProcessWindowFunction 用于简单的聚合（例如 count）是非常低效的<br>增量窗口聚合使用 AggregateFunction 或者 ReduceFunction同样可以达到相同的想过，并且，效率很高</p>
</blockquote>
<h4 id="WindowFunction-Legacy-：apply"><a href="#WindowFunction-Legacy-：apply" class="headerlink" title="WindowFunction (Legacy)：apply"></a>WindowFunction (Legacy)：apply</h4><p>在某些可以使用 ProcessWindowFunction 的地方，您也可以使用 WindowFunction。这是 ProcessWindowFunction 的旧版本，提供较少的上下文信息并且没有一些高级功能，例如每个窗口的键控状态。<br>此接口将在某些时候被弃用。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

input
    <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>key selector<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>window assigner<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyWindowFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="在-ProcessWindowFunction-中使用每个窗口状态"><a href="#在-ProcessWindowFunction-中使用每个窗口状态" class="headerlink" title="在 ProcessWindowFunction 中使用每个窗口状态"></a>在 ProcessWindowFunction 中使用每个窗口状态</h4><p>除了访问键控状态之外，ProcessWindowFunction 还可以使用键控状态，该键控状态的范围限定为函数当前正在处理的窗口。 在这种情况下，了解每个窗口状态所指的窗口是什么很重要。 涉及不同的“窗口”：</p>
<blockquote>
<p>这地方没看懂</p>
</blockquote>
<p>flink window相关内容，具体可以参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/">Flink Window</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink调优</title>
    <url>/2022/10/26/Flink%E8%B0%83%E4%BC%98/</url>
    <content><![CDATA[<h2 id="Checkpoint很慢，一直超时"><a href="#Checkpoint很慢，一直超时" class="headerlink" title="Checkpoint很慢，一直超时"></a>Checkpoint很慢，一直超时</h2><p>flink程序的Checkpoint一直超时失败<br><img src="/uploads/202206/checkpoint%E5%A4%B1%E8%B4%A5.png" alt="checkpoint失败"><br>taskmanager的日志打印以下日志：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">org.apache.flink.streaming.runtime.tasks.SubtaskCheckpointCoordinatorImpl [] - Time from receiving all checkpoint barriers&#x2F;RPC to executing it exceeded threshold: 135751ms<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>task 仅在接受到所有的 barrier 之后才会进行 snapshot，如果作业存在反压，或者有数据倾斜，则会导致全部的 channel 或者某些 channel 的 barrier 发送慢，从而整体影响 Checkpoint 的时间<br>具体可以参考<a href="https://blog.csdn.net/weixin_44904816/article/details/101062878">Flink Checkpoint 问题排查实用指南</a></p>
<p>通过查看<code>Flink WebUI</code>查看，确实存在反压，并且查看<code>taskmanagers</code>的各个并行度的消息消费情况，发现只有2哥并行度有数据消费，其他并行度没有数据。所以数据出现严重的数据倾斜<br>解决数据倾斜的方法是：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Alert</span><span class="token punctuation">></span></span> alertDS <span class="token operator">=</span> dataDS
                <span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>broadcastStream<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">DynamicKeyFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"DynamicKeyFunction"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">"Dynamic Partitioning Function"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>keyData <span class="token operator">-></span> <span class="token class-name">DigestUtils</span><span class="token punctuation">.</span><span class="token function">md5Hex</span><span class="token punctuation">(</span>keyData<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">random</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">10</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">connect</span><span class="token punctuation">(</span>broadcastStream<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">DynamicAlertFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">uid</span><span class="token punctuation">(</span><span class="token string">"DynamicAlertFunction"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">"Dynamic Rule Evaluation Function"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>把keyby的key打散即可</p>
<h2 id="Flink-1-13提交任务到yarn上没有tm和jm的日志"><a href="#Flink-1-13提交任务到yarn上没有tm和jm的日志" class="headerlink" title="Flink-1.13提交任务到yarn上没有tm和jm的日志"></a>Flink-1.13提交任务到yarn上没有tm和jm的日志</h2><p>这个是因为，flink-1.13提交任务到yarn上，并不会读取${FLINK_HOME}/lib下的jar，所以，log4j的依赖没有，这里有2个解决办法：</p>
<ol>
<li>把log4j的依赖打在maven项目里<pre class="line-numbers language-java" data-language="java"><code class="language-java">       <span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">></span></span>
<span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">></span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">></span></span>log4j<span class="token operator">-</span>slf4j<span class="token operator">-</span>impl<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">></span></span><span class="token number">2.17</span><span class="token number">.1</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>scope<span class="token punctuation">></span></span>compile<span class="token operator">&lt;</span><span class="token operator">/</span>scope<span class="token operator">></span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>

<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">></span></span>
<span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">></span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">></span></span>log4j<span class="token operator">-</span>api<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">></span></span><span class="token number">2.17</span><span class="token number">.1</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>scope<span class="token punctuation">></span></span>compile<span class="token operator">&lt;</span><span class="token operator">/</span>scope<span class="token operator">></span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>

<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">></span></span>
<span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">></span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">></span></span>log4j<span class="token operator">-</span>core<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">></span></span><span class="token number">2.17</span><span class="token number">.1</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>scope<span class="token punctuation">></span></span>compile<span class="token operator">&lt;</span><span class="token operator">/</span>scope<span class="token operator">></span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span>

<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">></span></span>
<span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span> API bridge between log4j <span class="token number">1</span> and <span class="token number">2</span><span class="token punctuation">;</span> included <span class="token keyword">for</span> convenience <span class="token operator">--</span><span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">></span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>log4j<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">></span></span>log4j<span class="token operator">-</span><span class="token number">1.2</span><span class="token operator">-</span>api<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">></span></span><span class="token number">2.17</span><span class="token number">.1</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span>
<span class="token generics"><span class="token punctuation">&lt;</span>scope<span class="token punctuation">></span></span>compile<span class="token operator">&lt;</span><span class="token operator">/</span>scope<span class="token operator">></span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>把log4j相关的依赖从maven项目里去掉，这时候flink-1.13会默认使用logback来处理日志</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink常见问题</title>
    <url>/2022/12/13/Flink%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink常见问题</li>
</ul>
<a id="more"></a>


<h2 id="Flink常见问题"><a href="#Flink常见问题" class="headerlink" title="Flink常见问题"></a>Flink常见问题</h2><h3 id="Flink-On-YARN中任务挂掉后，YARN的Web-UI显示还在运行，但实际上已经挂掉了"><a href="#Flink-On-YARN中任务挂掉后，YARN的Web-UI显示还在运行，但实际上已经挂掉了" class="headerlink" title="Flink On YARN中任务挂掉后，YARN的Web UI显示还在运行，但实际上已经挂掉了"></a>Flink On YARN中任务挂掉后，YARN的Web UI显示还在运行，但实际上已经挂掉了</h3><ul>
<li>原因：这是由于Flink提交给YARN之后，YARN后续并没有继续监控Flink任务的状态</li>
<li>解决办法：在提交任务时，命令行加一个参数 -d 即可，例如：run -m yarn-cluster  -d -p 2  -yn 2  -yjm 1024m -ytm 2048m  -ynm  xxxx -c xxxx</li>
</ul>
<h3 id="java-lang-Exception-Container-released-on-a-lost-node"><a href="#java-lang-Exception-Container-released-on-a-lost-node" class="headerlink" title="java.lang.Exception: Container released on a lost node"></a>java.lang.Exception: Container released on a <em>lost</em> node</h3><ul>
<li>原因：YARN队列压力过大或者磁盘满了之后，可能会导致Flink申请的节点标记为失败，导致taskmanager挂掉</li>
<li>解决办法：如果有配置重启策略的话，taskmanager会进行重启，如果没有配置重启策略但是配置了checkpoint，默认的重启策略是无限次重启，但是需要注意一点的是，taskmananger成功重启的前提是jobmanager没有挂掉，如果jobmanager也挂掉了，那么taskmanager重启成功之后也是无效的。</li>
</ul>
<h3 id="生产上的任务频繁挂掉"><a href="#生产上的任务频繁挂掉" class="headerlink" title="生产上的任务频繁挂掉"></a>生产上的任务频繁挂掉</h3><p>一开始以为是问题二导致的，但是实际上问题二配置了checkpoint或者重启策略之后会自己重启，所以证明主要原因并不是以上的问题，其实主要的原因就是当YARN的队列资源紧张的时候，也有可能导致jobmanager挂掉，我们生产上的集群并没有配置Flink On YARN的高可用，即jobmanager挂掉之后是不会进行重启的，所以需要配置Flink On YARN的高可用，配置如下（此配置适用于Flink On YARN的yarn-cluster模式）：</p>
<ol>
<li>首先配置 yarn-site.xml，配置resourcemanager重启次数<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.am.max-attempts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>
    The maximum number of application master execution attempts.
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>配置flink-conf.yaml ，这里必须添加zookeeper 信息，官方文档yarn-cluster模式只要求添加重启参数，不添加的话，task manager 会和job manager 一起挂掉， 只会重启对应的job manager<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># flink job manager次数  这个参数必须小于yarn.resourcemanager.am.max-attempts 
yarn.application-attempts: 3
# 添加zookeeper 配置
high-availability: zookeeper
high-availability.zookeeper.quorum: xx.x.x.xxx:2181
# job manager元数据在文件系统储存的位置
high-availability.storageDir: hdfs:&#x2F;&#x2F;&#x2F;flink&#x2F;recovery  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>此配置只能降低Flink的失败次数，如果想让Flink稳定运行，应该还是需要在YARN上单独划分一个队列给实时任务使用，避免因其他因素导致实时任务失败</p>
</blockquote>
</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flume使用笔记</title>
    <url>/2022/11/08/Flume%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flume简介</li>
<li>Flume采集kafka数据到hive</li>
</ul>
<a id="more"></a>


<h2 id="Flume简介"><a href="#Flume简介" class="headerlink" title="Flume简介"></a>Flume简介</h2><p>略过，网上一大堆</p>
<h2 id="Flume采集kafka数据到hive"><a href="#Flume采集kafka数据到hive" class="headerlink" title="Flume采集kafka数据到hive"></a>Flume采集kafka数据到hive</h2><h3 id="使用hive-sink"><a href="#使用hive-sink" class="headerlink" title="使用hive-sink"></a>使用hive-sink</h3><p>Flume采集kafka数据进入hive，在网上看到，Flume有原生的hive-sink，跟着网上的操作了一下，最终报错<br>操作步骤：</p>
<ol>
<li>把hive相关的jar放到flume下<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH&#x2F;lib&#x2F;flume-ng&#x2F;lib&#x2F;
ln -s ..&#x2F;..&#x2F;..&#x2F;jars&#x2F;hive-hcatalog-core-2.1.1-cdh6.2.0.jar hive-hcatalog-core-2.1.1-cdh6.2.0.jar
ln -s ..&#x2F;..&#x2F;..&#x2F;jars&#x2F;hive-hcatalog-pig-adapter-2.1.1-cdh6.2.0.jar hive-hcatalog-pig-adapter-2.1.1-cdh6.2.0.jar
ln -s ..&#x2F;..&#x2F;..&#x2F;jars&#x2F;hive-hcatalog-server-extensions-2.1.1-cdh6.2.0.jar hive-hcatalog-server-extensions-2.1.1-cdh6.2.0.jar
ln -s ..&#x2F;..&#x2F;..&#x2F;jars&#x2F;hive-hcatalog-streaming-2.1.1-cdh6.2.0.jar hive-hcatalog-streaming-2.1.1-cdh6.2.0.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>编写配置<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">a.sources&#x3D;source_from_kafka
a.channels&#x3D;mem_channel
a.sinks&#x3D;hive_sink
#kafka为souce的配置
a.sources.source_from_kafka.type&#x3D;org.apache.flume.source.kafka.KafkaSource
a.sources.source_from_kafka.batchSize&#x3D;10
a.sources.source_from_kafka.kafka.bootstrap.servers&#x3D;172.16.2.205:9092
a.sources.source_from_kafka.topic&#x3D;flume-mqtt
a.sources.source_from_kafka.channels&#x3D;mem_channel
a.sources.source_from_kafka.consumer.timeout.ms&#x3D;1000
#hive为sink的配置
a.sinks.hive_sink.type&#x3D;hive
a.sinks.hive_sink.hive.metastore&#x3D;thrift:&#x2F;&#x2F;172.16.2.204:9083
a.sinks.hive_sink.hive.database&#x3D;test
a.sinks.hive_sink.hive.table&#x3D;flume-mqtt
a.sinks.hive_sink.hive.txnsPerBatchAsk&#x3D;2
a.sinks.hive_sink.batchSize&#x3D;10
a.sinks.hive_sink.serializer&#x3D;JSON
a.sinks.hive_sink.serializer.fieldnames&#x3D;id,name,age
#channel的配置
a.channels.mem_channel.type&#x3D;memory
a.channels.mem_channel.capacity&#x3D;1000
a.channels.mem_channel.transactionCapacity&#x3D;100
#三者之间的关系
a.sources.source_from_kafka.channels&#x3D;mem_channel
a.sinks.hive_sink.channel&#x3D;mem_channel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>启动flume任务<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flume-ng agent --name a --conf &#x2F;etc&#x2F;flume-ng&#x2F;conf --conf-file hive.conf -Dflume.root.logger&#x3D;INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
报错如下：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flume.sink.hive.HiveWriter$ConnectException: Failed connecting to EndPoint &#123;metaStoreUri&#x3D;&#39;thrift:&#x2F;&#x2F;172.16.2.204:9083&#39;, database&#x3D;&#39;test&#39;, table&#x3D;&#39;flume-mqtt&#39;, partitionVals&#x3D;[] &#125;
	at org.apache.flume.sink.hive.HiveWriter.newConnection(HiveWriter.java:383)
	at org.apache.flume.sink.hive.HiveWriter.&lt;init&gt;(HiveWriter.java:86)
	... 6 more
Caused by: org.apache.hive.hcatalog.streaming.StreamingException: java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hadoop&#x2F;hive&#x2F;metastore&#x2F;api&#x2F;MetaException
	at org.apache.flume.sink.hive.HiveWriter.timedCall(HiveWriter.java:456)
	at org.apache.flume.sink.hive.HiveWriter.newConnection(HiveWriter.java:376)
	... 7 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
没找到解决办法：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flume-ng agent --name a --conf &#x2F;etc&#x2F;flume-ng&#x2F;conf --conf-file hive.conf --classpath &quot;&#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH&#x2F;jars&#x2F;*hive*&quot; -Dflume.root.logger&#x3D;INFO,console <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
注意：<br>官网说，flume中sink端需要采用orc格式传输数据，并且要分桶，但Impala不支持orc格式的Hive表，最终这里放弃</li>
</ol>
<h3 id="使用hdfs-sink"><a href="#使用hdfs-sink" class="headerlink" title="使用hdfs-sink"></a>使用hdfs-sink</h3><p>这个比较简单，一般公司都这么用</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">a.sources&#x3D;source_from_kafka
a.channels&#x3D;mem_channel
a.sinks&#x3D;k1
#kafka为souce的配置
a.sources.source_from_kafka.type&#x3D;org.apache.flume.source.kafka.KafkaSource
a.sources.source_from_kafka.batchSize&#x3D;10
a.sources.source_from_kafka.kafka.bootstrap.servers&#x3D;172.16.2.205:9092
a.sources.source_from_kafka.topic&#x3D;flume-mqtt
a.sources.source_from_kafka.channels&#x3D;mem_channel
a.sources.source_from_kafka.consumer.timeout.ms&#x3D;1000
#hive为sink的配置
#具体定义sink
a.sinks.k1.type &#x3D; hdfs
#%y-%m-%d&#x2F;%H%M&#x2F;%S
#这里对应就是hive 表的目录 此处如果是外部表，则直接对应你的localtion地址，如果普通则对应到你的hive表目录即可
a.sinks.k1.hdfs.path &#x3D; hdfs:&#x2F;&#x2F;nameservice1&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;test.db&#x2F;flume_mqtt&#x2F;%Y-%m-%d_%H
a.sinks.k1.hdfs.filePrefix &#x3D; flume-%Y-%m-%d_%H
a.sinks.k1.hdfs.fileSuffix &#x3D; .log
a.sinks.k1.hdfs.fileType &#x3D; DataStream
#不按照条数生成文件
a.sinks.k1.hdfs.rollCount &#x3D; 0
#HDFS上的文件达到128M时生成一个文件
a.sinks.k1.hdfs.rollSize &#x3D; 2914560
#HDFS上的文件达到60秒生成一个文件
a.sinks.k1.hdfs.rollInterval &#x3D; 60
a.sinks.k1.hdfs.useLocalTimeStamp &#x3D; true


#channel的配置
a.channels.mem_channel.type&#x3D;memory
a.channels.mem_channel.capacity&#x3D;1000
a.channels.mem_channel.transactionCapacity&#x3D;100
#三者之间的关系
a.sources.source_from_kafka.channels&#x3D;mem_channel
a.sinks.k1.channel&#x3D;mem_channel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>启动flume任务</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flume-ng agent --name a --conf &#x2F;etc&#x2F;flume-ng&#x2F;conf --conf-file hdfs.conf -Dflume.root.logger&#x3D;INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在hive里添加添加分区或者指定文件路径</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> test<span class="token punctuation">.</span>flume_mqtt <span class="token keyword">ADD</span> <span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span> <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>dt<span class="token operator">=</span><span class="token string">'20221108'</span><span class="token punctuation">,</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">)</span>
location <span class="token string">'hdfs://nameservice1/user/hive/warehouse/test.db/flume_mqtt/20221108/14'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>注意：<br>但是这样数据延迟会比较大，因为不可能一秒生成一个文件，生产上最起码也得1分钟生成一个文件。在flume写未完成的文件的时候，hive是读取不到这个文件内数据的</p>
<h3 id="使用hbase-sink"><a href="#使用hbase-sink" class="headerlink" title="使用hbase-sink"></a>使用hbase-sink</h3><p>考虑使用flume写数据到hbase，并在hive内创建hbase外表以达到实时访问hive数据的能力</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop杂记</title>
    <url>/2022/03/31/Hadoop%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hdfs的url在什么情况下指定ip:port</li>
</ul>
<a id="more"></a>


<h2 id="hdfs的url在什么情况下指定ip-port"><a href="#hdfs的url在什么情况下指定ip-port" class="headerlink" title="hdfs的url在什么情况下指定ip:port"></a>hdfs的url在什么情况下指定ip:port</h2><p>我们在使用hdfs的时候，一般情况下都是不指定ip:port的，原因是，在hadoop的core-site.xml里，我们配置了如下的参数</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&lt;property&gt;
  &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;
  &lt;value&gt;hdfs:&#x2F;&#x2F;golden-02:9000&lt;&#x2F;value&gt;
&lt;&#x2F;property&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>在我们指定hdfs的路径的时候，hadoop会自动代入<code>golden-02:9000</code>，例如：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop fs -ls &#x2F;flink&#x2F;checkpoint&#x2F;cdc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这时候我们不需要指定<code>hdfs://golden-02:9000/flink/checkpoint/cdc</code>也能访问</p>
<p>但是，如果不使用hadoop，例如使用flink访问hdfs上的文件，那么，hdfs://就是必须要添加的了，这里有2中指定方式：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setCheckpointStorage</span><span class="token punctuation">(</span><span class="token string">"hdfs://golden-02:9000/flink/checkpoint/cdc/gjc_test_Mysql2Kakfa"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setCheckpointStorage</span><span class="token punctuation">(</span><span class="token string">"hdfs:///flink/checkpoint/cdc/gjc_test_Mysql2Kakfa"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>可以指定以<code>hdfs://golden-02:9000</code>开头，也就是我们<code>fs.defaultFS</code>里配置的内容<br>也可以直接以<code>hdfs:///</code>开头，注意，这里是3个<code>/</code>，这两个都是一样的，因为flink程序会加载hadoop相关的配置的<br>这里推荐使用<code>hdfs:///</code>，因为namenode有可能会切换standby，切换了standby不知道还能不能访问到<br>如果不知道<code>fs.defaultFS</code>里的配置在哪里找，可以直接打开hive客户端，执行如下语句</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">hive<span class="token operator">></span> <span class="token keyword">set</span> fs<span class="token punctuation">.</span>defaultFS<span class="token punctuation">;</span>
<span class="token number">22</span><span class="token operator">/</span><span class="token number">03</span><span class="token operator">/</span><span class="token number">31</span> <span class="token number">15</span>:<span class="token number">36</span>:<span class="token number">26</span> INFO conf<span class="token punctuation">.</span>HiveConf: <span class="token keyword">Using</span> the <span class="token keyword">default</span> <span class="token keyword">value</span> passed <span class="token operator">in</span> <span class="token keyword">for</span> log id: <span class="token number">488</span>dc8a0<span class="token operator">-</span>b332<span class="token operator">-</span><span class="token number">4854</span><span class="token operator">-</span>b2a1<span class="token operator">-</span><span class="token number">585</span>b69a15bf6
fs<span class="token punctuation">.</span>defaultFS<span class="token operator">=</span>hdfs:<span class="token comment">//digiwin-hdfs2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop集群扩容</title>
    <url>/2022/03/08/Hadoop%E9%9B%86%E7%BE%A4%E6%89%A9%E5%AE%B9/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hadoop集群扩容</li>
</ul>
<a id="more"></a>

<h2 id="Hadoop集群扩容"><a href="#Hadoop集群扩容" class="headerlink" title="Hadoop集群扩容"></a>Hadoop集群扩容</h2><p>Hadoop集群扩容可以直接在原先的节点添加磁盘，或者是添加数据节点</p>
<h3 id="原有节点添加磁盘"><a href="#原有节点添加磁盘" class="headerlink" title="原有节点添加磁盘"></a>原有节点添加磁盘</h3><p>公司集群是CDH版本，本次扩容需要在CM上操作<br>首先运维把扩容的磁盘挂在到3台datanode节点，具体挂在方法，咱们这里不做深究，网上很多，后期可以自己尝试一下看看<br>扩容机器列表:</p>
<ul>
<li>ddp3.hadoop</li>
<li>ddp4.hadoop</li>
<li>ddp5.hadoop<br>扩容2T磁盘存储，首先登陆到3台节点，查看磁盘空间是否已经挂载成功<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@h3 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs         47G     0   47G   0% &#x2F;dev
tmpfs            47G  8.0K   47G   1% &#x2F;dev&#x2F;shm
tmpfs            47G  652K   47G   1% &#x2F;run
tmpfs            47G     0   47G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup
&#x2F;dev&#x2F;vda1        99G   31G   64G  33% &#x2F;
&#x2F;dev&#x2F;vdb1       493G  171G  301G  37% &#x2F;data
cm_processes     47G   29M   47G   1% &#x2F;run&#x2F;cloudera-scm-agent&#x2F;process
tmpfs           9.3G     0  9.3G   0% &#x2F;run&#x2F;user&#x2F;0
&#x2F;dev&#x2F;vdc1       2.0T   81M  1.9T   1% &#x2F;mnt&#x2F;data1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
可以看到，<code>/mnt/data1</code>就是新添加的磁盘<h4 id="扩容步骤"><a href="#扩容步骤" class="headerlink" title="扩容步骤"></a>扩容步骤</h4></li>
</ul>
<ol>
<li><p>在<code>/mnt/data1</code>文件夹下创建文件夹，并赋权限</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;mnt&#x2F;data1 &amp;&amp; mkdir -p dfs&#x2F;dn
chown -R hdfs:hadoop dfs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<blockquote>
<p>注意，3台节点都要创建并赋权</p>
</blockquote>
</li>
<li><p>在CM管理页面上，点击HDFS -&gt; 配置 -&gt; DataNode ，找到<code>DataNode 数据目录</code>，并新增一个数据盘，并点击保存<br><img src="/uploads/202203/Hadoop%E9%9B%86%E7%BE%A4%E6%B7%BB%E5%8A%A0%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B91.png" alt="Hadoop集群添加磁盘扩容1"></p>
</li>
<li><p>重启HDFS服务，使挂载的磁盘生效</p>
<blockquote>
<p>注意集群重启过程中一定不要中止。这个过程时间可能会比较长，因为可能会有数据搬迁，会执行Balancer</p>
</blockquote>
</li>
</ol>
<p><img src="/uploads/202203/Hadoop%E7%A3%81%E7%9B%98%E6%89%A9%E5%AE%B9%E9%9B%86%E7%BE%A4%E9%87%8D%E5%90%AF.png" alt="Hadoop磁盘扩容集群重启"><br>4. 可以通过查看hdfs-site.xml找到datanode的日志文件路径：/var/log/hadoop-hdfs，查看datanode的执行日志<br>可以参考<a href="https://blog.csdn.net/weixin_34348805/article/details/92378306">CDH（Hadoop）集群磁盘扩容</a></p>
<h3 id="添加数据节点扩容"><a href="#添加数据节点扩容" class="headerlink" title="添加数据节点扩容"></a>添加数据节点扩容</h3><p>可以参考<a href="https://juejin.cn/post/6844904117832253454">基于CDH6扩容</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Iceberg学习笔记</title>
    <url>/2021/08/27/Iceberg%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Iceberg简介</li>
<li>Iceberg架构</li>
<li>Iceberg简单使用案例</li>
<li>Iceberg压力测试<a id="more"></a>

</li>
</ul>
<h2 id="Iceberg简介："><a href="#Iceberg简介：" class="headerlink" title="Iceberg简介："></a>Iceberg简介：</h2><p>pache Iceberg 是一种用于大型分析数据集的开放表格式。 Iceberg 使用类似于 SQL 表的高性能表格式向包括 Spark、Trino、PrestoDB、Flink 和 Hive 在内的计算引擎添加表。<br>从这个定义上来看，Iceberg是一个用于海量数据分析场景下的开源的表格式（其实笔者更愿意用Table Format），也就是说Iceberg本质上是一个表格式。</p>
<h3 id="那什么是表格式？表格式和我们熟悉的文件格式（File-Format）是一回事吗？"><a href="#那什么是表格式？表格式和我们熟悉的文件格式（File-Format）是一回事吗？" class="headerlink" title="那什么是表格式？表格式和我们熟悉的文件格式（File Format）是一回事吗？"></a>那什么是表格式？表格式和我们熟悉的文件格式（File Format）是一回事吗？</h3><p>表和表格式是两个概念。表是一个具象的概念，应用层面的概念，我们天天说的表是简单的行和列的组合。而表格式是数据库系统实现层面一个抽象的概念，它定义了一个表中包含哪些字段，表下面文件的组织形式、表索引信息、统计信息以及上层查询引擎读取、写入表中文件的接口<br>可以参考<a href="https://blog.csdn.net/qq_31866793/article/details/115505649">Apache Iceberg 数据湖从入门到放弃(1) —— 初步入门三部曲</a></p>
<p>我们可以简单理解为他是基于计算层（flink、spark）和存储层（orc、parqurt）的一个中间层，我们可以把它定义成一种“数据组织格式”，Iceberg将其称之为“表格式”也是表达类似的含义。<br>他与底层的存储格式（比如ORC、Parquet之类的列式存储格式）最大的区别是，它并不定义数据存储方式，而是定义了数据、元数据的组织方式，向上提供统一的“表”的语义。<br>它构建在数据存储格式之上，其底层的数据存储仍然使用Parquet、ORC等进行存储。在hive建立一个iceberg格式的表。用flink或者spark写入iceberg，然后再通过其他方式来读取这个表，<br>比如spark、flink、presto等。</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul>
<li>增量读取处理能力：Iceberg支持通过流式方式读取增量数据，支持Structed Streaming以及Flink table Source；</li>
<li>支持事务（ACID），上游数据写入即可见，不影响当前数据处理任务，简化ETL；提供upsert和merge into能力，可以极大地缩小数据入库延迟；</li>
<li>可扩展的元数据，快照隔离以及对于文件列表的所有修改都是原子操作；</li>
<li>同时支持流批处理、支持多种存储格式和灵活的文件组织：提供了基于流式的增量计算模型和基于批处理的全量表计算模型。批处理和流任务可以使用相同的存储模型，数据不再孤立；Iceberg支持隐藏分区和分区进化，方便业务进行数据分区策略更新。支持Parquet、Avro以及ORC等存储格式。</li>
<li>支持多种计算引擎，优秀的内核抽象使之不绑定特定的计算引擎，目前Iceberg支持的计算引擎有Spark、Flink、Presto以及Hive。</li>
</ul>
<p>与其他数据湖产品对比：<br><img src="/uploads/20210520/Iceberg%E4%B8%8E%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E7%B3%8A%E7%BB%84%E4%BB%B6%E5%AF%B9%E6%AF%94.png" alt="Iceberg与其他数据糊组件对比"></p>
<h2 id="Iceberg架构"><a href="#Iceberg架构" class="headerlink" title="Iceberg架构"></a>Iceberg架构</h2><p>Iceberg只是一个table format，不存在架构方面</p>
<h3 id="Iceberg写数据流程"><a href="#Iceberg写数据流程" class="headerlink" title="Iceberg写数据流程"></a>Iceberg写数据流程</h3><p>Iceberg写入流程及文件结构：Iceberg在数据写入的时候，<br>① 先把数据写入到data file文件中；<br>② 当一组data file文件写完之后，会根据这个data file文件中column的一些统计信息（如:每个column的min/max值），生成一个对应的manifest文件；<br>③ 然后Iceberg把一次写入后涉及到的manifest文件组成一个 manifest list， manifest list文件中也会存入一些相关manifest的统计信息（如：分区信息，manifest有效性）等；<br>④ 然后按照整个manifest list 生成一个对应的snapshot文件；<br>⑤ 生成完snapshot文件之后，Iceberg会把当前snapshot的ID及存储路径等信息写入到metadata文件中；<br>⑥ 当一切准备完毕之后，会以原子操作的方式commit这个metadata文件，这样一次iceberg的数据写入就完成了。随着每次的写入iceberg就生成了如下图这样的一个文件组织模式。<br><img src="/uploads/20210520/iceberg-metadata.png" alt="Icreberg文件组织模式"></p>
<h3 id="Iceberg读数据流程"><a href="#Iceberg读数据流程" class="headerlink" title="Iceberg读数据流程"></a>Iceberg读数据流程</h3><p>Iceberg的分区查找优化：<br>Iceberg数据表每一次的修改后的状态都会生成一个snapshot（s0,s1）文件，snapshot文件中包含了一个manifest文件的list，<br>list中存储了当前的snapshot状态是由哪些manifest文件组成的。每一个manifest的文件中会指向到真实数据的存储文件 data file（一般是parquet格式）。<br>在这种结构中，每一个快照读取所需要的数据文件都已经清晰的定义在了manifest list 和 manifest的文件中，<br>并且manifest文件中还存储了相关的partition信息，那么在读取数据的时候如果需要删选partition，<br>通过manifest的中存储的信息以K&amp;V映射方式在O(1)复杂度的计算中就能定位到需要读取的partition目录。<br>当前常用的数据读取引擎，例如hive需要遍历整个数据目录下的文件索引来寻找必要的partition，是一个O(n)的复杂度查找过程。<br>在大数据常见的海量分区下，采用partition映射的模式来选取目录的优化效果是非常明显的，<br>可以在Ryan Blue的讲座中看到在NetFlix的应用场景中2600个分区只需要10S就列出了，<br>而使用hive大概10分钟还没有完成 。</p>
<p>Iceberg谓词下推的三层过滤：<br>① 分区过滤：Iceberg支持查询中的谓词下推，前面已经说了Iceberg是支持隐式分区的，就是说在读取数据的时候不需要在SQL中指定分区。<br> Iceberg会接收上层计算引擎下推过来的谓词表达式，根据谓词表达式中column分区列的信息进行分区转换的计算。<br> 例如 一个Iceberg表有一列 time ，用户设定了在 time 列上按照小时分区，当查询条件为   time &gt;= 2020-01-01 10：00 AND &lt; 2020-01-01 13:00 的时候Iceberg会根据下推过来的谓词表达式和Schema中定义的分区转换表达式进行计算。<br> 直接算出数据分区是在 10点11点12点三个分区中，然后依据manifest中的分区字段直接定位到分区目录。<br>② 文件过滤：Iceberg会把谓词继续下推到更细的筛选粒度，根据谓词的表达式和manifest中column的min/max值Iceberg可以有效的过滤查询数据所覆盖的具体data file，<br>对扫描集做进一步的筛选，如果筛选column是有序的那么下推效果将更加明显。<br>③ RowGroup过滤：经过分区过滤和文件过滤之后Iceberg还会继续把谓词表达式下推到data file文件内部的RowGroup级别，<br>根据parquet文件的metadata信息对RowGroup做进一步的筛选。经过以上三层的筛选，Iceberg最终把数据的扫描集缩小到必须读取的RowGroup级别，<br>然后把需要读取的RowGroup数据读入到内存之中。<br>（同样在Ryan Blue的讲座中我们可以看到，通过层层筛选(命中 min/max)之后，iceberg使得数据计算任务从61小时降低到了22分钟）。</p>
<p>Iceberg的向量化读取和数据的zero copy：在低版本的spark中，由于spark DataSourceV2的API不支持批量读取，<br>因此Iceberg通过for循环把筛选后的数据一行一行的返回给spark去处理这个过程中既需要数据不断的在内存中互相拷贝，<br>也无法发挥列式数据在现代CPU架构中的向量化处理能力。为了进一步提升读取速度，Iceberg在spark2.4.4版本之后，<br>利用spark BatchColumn的读取特性引入了向量化读取的能力。<br> ① 经过谓词下推后，Iceberg把需要的RowGroup数据读入到了内存中。RowGroup是列式组织的，具有可向量化处理的优势；<br> ② Iceberg会根据SQL语句的project来删减需要读取的 column trunk；<br> ③ 然后Iceberg借助Arrow插件作为共享内存，以page + Batch size 为单位一次性的把一个批次大小的数据存入到共享内存中；<br> ④ 当数据存储完之后把共享内存地址返回给spark，spark拿到共享内存地址之后，可以不再进行数据拷贝直接通过偏移量来访问Arrow获取数据。</p>
<p>可以参考<a href="https://www.codercto.com/a/106417.html">Apache Iceberg 对推荐应用架构的优化及读写流程解析</a></p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ul>
<li>Iceberg数据更新的时候貌似不是实时更新的，而是准实时更新的，而且，每次更新，都会生成文件，这就导致，如果频繁更新，那么HDFS上的小文件可能会比较多，这里可以测试一下</li>
<li><h2 id="Iceberg简单使用案例"><a href="#Iceberg简单使用案例" class="headerlink" title="Iceberg简单使用案例"></a>Iceberg简单使用案例</h2><h3 id="flinkcdc-读取mysql并写入Iceberg"><a href="#flinkcdc-读取mysql并写入Iceberg" class="headerlink" title="flinkcdc 读取mysql并写入Iceberg"></a>flinkcdc 读取mysql并写入Iceberg</h3>需要注意的是，flink实时写Iceberg必须要开启checkpoint<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> execution<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span><span class="token keyword">interval</span><span class="token operator">=</span><span class="token number">3</span>sec<span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> users_source_mysql <span class="token punctuation">(</span>
  uuid string <span class="token punctuation">,</span>
  name STRING<span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  part string 
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'mysql-cdc'</span><span class="token punctuation">,</span>
<span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'150.158.190.192'</span><span class="token punctuation">,</span>
<span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'3306'</span><span class="token punctuation">,</span>
<span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'root'</span><span class="token punctuation">,</span>
<span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">,</span>
<span class="token string">'server-time-zone'</span> <span class="token operator">=</span> <span class="token string">'Asia/Shanghai'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.mode'</span> <span class="token operator">=</span> <span class="token string">'initial'</span><span class="token punctuation">,</span>
<span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">,</span>
<span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'users_source_mysql'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
  
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> iceberg_users_source_mysql <span class="token punctuation">(</span>
    uuid <span class="token keyword">INT</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token operator">NOT</span> ENFORCED<span class="token punctuation">,</span>
    name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    age <span class="token keyword">INT</span><span class="token punctuation">,</span>
    ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    part <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> 
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
     <span class="token string">'connector'</span><span class="token operator">=</span><span class="token string">'iceberg'</span>                           <span class="token comment">-- 主键和分区均可多个，分割</span>
   <span class="token punctuation">,</span> <span class="token string">'format-version'</span> <span class="token operator">=</span> <span class="token string">'2'</span>                          <span class="token comment">-- iceberg表版本，可选1，2</span>
   <span class="token punctuation">,</span> <span class="token string">'write.upsert.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span>                 <span class="token comment">-- 开启upsert</span>
   <span class="token punctuation">,</span> <span class="token string">'engine.hive.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span>                  <span class="token comment">-- 启用hive同步</span>
   <span class="token punctuation">,</span> <span class="token string">'catalog-name'</span><span class="token operator">=</span><span class="token string">'hive_catalog'</span>                   <span class="token comment">-- 指定catalog</span>
   <span class="token punctuation">,</span> <span class="token string">'catalog-database'</span><span class="token operator">=</span><span class="token string">'iceberg'</span>                    <span class="token comment">-- 指定hive database</span>
   <span class="token punctuation">,</span> <span class="token string">'uri'</span><span class="token operator">=</span><span class="token string">'thrift://172.16.2.204:9083'</span>                      <span class="token comment">-- hive hms地址，分割 </span>
   <span class="token punctuation">,</span> <span class="token string">'warehouse'</span><span class="token operator">=</span><span class="token string">'hdfs:///user/hive/warehouse/iceberg.db/iceberg_users_source_mysql'</span>  <span class="token comment">-- 仓库地址</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">insert</span> <span class="token keyword">into</span> iceberg_users_source_mysql <span class="token keyword">select</span> uuid<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">,</span>ts<span class="token punctuation">,</span>part <span class="token keyword">from</span> users_source_mysql<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


</li>
</ul>
<h2 id="Iceberg压力测试"><a href="#Iceberg压力测试" class="headerlink" title="Iceberg压力测试"></a>Iceberg压力测试</h2>]]></content>
      <categories>
        <category>大数据</category>
        <category>Iceberg</category>
      </categories>
      <tags>
        <tag>Iceberg</tag>
      </tags>
  </entry>
  <entry>
    <title>Java杂记</title>
    <url>/2021/08/18/Java%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Java范型</li>
</ul>
<a id="more"></a>

<h2 id="Java范型"><a href="#Java范型" class="headerlink" title="Java范型"></a>Java范型</h2><h3 id="什么是范型？"><a href="#什么是范型？" class="headerlink" title="什么是范型？"></a>什么是范型？</h3><p>泛型（generic）是指参数化类型的能力。可以定义带泛型类型的类或方法，随后编译器会用具体的类型来代替它。</p>
<h3 id="为什么要用范型？"><a href="#为什么要用范型？" class="headerlink" title="为什么要用范型？"></a>为什么要用范型？</h3><p>Java语言引入泛型的好处是安全简单。泛型的好处是在编译的时候检查类型安全，并且所有的强制转换都是自动和隐式的，提高代码的重用率。</p>
<ul>
<li>类型安全。 泛型的主要目标是提高 Java 程序的类型安全。通过知道使用泛型定义的变量的类型限制，编译器可以在一个高得多的程度上验证类型假设。没有泛型，这些假设就只存在于程序员的头脑中（或者如果幸运的话，还存在于代码注释中）。</li>
<li>消除强制类型转换。泛型的一个附带好处是，消除源代码中的许多强制类型转换。这使得代码更加可读，并且减少了出错机会。</li>
<li>潜在的性能收益。 泛型为较大的优化带来可能。在泛型的初始实现中，编译器将强制类型转换（没有泛型的话，程序员会指定这些强制类型转换）插入生成的字节码中。但是更多类型信息可用于编译器这一事实，为未来版本的 JVM 的优化带来可能。由于泛型的实现方式，支持泛型（几乎）不需要 JVM 或类文件更改。所有工作都在编译器中完成，编译器生成类似于没有泛型（和强制类型转换）时所写的代码，只是更能确保类型安全而已。</li>
</ul>
<p>注意：<br>Point<T>,这个T表示派生自Object类的任何类，但是使用哪个字母是没有特定意义的！只是为了提高可读性！！！！</p>
<p>遇到一个静态方法，使用如下范型：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token class-name">WatermarkStrategy</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token function">forBoundedOutOfOrderness</span><span class="token punctuation">(</span><span class="token class-name">Duration</span> maxOutOfOrderness<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>ctx<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">BoundedOutOfOrdernessWatermarks</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>maxOutOfOrderness<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这个方法的返回值是<code>WatermarkStrategy&lt;T&gt;</code>,前面那个T，不知道是什么意思，在用的时候，使用如下方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">stream<span class="token punctuation">.</span><span class="token function">assignTimestampsAndWatermarks</span><span class="token punctuation">(</span><span class="token class-name">WatermarkStrategy</span>
                <span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token function">forBoundedOutOfOrderness</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withIdleness</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withTimestampAssigner</span><span class="token punctuation">(</span><span class="token punctuation">(</span>event<span class="token punctuation">,</span>timestamp<span class="token punctuation">)</span> <span class="token operator">-></span> event<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>x <span class="token operator">-></span> x<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingEventTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">WindowFunctionTest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>WatermarkStrategy.&lt;Tuple2&lt;String, Long&gt;&gt;</code>：因为这个方法是静态方法，所以可以直接类名.方法，后面的<code>.&lt;Tuple2&lt;String, Long&gt;&gt;</code>就是方法里前面那个<T></p>
<h2 id="Java的多态"><a href="#Java的多态" class="headerlink" title="Java的多态"></a>Java的多态</h2><p>多态是指，针对某个类型的方法调用，其真正执行的方法取决于运行时期实际类型的方法<br>多态体现为父类引用变量可以指向子类对象。<br>前提条件：必须有子父类关系。</p>
<blockquote>
<p>注意：在使用多态后的父类引用变量调用方法时，会调用子类重写后的方法。</p>
</blockquote>
<ul>
<li><p>多态的定义与使用格式<br>  定义格式：父类类型 变量名=new 子类类型();</p>
</li>
<li><p>多态是同一个行为具有多个不同表现形式或形态的能力。多态就是同一个接口，使用不同的实例而执行不同操作。</p>
</li>
<li><p>多态成员变量：编译运行看左边</p>
</li>
<li><p>多态成员方法：编译看左边，运行看右边</p>
<h3 id="多态的转型"><a href="#多态的转型" class="headerlink" title="多态的转型"></a>多态的转型</h3><p>多态的转型分为向上转型和向下转型两种<br>向上转型：多态本身就是向上转型过的过程<br>使用格式：父类类型 变量名=new 子类类型();<br>适用场景：当不需要面对子类类型时，通过提高扩展性，或者使用父类的功能就能完成相应的操作。  </p>
</li>
</ul>
<p>向下转型：一个已经向上转型的子类对象可以使用强制类型转换的格式，将父类引用类型转为子类引用各类型<br>使用格式：子类类型 变量名=（子类类型） 父类类型的变量；<br>适用场景：当要使用子类特有功能时。  </p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Main</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 给一个有普通收入、工资收入和享受国务院特殊津贴的小伙伴算税:</span>
        <span class="token class-name">Income</span><span class="token punctuation">[</span><span class="token punctuation">]</span> incomes <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Income</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">new</span> <span class="token class-name">Income</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token keyword">new</span> <span class="token class-name">Salary</span><span class="token punctuation">(</span><span class="token number">7500</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token keyword">new</span> <span class="token class-name">StateCouncilSpecialAllowance</span><span class="token punctuation">(</span><span class="token number">15000</span><span class="token punctuation">)</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token function">totalTax</span><span class="token punctuation">(</span>incomes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">double</span> <span class="token function">totalTax</span><span class="token punctuation">(</span><span class="token class-name">Income</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> incomes<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">double</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Income</span> income<span class="token operator">:</span> incomes<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            total <span class="token operator">=</span> total <span class="token operator">+</span> income<span class="token punctuation">.</span><span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token keyword">return</span> total<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> <span class="token class-name">Income</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">protected</span> <span class="token keyword">double</span> income<span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token class-name">Income</span><span class="token punctuation">(</span><span class="token keyword">double</span> income<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">this</span><span class="token punctuation">.</span>income <span class="token operator">=</span> income<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> income <span class="token operator">*</span> <span class="token number">0.1</span><span class="token punctuation">;</span> <span class="token comment">// 税率10%</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> <span class="token class-name">Salary</span> <span class="token keyword">extends</span> <span class="token class-name">Income</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token class-name">Salary</span><span class="token punctuation">(</span><span class="token keyword">double</span> income<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>income<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>income <span class="token operator">&lt;=</span> <span class="token number">5000</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>income <span class="token operator">-</span> <span class="token number">5000</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.2</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> <span class="token class-name">StateCouncilSpecialAllowance</span> <span class="token keyword">extends</span> <span class="token class-name">Income</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token class-name">StateCouncilSpecialAllowance</span><span class="token punctuation">(</span><span class="token keyword">double</span> income<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>income<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>样例2：     </p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Test</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">testDuo</span><span class="token punctuation">(</span><span class="token class-name">Test1</span> t<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"aa"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">Test2</span> t1 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Test2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        t1<span class="token punctuation">.</span><span class="token function">test</span><span class="token punctuation">(</span><span class="token string">"bb"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">testDuo</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Test1</span><span class="token punctuation">&#123;</span>

    <span class="token punctuation">&#125;</span>
   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Test2</span> <span class="token keyword">implements</span> <span class="token class-name">Test1</span><span class="token punctuation">&#123;</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token class-name">String</span> str<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这样做的好处是：</p>
<ol>
<li>消除类型之间的耦合关系</li>
<li>可替换性</li>
<li>可扩充性</li>
<li>接口性</li>
<li>灵活性</li>
<li>简化性</li>
</ol>
<h2 id="抽象类与接口"><a href="#抽象类与接口" class="headerlink" title="抽象类与接口"></a>抽象类与接口</h2><h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><p>在Java中被abstract关键字修饰的类称为抽象类，被abstract关键字修饰的方法称为抽象方法，抽象方法只有方法的声明，没有方法体。抽象类的特点：</p>
<ol>
<li>抽象类不能被实例化只能被继承；<br> 1.1 抽象类不能被实例化，所以抽象类必须被继承，才能被使用<br> 1.2 抽象类可以和类一样，实现接口，但抽象类<font color=#FF0000 >不需要实现接口下的所有方法</font><br> 1.3 抽象类被子类继承以后，就会强迫子类充血抽象类中定义的抽象方法，除非子类也是抽象类</li>
<li>包含抽象方法的一定是抽象类，但是抽象类不一定含有抽象方法</li>
<li>抽象类中的抽象方法的修饰符只能是public或者protected，默认为default</li>
<li>抽象类可以包含属性、方法、构造方法，但是构造方法不能用于实例化，并且子类实例化以后，<font color=#FF0000 >抽象类的构造方法一定会被调用</font></li>
</ol>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>Java中接口用interface关键字修饰，特点为:</p>
<ol>
<li>接口可以包含变量、方法；变量被隐式的指定为 public stastic final，方法被隐式指定为public abstract</li>
<li>接口支持多继承，即一个接口可以extends多个接口，间接的解决了java中类的单继承问题</li>
<li>一个类可以实现多个接口</li>
<li>JDK1.8中对接口增加了新的特性：<br> 4.1 默认方法（default method）：JDK 1.8允许给接口添加非抽象的方法实现，但必须使用default关键字修饰；定义了default的方法可以不被实现子类所实现，但只能被实现子类的对象调用；如果子类实现了多个接口，并且这些接口包含一样的默认方法，则子类必须重写默认方法；<br> 4.2 静态方法（static method）：JDK 1.8中允许使用static关键字修饰一个方法，<font color=#FF0000 >并可以提供实现</font>，称为接口静态方法。接口静态方法只能通过接口调用（接口名.静态方法名）。</li>
</ol>
<blockquote>
<p>总结：继承是一个 “是不是”的关系，而 接口 实现则是 “有没有”的关系。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系，比如狗是否能钻火圈，能则可以实现这个接口，不能就不实现这个接口。</p>
</blockquote>
<h2 id="Java常用的设计模式"><a href="#Java常用的设计模式" class="headerlink" title="Java常用的设计模式"></a>Java常用的设计模式</h2><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><p><strong>解决了什么痛点或有什么好处?</strong><br>保证在Java应用程序中，一个类Class只有一个实例存在。 使用单例模式的好处还在于可以节省内存，因为它限制了实例的个数，有利于Java垃圾回收</p>
<p><strong>什么情况下使用单例模式?</strong><br>第一、控制资源的使用，通过线程同步来控制资源的并发访问；<br>第二、控制实例产生的数量，达到节约资源的目的。<br>第三、作为通信媒介使用，也就是数据共享，它可以在不建立直接关联的条件下，让多个不相关的两个线程或者进程之间实现通信。<br>比如，数据库连接池的设计一般采用单例模式，数据库连接是一种数据库资源  </p>
<h3 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h3><p><strong>解决了什么痛点或有什么好处?</strong></p>
<p><strong>什么情况下使用策略模式?</strong></p>
<h3 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h3><p>mysql的jdbc<br><strong>解决了什么痛点或有什么好处?</strong></p>
<blockquote>
<p>好处<br>将创建实例的工作与使用实例的工作分开，使用者不必关心类对象如何创建，明确了职责。<br>把初始化实例时的工作放到工厂里进行，使代码更容易维护。 更符合面向对象的原则，面向接口编程，而不是面向实现编程。</p>
</blockquote>
<blockquote>
<p>缺点：<br>由于工厂类集中了所有产品创建逻辑，一旦不能正常工作，整个系统都要受到影响。<br>要新增产品类的时候，就要修改工厂类的代码，违反了开放封闭原则(对扩展的开放，对修改的关闭)。<br>简单工厂模式由于使用了静态工厂方法，静态方法不能被继承和重写，会造成工厂角色无法形成基于继承的等级结构。</p>
</blockquote>
<p><strong>什么情况下使用工厂模式?</strong> </p>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><p>kafka的发布订阅，其实就类似于这种观察者模式<br><strong>解决了什么痛点或有什么好处?</strong></p>
<p><strong>什么情况下使用观察者模式?</strong> </p>
<h2 id="JVM知识点总结"><a href="#JVM知识点总结" class="headerlink" title="JVM知识点总结"></a>JVM知识点总结</h2><p>栈解决程序的运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储的问题，即数据怎么放、放在哪儿。<br>堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用。<br>一个对象的大小是不可估计的，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4btye的引用（堆栈分离的好处：））</p>
<h3 id="JVM调优"><a href="#JVM调优" class="headerlink" title="JVM调优"></a>JVM调优</h3>]]></content>
      <categories>
        <category>大数据</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java面试题</title>
    <url>/2021/11/18/Java%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Java面试题总结</li>
</ul>
<a id="more"></a>


<h2 id="Java基础面试题"><a href="#Java基础面试题" class="headerlink" title="Java基础面试题"></a>Java基础面试题</h2><p><strong><font size = 5>1. 抽象类和接口的区别？</font></strong><br><strong>相同点:</strong>  </p>
<ol>
<li>都位于继承的顶端,用于被其他类实现或继承;  </li>
<li>都不能直接实例化对象;  </li>
<li>都可以包含抽象方法,其子类都必须覆写这些抽象方法;  </li>
</ol>
<p><strong>区别:</strong>  </p>
<ol>
<li>抽象类为部分方法提供实现,避免子类重复实现这些方法,提高代码重用性;接口只能包含抽象方法,java1.8以后也有default修饰的方法，还有stastic的方法可以有方法体;  </li>
<li>一个类只能继承一个直接父类(可能是抽象类),却可以实现多个接口;(接口弥补了Java的单继承)  </li>
<li>抽象类是这个事物中应该具备的内容, 继承体系是一种 is..a关系  </li>
<li>接口是这个事物中的额外内容,继承体系是一种 like..a关系  </li>
</ol>
<h2 id="常见JVM面试题及答案整理"><a href="#常见JVM面试题及答案整理" class="headerlink" title="常见JVM面试题及答案整理"></a>常见JVM面试题及答案整理</h2><p><strong><font size = 5>1. 什么情况下会发生栈内存溢出？</font></strong><br>栈是线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口等信息。局部变量表又包含基本数据类型，对象引用类型<br>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常，方法递归调用产生这种结果。<br>如果Java虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是无法申请到足够的内存去完成扩展，或者在新建立线程的时候没有足够的内存去创建对应的虚拟机栈，那么Java虚拟机将抛出一个OutOfMemory 异常。(线程启动过多)<br>参数 -Xss 去调整JVM栈的大小</p>
<p>可以参考<a href="https://blog.csdn.net/qq_41701956/article/details/100074023">常见JVM面试题及答案整理</a></p>
<p><strong><font size = 5>2. 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。</font></strong><br>1）几种垃圾收集器：</p>
<ul>
<li>Serial收集器： 单线程的收集器，收集垃圾时，必须stop the world，使用复制算法。</li>
<li>ParNew收集器： Serial收集器的多线程版本，也需要stop the world，复制算法。</li>
<li>Parallel Scavenge收集器： 新生代收集器，复制算法的收集器，并发的多线程收集器，目标是达到一个可控的吞吐量。如果虚拟机总共运行100分钟，其中垃圾花掉1分钟，吞吐量就是99%。</li>
<li>Serial Old收集器： 是Serial收集器的老年代版本，单线程收集器，使用标记整理算法。</li>
<li>Parallel Old收集器： 是Parallel Scavenge收集器的老年代版本，使用多线程，标记-整理算法。</li>
<li>CMS(Concurrent Mark Sweep) 收集器： 是一种以获得最短回收停顿时间为目标的收集器，标记清除算法，运作过程：初始标记，并发标记，重新标记，并发清除，收集结束会产生大量空间碎片。</li>
<li>G1收集器： 标记整理算法实现，运作流程主要包括以下：初始标记，并发标记，最终标记，筛选标记。不会产生空间碎片，可以精确地控制停顿。<br>2）CMS收集器和G1收集器的区别：</li>
<li>CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用；</li>
<li>G1收集器收集范围是老年代和新生代，不需要结合其他收集器使用；</li>
<li>CMS收集器以最小的停顿时间为目标的收集器；</li>
<li>G1收集器可预测垃圾回收的停顿时间</li>
<li>CMS收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片</li>
<li>G1收集器使用的是“标记-整理”算法，进行了空间整合，降低了内存空间碎片。 </li>
</ul>
]]></content>
      <categories>
        <category>面试题</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka学习笔记</title>
    <url>/2021/01/21/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Kafka简介（后补）</li>
<li>Kafka可以干什么？（后补）</li>
<li>Kafka安装与启动</li>
<li>Kafka常用操作<a id="more"></a>
<h2 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h2></li>
</ul>
<h2 id="Kafka可以干什么？"><a href="#Kafka可以干什么？" class="headerlink" title="Kafka可以干什么？"></a>Kafka可以干什么？</h2><h2 id="Kafka安装与启动"><a href="#Kafka安装与启动" class="headerlink" title="Kafka安装与启动"></a>Kafka安装与启动</h2><h3 id="Kafka安装"><a href="#Kafka安装" class="headerlink" title="Kafka安装"></a>Kafka安装</h3><p>Kafka需要用到java，安装前需要安装java，这里省略<br>Kafka可以使用内置的zookeeper，也可以使用单独的zookeeper，一般生产环境都是使用单独的zookeeper集群<br>zookeeper安装可以参考<a href="https://gujincheng.github.io/2021/01/21/Zookeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/">Zookeeper学习笔记（一）</a><br>官网下载Kafka安装包，并解压</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar zxvf kafka-2.11.0.tar.gz -C .
cd kafka-2.11.0&#x2F;config
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>修改server.properties</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">host.name&#x3D;golden-02
# 指定kafka日志文件的存储目录
log.dirs&#x3D;&#x2F;opt&#x2F;modules&#x2F;kafka-2.11.0&#x2F;kafka-logs
# 指定zookeeper的连接地址，多个地址用逗号分隔
zookeeper.connect&#x3D;golden-02:2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里设置了kafka-logs，手动生成了这个文件夹</p>
<p>最后，设置Kakfa的环境变量</p>
<h3 id="Kafka启动等操作"><a href="#Kafka启动等操作" class="headerlink" title="Kafka启动等操作"></a>Kafka启动等操作</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 启动
cd &#x2F;opt&#x2F;modules&#x2F;kafka-2.11.0&#x2F; &amp;&amp; bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &amp;
# 关闭
cd &#x2F;opt&#x2F;modules&#x2F;kafka-2.11.0&#x2F; &amp;&amp; bin&#x2F;kafka-server-stop.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Kafka操作样例"><a href="#Kafka操作样例" class="headerlink" title="Kafka操作样例"></a>Kafka操作样例</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 查看所有topic
bin&#x2F;kafka-topics.sh --bootstrap-server golden-02:9092 --list
## 创建topic
bin&#x2F;kafka-topics.sh --bootstrap-server golden-02:9092 --create --replication-factor 3 --partitions 1 --topic first
## 删除topic
bin&#x2F;kafka-topics.sh --bootstrap-server golden-02:9092 --delete --topic first
## 发送消息
bin&#x2F;kafka-console-producer.sh --broker-list golden-02:9092 --topic first
# 或者下面命令
bin&#x2F;kafka-console-producer.sh --bootstrap-server golden-02:9092 --topic first
## 消费消息
bin&#x2F;kafka-console-consumer.sh  --bootstrap-server golden-02:9092  --from-beginning --topic first
## 查看某个Topic的详情
bin&#x2F;kafka-topics.sh --bootstrap-server golden-02:9092  --describe --topic first
## 查看某个group_id的消费情况，offset
bin&#x2F;kafka-consumer-groups.sh --bootstrap-server golden-02:9092 --describe --group fink-test

## 重置offset
kafka-consumer-groups --group dwd4rule_group --bootstrap-server ddp3.hadoop:9092 --reset-offsets --all-topics --to-offset 210000 --execute
kafka-consumer-groups --group dwd4rule_group --bootstrap-server ddp3.hadoop:9092 --reset-offsets --all-topics --to-offset --to-latest --execute
kafka-consumer-groups --group dwd4rule_group --bootstrap-server ddp3.hadoop:9092 --reset-offsets --all-topics --to-offset --to-datetime 2022-10-25T12:30:00.000 --execute

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>选项说明：  </p>
<ul>
<li>–topic 定义topic名</li>
<li>–replication-factor 定义副本数</li>
<li>–partitions 定义分区数</li>
</ul>
<p>删除topic时删除不掉，日志提醒：<br><code>This will have no impact if delete.topic.enable is not set to true</code><br><img src="/uploads/20210121/kafka-delete-error.png" alt="kafka-delete-error"><br>到kafka的server.properties里设置<code>delete.topic.enable=true</code></p>
<h2 id="Kafka常见问题"><a href="#Kafka常见问题" class="headerlink" title="Kafka常见问题"></a>Kafka常见问题</h2><ul>
<li>auto.offset.reset设置无效<blockquote>
<p>原因:<code>auto.offset.reset</code>只会在Kafka中没有初始偏移量，或者服务器上不再存在当前偏移量的时候才会生效。<br>换句话说，如果当前<code>group_id</code>已经消费过这个<code>topic</code>（可以查到offset），这个参数就没用了，要再想从头开始消费，就得换个group_id了<br>官网说明：<br><img src="/uploads/20210125/Kafka%E5%AE%98%E7%BD%91%E8%A7%A3%E9%87%8Aauto.offset.reset.png" alt="Kafka官网解释auto.offset.reset"></p>
</blockquote>
</li>
</ul>
<h2 id="Kafka数据迁移"><a href="#Kafka数据迁移" class="headerlink" title="Kafka数据迁移"></a>Kafka数据迁移</h2><p>公司的kafka数据存储所在磁盘空间太小，后期扩容后，也没有把扩容后的磁盘加入到kafka。现在想把之前的磁盘换到新扩容的磁盘里</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@ddp3 ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs         16G     0   16G   0% &#x2F;dev
tmpfs            16G     0   16G   0% &#x2F;dev&#x2F;shm
tmpfs            16G  856K   16G   1% &#x2F;run
tmpfs            16G     0   16G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup
&#x2F;dev&#x2F;vda1        99G   86G  8.2G  92% &#x2F;
&#x2F;dev&#x2F;vdb1       296G   90G  193G  32% &#x2F;data
cm_processes     16G   29M   16G   1% &#x2F;run&#x2F;cloudera-scm-agent&#x2F;process
tmpfs           3.1G     0  3.1G   0% &#x2F;run&#x2F;user&#x2F;0
overlay          99G   86G  8.2G  92% &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;eab5e26d05206a9ae6591a28f66bebd4dc79529d2fcc462a135c855052fd49bd&#x2F;merged
shm              64M     0   64M   0% &#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;2733068e2bd0a33d90df3ce3a011a651e8d6a9ab81b4782fe2f9896701e48f1e&#x2F;shm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>kafka数据存储在<code>/dev/vda1</code>磁盘下，现在想换到<code>/dev/vdb1</code><br>需要解决两个问题：</p>
<ol>
<li>kafka数据盘挂在新的文件夹下</li>
<li>kakfa的历史数据需要移动到新的文件夹下</li>
</ol>
<p>但是不知道直接mv历史数据到新的磁盘下，数据会不会丢失，这里在自己电脑上做一下测试<br>本机的server.properties里配置的<code>log.dirs=/opt/modules/kafka-2.8.0/kafka-logs</code><br>目标是把数据迁移到<code>/tmp/kafka/kafka-logs</code><br>具体操作步骤：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 1. 创建kafkatopic
bin&#x2F;kafka-topics.sh --bootstrap-server golden-cloud:9092 --create --replication-factor 1 --partitions 3 --topic first
# 2. 向topic里发送4条数据，aaa&#x2F;bbb&#x2F;ccc&#x2F;ddd
bin&#x2F;kafka-console-producer.sh --broker-list golden-cloud:9092 --topic first
# 3.kafka服务不停止，直接mv文件夹
cd &#x2F;tmp&#x2F;kafka&#x2F; &amp;&amp; mv &#x2F;opt&#x2F;modules&#x2F;kafka-2.8.0&#x2F;kafka-logs&#x2F; .
# 这时候kafka因为数据文件夹切换了，kafka服务报错停止
[2022-03-31 16:57:50,559] ERROR Error while reading checkpoint file &#x2F;opt&#x2F;modules&#x2F;kafka-2.8.0&#x2F;kafka-logs&#x2F;cleaner-offset-checkpoint (kafka.server.LogDirFailureChannel)
java.nio.file.NoSuchFileException: &#x2F;opt&#x2F;modules&#x2F;kafka-2.8.0&#x2F;kafka-logs&#x2F;cleaner-offset-checkpoint
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at java.nio.file.Files.newBufferedReader(Files.java:2784)
...
[2022-03-31 16:57:50,584] WARN [ReplicaManager broker&#x3D;0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,first-1,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,first-2,__consumer_offsets-37,first-0,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory &#x2F;opt&#x2F;modules&#x2F;kafka-2.8.0&#x2F;kafka-logs. (kafka.server.ReplicaManager)
[2022-03-31 16:57:50,584] WARN Stopping serving logs in dir &#x2F;opt&#x2F;modules&#x2F;kafka-2.8.0&#x2F;kafka-logs (kafka.log.LogManager)
[2022-03-31 16:57:50,586] ERROR Shutdown broker because all log dirs in &#x2F;opt&#x2F;modules&#x2F;kafka-2.8.0&#x2F;kafka-logs have failed (kafka.log.LogManager)

# 4. 修改server.properties的配置
log.dirs&#x3D;&#x2F;tmp&#x2F;kafka&#x2F;kafka-logs
# 5. 重启kafka服务
bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &amp;
# 6. 消费kafka first topic的数据
bin&#x2F;kafka-console-consumer.sh  --bootstrap-server golden-cloud:9092  --from-beginning --topic first
bbb
aaa
ddd
ccc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果表明，直接修改日志的文件夹，然后重启kafka服务，数据不会丢失</p>
<p>线上操作步骤应该如下：</p>
<ol>
<li>修改<code>server.properties</code>配置文件的<code>log.dirs</code>,或者在CM页面修改kafka的<code>Data Directories log.dirs</code></li>
<li>停止kafka服务，这个步骤可以不操作，报错也没关系，但是最好做一下</li>
<li>复制kafka数据到新的数据文件夹</li>
<li>重启kafka服务</li>
<li>测试数据是否完整，一切正常后，删除原本数据文件夹</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac使用笔记（一）</title>
    <url>/2021/05/20/Mac%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>安装并配置<code>oh my zsh</code></li>
<li>安装并配置java</li>
<li>mac环境下Sublime使用技巧</li>
<li>Mac常用快捷键</li>
</ul>
<a id="more"></a>

<p>最近新买了MacBook，但是刚从Windows切换到Mac OS系统感觉很不适应，记录一下适应的过程</p>
<h2 id="Mac下必备软件"><a href="#Mac下必备软件" class="headerlink" title="Mac下必备软件"></a>Mac下必备软件</h2><ul>
<li>the unarchiver: 无感解压</li>
<li>有道云笔记</li>
<li>IDEA</li>
<li>大数据相关软件</li>
<li>Iterm2  &amp;&amp; oh my zsh</li>
<li>sublime</li>
<li>百度云网盘</li>
<li>Snipaste：截图神器</li>
</ul>
<h2 id="安装并配置oh-my-zsh"><a href="#安装并配置oh-my-zsh" class="headerlink" title="安装并配置oh my zsh"></a>安装并配置<code>oh my zsh</code></h2><p>Mac自带的终端界面体验实在不敢恭维。这里记录一下安装<code>oh my zsh</code>的过程</p>
<ul>
<li>首先确保当前shell是zsh，如果不是，使用<code>chsh -s /bin/zsh</code></li>
<li>用自己的git fork一下<code>ohmyzsh/ohmyzsh</code>,然后从自己的git仓库clone下来，这样快一点<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">## clone程序
git clone git@github.com:gujincheng&#x2F;ohmyzsh.git ~&#x2F;.oh-my-zsh
## 编辑.zshrc
cp ~&#x2F;.oh-my-zsh&#x2F;templates ~&#x2F;.zshrc
## 修改主题为arrow
ZSH_THEME&#x3D;&quot;arrow&quot;
## 安装常用插件
plugins&#x3D;(git zsh-autosuggestions zsh-syntax-highlighting)
## 安装插件的时候，可以把插件fork到自己的git上，然后从自己的git上clone到~&#x2F;.oh-my-zsh&#x2F;custom&#x2F;plugins
&#96;&#96;&#96;  
* .zshrc完整配置：
&#96;&#96;&#96;shell 
# If you come from bash you might have to change your $PATH.
# export PATH&#x3D;$HOME&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;bin:$PATH

# Path to your oh-my-zsh installation.
export ZSH&#x3D;$HOME&#x2F;.oh-my-zsh

# Set name of the theme to load --- if set to &quot;random&quot;, it will
# load a random theme each time oh-my-zsh is loaded, in which case,
# to know which specific one was loaded, run: echo $RANDOM_THEME
# See https:&#x2F;&#x2F;github.com&#x2F;ohmyzsh&#x2F;ohmyzsh&#x2F;wiki&#x2F;Themes
#ZSH_THEME&#x3D;&quot;robbyrussell&quot;
#ZSH_THEME&#x3D;&quot;essembeh&quot;
ZSH_THEME&#x3D;&quot;arrow&quot;
# Set list of themes to pick from when loading at random
# Setting this variable when ZSH_THEME&#x3D;random will cause zsh to load
# a theme from this variable instead of looking in $ZSH&#x2F;themes&#x2F;
# If set to an empty array, this variable will have no effect.
#ZSH_THEME_RANDOM_CANDIDATES&#x3D;( &quot;robbyrussell&quot; &quot;agnoster&quot; )

# Uncomment the following line to use case-sensitive completion.
# CASE_SENSITIVE&#x3D;&quot;true&quot;

# Uncomment the following line to use hyphen-insensitive completion.
# Case-sensitive completion must be off. _ and - will be interchangeable.
# HYPHEN_INSENSITIVE&#x3D;&quot;true&quot;

# Uncomment the following line to disable bi-weekly auto-update checks.
# DISABLE_AUTO_UPDATE&#x3D;&quot;true&quot;

# Uncomment the following line to automatically update without prompting.
# DISABLE_UPDATE_PROMPT&#x3D;&quot;true&quot;

# Uncomment the following line to change how often to auto-update (in days).
# export UPDATE_ZSH_DAYS&#x3D;13

# Uncomment the following line if pasting URLs and other text is messed up.
# DISABLE_MAGIC_FUNCTIONS&#x3D;&quot;true&quot;

# Uncomment the following line to disable colors in ls.
# DISABLE_LS_COLORS&#x3D;&quot;true&quot;

# Uncomment the following line to disable auto-setting terminal title.
# DISABLE_AUTO_TITLE&#x3D;&quot;true&quot;

# Uncomment the following line to enable command auto-correction.
# ENABLE_CORRECTION&#x3D;&quot;true&quot;

# Uncomment the following line to display red dots whilst waiting for completion.
# Caution: this setting can cause issues with multiline prompts (zsh 5.7.1 and newer seem to work)
# See https:&#x2F;&#x2F;github.com&#x2F;ohmyzsh&#x2F;ohmyzsh&#x2F;issues&#x2F;5765
# COMPLETION_WAITING_DOTS&#x3D;&quot;true&quot;

# Uncomment the following line if you want to disable marking untracked files
# under VCS as dirty. This makes repository status check for large repositories
# much, much faster.
# DISABLE_UNTRACKED_FILES_DIRTY&#x3D;&quot;true&quot;

# Uncomment the following line if you want to change the command execution time
# stamp shown in the history command output.
# You can set one of the optional three formats:
# &quot;mm&#x2F;dd&#x2F;yyyy&quot;|&quot;dd.mm.yyyy&quot;|&quot;yyyy-mm-dd&quot;
# or set a custom format using the strftime function format specifications,
# see &#39;man strftime&#39; for details.
# HIST_STAMPS&#x3D;&quot;mm&#x2F;dd&#x2F;yyyy&quot;

# Would you like to use another custom folder than $ZSH&#x2F;custom?
# ZSH_CUSTOM&#x3D;&#x2F;path&#x2F;to&#x2F;new-custom-folder

# Which plugins would you like to load?
# Standard plugins can be found in $ZSH&#x2F;plugins&#x2F;
# Custom plugins may be added to $ZSH_CUSTOM&#x2F;plugins&#x2F;
# Example format: plugins&#x3D;(rails git textmate ruby lighthouse)
# Add wisely, as too many plugins slow down shell startup.
plugins&#x3D;(git zsh-autosuggestions zsh-syntax-highlighting)

source $ZSH&#x2F;oh-my-zsh.sh

# User configuration

# export MANPATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;man:$MANPATH&quot;
#JAVA_HOME&#x3D;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_291.jdk&#x2F;Contents&#x2F;Home
JAVA_HOME&#x3D;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_291.jdk&#x2F;Contents&#x2F;Home
MAVEN_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-maven-3.8.1
CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar

NODE_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;node-v14.16.1
SCALA_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;scala-2.12.13
HADOOP_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;hadoop-3.2.2
HIVE_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;hive-3.1.2
SPARK_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;spark-3.1.1
HBASE_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;hbase-2.3.5
FLINK_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;flink-1.12.2
ZK_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.6.3

export JAVA_HOME&#x3D;$JAVA_HOME
PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH:$MAVEN_HOME&#x2F;bin:$PATH:$NODE_HOME&#x2F;bin:$PATH
PATH&#x3D;$SCALA_HOME&#x2F;bin:$PATH:$HADOOP_HOME&#x2F;bin:$PATH:$SPARK_HOME&#x2F;bin:$PATH
PATH&#x3D;$HIVE_HOME&#x2F;bin:$HBASE_HOME&#x2F;bin:$PATH:$FLINK_HOME&#x2F;bin:$PATH:$ZK_HOME&#x2F;bin:$PATH
PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin


export PATH
export LANG&#x3D;zh_CN.UTF-8
alias subl&#x3D;&quot;&#x2F;Applications&#x2F;Sublime\ Text.app&#x2F;Contents&#x2F;SharedSupport&#x2F;bin&#x2F;subl&quot;
alias emacs&#x3D;&quot;&#x2F;Applications&#x2F;Emacs.app&#x2F;Contents&#x2F;MacOS&#x2F;Emacs&quot;
# You may need to manually set your language environment
# export LANG&#x3D;en_US.UTF-8

# Preferred editor for local and remote sessions
# if [[ -n $SSH_CONNECTION ]]; then
#   export EDITOR&#x3D;&#39;vim&#39;
# else
#   export EDITOR&#x3D;&#39;mvim&#39;
# fi

# Compilation flags
# export ARCHFLAGS&#x3D;&quot;-arch x86_64&quot;

# Set personal aliases, overriding those provided by oh-my-zsh libs,
# plugins, and themes. Aliases can be placed here, though oh-my-zsh
# users are encouraged to define aliases within the ZSH_CUSTOM folder.
# For a full list of active aliases, run &#96;alias&#96;.
#
# Example aliases
# alias zshconfig&#x3D;&quot;mate ~&#x2F;.zshrc&quot;
# alias ohmyzsh&#x3D;&quot;mate ~&#x2F;.oh-my-zsh&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
Iterm2快捷键：</li>
<li>Command + N ： 新建tab页</li>
<li>Command + Enter ： 全屏/退出全屏</li>
</ul>
<h2 id="Mac使用ssh-agent登陆远程服务器"><a href="#Mac使用ssh-agent登陆远程服务器" class="headerlink" title="Mac使用ssh-agent登陆远程服务器"></a>Mac使用ssh-agent登陆远程服务器</h2><p>该功能类似SecureCRT里的<code>Tools-Manage Agent Keys</code></p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">eval &#96;ssh-agent&#96;
## id_rsa_work为之前保存的私钥文件
ssh-add ~&#x2F;.ssh&#x2F;id_rsa_work<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>但是，这种方式有一个缺点，每次打开终端都要执行一次，这里把它加载到环境变量里<br>在.zshrc里添加一下内容：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">eval &#96;ssh-agent&#96; &gt; &#x2F;dev&#x2F;null
ssh-add ~&#x2F;.ssh&#x2F;id_rsa_work &gt; &#x2F;dev&#x2F;null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="安装并配置java"><a href="#安装并配置java" class="headerlink" title="安装并配置java"></a>安装并配置java</h2><p>mac下安装java很简单，但是配置java的环境变量，被恶心到了，找不到java的安装路径</p>
<ul>
<li>首先到官网上下载java安装包，注意，下载那个大的，也就是200多M的文件，下载小的，不包含jdk</li>
<li>查找JDK安装目录<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">## 执行如下命令
&#x2F;usr&#x2F;libexec&#x2F;java_home -V
## 该命令会把机器上所有的java版本都列出来，因为我之前先安装了一个不包含jdk的java，就导致我这里有两个java
## 但是很明显，我需要的jdk是下面的那个
JAVA_HOME&#x3D;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_291.jdk&#x2F;Contents&#x2F;Home

## 自己跟着网上安装了一次jdk11，但是找不到tools.jar和dt.jar,在idea中调试代码的时候，一直报错，最终放弃了
## 之后有空再试试<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<img src="/uploads/20210520/jdk%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF.png" alt="jdk版本信息"><br>有2个java是因为一开始装的java不是jdk，是jre，而且两个的版本不一样。</li>
</ul>
<h2 id="mac环境下Sublime使用技巧"><a href="#mac环境下Sublime使用技巧" class="headerlink" title="mac环境下Sublime使用技巧"></a>mac环境下Sublime使用技巧</h2><ul>
<li><p>命令行使用Sublime打开文件</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">alias subl&#x3D;&quot;&#x2F;Applications&#x2F;Sublime\ Text.app&#x2F;Contents&#x2F;SharedSupport&#x2F;bin&#x2F;subl&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>Sublime列式编辑<br>按住鼠标中键，或者按住<code>command</code>使用鼠标选择文本</p>
</li>
<li><p>Sublime查找与替换快捷键  </p>
<ul>
<li>查找：<code>command + F</code></li>
<li>替换：<code>command +shift + F</code>,需要注意是否忽略大小写，是否正则匹配</li>
</ul>
</li>
<li><p>Sublime使用home/end快捷键到行首行尾</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"ctrl+shift+t"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"toggle_terminus_panel"</span> <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"move_to"</span><span class="token punctuation">,</span> <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span><span class="token property">"to"</span><span class="token operator">:</span> <span class="token string">"bol"</span><span class="token punctuation">,</span> <span class="token property">"extend"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"move_to"</span><span class="token punctuation">,</span> <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span><span class="token property">"to"</span><span class="token operator">:</span> <span class="token string">"eol"</span><span class="token punctuation">,</span> <span class="token property">"extend"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">&#125;</span> <span class="token punctuation">&#125;</span>
<span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>Sublime配置文件：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
	<span class="token property">"theme"</span><span class="token operator">:</span> <span class="token string">"Default.sublime-theme"</span><span class="token punctuation">,</span>
	<span class="token property">"translate_tabs_to_spaces"</span><span class="token operator">:</span>  <span class="token boolean">true</span><span class="token punctuation">,</span>
	<span class="token property">"color_scheme"</span><span class="token operator">:</span> <span class="token string">"Packages/Color Scheme - Default/Monokai.tmTheme"</span><span class="token punctuation">,</span>
	<span class="token property">"font_face"</span><span class="token operator">:</span> <span class="token string">"Courier New"</span><span class="token punctuation">,</span>
	<span class="token property">"font_size"</span><span class="token operator">:</span> <span class="token number">18</span><span class="token punctuation">,</span>
	<span class="token property">"ignored_packages"</span><span class="token operator">:</span>
	<span class="token punctuation">[</span>
		<span class="token string">"Vintage"</span><span class="token punctuation">,</span>
	<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>Sumblime JSON格式化<br>安装Pretty JSON插件，command + shift + p，搜索 package install，进入后选择pretty json并安装<br>在sumblime里添加快捷键配置</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"ctrl+command+j"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"pretty_json"</span> <span class="token punctuation">&#125;</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="mac-安装homebrew"><a href="#mac-安装homebrew" class="headerlink" title="mac 安装homebrew"></a>mac 安装homebrew</h2><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">&#x2F;bin&#x2F;zsh -c &quot;$(curl -fsSL https:&#x2F;&#x2F;gitee.com&#x2F;cunkai&#x2F;HomebrewCN&#x2F;raw&#x2F;master&#x2F;Homebrew.sh)&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Mac安装mysql"><a href="#Mac安装mysql" class="headerlink" title="Mac安装mysql"></a>Mac安装mysql</h2><p>具体参考<br><a href="https://zhuanlan.zhihu.com/p/257006114">mac 安装mysql详细教程</a></p>
</li>
</ul>
<h2 id="Mac常用快捷键"><a href="#Mac常用快捷键" class="headerlink" title="Mac常用快捷键"></a>Mac常用快捷键</h2><p>Mac系统快捷键设置：<br>系统偏好设置 -&gt; 键盘 -&gt; 快捷键<br><code>command + 左右方向键</code>： 到句首/尾（下一个/上一个标点符号）<br><code>option + 左右方向键</code>：跳到行首/行尾<br><code>ctrl + 左右方向键</code>：切换后台进程（窗口），是直接上一个/下一个窗口<br><code>ctrl + 上下方向键</code>:  呼出所有后台进程（窗口）<br><code>shift + 中/英</code>：切换大小写<br><code>command + tab</code>:切换后台进程，按住command会有所有后台，然后按tab可以切换（只是图标）<br><code>command + 上下方向键</code>：进入上层文件夹（在访达里使用）<br><code>ctrl + command + Q</code>: 锁屏<br><code>command + 空格</code>：聚焦搜索<br><code>option + command + 空格</code>：在访达里搜索<br><code>option + command + D</code>:显示/隐藏程序坞<br><code>shift + command + 2</code>:截图到剪切板<br><code>option + command + T</code>:自动生成try catch<br><code>command + 7</code>: 打开/关闭structure<br><code>ctrl + option + o</code>: 自动删除java不用了的package</p>
<h2 id="开启-HIDPI，让-2K-显示器更舒适"><a href="#开启-HIDPI，让-2K-显示器更舒适" class="headerlink" title="开启 HIDPI，让 2K 显示器更舒适"></a>开启 HIDPI，让 2K 显示器更舒适</h2><p>mac自带的屏幕太小了，自己买的外接显示器是2k的，mac不会自动启动hidpi，所以字特别小，不好看。这里强行让mac知道可以启用hidpi<br>具体可以参考:<br><a href="https://sspai.com/post/57549">为 macOS 10.15 开启 HiDPI，让 2K 显示器更舒适</a></p>
<h2 id="Mac安装Hadoop、hive遇到的问题"><a href="#Mac安装Hadoop、hive遇到的问题" class="headerlink" title="Mac安装Hadoop、hive遇到的问题"></a>Mac安装Hadoop、hive遇到的问题</h2><p>具体的配置，会放到github上，之后再换电脑，直接从git上clone即可</p>
<ul>
<li><p>运行start-all.sh,报异常<code>golden-02: ssh: connect to host golden-02 port 22: Connection refused</code></p>
<blockquote>
<p>原因: mac原本没有打开远程访问的权限，即ssh到本机不通。<br>解决方法：系统偏好设置-&gt;共享-&gt;远程登录</p>
</blockquote>
</li>
<li><p><code>golden-02: gujincheng@golden-02: Permission denied (publickey,password,keyboard-interactive).</code></p>
<blockquote>
<p>原因：没有配置ssh免密钥<br>解决方法：cd ~/.ssh &amp;&amp; cat id_rsa.pub &gt;&gt; authorized_keys</p>
</blockquote>
</li>
<li><p>在HDFS管理页面，查看/tmp目录出现没有权限访问</p>
<blockquote>
<p>原因：core-site.xml的默认配置<code>hadoop.http.staticuser.user=dr.who</code><br>解决方法：在core-site.xml添加如下内容：</p>
</blockquote>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>gujincheng<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>不需要重新初始化namenode（<code>hdfs namenode -format</code>）</p>
</li>
<li><p>hive报错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>原因：安装包是直接复制过来的，mysql虽然重新安装了，但是hive的元数据没有重新初始化<br>解决方法：<code>schematool -dbType mysql -initSchema</code></p>
</blockquote>
</li>
</ul>
<h2 id="Mac终端设置ls颜色"><a href="#Mac终端设置ls颜色" class="headerlink" title="Mac终端设置ls颜色"></a>Mac终端设置ls颜色</h2><p>这种方式设置的颜色，会随着终端的颜色变化而变化，很实用。<br>具体步骤如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 1.下载安装 coreutils
brew install coreutils
# 2.创建颜色配置文件
gdircolors --print-database &gt; ~&#x2F;.dir_colors<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>编辑.zshrc</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">if brew list | grep coreutils &gt; &#x2F;dev&#x2F;null ; then
    PATH&#x3D;&quot;$(brew --prefix coreutils)&#x2F;libexec&#x2F;gnubin:$PATH&quot; 
    alias ls&#x3D;&#39;ls -F --show-control-chars --color&#x3D;auto&#39; 
    eval &#96;gdircolors -b $HOME&#x2F;.dir_colors&#96; 
fi

## 可以省略if条件，直接执行条件语句的内容
PATH&#x3D;&quot;$(brew --prefix coreutils)&#x2F;libexec&#x2F;gnubin:$PATH&quot; 
alias ls&#x3D;&#39;ls -F --show-control-chars --color&#x3D;auto&#39; 
eval &#96;gdircolors -b $HOME&#x2F;.dir_colors&#96; 
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>最后<code>source .zshrc</code></p>
<h2 id="Mac下使用netcat发送消息"><a href="#Mac下使用netcat发送消息" class="headerlink" title="Mac下使用netcat发送消息"></a>Mac下使用netcat发送消息</h2><p>直接使用nc命令，不知道为啥不行。<br>需要使用brew安装一下<code>brew install netcat</code><br><code>netcat -l -p 9999</code>:发送消息<br><code>netcat golden-02 9999</code>:接受消息<br>9999是端口号，默认是localhost</p>
<h2 id="MAC下设置全局环境变量"><a href="#MAC下设置全局环境变量" class="headerlink" title="MAC下设置全局环境变量"></a>MAC下设置全局环境变量</h2><p>当mac的执行环境是zsh的时候，设置环境变量不要在<code>.zshrc</code>里设置<br>原因是，<code>.zshrc</code>的环境变量只是当前用户的，在启动<code>hadoop</code>相关任务的时候，会报错找不到hadoop的环境变量<br>这里正确的设置方法是：</p>
<ol>
<li>在<code>/etc/profile</code>里配置相应的环境变量</li>
<li>在<code>.zshrc</code>里<code>source /etc/profile</code></li>
</ol>
<h2 id="谷歌浏览器快捷键"><a href="#谷歌浏览器快捷键" class="headerlink" title="谷歌浏览器快捷键"></a>谷歌浏览器快捷键</h2><table>
<thead>
<tr>
<th>快捷键</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>⌘ + N</td>
<td>打开新窗口</td>
</tr>
<tr>
<td>⌘-T</td>
<td>打开新标签页</td>
</tr>
<tr>
<td>⌘-Shift-N</td>
<td>在隐身模式下打开新窗口。</td>
</tr>
<tr>
<td>按 ⌘-O，然后选择文件。</td>
<td>在 Google Chrome 浏览器中打开计算机中的文件。</td>
</tr>
<tr>
<td>按住 Shift 键，然后点击链接。</td>
<td>在新窗口中打开链接。</td>
</tr>
<tr>
<td>按住 ⌘-Shift 键，然后点击链接。</td>
<td>在新标签页中打开链接并切换到刚打开的标签页。</td>
</tr>
<tr>
<td>同时按 ⌘-Option 和向右箭头键。</td>
<td>切换到下一个标签页。</td>
</tr>
<tr>
<td>同时按 ⌘-Option 和向左箭头键。</td>
<td>切换到上一个标签页。</td>
</tr>
<tr>
<td>⌘-W</td>
<td>关闭当前标签页或弹出窗口。</td>
</tr>
<tr>
<td>⌘-Shift-W</td>
<td>关闭当前窗口。</td>
</tr>
<tr>
<td>按住⌘ + Q</td>
<td>关闭浏览器</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>Sublime</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven杂记</title>
    <url>/2022/03/18/Maven%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Maven杂记</li>
</ul>
<a id="more"></a>


<h2 id="Maven配置cloudera源下载CDH依赖包"><a href="#Maven配置cloudera源下载CDH依赖包" class="headerlink" title="Maven配置cloudera源下载CDH依赖包"></a>Maven配置cloudera源下载CDH依赖包</h2><p>由于Cloudera Manager自动安装部署的Hadoop、Hbase，Zookeeper等组件与Apache提供的会有差异，所以需要配置为对应CDH版本的依赖包。</p>
<h3 id="添加cloudera仓库"><a href="#添加cloudera仓库" class="headerlink" title="添加cloudera仓库"></a>添加cloudera仓库</h3><p>在pom.xml，project标签内开头添加如下仓库：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repositories</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repository</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>cloudera<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repository</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repositories</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>不需要在settings.xml里添加</p>
]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB杂记</title>
    <url>/2021/01/18/MongoDB%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="collection表名包含特殊字符"><a href="#collection表名包含特殊字符" class="headerlink" title="collection表名包含特殊字符"></a>collection表名包含特殊字符</h2><p>   当collection表名包含特殊字符时，mongo sehll在find()等操作时会报错，这时候，可以使用getCollection函数，把表明以字符串的形式传进函数内<br>例如：  </p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">db.getCollection(&#39;all-aa-bb_cc_dd_20200129&#39;).find()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
]]></content>
      <categories>
        <category>大数据</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Mqtt调研</title>
    <url>/2022/10/27/Mqtt%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Mqtt简介</li>
<li>centos搭建EMQ mqtt服务器</li>
</ul>
<a id="more"></a>

<h2 id="Mqtt简介"><a href="#Mqtt简介" class="headerlink" title="Mqtt简介"></a>Mqtt简介</h2><h2 id="centos搭建EMQ-emqx服务器"><a href="#centos搭建EMQ-emqx服务器" class="headerlink" title="centos搭建EMQ emqx服务器"></a>centos搭建EMQ emqx服务器</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">curl -s https:&#x2F;&#x2F;assets.emqx.com&#x2F;scripts&#x2F;install-emqx-rpm.sh | sudo bash
yum install emqx
emqx start | stop | restart
emqx_ctl status
## 卸载
emqx uninstall
# 添加用户
emqx_ctl admins add gujc gujc@123
# 给admin用户赋密码
emqx_ctl admins passwd admin admin@123<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="默认占用的-TCP-端口"><a href="#默认占用的-TCP-端口" class="headerlink" title="默认占用的 TCP 端口"></a>默认占用的 TCP 端口</h3><table>
<thead>
<tr>
<th>端口</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td>1883</td>
<td>MQTT 协议端口</td>
</tr>
<tr>
<td>8883</td>
<td>MQTT/SSL 端口</td>
</tr>
<tr>
<td>8083</td>
<td>MQTT/WebSocket 端口</td>
</tr>
<tr>
<td>8080</td>
<td>HTTP API 端口</td>
</tr>
<tr>
<td>18083</td>
<td>Dashboard 管理控制台端口</td>
</tr>
</tbody></table>
<p>具体可以参考 <a href="https://blog.csdn.net/qq_37634156/article/details/123223538">centos搭建EMQ mqtt服务器</a></p>
<h3 id="MQTT-Flink实现实时消息的订阅与发布"><a href="#MQTT-Flink实现实时消息的订阅与发布" class="headerlink" title="MQTT+Flink实现实时消息的订阅与发布"></a>MQTT+Flink实现实时消息的订阅与发布</h3><p>具体可以参考<a href="https://blog.csdn.net/weixin_43222122/article/details/114586944">MQTT+Flink实现实时消息的订阅与发布</a></p>
<h2 id="Centos安装mosquitto"><a href="#Centos安装mosquitto" class="headerlink" title="Centos安装mosquitto"></a>Centos安装mosquitto</h2><p>在使用EMQX过程中，发现设置Qos不生效，具体情况表现为：<br>当Qos=1时：</p>
<ol>
<li>不启动consumer，数据发送会被直接丢弃</li>
<li>启动consumer，被丢弃的数据不会重发，不会被消费掉，但是启动了consumer后，再次发送消息，就能正常消费</li>
<li>再次停止consumer，再次发送新的消息，数据会存储在类似一个队列里，再次启动consumer会把消息一口气消费进来</li>
<li>停止consumer，并把session也关闭，发送数据，这时候数据还是会被直接丢弃掉<br>当Qos=0的时候，效果和Qos=1一摸一样，没有生效</li>
</ol>
<p>这里考虑使用mosquitto测试一下看看，首先安装</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yum -y install epel-release
yum -y install mosquitto
# 启动mosquitto
systemctl start mosquitto
# 开机自启
systemctl enable mosquitto<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>测试案例：</p>
<ol>
<li>发布消息<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mosquitto_pub -h localhost -t &quot;test&quot; -i &quot;client2&quot; -q 0 -m &quot;bbb&quot; # -q 0 代表qos&#x3D;0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
参数说明：<pre class="line-numbers language-text" data-language="text"><code class="language-text">-d 打印debug信息
-f 将指定文件的内容作为发送消息的内容
-h 指定要连接的域名 默认为localhost
-i 指定要给哪个clientId的用户发送消息
-I 指定给哪个clientId前缀的用户发送消息
-m 消息内容
-n 发送一个空（null）消息
-p 连接端口号（小写）
-q 指定QoS的值（0,1,2）
-t 指定topic
-u 指定broker访问用户
-P 指定broker访问密码（大写）
-V 指定MQTT协议版本
--will-payload 指定一个消息，该消息当客户端与broker意外断开连接时发出。该参数需要与--will-topic一起使用
--will-qos Will的QoS值。该参数需要与--will-topic一起使用
--will-retain 指定Will消息被当做一个retain消息（即消息被广播后，该消息被保留起来）。该参数需要与--will-topic一起使用
--will-topic 用户发送Will消息的topic<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>订阅消息<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mosquitto_sub -c -h localhost -t &quot;test&quot; -i &quot;client1&quot; -q 0 # -c 代表<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
参数说明：<pre class="line-numbers language-text" data-language="text"><code class="language-text">-c 设定‘clean session’为无效状态，这样一直保持订阅状态，即便是已经失去连接，如果再次连接仍旧能够接收的断开期间发送的消息。
-d 打印debug信息
-h 指定要连接的域名 默认为localhost
-i 指定clientId
-I 指定clientId前缀
-k keepalive 每隔一段时间，发PING消息通知broker，仍处于连接状态。 默认为60秒。
-q 指定希望接收到QoS为什么的消息 默认QoS为0
-R 不显示陈旧的消息
-t 订阅topic
-v 打印消息
-u 指定broker访问用户
-P 指定broker访问密码（大写）
--will-payload 指定一个消息，该消息当客户端与broker意外断开连接时发出。该参数需要与--will-topic一起使用
--will-qos Will的QoS值。该参数需要与--will-topic一起使用
--will-retain 指定Will消息被当做一个retain消息（即消息被广播后，该消息被保留起来）。该参数需要与--will-topic一起使用
--will-topic 用户发送Will消息的topic<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
测试结果，使用mosquitto能达到预期效果，不知道EMQX是不是哪里设置不对，还是开源版有bug</li>
</ol>
<h2 id="自定义flume-mqtt-source"><a href="#自定义flume-mqtt-source" class="headerlink" title="自定义flume-mqtt source"></a>自定义flume-mqtt source</h2><p>自定义flume source比较简单，网上一大堆，这里直接上代码</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">package org.apache.flume.source.mqtt;

import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.PollableSource;
import org.apache.flume.conf.Configurable;
import org.apache.flume.conf.ConfigurationException;
import org.apache.flume.event.EventBuilder;
import org.apache.flume.source.AbstractSource;
import org.eclipse.paho.client.mqttv3.*;
import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.ArrayList;
import java.util.List;

public class MqttSource extends AbstractSource
        implements Configurable, PollableSource &#123;

    private static final Logger log &#x3D; LoggerFactory.getLogger(MqttSource.class);

    private String host;
    private String topic;
    private Integer qos;
    private Integer batchSize;

    private Boolean cleanSession;
    private Integer connectionTimeout;
    private Integer keepAliveInterval;
    private String username;
    private String password;
    private Boolean retryConnection;

    private String clientId &#x3D; MqttSourceConstants.getUuid();

    private MemoryPersistence memoryPersistence &#x3D; null;
    private MqttConnectOptions mqttConnectOptions &#x3D; null;
    private MqttClient mqttClient &#x3D; null;

    private Context context;
    private Event event;
    private final List&lt;Event&gt; eventList &#x3D; new ArrayList&lt;Event&gt;();

    &#x2F;**
     * Process business
     *
     * @return
     *&#x2F;
    @Override
    public Status process() &#123;

        if (null !&#x3D; mqttClient &amp;&amp; mqttClient.isConnected()) &#123;
            if (null !&#x3D; topic &amp;&amp; null !&#x3D; qos) &#123;
                try &#123;
                    mqttClient.subscribe(topic, qos);
                &#125; catch (MqttException e) &#123;
                    log.error(&quot;Subscription topic &#123;&#125; has an exception, the exception is: &#123;&#125;&quot;, topic, e.fillInStackTrace());
                &#125;
            &#125; else &#123;
                throw new ConfigurationException(&quot;Mqtt host or topic config error.&quot;);
            &#125;
            return Status.READY;
        &#125; else &#123;
            if (retryConnection) &#123;
                log.error(&quot;The MQTT connection is disconnected and reconnected ......&quot;);
                reConnect();
                return Status.READY;
            &#125;
            return Status.BACKOFF;
        &#125;
    &#125;

    @Override
    public long getBackOffSleepIncrement() &#123;
        return 0;
    &#125;

    @Override
    public long getMaxBackOffSleepInterval() &#123;
        return 0;
    &#125;

    &#x2F;**
     * Mqtt configure
     *
     * @param context
     *&#x2F;
    @Override
    public void configure(Context context) &#123;
        this.context &#x3D; context;

        host &#x3D; context.getString(MqttSourceConstants.HOST);
        log.info(&quot;host &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; &#123;&#125;&quot; ,host);
        if (host &#x3D;&#x3D; null) &#123;
            throw new ConfigurationException(&quot;Mqtt host must be specified.&quot;);
        &#125;

        topic &#x3D; context.getString(MqttSourceConstants.TOPIC);
        log.info(&quot;topic &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt; &#123;&#125;&quot; ,topic);
        if (topic &#x3D;&#x3D; null) &#123;
            throw new ConfigurationException(&quot;Mqtt topic must be specified.&quot;);
        &#125;

        qos &#x3D; context.getInteger(MqttSourceConstants.QOS, MqttSourceConstants.DEFAULT_QOS);
        batchSize &#x3D; context.getInteger(MqttSourceConstants.BATCH_SIZE);

        cleanSession &#x3D; context.getBoolean(MqttSourceConstants.IF_SESSION_CLEAN, MqttSourceConstants.DEFAULT_IF_SESSION_CLEAN);
        connectionTimeout &#x3D; context.getInteger(MqttSourceConstants.CONNECTION_TIMEOUT, MqttSourceConstants.DEFAULT_CONNECTION_TIMEOUT);
        keepAliveInterval &#x3D; context.getInteger(MqttSourceConstants.KEEP_ALIVE_INTERVAL, MqttSourceConstants.DEFAULT_KEEP_ALIVE_INTERVAL);

        username &#x3D; context.getString(MqttSourceConstants.USERNAME);
        password &#x3D; context.getString(MqttSourceConstants.PASSWORD);

        retryConnection &#x3D; context.getBoolean(MqttSourceConstants.RETRY_CONNECTION, MqttSourceConstants.DEFAULT_RETRY_CONNECTION);
    &#125;

    &#x2F;**
     * Start Job
     *&#x2F;
    @Override
    public synchronized void start() &#123;
        log.info(&quot;Starting mqtt source job ......&quot;);

        mqttConnectOptions &#x3D; new MqttConnectOptions();
        memoryPersistence &#x3D; new MemoryPersistence();

        if (null !&#x3D; memoryPersistence &amp;&amp; null !&#x3D; host) &#123;
            try &#123;
                mqttClient &#x3D; new MqttClient(host, clientId, memoryPersistence);
            &#125; catch (MqttException e) &#123;
                throw new ConfigurationException(&quot;Mqtt host config error and error message : &#123;&#125;&quot;, e.fillInStackTrace());
            &#125;
        &#125;

        if (null !&#x3D; mqttConnectOptions) &#123;

            mqttConnectOptions.setCleanSession(cleanSession);
            mqttConnectOptions.setConnectionTimeout(connectionTimeout);
            mqttConnectOptions.setKeepAliveInterval(keepAliveInterval);
            if (null !&#x3D; username) &#123;
                mqttConnectOptions.setUserName(username);
            &#125;
            if (null !&#x3D; password) &#123;
                mqttConnectOptions.setPassword(password.toCharArray());
            &#125;

            if (null !&#x3D; mqttClient &amp;&amp; !mqttClient.isConnected()) &#123;

                mqttClient.setCallback(new MqttCallback() &#123;
                    @Override
                    public void connectionLost(Throwable cause) &#123;
                        log.error(&quot;MqttClient disconnect call back retry connect......&quot;);
                        reConnect();
                    &#125;

                    @Override
                    public void messageArrived(String topic, MqttMessage message) &#123;
                        event &#x3D; EventBuilder.withBody(message.getPayload());
                        if (null &#x3D;&#x3D; batchSize) &#123;
                            getChannelProcessor().processEvent(event);
                        &#125; else if (eventList.size() &lt; batchSize) &#123;
                            eventList.add(event);
                        &#125; else &#123;
                            getChannelProcessor().processEventBatch(eventList);
                            eventList.clear();
                        &#125;
                    &#125;

                    @Override
                    public void deliveryComplete(IMqttDeliveryToken token) &#123;
                    &#125;
                &#125;);

                try &#123;
                    mqttClient.connect(mqttConnectOptions);
                &#125; catch (MqttException e) &#123;
                    log.error(&quot;Get the MQTT connection exception, exception information is : &#123;&#125;&quot;, e.fillInStackTrace());
                    reConnect();
                &#125;
            &#125;
        &#125;
    &#125;

    &#x2F;**
     * 重连
     *&#x2F;
    public void reConnect() &#123;

        try &#123;
            Thread.sleep(10000);
        &#125; catch (InterruptedException e) &#123;
            log.error(&quot;Retry Get the MQTT Thread sleep exception, exception information is : &#123;&#125;&quot;, e.fillInStackTrace());
        &#125;

        if (null !&#x3D; mqttClient &amp;&amp; !mqttClient.isConnected() &amp;&amp; null !&#x3D; mqttConnectOptions) &#123;
            try &#123;
                mqttClient.connect(mqttConnectOptions);
            &#125; catch (MqttException e) &#123;
                log.error(&quot;Retry Get the MQTT connection exception, exception information is : &#123;&#125;&quot;, e.fillInStackTrace());
            &#125;
        &#125; else &#123;
            start();
        &#125;
    &#125;

    &#x2F;**
     * close source
     *&#x2F;
    @Override
    public synchronized void stop() &#123;
        if (mqttClient !&#x3D; null) &#123;
            try &#123;
                mqttClient.close();
            &#125; catch (MqttException e) &#123;
                log.error(&quot;mqttClient close an error occurs : &#123;&#125;&quot;, e.fillInStackTrace());
            &#125;
        &#125;

        if (mqttConnectOptions !&#x3D; null) &#123;
            mqttConnectOptions &#x3D; null;
        &#125;

        if (memoryPersistence !&#x3D; null) &#123;
            try &#123;
                memoryPersistence.close();
            &#125; catch (MqttPersistenceException e) &#123;
                log.error(&quot;memoryPersistence close an error occurs : &#123;&#125;&quot;, e.fillInStackTrace());
            &#125;
        &#125;

        log.info(&quot;Mqtt Source &#123;&#125; stopped success.&quot;, getName());
        super.stop();
    &#125;

&#125;


package org.apache.flume.source.mqtt;

import java.util.UUID;


public class MqttSourceConstants &#123;

    public static final String HOST &#x3D; &quot;host&quot;;
    public static final String TOPIC &#x3D; &quot;topic&quot;;

    public static final String QOS &#x3D; &quot;qos&quot;;
    public static final String BATCH_SIZE &#x3D; &quot;batchSize&quot;;

    public static final String USERNAME &#x3D; &quot;username&quot;;
    public static final String PASSWORD &#x3D; &quot;password&quot;;

    public static final String IF_SESSION_CLEAN &#x3D; &quot;cleanSession&quot;;
    public static final String CONNECTION_TIMEOUT &#x3D; &quot;connectionTimeout&quot;;
    public static final String KEEP_ALIVE_INTERVAL &#x3D; &quot;keepAliveInterval&quot;;

    public static final String RETRY_CONNECTION &#x3D; &quot;retryConnection&quot;;

    public static final Integer DEFAULT_QOS &#x3D; 1;

    public static final Boolean DEFAULT_IF_SESSION_CLEAN &#x3D; false;
    public static final Integer DEFAULT_CONNECTION_TIMEOUT &#x3D; 30;
    public static final Integer DEFAULT_KEEP_ALIVE_INTERVAL &#x3D; 60;

    public static final Boolean DEFAULT_RETRY_CONNECTION &#x3D; false;

    public static String getUuid() &#123;
        return UUID.randomUUID().toString().replaceAll(&quot;-&quot;, &quot;&quot;).substring(0, 8);
    &#125;

&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>任务配置：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 配置文件名称为 mqtt.conf
# 指定Source的类型

agent.sources &#x3D; mqtt
agent.channels &#x3D; memory-channel
agent.sinks &#x3D; logger

agent.sources.mqtt.type &#x3D; org.apache.flume.source.mqtt.MqttSource
agent.sources.mqtt.host &#x3D; tcp:&#x2F;&#x2F;150.158.190.192:1883
agent.sources.mqtt.topic &#x3D; flume-demo
agent.sources.mqtt.qos &#x3D; 1
#agent.sources.mqtt.batchSize &#x3D; 1000
agent.sources.mqtt.cleanSession &#x3D; false
agent.sources.mqtt.connectionTimeout &#x3D; 10
agent.sources.mqtt.keepAliveInterval &#x3D; 100
#agent.sources.mqtt.username &#x3D; admin
#agent.sources.mqtt.password &#x3D; admin@123
agent.sources.mqtt.retryConnection &#x3D; true

agent.channels.memory-channel.type &#x3D; memory

agent.sinks.logger.type &#x3D; logger

agent.sources.mqtt.channels &#x3D; memory-channel
agent.sinks.logger.channel &#x3D; memory-channel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>任务启动：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flume-ng agent --name agent --conf $FLUME_HOME&#x2F;conf --conf-file mqtt.conf -Dflume.root.logger&#x3D;INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里需要注意的是，–name 的值，应该与配置文件里的一样，这里一开始测试的时候，写成了mqtt，导致flume获取不到任务配置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">02 十一月 2022 17:29:35,413 INFO  [main] (org.apache.flume.node.Application.startAllComponents:207)  - Starting new configuration:&#123; sourceRunners:&#123;&#125; sinkRunners:&#123;&#125; channels:&#123;&#125; &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Mqtt</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis杂记</title>
    <url>/2021/01/18/Redis%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>什么是Redis</li>
<li>Redis有哪些优缺点</li>
<li>为什么要用 Redis 而不用 map/guava 做缓存?</li>
<li>Redis为什么这么快</li>
<li>Redis的应用场景</li>
<li>Redis持久化</li>
<li>Redis踩的坑</li>
</ul>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h3><p>Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。<br>Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求<br><img src="/uploads/20211109/Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" alt="Redis数据类型"></p>
<p>以上可以参考<a href="https://www.cnblogs.com/javazhiyin/p/13839357.html">Redis 常见面试题</a></p>
<h2 id="Redis踩的坑"><a href="#Redis踩的坑" class="headerlink" title="Redis踩的坑"></a>Redis踩的坑</h2><p>最近在测试任务的时候，把reids的key和value写反了，导致生产环境的reids凭空多了200多万脏数据，在网上查了一个批量删除的命令，直接在生产环境执行了，导致redis宕机、OOM了</p>
<p>所以，以后再操作生产环境数据库，特别是删除、大规模数据遍历、消耗性能比较大的情况下，在网上查的命令最好还是在测试环境测试一下再用，多么痛的领悟</p>
<p>这里记录一下两个命令：</p>
<h3 id="错误的命令"><a href="#错误的命令" class="headerlink" title="错误的命令"></a>错误的命令</h3><p>在数据量较大的情况下，千万别用类似keys *的操作，keys会把reids里所有的key一口气都遍历一遍，消耗性能奇高。。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;pws&#125;&#39; keys &#39;0^!*&#39; |xargs redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;psw&#125;&#39; DEL<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="正确的命令："><a href="#正确的命令：" class="headerlink" title="正确的命令："></a>正确的命令：</h3><p>在生产环境下，尽量使用scan</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;psw&#125;&#39; --scan --pattern &quot;0^!*&quot; | xargs -L 1000 redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;psw&#125;&#39; del<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>具体可以参考：<a href="https://zhuanlan.zhihu.com/p/102092251">Redis 千万不要乱用KEYS命令，不然会挨打的</a>  </p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala杂记</title>
    <url>/2021/01/18/Scala%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>使用Scala解析Json</li>
</ul>
<a id="more"></a>
<h3 id="解析json"><a href="#解析json" class="headerlink" title="解析json"></a>解析json</h3><p>个人认为，解析json用的最多的就是fastjson了<br>使用前需要在pom文件中引用：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.alibaba<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>fastjson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.47<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码案例：</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> jsonStr <span class="token operator">=</span>
  <span class="token triple-quoted-string string">"""
    |[
    |        &#123;
    |            "type_name" : "aa",
    |            "score" : 0.9995,
    |            "classcode" : "a1:0.2136;a2:0.2136;a3:0.2136;a4:0.1582;a5:0.1578;a6:0.0429;a7:0.0004"
    |        &#125;,
    |        &#123;
    |            "type_name" : "bb",
    |            "score" : 0.0005,
    |            "classcode" : "b1:0.5000;b2:0.5000"
    |        &#125;
    |    ]
    |"""</span><span class="token punctuation">.</span>stripMargin
<span class="token keyword">val</span> typeTageArr <span class="token operator">=</span> mutable<span class="token punctuation">.</span>ArrayBuffer<span class="token punctuation">[</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token string">""</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>jsonStr<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token string">"[]"</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>jsonStr<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">val</span> jsonArr <span class="token operator">=</span> JSON<span class="token punctuation">.</span>parseArray<span class="token punctuation">(</span>jsonStr<span class="token punctuation">)</span>
  <span class="token keyword">val</span> houses <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0</span> until jsonArr<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>jsonArr<span class="token punctuation">.</span>getJSONObject<span class="token punctuation">)</span><span class="token punctuation">.</span>toArray
  <span class="token keyword">for</span><span class="token punctuation">(</span>jsMap <span class="token keyword">&lt;-</span> houses<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> typeName <span class="token operator">=</span> jsMap<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"type_name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString
    <span class="token keyword">val</span> classCode <span class="token operator">=</span> jsMap<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"classcode"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">";"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">":"</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
    typeTageArr <span class="token operator">+=</span> Map<span class="token punctuation">(</span><span class="token string">"type"</span> <span class="token operator">-></span> typeName<span class="token punctuation">,</span><span class="token string">"classTags"</span> <span class="token operator">-></span> classCode<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="array转json"><a href="#array转json" class="headerlink" title="array转json"></a>array转json</h3><p>一开始使用JSON.toJSONString(typeTageArr)这种方式，但是报如下错</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">error: ambiguous reference to overloaded definition,
both method toJSONString in object JSON of type (x$1: Any, x$2: com.alibaba.fastjson.serializer.SerializerFeature*)String
and  method toJSONString in object JSON of type (x$1: Any)String<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>从报错的信息当中我们得知是scala对对重载定义的模糊引用造成，从fastjson的源码中可以看到，有两个toJSONString的方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token class-name">Object</span> object<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> emptyFilters<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token class-name">Object</span> object<span class="token punctuation">,</span> <span class="token class-name">SerializerFeature</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> features<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> DEFAULT_GENERATE_FEATURE<span class="token punctuation">,</span> features<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在第二个方法中SerializerFeature… features 是一个可变长参数，带有变长参数的方法重载使得scala在调用方法时感到“模糊”，就无法匹配参数的类型</p>
<p>所以在array或者map转json对象的时候，使用json4s比较好<br>使用案例：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>json4s<span class="token punctuation">.</span></span><span class="token class-name">JsonDSL</span><span class="token punctuation">.</span>_
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>json4s<span class="token punctuation">.</span>jackson<span class="token punctuation">.</span></span><span class="token class-name">JsonMethods</span><span class="token punctuation">.</span>_
<span class="token function">compact</span><span class="token punctuation">(</span><span class="token function">render</span><span class="token punctuation">(</span>typeTageArr<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>使用起来很方便</p>
<h2 id="Scala中调用方法和函数"><a href="#Scala中调用方法和函数" class="headerlink" title="Scala中调用方法和函数"></a>Scala中调用方法和函数</h2><p>Scala中的+ - * / %等操作符的作用与Java一样，位操作符 &amp; | ^ &gt;&gt; &lt;&lt;也一样。只是有一点特别的：这些操作符实际上是方法。例如：<br><code>a + b</code>是<code>a.+(b)</code>的简写<br><code>a 方法 b</code>可以写成 <code>a.方法(b)</code></p>
<h2 id="Scala-方法和函数的区别"><a href="#Scala-方法和函数的区别" class="headerlink" title="Scala 方法和函数的区别"></a>Scala 方法和函数的区别</h2><p>可以参考<a href="https://www.huaweicloud.com/articles/da048fd844830f817cc39b6cf484cc16.html">Scala 方法与函数</a><br>Scala 方法与函数,二者在语义上的区别很小,Scala 方法是类的一部分，而函数是一个对象可以赋值给一个变量。换句话来说在类中定义的函数即是方法。<br>Scala 中使用<code>val</code>语句可以定义函数，<code>def</code>语句定义方法。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala面试题</title>
    <url>/2021/12/06/Scala%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Scala面试题总结</li>
</ul>
<a id="more"></a>


<p><strong><font size = 5>1. 方法和函数的区别？</font></strong><br>Scala 方法与函数,二者在语义上的区别很小,Scala 方法是类的一部分，而函数是一个对象可以赋值给一个变量。换句话来说在类中定义的函数即是方法。<br>Scala 中使用<code>val</code>语句可以定义函数，<code>def</code>语句定义方法。</p>
<p><strong><font size = 5>2. Scala类型系统中Nil, Null, None, Nothing四个类型的区别？？</font></strong><br>Null是一个trait（特质），是所以引用类型AnyRef的一个子类型，null是Null唯一的实例。<br>Nothing也是一个trait（特质），是所有类型Any（包括值类型和引用类型）的子类型，它不在有子类型，它也没有实例，实际上为了一个方法抛出异常，通常会设置一个默认返回类型。<br>Nil代表一个List空类型，等同List[Nothing]<br>None是Option monad的空标识（深入了解请参考问题Q11）</p>
<p><strong><font size = 5>3. 什么是高阶函数？</font></strong><br>高阶函数指能接受或者返回其他函数的函数，scala中的filter map flatMap函数都能接受其他函数作为参数。</p>
<p><strong><font size = 5>4. 什么是隐式转换？</font></strong><br>通过隐式转换，程序员可以在编写Scala程序时故意漏掉一些信息，让编译器去尝试在编译期间自动推导出这些信息来，这种特性可以极大的减少代码量，忽略那些冗长，过于细节的代码<br>隐式转换必须满足无歧义规则，在声明隐式参数的类型是最好使用特别的或自定义的数据类型，不要使用Int,String这些常用类型，避免碰巧匹配<br>调用方法：</p>
<ol>
<li>将方法或变量标记为implicit</li>
<li>将方法的参数列表标记为implicit</li>
<li>将类标记为implicit</li>
</ol>
<p>Scala支持3种形式的隐式转换：<br>隐式值：用于给方法提供参数<br>隐式视图：用于类型间转换或使针对某类型的方法能调用成功<br>隐式类：使用implicit声明类</p>
<p><strong><font size = 5>5. scala的模式匹配？</font></strong><br>有点类似于Java语言的 switch，但其实还是有很大的不同的</p>
<ul>
<li>java 的 switch 仅仅会做一些基本类型的匹配，然后执行一些动作，并且是没有返回值的。</li>
<li>scala 的模式匹配除了可以匹配数值，同时它还能匹配类型，同时它还是有返回值的</li>
</ul>
]]></content>
      <categories>
        <category>面试题</category>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Selenium与PhantomJS踩过的坑</title>
    <url>/2021/01/16/Selenium%E4%B8%8EPhantomJS%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Selenium与PhantomJS踩过的坑<a id="more"></a>
<h2 id="Selenium与PhantomJS踩过的坑"><a href="#Selenium与PhantomJS踩过的坑" class="headerlink" title="Selenium与PhantomJS踩过的坑"></a>Selenium与PhantomJS踩过的坑</h2><h3 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h3>Selenium是一个Web的自动化测试工具，最初是为网站自动化测试而开发的，类型像我们玩游戏用的按键精灵，可以按指定的命令自动化操作，不同是Selenium可以直接运行在浏览器上，它支持所有主流的浏览器(包括PhantomJS这些无界面的浏览器)。</li>
</ul>
<p>Selenium可以根据我们的指令，让浏览器自动加载页面，获取需要的页面，甚至页面截屏，或者判断网站上某些动作是否发生。</p>
<p>Selenium自己不带浏览器，不支持浏览器的功能，它需要与第三方浏览器结合在一起才能使用。但是我们有时候需要让它内嵌在代码中运行，所有我们需要用一个叫PhantomJS的工具代替真实的浏览器。</p>
<h4 id="Selenium的安装"><a href="#Selenium的安装" class="headerlink" title="Selenium的安装"></a>Selenium的安装</h4><p>直接通过pip安装即可，这里没什么坑</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install selenium<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="PhantomJS"><a href="#PhantomJS" class="headerlink" title="PhantomJS"></a>PhantomJS</h3><p>PhantomJS是一个基于Webkit的”无界面”(headless)浏览器，它会把网站加载到内存并执行页面上的JavaScript，因为不会展示图形界面，所以运行起来比完整的浏览器更高效。</p>
<p>如果我们把Selenium和PhantomJS结合在一起，就可以运行一个非常强大的网络爬虫了，这个爬虫可以处理JavaScript、Cookie、headers，以及任何我们真实用户需要做的事情。</p>
<h4 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h4><ul>
<li>PhantomJS只能从它的网站(<a href="http://phantomjs.org/download.html)%E4%B8%8B%E8%BD%BD%E3%80%82">http://phantomjs.org/download.html)下载。</a></li>
<li>因为PhantomJS是一个功能完善(虽然无界面)的浏览器而非一个Python库，所以它不需要像Python的其它库一样安装，但我们可以通过Selenium调用PhantomJS来直接使用</li>
<li>PhantomsJS官方才考文档：<a href="http://phantomjs.org/documention">http://phantomjs.org/documention</a></li>
<li>这里不能通过pip、apt-get，yum等方式安装，一开始在自己虚拟机通过apt-get安装，但是一直报错。后来又全卸载，重新通过官网下载手动安装才行。</li>
<li>在自己的远程服务器中运行代码，报错：<pre class="line-numbers language-python" data-language="python"><code class="language-python">TypeError<span class="token punctuation">:</span> urlopen<span class="token punctuation">(</span><span class="token punctuation">)</span> got multiple values <span class="token keyword">for</span> keyword argument <span class="token string">'body'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
原因是服务器的urllib3版本太低，卸载以后重装就好了<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo apt-get remove python-urllib3
sudo pip install -U urllib3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
下面是代码：<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#-*-  coding:utf-8 -*-</span>
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>keys <span class="token keyword">import</span> Keys
<span class="token keyword">import</span> time
driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>PhantomJS<span class="token punctuation">(</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"www.wangzhi.com"</span><span class="token punctuation">)</span>  <span class="token comment">#穿入你的网址</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"email"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"aaa@qq.com"</span><span class="token punctuation">)</span> <span class="token comment">#按F12，查看网页源代码中登录界面的name传参是什么</span>
<span class="token comment"># 我的网页：&lt;input id="loginEmail" class='login_input' type="text" name="email" placeholder="请输入您的邮箱"></span>
<span class="token comment"># 所以 find_element_by_name("email")里面穿的是email，pwd一样，find_element_by_id也一样</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"pwd"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'111111'</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"loginButton"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>save_screenshot<span class="token punctuation">(</span><span class="token string">'broad.png'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

</li>
</ul>
<h3 id="服务器没有中文字体"><a href="#服务器没有中文字体" class="headerlink" title="服务器没有中文字体"></a>服务器没有中文字体</h3><p>所有都准备好了，原本以为万事大吉，但是发现截图的内容，不能显示中文。<br>在网上查了原因是系统没有装中文字体。<br>安装字体可以参考<a href="https://www.jianshu.com/p/e7f12b8c8602">https://www.jianshu.com/p/e7f12b8c8602</a></p>
<h3 id="中文字体解决以后，又出现了截图页面不完整"><a href="#中文字体解决以后，又出现了截图页面不完整" class="headerlink" title="中文字体解决以后，又出现了截图页面不完整"></a>中文字体解决以后，又出现了截图页面不完整</h3><p>最后在网上查了原因 ，是因为分辨率的原因<br>在代码上添加</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">driver<span class="token punctuation">.</span>set_window_size<span class="token punctuation">(</span><span class="token number">1366</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>完整代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#-*-  coding:utf-8 -*-</span>
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>keys <span class="token keyword">import</span> Keys
<span class="token keyword">import</span> time
driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>PhantomJS<span class="token punctuation">(</span>service_args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'--ignore-ssl-errors=true'</span><span class="token punctuation">,</span> <span class="token string">'--ssl-protocol=any'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"yourwebsite"</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>set_window_size<span class="token punctuation">(</span><span class="token number">1366</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">)</span> <span class="token comment">#这里必须加在get网页的后面，加在它之前没用</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"email"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"你的用户名"</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"pwd"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'你的密码'</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"loginButton"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>save_screenshot<span class="token punctuation">(</span><span class="token string">'/data/jenkins/broadcastPicture/broad.png'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>因为截图涉及公司数据，就不粘贴到这里了。</p>
<p>实践过程中，通过参考 <a href="https://www.cnblogs.com/miqi1992/p/8093958.html">Python爬虫(二十一)_Selenium与PhantomJS</a>实现了自动截图，<br>参考<a href="https://www.cnblogs.com/miqi1992/p/8120185.html">Python爬虫(二十二)_selenium案例：模拟登陆豆瓣</a>实现了自动登录  </p>
]]></content>
      <categories>
        <category>爬虫</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Selenium</tag>
        <tag>PhantomJS</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark面试题</title>
    <url>/2021/11/18/Spark%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Spark面试题总结</li>
</ul>
<a id="more"></a>


<p><strong><font size = 5>1. 对于 Spark 中的数据倾斜问题你有什么好的方案?</font></strong><br>数据倾斜是因为数据中的key分布的不均匀导致的。</p>
<ol>
<li>可以把小表广播出去或者使用<code>map join</code></li>
<li>采样倾斜key并分拆join操作，对倾斜key做添加随机数处理。</li>
<li>如果其中一个表存在多个key倾斜，把主表的所有key都添加1-n随机数，把从表每条数据都复制n次，并添加1-n的随机数，然后再join</li>
<li>自定义Partitioner：原始的spark使用的是hashPartition，可以自定义一个paritioner，把key拆分到多个task里去</li>
<li>提高shuffle操作的并行度，使用reduceByKey(1000)，sparkSQL里设置<code>spark.sql.shuffle.partitions=1000</code></li>
</ol>
<p><strong><font size = 5>2. 描述一下RDD,DataFrame,DataSet,DataStream的区别和联系？</font></strong><br>RDD：弹性分布式数据集，RDD是SparkCore的基本数据结构<br>DataFrame: 从源码上看，DataFrame其实就是指定row的DataSet，<code>type DataFrame = Dataset[Row]</code><br>DataSet：Dataset是一个由特定领域的对象组成强类型集合，可以使用函数（DSL）或关系运算（SQL）进行并行的转换操作。 每个Dataset 还有一个称为“DataFrame”的无类型（untypedrel）视图，它是[[Row]]的数据集。<br>Dataset和DataFrame的区别与联系：<br>1、Dataset是强类型，会在编译的时候进行类型检测；而DataFrame是弱类型的，在执行的时候进行类型检测；<br>2、序列化方式不通，Dataset是通过Encoder进行序列化，支持动态的生成代码，直接在bytes的层面进行排序，过滤等的操作；而DataFrame是采用可选的java的标准序列化或是kyro进行序列化<br>3、DataFrame和Dataset实质上都是一个逻辑计划，并且是懒加载的，都包含着scahema信息，只有到数据要读取的时候，才会将逻辑计划进行分析和优化，并最终转化为RDD<br>4、二者由于api是统一的，所以都可以采用DSL和SQL方式进行开发，都可以通过sparksession对象进行创建或者是通过transform转化操作得到<br>Dataset和RDD的区别与联系：<br>首先，Dataset的底层不是RDD，但是它可以和RDD互相转化，DS的一些算子例如filter等都是自己实现的，并没有调用RDD的算子<br>DStream：离散化流（DStream），SparkStreaming中的基本抽象，DSream 代表了一系列连续的RDD，DStream中每个RDD包含特定时间间隔的数据，一个DStream 对应了时间维度上的多个RDD。</p>
<p><strong><font size = 5>3. 简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数? </font></strong><br>窄依赖：每一个父RDD的partition最多被子RDD的一个partition使用<br>宽依赖：多个子RDD的partition会依赖同一个父RDD的partition<br>spark根据RDD的依赖关系划分stage，遇到一个宽依赖，就划分一个stage<br>stage中task数目由stage末端的RDD分区个数来决定</p>
<p><strong><font size = 5>4. 列举Spark常用的transformation和action算子，有哪些算子会导致Shuffle?</font></strong><br>transformation算子：map、flatMap、reduceByKey、groupByKey、filter等<br>action算子：take、ccollect、count、reduce等<br>reduceByKey、groupByKey等会产生Shuffle<br>注意：<br>reduceByKey和groupByKey只是会产生shuffle，但是不是action算子</p>
<p><strong><font size = 5>5. 简述下Spark中的缓存(cache和persist)与checkpoint机制，并指出两者的区别和联系</font></strong><br>cache缓存到内存中<br>persist可以缓存到磁盘和内存里<br>checkpoint只能缓存到hdfs上（磁盘上）<br>Persist 和 Cache，不会丢掉RDD间的依赖链/依赖关系，CheckPoint会斩断依赖链</p>
<p><strong><font size = 5>6. Spark开发调优总结</font></strong></p>
<ol>
<li>避免创建重复的RDD</li>
<li>尽可能复用同一个RDD</li>
<li>对多次使用的RDD进行持久化</li>
<li>尽量避免使用shuffle类算子</li>
<li>使用map-side预聚合的shuffle操作</li>
<li>使用高性能的算子<br> 6.1 使用reduceByKey/aggregateByKey替代groupByKey<br> 6.2 使用mapPartitions替代普通map<br> 6.3 使用foreachPartitions替代foreach<br> 6.4 使用filter之后进行coalesce操作<br> 6.4 使用repartitionAndSortWithinPartitions替代repartition与sort类操作  </li>
<li>广播大变量，减少大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC(垃圾回收)</li>
<li>使用Kryo优化序列化性能</li>
<li>优化数据结构</li>
</ol>
<p><strong><font size = 5>7. Spark为什么快，Spark SQL 一定比 Hive 快吗</font></strong><br>1、Spark 计算比 MapReduce 快的根本原因在于 DAG 计算模型，消除了冗余的 HDFS 读写，Spark不需要将计算的中间结果写入磁盘<br>    如果计算不涉及与其他节点进行数据交换，Spark 可以在内存中一次性完成这些操作，也就是中间结果无须落盘，减少了磁盘 IO 的操作<br>2、Spark 是基于内存的计算并不是spark快的根本原因<br>3、MapReduce每启动一个Task便会启动一次JVM，基于进程的操作。而Spark每次MapReduce操作是基于线程的，只在启动Executor时启动一次JVM，内存的Task操作是在线程复用的<br>总结：Spark比Mapreduce运行更快，主要得益于其对mapreduce操作的优化以及对JVM使用的优化<br>Spark SQL 不一定比Hive快，例如没有shuffle的或者只有一次shuffle的，有可能hive的速度不会低于spark-sql</p>
<p><strong><font size = 5>8. Spark Streaming小文件问题</font></strong><br>1、增加 batch 大小<br>2、在输出到hdfs的时候，Coalesce一下<br>3、单独起一个定时任务来合并小文件</p>
<p><strong><font size = 5>9. Checkpoint和持久化有什么区别？</font></strong><br>1、持久化只是将数据保存在BlockManager中，而RDD的lineage是不变的，但是checkpoint执行完后，RDD已经没有之前所谓的依赖RDD了，而只有一个强行为其设置的checkpointRDD，RDD的lineage（血缘关系，依赖关系）改变了<br>2、持久化的数据丢失可能性更大，磁盘、内存都可能会存在数据丢失的情况。但是checkpoint的数据通常是存储在如HDFS等容错、高可用的文件系统，数据丢失可能性较小。<br>注：默认情况下，如果某个RDD没有持久化，但是设置了checkpoint，会存在问题，本来这个job都执行结束了，但是由于中间RDD没有持久化，checkpoint job想要将RDD的数据写入外部文件系统的话，需要全部重新计算一次，<br>再将计算出来的RDD数据checkpoint到外部文件系统。所以，建议对checkpoint()的RDD使用persist(StorageLevel.DISK_ONLY)，该RDD计算之后，就直接持久化到磁盘上。后面进行checkpoint操作时就可以直接从磁盘上读取RDD的数据，并checkpoint到外部文件系统。</p>
<p><strong><font size = 5>10. SparkStreaming读取Kafka数据的两种方式，有什么区别？</font></strong><br>SparkStreaming读取Kafka数据有两种方式，分别为基于Receiver方式和基于Direct(No Receiver)方式<br>1、基于Receiver方式：<br>    1.1 需要使用单独的Receiver线程来异步获取Kafka数据。<br>    1.2 Receiver底层实现中使用了Kafka高级消费者API,因此,不需要自己管理Offset,只需指定Zookeeper和消费者组GroupID,系统便会自行管理。<br>    1.3 执行过程: Spark Streaming启动时，会在Executor中同时启动Receiver异步线程用于从Kafka持续获取数据，获取的数据先存储在Receiver中(存储方式由StorageLevel决定)，后续，当Batch Job触发后，这些数据会被转移到剩下的Executor中被处理。处理完毕后，Receiver会自动更新Zookeeper中的Offset。<br>    1.4 默认情况下,程序失败或Executor宕掉后可能会丢失数据，为避免数据丢失，可启用预写日志(Write Ahead Log,WAL)。将Receiver收到的数据再备份一份到更可靠的系统如HDFS分布式文件中，以冗余的数据来换取数据不丢失。<br>    1.5 生产下，为保证数据完全不丢失，一般需要启用WAL。启用WAL，在数据量较大，网络不好情况下，会严重降低性能<br>2、基于Direct(No Receiver)方式<br>    2.1 不需要使用单独的Receiver线程从Kafka获取数据。<br>    2.2 使用Kafka简单消费者API,不需要ZooKeeper参与，直接从Kafka Broker获取数据。<br>    2.3 执行过程:Spark Streaming Batch Job触发时，Driver端确定要读取的Topic-Partition的OffsetRange，然后由Executor并行从Kafka各Partition读取数据并计算。<br>    2.4 为保证整个应用EOS， Offset管理一般需要借助外部存储实现。如Mysql、HBase等。<br>    2.5 由于不需要WAL，且Spark Streaming会创建和Kafka Topic Partition一样多的RDD Partition,且一一对应，这样,就可以并行读取，大大提高了性能。<br>    2.6 Spark Streaming应用启动后，自己通过内部currentOffsets变量跟踪Offset，避免了基于Receiver的方式中Spark Streaming和Zookeeper中的Offset不一致问题。</p>
<p><strong><font size = 5>11. 如何使用Spark实现TopN的获取（描述思路或使用伪代码）？</font></strong><br>最简单的就是，直接reduceByKey计算key的个数，然后按照value排序<br>但是，这样会有一个问题，就是当数据量很大的时候，有可能会导致OOM，或者数据倾斜<br>可以使用map算子，把每个key添加一个随机数，然后再reduceByKey,最后再把key拆出来，再做一次reduceByKey</p>
<p><strong><font size = 5>12. Spark在什么情况下会OOM</font></strong></p>
<ol>
<li>map过程产生大量对象导致内存溢出</li>
<li>数据不平衡导致内存溢出</li>
<li>coalesce调用导致内存溢出</li>
<li>shuffle后内存溢出</li>
<li>广播了大变量</li>
</ol>
<p>指定spark的垃圾回收算法G1GC：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">-conf spark.driver.extraJavaOptions&#x3D;&quot;-XX:+UseG1GC -Dlog4j.configuration&#x3D;log4j.properties&quot; \
--conf spark.executor.extraJavaOptions&#x3D;&quot;-XX:+UseG1GC -Dlog4j.configuration&#x3D;log4j.properties&quot; \<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<p><strong><font size = 5>13. RDD的弹性表现在哪几点？</font></strong></p>
<ol>
<li>自动的进行内存和磁盘的存储切换</li>
<li>基于Linage的高效容错</li>
<li>task如果失败会自动进行特定次数的重试</li>
<li>stage如果失败会自动进行特定次数的重试，而且只会计算失败的分片</li>
<li>checkpoint和persist，数据计算之后持久化缓存</li>
<li>数据调度弹性，DAG TASK调度和资源无关</li>
<li>数据分片的高度弹性</li>
</ol>
<p><strong><font size = 5>14. RDD通过Linage（记录数据更新）的方式为何很高效？</font></strong></p>
<p><strong><font size = 5>14. Spark与MapReduce以及Tez的区别？</font></strong></p>
<ul>
<li>spark与tez都是以dag方式处理数据</li>
<li>MR相比tez和spark，每次计算结果都会落盘，增加了磁盘IO</li>
</ul>
<p>tez和spark的区别：</p>
<ul>
<li>spark更像是一个通用的计算引擎，提供内存计算，实时流处理，机器学习等多种计算方式，适合迭代计算</li>
<li>tez作为一个框架工具，特定为hive和pig提供批量计算</li>
<li>spark属于内存计算，支持多种运行模式，可以跑在standalone，yarn上；而tez只能跑在yarn上；虽然spark与yarn兼容，但是spark不适合和其他yarn应用跑在一起</li>
<li>tez能够及时的释放资源，重用container，节省调度时间，对内存的资源要求率不高； 而spark如果存在迭代计算时，container一直占用资源；</li>
</ul>
<p>可以参考<a href="https://zhuanlan.zhihu.com/p/49169166">Spark面试题(一)</a></p>
]]></content>
      <categories>
        <category>面试题</category>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>StreamX学习笔记</title>
    <url>/2022/10/19/StreamX%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>StreamX简介</li>
<li>StreamX源码调试</li>
</ul>
<a id="more"></a>


<h2 id="StreamX简介"><a href="#StreamX简介" class="headerlink" title="StreamX简介"></a>StreamX简介</h2><p>StreamX 是主打一站式的实时计算平台，集成了项目编译、发布、参数配置、启动、停止、监控等诸多功能于一体， 大大简化了 Flink 任务的日常操作和维护，而且足够专注，比其他开源项目更加轻量</p>
<h2 id="StreamX源码调试"><a href="#StreamX源码调试" class="headerlink" title="StreamX源码调试"></a>StreamX源码调试</h2><h3 id="下载StreamX源码并编译源码"><a href="#下载StreamX源码并编译源码" class="headerlink" title="下载StreamX源码并编译源码"></a>下载StreamX源码并编译源码</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone git@github.com:apache&#x2F;incubator-streampark.git
git checkout -b 1.2.3-release
mvn clean install -DskipTests -Dscala.version&#x3D;2.12.13 -Dscala.binary.version&#x3D;2.12 -Pwebapp -T10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>用IDEA打开streampark源码，勾选Profiles -&gt; webapp</p>
<h3 id="StreamX本地调试"><a href="#StreamX本地调试" class="headerlink" title="StreamX本地调试"></a>StreamX本地调试</h3><p>查看StreamX安装目录bin/streampark.sh，查看项目的启动类为<code>org.apache.streampark.console.StreamParkConsoleBootstrap</code></p>
<h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol>
<li><code>object TableExt is not a member of package org.apache.streampark.flink.core</code><br>这个问题很奇怪，按照网上查到的，在<code>project structure</code>里配置scala的sdk，没啥用，但是在代码里找到报错的类，点了点上下依赖，就成功了</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>StreamX</category>
      </categories>
      <tags>
        <tag>StreamX</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper学习笔记</title>
    <url>/2021/01/21/Zookeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Zookeeper简介</li>
<li>Zookeeper可以干什么？</li>
<li>Zookeeper安装与启动</li>
<li>Zookeeper常用操作<a id="more"></a>
<h2 id="Zookeeper简介"><a href="#Zookeeper简介" class="headerlink" title="Zookeeper简介"></a>Zookeeper简介</h2></li>
</ul>
<h2 id="Zookeeper可以干什么？"><a href="#Zookeeper可以干什么？" class="headerlink" title="Zookeeper可以干什么？"></a>Zookeeper可以干什么？</h2><h2 id="Zookeeper安装与启动"><a href="#Zookeeper安装与启动" class="headerlink" title="Zookeeper安装与启动"></a>Zookeeper安装与启动</h2><h3 id="Zookeeper安装"><a href="#Zookeeper安装" class="headerlink" title="Zookeeper安装"></a>Zookeeper安装</h3><p>Zookeeper需要用到java，安装前需要安装java，这里省略<br>官网下载Zookeeper安装包，并解压</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar zxvf zookeeper-3.4.6.tar.gz -C .
cd zookeeper-3.4.6&#x2F;conf
cp zoo_sample.cfg zoo.cfg <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>修改zoo.cfg</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># The number of milliseconds of each tick
tickTime&#x3D;2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit&#x3D;10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit&#x3D;5
# the directory where the snapshot is stored.
# do not use &#x2F;tmp for storage, &#x2F;tmp here is just 
# example sakes.
dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F;zkData
dataLogDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F;zkDataLog
# the port at which the clients will connect
clientPort&#x3D;2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里设置了dataDir和dataLogDir，手动生成了这两个文件，不知道会不会自动生成<br>最后，设置Zookeeper的环境变量</p>
<h3 id="Zookeeper启动等操作"><a href="#Zookeeper启动等操作" class="headerlink" title="Zookeeper启动等操作"></a>Zookeeper启动等操作</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 启动
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh start
# 关闭
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh stop
# 查看ZK服务状态
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh status
#  重启ZK服务
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh restart<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Zookeeper操作样例"><a href="#Zookeeper操作样例" class="headerlink" title="Zookeeper操作样例"></a>Zookeeper操作样例</h2>]]></content>
      <categories>
        <category>大数据</category>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>azkban从编译开始安装</title>
    <url>/2021/01/16/azkban%E4%BB%8E%E7%BC%96%E8%AF%91%E5%BC%80%E5%A7%8B%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>如何下载Azkaban稳定版代码</li>
<li>如何构建Azkaban源码</li>
<li>如何配置Azkaban</li>
<li>启动Azkaban注意点<a id="more"></a>
<h2 id="从git上下载最新的azkban稳定版代码"><a href="#从git上下载最新的azkban稳定版代码" class="headerlink" title="从git上下载最新的azkban稳定版代码"></a>从git上下载最新的azkban稳定版代码</h2>git clone <a href="https://github.com/azkaban/azkaban.git">https://github.com/azkaban/azkaban.git</a> -b 3.74.3<br>这里还有个问题，如何把这个代码放到自己的git上，我放到公司的gitlab上之后，编译的名字就变了，很奇怪。</li>
</ul>
<h2 id="构建Azkaban"><a href="#构建Azkaban" class="headerlink" title="构建Azkaban"></a>构建Azkaban</h2><p>./gradlew clean<br>./gradlew build -x test<br>-x是指不做单元测试，不加这个会特别慢<br>这里我构建了很多次，用公司配制好的服务器构建，文件名老是不对<br>名字老是azkaban-web-server-0.1.0-SNAPSHOT.tar.gz和azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz</p>
<p>后来还是直接clone官网上的代码来构建</p>
<h2 id="配置mysql"><a href="#配置mysql" class="headerlink" title="配置mysql"></a>配置mysql</h2><p>需要用mysql的root用户创建一个azkban数据库，我这里创建的数据库名为azkban3<br>然后 从编译文件夹里：<br>在azkaban/azkaban-db/build/sql下找到create-all-sql-3.74.3.sql<br>然后再mysql命令行：<br>create database azkaban3；<br>use azkaban3<br>source /home/data-platform/create-all-sql-3.74.3.sql<br>这样就把azkaban的所有表都创建完了</p>
<p>创建用户名为azkban的用户，用户名为azkban@123<br>CREATE USER ‘azkaban’@’%’ IDENTIFIED BY ‘azkaban@123’; #创建用户<br>grant all on azkaban3.* to azkaban@’%’ identified by ‘azkaban@123’; #授权azkaban3给azkaban<br>flush privileges  #s刷新</p>
<p>##启动azkban-exec-server<br>cd /opt/azkaban/azkaban-exec-server-3.74.3 &amp;&amp; ./bin/start-exec.sh</p>
<p>这里有个问题：<br>直接启动exec-server后启动web-server，webserver会找不到活跃的excutor<br>报错信息为:</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2019&#x2F;07&#x2F;04 14:32:08.532 +0800 INFO [ExecutorManager] [Azkaban] Initializing executors from database.
2019&#x2F;07&#x2F;04 14:32:08.535 +0800 ERROR [ExecutorManager] [Azkaban] No active executors found
2019&#x2F;07&#x2F;04 14:32:08.536 +0800 ERROR [StdOutErrRedirect] [Azkaban] Exception in thread &quot;main&quot;
2019&#x2F;07&#x2F;04 14:32:08.536 +0800 ERROR [StdOutErrRedirect] [Azkaban] azkaban.executor.ExecutorManagerException: No active executors found
2019&#x2F;07&#x2F;04 14:32:08.536 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ActiveExecutors.setupExecutors(ActiveExecutors.java:52)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ExecutorManager.setupExecutors(ExecutorManager.java:197)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ExecutorManager.initialize(ExecutorManager.java:131)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ExecutorManager.start(ExecutorManager.java:145)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.webapp.AzkabanWebServer.launch(AzkabanWebServer.java:231)
2019&#x2F;07&#x2F;04 14:32:08.538 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.webapp.AzkabanWebServer.main(AzkabanWebServer.java:224)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>解决办法：<br>手动激活exec-server<br>curl http://${executorHost}:${executorPort}/executor?action=activate<br>executorHost：就是安装服务器的IP<br>executorPort：就是启动azkban-exec-server后，产生的executor.port里的端口号</p>
<h2 id="启动azkaban-web-server"><a href="#启动azkaban-web-server" class="headerlink" title="启动azkaban-web-server"></a>启动azkaban-web-server</h2><p>cd /opt/azkaban/azkaban-web-server-3.74.3 &amp;&amp; ./bin/start-web.sh</p>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>启动server必须要到azkaban-web-server-3.74.3这个目录，因为默认启动找的配置文件为 conf/azkaban.properties</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Azkaban</category>
      </categories>
      <tags>
        <tag>Azkaban</tag>
      </tags>
  </entry>
  <entry>
    <title>clickhouse学习笔记</title>
    <url>/2022/06/01/clickhouse%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>clickhouse学习笔记</li>
</ul>
<a id="more"></a>



<h2 id="clickhouse简介"><a href="#clickhouse简介" class="headerlink" title="clickhouse简介"></a>clickhouse简介</h2><h3 id="clickhouse架构"><a href="#clickhouse架构" class="headerlink" title="clickhouse架构"></a>clickhouse架构</h3><h2 id="clickhouse安装与配置"><a href="#clickhouse安装与配置" class="headerlink" title="clickhouse安装与配置"></a>clickhouse安装与配置</h2><p>略，可以参考[clickhouse安装与配置][1]</p>
<h2 id="clickhouse客户端命令"><a href="#clickhouse客户端命令" class="headerlink" title="clickhouse客户端命令"></a>clickhouse客户端命令</h2><h3 id="连接命令"><a href="#连接命令" class="headerlink" title="连接命令"></a>连接命令</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">clickhouse-client --host&#x3D;172.16.2.220 --port&#x3D;9123 --user&#x3D;default --password&#x3D;root123456
# --host, -h        – 服务端的 host 名称, 默认是 &#39;localhost&#39;。 您可以选择使⽤ host 名称或者 IPv4 或 IPv6 地址。 
# --port            – 连接的端⼝，默认值： 9000。注意 HTTP 接⼝以及 TCP 原⽣接⼝是使⽤不同端⼝的。 
# --user, -u        – ⽤户名。 默认值： default。 
# --password        – 密码。 默认值： 空字符串。 
# --query, -q       – ⾮交互模式下的查询语句. 
# --database, -d    – 默认当前操作的数据库. 默认值： 服务端默认的配置 （默认是 default ）。 
# --multiline, -m   – 如果指定，允许多⾏语句查询（Enter 仅代表换⾏，不代表查询语句完结）。 
# --multiquery, -n  – 如果指定, 允许处理⽤逗号分隔的多个查询，只在⾮交互模式下⽣效。 
# --format, -f      – 使⽤指定的默认格式输出结果。 
# --vertical, -E    – 如果指定，默认情况下使⽤垂直格式输出结果。这与 &#39;--format&#x3D;Vertical&#39; 相同。在这种格式中，每个值都在单独的⾏上打印，这种⽅式对显示宽表很有帮助。 
# --time, -t        – 如果指定，⾮交互模式下会打印查询执⾏的时间到 &#39;stderr&#39; 中。 
# --stacktrace      – 如果指定，如果出现异常，会打印堆栈跟踪信息。 
# -config-file      – 配置⽂件的名称。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>具体可以参考<a href="https://blog.csdn.net/wangzhongshun/article/details/124104547">clickhouse客户端命令</a></p>
<h3 id="SQL语法"><a href="#SQL语法" class="headerlink" title="SQL语法"></a>SQL语法</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 查看数据库列表</span>
<span class="token keyword">show</span> <span class="token keyword">databases</span><span class="token punctuation">;</span>
<span class="token comment">--查看当前使用的数据库</span>
<span class="token keyword">select</span> currentDatabase<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 查看数据库中表列表</span>
<span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
<span class="token comment">-- 创建数据库</span>
<span class="token keyword">create</span> <span class="token keyword">database</span> test<span class="token punctuation">;</span>
<span class="token comment">-- 创建一个表(建表的时候指定数据类型，建表的时候一定要指定表引擎，要么使用-m，要么使用反斜杠，不然不能写多行)</span>
<span class="token keyword">create</span>  <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> test<span class="token punctuation">.</span>t1 <span class="token punctuation">(</span> id UInt16<span class="token punctuation">,</span>name String<span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">;</span>
<span class="token comment">-- 查看表结构</span>
<span class="token keyword">desc</span> test<span class="token punctuation">.</span>t1<span class="token punctuation">;</span>
<span class="token comment">--删除表</span>
<span class="token keyword">drop</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> test<span class="token punctuation">.</span>t1<span class="token punctuation">;</span>
<span class="token comment">--删除库</span>
<span class="token keyword">drop</span> <span class="token keyword">database</span> test<span class="token punctuation">;</span>
<span class="token comment">--清空数据</span>
<span class="token keyword">truncate</span> <span class="token keyword">table</span> test<span class="token punctuation">.</span>t1<span class="token punctuation">;</span>
<span class="token comment">--插入数据</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> test<span class="token punctuation">.</span>t1 <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token keyword">values</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'zhangsan'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'lishi'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">--查询</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> test<span class="token punctuation">.</span>t1<span class="token punctuation">;</span>
<span class="token comment">--重命名表</span>
<span class="token keyword">rename</span> <span class="token keyword">table</span> tab1 <span class="token keyword">to</span> tab2<span class="token punctuation">;</span>
<span class="token comment">--添加列</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> tbl <span class="token keyword">add</span> <span class="token keyword">column</span> cost UInt32 <span class="token keyword">default</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token comment">--查看分区信息</span>
<span class="token keyword">select</span> <span class="token keyword">partition</span><span class="token punctuation">,</span> name<span class="token punctuation">,</span> active <span class="token keyword">from</span> system<span class="token punctuation">.</span>parts <span class="token keyword">WHERE</span> <span class="token keyword">table</span> <span class="token operator">=</span> <span class="token string">'t1'</span><span class="token punctuation">;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>db<span class="token punctuation">.</span><span class="token punctuation">]</span>table_name <span class="token punctuation">[</span><span class="token keyword">ON</span> CLUSTER cluster<span class="token punctuation">]</span>
<span class="token punctuation">(</span>
    name1 <span class="token punctuation">[</span>type1<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">DEFAULT</span><span class="token operator">|</span>MATERIALIZED<span class="token operator">|</span>ALIAS expr1<span class="token punctuation">]</span> <span class="token punctuation">[</span>TTL expr1<span class="token punctuation">]</span><span class="token punctuation">,</span>
    name2 <span class="token punctuation">[</span>type2<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">DEFAULT</span><span class="token operator">|</span>MATERIALIZED<span class="token operator">|</span>ALIAS expr2<span class="token punctuation">]</span> <span class="token punctuation">[</span>TTL expr2<span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">INDEX</span> index_name1 expr1 <span class="token keyword">TYPE</span> type1<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> GRANULARITY value1<span class="token punctuation">,</span>
    <span class="token keyword">INDEX</span> index_name2 expr2 <span class="token keyword">TYPE</span> type2<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> GRANULARITY value2
<span class="token punctuation">)</span> <span class="token keyword">ENGINE</span> <span class="token operator">=</span> MergeTree<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> expr
<span class="token punctuation">[</span><span class="token keyword">PARTITION</span> <span class="token keyword">BY</span> expr<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> expr<span class="token punctuation">]</span>
<span class="token punctuation">[</span>SAMPLE <span class="token keyword">BY</span> expr<span class="token punctuation">]</span>
<span class="token punctuation">[</span>TTL expr <span class="token punctuation">[</span><span class="token keyword">DELETE</span><span class="token operator">|</span><span class="token keyword">TO</span> <span class="token keyword">DISK</span> <span class="token string">'xxx'</span><span class="token operator">|</span><span class="token keyword">TO</span> VOLUME <span class="token string">'xxx'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span>SETTINGS name<span class="token operator">=</span><span class="token keyword">value</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>建表的时候指定数据类型，建表的时候一定要指定表引擎</li>
<li>如果想写多行，要么使用-m，要么使用反斜杠</li>
</ul>
<h3 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--删除分区</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> xxx <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token string">'2018-08-08'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>默认情况下，Clickhouse 不允许删除分区或表的大小大于 50GB 的分区或表。可以通过修改server的配置文件来永久配置，也可以临时设置一下来删除而不用重启服务。<br>永久配置：更改config.xml配置文件。</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- &lt;max_table_size_to_drop>0&lt;/max_table_size_to_drop> --></span>
<span class="token comment">&lt;!-- &lt;max_partition_size_to_drop>0&lt;/max_partition_size_to_drop> --></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>0表示不限制，或者你可以设置为你想限制的最大的大小。</p>
<h2 id="flinksql写数据到clickhouse"><a href="#flinksql写数据到clickhouse" class="headerlink" title="flinksql写数据到clickhouse"></a>flinksql写数据到clickhouse</h2><p>由于flink的官网没有实现flink-connector-clickhosue，这里需要自己实现<br>在github上找到一个现成的，实际测试了一把，发现可以正常使用，项目地址在<a href="https://github.com/gujincheng/flink-connector-clickhouse.git">flink-connector-clickhosue</a></p>
<p>实现步骤：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># clone源代码到本地，并编译代码，我们的flink版本是1.13.6，这里指定代码版本
git clone https:&#x2F;&#x2F;github.com&#x2F;gujincheng&#x2F;flink-connector-clickhouse.git -b release-1.13
cd flink-connector-clickhouse &amp;&amp; mvn clean package<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="flinkcdc采集mysql并写入clickhouse"><a href="#flinkcdc采集mysql并写入clickhouse" class="headerlink" title="flinkcdc采集mysql并写入clickhouse"></a>flinkcdc采集mysql并写入clickhouse</h3><h4 id="使用sql-client"><a href="#使用sql-client" class="headerlink" title="使用sql-client"></a>使用sql-client</h4><ul>
<li>首先把编译的connector的jar放到${FLINK_HOME}/lib下<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mv target&#x2F;flink-connector-clickhouse-1.13.2-SNAPSHOT.jar &#x2F;opt&#x2F;soft&#x2F;flink-1.13.6&#x2F;lib<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>启动flink-standalone，并启动sql-client</li>
<li>执行sql语句<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> <span class="token keyword">sql</span><span class="token operator">-</span>client<span class="token punctuation">.</span>execution<span class="token punctuation">.</span>result<span class="token operator">-</span><span class="token keyword">mode</span><span class="token operator">=</span>tableau<span class="token punctuation">;</span>
<span class="token keyword">set</span> execution<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span><span class="token keyword">interval</span><span class="token operator">=</span><span class="token number">3</span>sec<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> users_source_mysql <span class="token punctuation">(</span>
   uuid string <span class="token punctuation">,</span>
   name STRING<span class="token punctuation">,</span>
   age <span class="token keyword">int</span><span class="token punctuation">,</span>
   ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   part string
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'mysql-cdc'</span><span class="token punctuation">,</span>
<span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'150.158.190.192'</span><span class="token punctuation">,</span>
<span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'3306'</span><span class="token punctuation">,</span>
<span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'root'</span><span class="token punctuation">,</span>
<span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">,</span>
<span class="token string">'server-time-zone'</span> <span class="token operator">=</span> <span class="token string">'Asia/Shanghai'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.mode'</span> <span class="token operator">=</span> <span class="token string">'initial'</span><span class="token punctuation">,</span>
<span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">,</span>
<span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'users_source_mysql'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> gjc_test_binlog <span class="token punctuation">(</span>
   uuid string <span class="token keyword">primary</span> <span class="token keyword">key</span> <span class="token punctuation">,</span>
   name STRING<span class="token punctuation">,</span>
   age <span class="token keyword">int</span><span class="token punctuation">,</span>
   ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   part string
 <span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
     <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'clickhouse'</span><span class="token punctuation">,</span>
     <span class="token string">'url'</span> <span class="token operator">=</span> <span class="token string">'clickhouse://172.16.2.220:8123'</span><span class="token punctuation">,</span>
     <span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'default'</span><span class="token punctuation">,</span>
     <span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'root123456'</span><span class="token punctuation">,</span>
     <span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'default'</span><span class="token punctuation">,</span>
     <span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'gjc_test_binlog'</span><span class="token punctuation">,</span>
     <span class="token string">'sink.batch-size'</span> <span class="token operator">=</span> <span class="token string">'1000'</span><span class="token punctuation">,</span>
     <span class="token string">'sink.max-retries'</span> <span class="token operator">=</span> <span class="token string">'3'</span><span class="token punctuation">,</span>
     <span class="token string">'sink.partition-strategy'</span> <span class="token operator">=</span> <span class="token string">'balanced'</span><span class="token punctuation">,</span>
     <span class="token string">'sink.ignore-delete'</span> <span class="token operator">=</span> <span class="token string">'true'</span>
 <span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">insert</span> <span class="token keyword">into</span>  gjc_test_binlog <span class="token keyword">select</span> uuid<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">,</span>ts<span class="token punctuation">,</span>part <span class="token keyword">from</span> users_source_mysql<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
实现效果：<br><img src="/uploads/202206/flinkcdc%E5%86%99%E6%95%B0%E6%8D%AE%E5%88%B0clickhouse.png" alt="flinkcdc写数据到clickhouse"></li>
</ul>
<p><font color=#FF000 >注意：</font><br>这里在测试数据的增删改查过程中，针对修改与删除数据，总结以下几点：</p>
<ol>
<li>clickhouse必须有主键才能支持修改和删除数据</li>
<li>如果clickhouse表是分区表，那么在flinksql中创建的映射表也必须要有分区，否则，修改操作会不生效</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>clickhouse</tag>
      </tags>
  </entry>
  <entry>
    <title>emacs手动安装、解决不能使用中文输入法</title>
    <url>/2021/01/16/emacs%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E3%80%81%E8%A7%A3%E5%86%B3%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>emacs下载杆状</li>
<li>解决不能使用中文输入法</li>
</ul>
<a id="more"></a>
<h2 id="emacs的安装"><a href="#emacs的安装" class="headerlink" title="emacs的安装"></a>emacs的安装</h2><h3 id="emacs的下载，解压"><a href="#emacs的下载，解压" class="headerlink" title="emacs的下载，解压"></a>emacs的下载，解压</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wget http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;gnu&#x2F;emacs&#x2F;emacs-25.3.tar.gz
tar -zxf emacs-25.3.tar.gz -C &#x2F;opt&#x2F;modules
cd &#x2F;opt&#x2F;modules&#x2F;emacs-25.3&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local --with-x-toolkit&#x3D;gtk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里会报错。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">You seem to be running X, but no X development libraries
were found.  You should install the relevant development files for X
and for the toolkit you want, such as Gtk+, Lesstif or Motif.  Also make
sure you have development files for image handling, i.e.
tiff, gif, jpeg, png and xpm.
If you are sure you want Emacs compiled without X window support, pass
  --without-x
to configure.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>需要下载相关依赖</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo apt-get install libxpm-dev
sudo apt-get install libjpeg62-dev
sudo apt-get install libgif-dev
sudo apt-get install libtiff5-dev
sudo apt-get install libncurses5-dev
sudo apt-get install libgtk2.0-dev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>重新编译后正常</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">make
sudo make install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>到此，emac的安装已经结束</p>
<h3 id="安装spacemacs"><a href="#安装spacemacs" class="headerlink" title="安装spacemacs"></a>安装spacemacs</h3><p>spacemacs可以在emacs里使用vim的命令，让emacs更人性化一点。</p>
<p>安装很简单，就是clone项目到~/.emacs.d目录去</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;syl20bnr&#x2F;spacemacs ~&#x2F;.emacs.d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>安装完spacemacs，第一次启动emacs会加载很多包，没关系，等一会就好了</p>
<h3 id="解决emacs不能使用中文输入法"><a href="#解决emacs不能使用中文输入法" class="headerlink" title="解决emacs不能使用中文输入法"></a>解决emacs不能使用中文输入法</h3><p>我的环境是ubuntu16.04，系统语言是English，但是在vim里，gedit都可以输入中文。只有emacs不行，在网上查了原因，是emacs自带的一个bug，因为比较久远，不会再修复了<br>这里在修复之前，已经安装了搜狗输入法</p>
<p>这里的处理办法是：<br>    在 .bashrc文件下添加：<br>    export LC_CTYPE=zh_CN.UTF-8<br>这样不会修改整个系统的环境，但是只针对自己这个用户来书，够用了。但是报了没有zh_CN.UTF-8这个文件</p>
<p>原因是系统中还没有中文语言包<br>这里安装一下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo apt-get install  -y language-pack-zh-hans
sudo apt-get install -y language-pack-zh-hant
cd &#x2F;usr&#x2F;share&#x2F;locales    
sudo .&#x2F;install-language-pack zh_CN   ##开始安装zh_CN中文字符集<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/20210116/emacs-install-error.png" alt="emacs-install-error"><br>这里的报错不用管<br>然后重启电脑就好了。</p>
<h3 id="Emacs-Org-mode"><a href="#Emacs-Org-mode" class="headerlink" title="Emacs Org-mode"></a>Emacs Org-mode</h3><p>使用emacs生成 表格是真的方便</p>
<h4 id="生成表格"><a href="#生成表格" class="headerlink" title="生成表格"></a>生成表格</h4><p><code>C-c |</code>    :生成表格，在buffer区域会提示输入N*M,代表N列M行的表格（注意，这里的<code>*</code>其实输入的是<code>x</code>）<br>使用<code>TAB</code>格式化表格</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title>git使用笔记</title>
    <url>/2022/08/26/git%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>git常用命令</li>
<li>git版本发布流程</li>
<li>IDEA使用git方式</li>
</ul>
<a id="more"></a>

<h2 id="git常用命令"><a href="#git常用命令" class="headerlink" title="git常用命令"></a>git常用命令</h2><ul>
<li>分支的创建、切换、删除等操作<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 基于develop创建分支。
git branch mydev develop
## 切换分支
git checkout mydev
## 创建分支并切换到该分支下
git checkout -b mydev develop
## 删除分支,删除分支需要先切换到它的父分支，例如删除mydev，需要先切换到develop分支
git checkout develop &amp;&amp; git branch -d mydev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>拉取代码与提交代码<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 拉取代码
git clone https:&#x2F;&#x2F;github.com&#x2F;gujincheng&#x2F;blog.git
## 提交代码
git add -A  ## 提交所有文件 &#x2F; git add [file1] [file2] ...  &#x2F; git add [dir]
git commit -m &quot;commit_message&quot;
git push origin branch_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="git版本发布流程"><a href="#git版本发布流程" class="headerlink" title="git版本发布流程"></a>git版本发布流程</h2>一般情况：<br>master和develop并行。</li>
<li>master上始终是最稳定的代码，develop是正在开发的代码。</li>
<li>feature则是某个开发为了自己的功能拉的分支。<br>不一般情况：</li>
<li>develop正在开发，如果你上线突然被拒绝了，这时候就要从master上开一个热分支，或者release分支也行，改好之后在分别合并到其他分支。但，本人感觉release通常意味着终止。别在从release上拉分支了。</li>
</ul>
<h3 id="创建一个release分支"><a href="#创建一个release分支" class="headerlink" title="创建一个release分支"></a>创建一个release分支</h3><p>Release分支是从develop分支创建的。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">##  基于develop创建release分支。
git checkout -b release-0.2.0 develop
git push origin release-0.2.0  # 新创建的release分支推送到远程仓库<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>创建新分支以后，切换到该分支，添加版本号。这里，bump-version.sh 是一个虚构的shell脚本，它可以复制一些文件来反映新的版本（这当然可以手动改变–目的就是修改一些文件）。然后版本号被提交。<br>这个新分支可能会存在一段时间，直到该发行版到达它的预定目标。在此期间，bug的修复可能被提交到该分支上（而不是提交到develop分支上）。在这里严格禁止增加大的新features。他们必须合并到develop分支上，然后等待下一次大的发行版。</p>
<h3 id="完成一个release分支"><a href="#完成一个release分支" class="headerlink" title="完成一个release分支"></a>完成一个release分支</h3><p>当一个release分支准备好成为一个真正的发行版的时候，有一些工作必须完成。首先，release分支要合并到master上（因为每一次提交到master上的都是一个新定义的发行版，记住）。然后，提交到master上必须打一个标签，以便以后更加方便的引用这个历史版本。最后，在release分支上的修改必须合并到develop分支上，以便未来发行版也包含这些bugs的修复。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 切换到master分支
git checkout master
# 合并release分支到master
git merge --no-ff release-0.2.0 
# 推送到远程master仓库 
git push origin master  
# 打上release标签 
git tag -a release-0.2.0
# 推送tag标签到远程仓库
git push origin --tags # push所有tag
# 或者单独推送某个tag，但是这样tag名称和release分支名称一样的话可能会有问题
git push origin [tagname]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>为了是修改保持在release分支上，我们需要合并这些到develop分支上去，在Git上：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git checkout develop
git merge --no-ff release-0.2.0
git push origin develop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这个步骤可能会导致合并冲突（可能由于改变版本号更是如此）。如果是这样，修复它然后提交。<br>现在我们真正的完成了，这个release分支将被删除，因为我们不再需要它了。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$ git branch -d release-0.2.0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>具体可以参考<a href="https://blog.csdn.net/hj7jay/article/details/84527062">Git分支模型(master/hotfix/develop/feature/release)</a></p>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>hdfs块文件丢失</title>
    <url>/2022/03/08/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hdfs块文件丢失</li>
</ul>
<a id="more"></a>

<h2 id="hdfs块文件丢失"><a href="#hdfs块文件丢失" class="headerlink" title="hdfs块文件丢失"></a>hdfs块文件丢失</h2><p>最近公司集群扩容，运维那边不知道怎么操作的，导致hdfs的block块文件丢失了。</p>
<p>个人猜测，公司的五台节点，都新挂载了一个新盘，datanode上配置了新盘，重启之后，hadoop集群肯定是要负载均衡一下的，迁移一些文件到新盘<br>这时候namenode会可能会进入安全模式，CM上很多组件都会报红，这时候我们的运维强制退出了安全模式，重启了hadoop集群，但是只是猜测，具体原因找不到了</p>
<p>先说问题描述：<br>启动hive的时候，报如下报错日志：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory &#x2F;tmp&#x2F;hive&#x2F;root&#x2F;eceb6690-1510-4703-8a4b-60ea03c3fcec. Name node is in safe mode.
The reported blocks 10427 needs additional 4373 blocks to reach the threshold 0.9990 of total blocks 14815.
The number of live datanodes 3 has reached the minimum number 1. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:ddp2
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1448)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1435)
        ... 12 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>很明显，报错就是丢失了4373个block，导致namenode进入安全模式</p>
<h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>出现前面提到的问题主要原因是客户端写入的数据没有及时保存到磁盘中，从而导致数据丢失；又因为数据块丢失达到一定的比率，导致hdfs启动进入安全模式。</p>
<p>为了弄清楚导致安全模式的原因，下面主要对hdfs安全模式和如何退出安全模式进行分析。</p>
<h3 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h3><p>当 hdfs的NameNode节点启动时，会进入安全模式阶段。安全模式主要是为了系统启动的时候检查各个DataNode上数据块的有效性，同时根据策略必要的复制或者删除部分数据块。</p>
<p>在此阶段，NameNode加载fsimage（Filesystem image：文件meta信息的持久化的检查点）文件到内存中，然后在editlog中执行相应的操作。加载fsimage文件包含文件metadata信息，但是不包含文件块位置的信息。</p>
<p>DataNode启动的时候扫描本地磁盘，保存的block信息，然后将这些信息汇报给NameNode,让 NameNode得到块的位置信息，并对每个文件对应的数据块副本进行统计。</p>
<p>如果hdfs数据量很大时，进入至退出安全模式时间较长。</p>
<h3 id="安全模式退出条件"><a href="#安全模式退出条件" class="headerlink" title="安全模式退出条件"></a>安全模式退出条件</h3><p>当最小副本条件满足时，即一定比例（dfs.safemode.threshold.pct缺省值0.999f）的数据块都达到最小副本数，系统就会退出安全模式。当最小副本条件未达到要求时，就会对副本数不足的数据块安排DataNode进行复制，直至达到最小副本数。如果datanode丢失的block达到一定的比例（1-dfs.safemode.threshold.pct），则系统会一直处于安全模式状态即只读状态。而在安全模式下，系统会处于只读状态，NameNode不会处理任何块的复制和删除命令。</p>
<p>dfs.safemode.threshold.pct（缺省值0.999f）表示HDFS启动的时候，如果DataNode上报的block个数达到了元 数据 记录的block个数的0.999倍才可以离开安全模式，否则一直是这种只读模式。如果设为1则HDFS永远是处于SafeMode。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>比较粗暴的方式，删除损坏掉的block</p>
<ol>
<li>执行命令退出安全模式：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop dfsadmin -safemode leave<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>执行健康检查，删除损坏掉的block。<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs fsck  &#x2F;  -delete<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里的路径虽然写的是<code>/</code>，但是不是删除所有文件，是删除根目录以下的所有的损坏的块文件</li>
</ol>
<p>生产环境一般考虑先恢复： 找到数据块的位置和丢失的数据信息</p>
<ol>
<li>查看/所有分区信息：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs hdfs fsck &#x2F; -files -blocks -locations<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>恢复数据文件，前提是，datanode里的block文件还存在，如果不存在了，虽然信息提示SUCCESS，但是其实还是没有恢复成功<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs debug recoverLease -path $&#123;path&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
我这里使用恢复命令没有效果，直接到datanode的文件存储目录查看了以下，报找不到的block都找不到<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;data&#x2F;dfs&#x2F;dn&#x2F;current ## 通过查看hdfs-site.xml查看datanode的文件实际存储位置
find . -name &quot;blk_1073743358_2534*&quot;   ## 查看当前目录及以下，文件名包含blk_1073743358_2534的文件。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


</li>
</ol>
<p>通过查看hdfs-site.xmhjl找到datanode的日志文件路径：/var/log/hadoop-hdfs<br>查看datanode日志文件：<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D1.png" alt="hdfs块文件丢失恢复1"><br>通过日志可以看出，之前的恢复命令有的成功，有的失败，这里分别找了成功和失败的block查看了一下，发现成功日志的block块是恢复成功了，但是失败的确实没有成功</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 以下文件是成功的block块的文件，查看block块所属哪个文件路径，可以通过hdfs hdfs fsck &#x2F; -files -blocks -locations命令查看
[root@ddp3 tmp]# hadoop fs -ls &#x2F;tmp&#x2F;logs&#x2F;digiwin&#x2F;logs&#x2F;application_1645166873581_4910&#x2F;ddp4_8041
-rw-r-----   3 digiwin hadoop      70423 2022-03-01 11:13 &#x2F;tmp&#x2F;logs&#x2F;digiwin&#x2F;logs&#x2F;application_1645166873581_4910&#x2F;ddp4_8041<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>查看datanode3的log，找其中一块block查看具体的生成时间，已经从哪台节点复制过来的<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D2.png" alt="hdfs块文件丢失恢复2"><br>可以看出，blk_1073741854是2022-03-07 13:27:37从192.168.5.25复制过来的。<br>查看datanode3的blk_1073741854生成时间：<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D3.png" alt="hdfs块文件丢失恢复3"><br>查看datanode5的blk_1073741854生成时间：<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D4.png" alt="hdfs块文件丢失恢复4"><br>可以很明显的看出，blk_1073741854在dn5上是2022-03-04的时候生成的，但是dn3是2022-03-07新复制的<br>所以，数据恢复操作，要有一个前提，丢失的块不能没有副本，需要从其他副本节点复制过来</p>
<p>这里也可以参考一下<a href="https://www.cnblogs.com/prayer21/p/4819789.html">HDFS中datanode节点block损坏后的自动恢复过程</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>impala3.4源码编译</title>
    <url>/2022/05/05/impala3-4%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>impala3.4源码编译<a id="more"></a>



</li>
</ul>
<h2 id="impala3-4源码编译"><a href="#impala3-4源码编译" class="headerlink" title="impala3.4源码编译"></a>impala3.4源码编译</h2><p>最近在集成impala与hudi，但是impala需要在3.4版本以后才支持hudi的读取，所以这里尝试升级impala，废话不多说，下面是编译步骤：</p>
<p>Apache Impala是以源码的形式release的，因此需要自行在对应的平台上编译。找一个跟集群环境一致的机器。<br>根据文档中的“Building Impala without Test Data (for testing Impala)”章节来编译Impala:<br><a href="https://cwiki.apache.org/confluence/display/IMPALA/Building+Impala">https://cwiki.apache.org/confluence/display/IMPALA/Building+Impala</a></p>
<h3 id="下载impala源码"><a href="#下载impala源码" class="headerlink" title="下载impala源码"></a>下载impala源码</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone --single-branch --branch 3.4.1 https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;impala.git impala-3.4
cd impala-3.4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="bin-bootstrap-system-sh-脚本安装编译依赖："><a href="#bin-bootstrap-system-sh-脚本安装编译依赖：" class="headerlink" title="bin/bootstrap_system.sh 脚本安装编译依赖："></a>bin/bootstrap_system.sh 脚本安装编译依赖：</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export IMPALA_HOME&#x3D;&#96;pwd&#96;
.&#x2F;bin&#x2F;bootstrap_system.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="bin-bootstrap-system-sh-踩坑记录"><a href="#bin-bootstrap-system-sh-踩坑记录" class="headerlink" title="bin/bootstrap_system.sh 踩坑记录"></a>bin/bootstrap_system.sh 踩坑记录</h4><ul>
<li>package make-1:3.82-24.el7.x86_64 is already installed<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 很明显，这个包已经安装过，remove之后重新执行
yum remove make-1:3.82-24.el7.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>apache-ant-1.9.14-bin.tar.gz下载失败<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">正在清理软件源： base docker-ce-stable epel extras updates
Cleaning up list of fastest mirrors
++ redhat sudo wget -nv https:&#x2F;&#x2F;downloads.apache.org&#x2F;ant&#x2F;binaries&#x2F;apache-ant-1.9.14-bin.tar.gz
++ [[ true &#x3D;&#x3D; true ]]
++ sudo wget -nv https:&#x2F;&#x2F;downloads.apache.org&#x2F;ant&#x2F;binaries&#x2F;apache-ant-1.9.14-bin.tar.gz
https:&#x2F;&#x2F;downloads.apache.org&#x2F;ant&#x2F;binaries&#x2F;apache-ant-1.9.14-bin.tar.gz:
2022-05-05 13:36:24 错误 404：Not Found。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
解决方法是：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 修改bootstrap_system.sh ant下载地址
vim $IMPALA_HOME&#x2F;bin&#x2F;bootstrap_system.sh

244   https:&#x2F;&#x2F;downloads.apache.org&#x2F;ant&#x2F;binaries&#x2F;apache-ant-1.10.12-bin.tar.gz
245 redhat sha512sum -c - &lt;&lt;&lt; &#39;2287dc5cfc21043c14e5413f9afb1c87c9f266ec2a9ba2d3bf2285446f6e4ccb59b558bf2e5c57911a05dfa293c7d5c7ad60ac9f744ba11406f4e6f9a27b2403  apache-ant-1.10.12-bin.tar.gz&#39;
246 redhat sudo tar -C &#x2F;usr&#x2F;local -xzf apache-ant-1.10.12-bin.tar.gz
247 redhat sudo ln -s &#x2F;usr&#x2F;local&#x2F;apache-ant-1.10.12&#x2F;bin&#x2F;ant &#x2F;usr&#x2F;local&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>Data directory is not empty!<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Hint: the preferred way to do this is now &quot;postgresql-setup initdb&quot;
Data directory is not empty!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
这个问题是因为多次执行了bin/bootstrap_system.sh，导致初始化postgresql多次，这里只需要删除<code>/var/lib/pgsql</code>下的data文件夹和<code>initdb.log</code><br>然后重新执行bin/bootstrap_system.sh即可</li>
</ul>
<p>如果之前在这台机器上编译过Impala，也可以跳过上面这一步。直接进行编译：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">source $IMPALA_HOME&#x2F;bin&#x2F;impala-config.sh
$IMPALA_HOME&#x2F;buildall.sh -noclean -notests -release<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="编译成功查看"><a href="#编译成功查看" class="headerlink" title="编译成功查看"></a>编译成功查看</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@V-NJ-2-220 impala]# ll -h be&#x2F;build&#x2F;latest&#x2F;service&#x2F;impalad fe&#x2F;target&#x2F;impala-frontend-0.1-SNAPSHOT.jar
-rwxr-xr-x. 1 root root 530M 5月   6 16:39 be&#x2F;build&#x2F;latest&#x2F;service&#x2F;impalad
-rw-r--r--. 1 root root 7.5M 5月   6 16:41 fe&#x2F;target&#x2F;impala-frontend-0.1-SNAPSHOT.jar
[root@V-NJ-2-220 impala]# strings be&#x2F;build&#x2F;latest&#x2F;service&#x2F;impalad | grep 3.4.1-
3.4.1-RELEASE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>impala默认使用静态编译，但还是有一些动态依赖，用 ldd 指令查看：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@V-NJ-2-220 impala]# ldd be&#x2F;build&#x2F;latest&#x2F;service&#x2F;impalad
	linux-vdso.so.1 &#x3D;&gt;  (0x00007fff13bda000)
	&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.322.b06-1.el7_9.x86_64&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;libjsig.so (0x00007f03f6fbe000)
	libpthread.so.0 &#x3D;&gt; &#x2F;lib64&#x2F;libpthread.so.0 (0x00007f03f6da2000)
	libsasl2.so.3 &#x3D;&gt; &#x2F;lib64&#x2F;libsasl2.so.3 (0x00007f03f6b85000)
	libjvm.so &#x3D;&gt; &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.322.b06-1.el7_9.x86_64&#x2F;jre&#x2F;lib&#x2F;amd64&#x2F;server&#x2F;libjvm.so (0x00007f03f5ada000)
	libkudu_client.so.0 &#x3D;&gt; &#x2F;root&#x2F;gujc&#x2F;impala&#x2F;toolchain&#x2F;kudu-4ed0dbbd1&#x2F;release&#x2F;lib64&#x2F;libkudu_client.so.0 (0x00007f03f53f7000)
	librt.so.1 &#x3D;&gt; &#x2F;lib64&#x2F;librt.so.1 (0x00007f03f51ef000)
	libdl.so.2 &#x3D;&gt; &#x2F;lib64&#x2F;libdl.so.2 (0x00007f03f4feb000)
	libssl.so.10 &#x3D;&gt; &#x2F;lib64&#x2F;libssl.so.10 (0x00007f03f4d79000)
	libcrypto.so.10 &#x3D;&gt; &#x2F;lib64&#x2F;libcrypto.so.10 (0x00007f03f4916000)
	libkrb5.so.3 &#x3D;&gt; &#x2F;lib64&#x2F;libkrb5.so.3 (0x00007f03f462d000)
	libgssapi_krb5.so.2 &#x3D;&gt; &#x2F;lib64&#x2F;libgssapi_krb5.so.2 (0x00007f03f43e0000)
	libstdc++.so.6 &#x3D;&gt; &#x2F;root&#x2F;gujc&#x2F;impala&#x2F;toolchain&#x2F;snappy-1.1.4&#x2F;lib&#x2F;libstdc++.so.6 (0x00007f03f40d6000)
	libm.so.6 &#x3D;&gt; &#x2F;lib64&#x2F;libm.so.6 (0x00007f03f3dd4000)
	libgcc_s.so.1 &#x3D;&gt; &#x2F;root&#x2F;gujc&#x2F;impala&#x2F;toolchain&#x2F;snappy-1.1.4&#x2F;lib&#x2F;libgcc_s.so.1 (0x00007f03f3bbd000)
	libc.so.6 &#x3D;&gt; &#x2F;lib64&#x2F;libc.so.6 (0x00007f03f37ef000)
	&#x2F;lib64&#x2F;ld-linux-x86-64.so.2 (0x00007f03f71c2000)
	libresolv.so.2 &#x3D;&gt; &#x2F;lib64&#x2F;libresolv.so.2 (0x00007f03f35d5000)
	libcrypt.so.1 &#x3D;&gt; &#x2F;lib64&#x2F;libcrypt.so.1 (0x00007f03f339e000)
	libk5crypto.so.3 &#x3D;&gt; &#x2F;lib64&#x2F;libk5crypto.so.3 (0x00007f03f316b000)
	libcom_err.so.2 &#x3D;&gt; &#x2F;lib64&#x2F;libcom_err.so.2 (0x00007f03f2f67000)
	libkrb5support.so.0 &#x3D;&gt; &#x2F;lib64&#x2F;libkrb5support.so.0 (0x00007f03f2d57000)
	libz.so.1 &#x3D;&gt; &#x2F;lib64&#x2F;libz.so.1 (0x00007f03f2b41000)
	libkeyutils.so.1 &#x3D;&gt; &#x2F;lib64&#x2F;libkeyutils.so.1 (0x00007f03f293d000)
	libfreebl3.so &#x3D;&gt; &#x2F;lib64&#x2F;libfreebl3.so (0x00007f03f273a000)
	libselinux.so.1 &#x3D;&gt; &#x2F;lib64&#x2F;libselinux.so.1 (0x00007f03f2513000)
	libpcre.so.1 &#x3D;&gt; &#x2F;lib64&#x2F;libpcre.so.1 (0x00007f03f22b1000)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这些 so 文件大部分是系统自带的或者已安装的，我们只要复制跟Impala版本相关的就好，比如说 libkudu_client.so.0，其它的不需要一并复制。<br>这里说的复制，是指，需要把非系统安装的依赖，复制到CM的安装文件夹内，可以看出，只有libkudu_client是放在新编译的源码内的，其他的都是引用的系统安装的依赖</p>
<h2 id="新版本impala部署"><a href="#新版本impala部署" class="headerlink" title="新版本impala部署"></a>新版本impala部署</h2><p>我们来生成一个和 /opt/cloudera/parcels/CDH/lib/impala 目录结构一样的目录，然后通过在 CM 里设置 IMPALA_HOME 环境变量来使用它<br>具体的文件结构这里就不细看了，可以参考<a href="https://www.freesion.com/article/8587908372/">在CDH6.3中单独升级IMPALA到APACHE IMPALA 3.4</a></p>
<h3 id="生成新Impala目录"><a href="#生成新Impala目录" class="headerlink" title="生成新Impala目录"></a>生成新Impala目录</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH&#x2F;lib
cp -r impala impala-3.4
cd impala-3.4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>下面按照一下步骤操作：</p>
<ol>
<li>把lib目录里的jar包都删了，剩下so文件</li>
<li>libkudu_client.so.0 替换为我们编译Impala 3.4时用的，从前面ldd的输出可以看到在 /root/gujc/impala/toolchain/kudu-4ed0dbbd1/release/lib64/libkudu_client.so.0,其它so文件不用管</li>
<li>impala-3.4依赖的jar包也都复制进这个lib目录，它们在编译目录里能找到，具体路径是 $IMPALA_HOME/fe/target/dependency/</li>
<li>impala-3.4编译出来的 impala-frontend-0.1-SNAPSHOT.jar 放进lib目录，在编译目录里的路径是 fe/target/impala-frontend-0.1-SNAPSHOT.jar</li>
<li>把 impala-3.4编译出来的 impala-data-source-api-1.0-SNAPSHOT.jar 放进lib目录，在编译目录里的路径是 ext-data-source/api/target/impala-data-source-api-1.0-SNAPSHOT.jar。</li>
<li>把sbin-retail目录的impalad换成apache impala 3.4编译后的impalad，在编译目录里的路径是 be/build/latest/service/impalad</li>
<li>把新的Impala目录放到所有机器上，确保它们一致</li>
<li>更改CM配置并重启,在CM中去到Impala -&gt; 配置 -&gt; env，加一个环境变量 IMPALA_HOME=/opt/cloudera/parcels/CDH/lib/impala-3.4</li>
<li>然后重启整个Impala集群</li>
</ol>
<p>通过beeline链接impala，查看输出日志：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@V-NJ-2-220 ~]# beeline -u &quot;jdbc:impala:&#x2F;&#x2F;172.16.2.205:21050;AuthMech&#x3D;3;UID&#x3D;root;PWD&#x3D;;UseSasl&#x3D;0&quot;
WARNING: Use &quot;yarn jar&quot; to launch YARN applications.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:&#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH-6.2.0-1.cdh6.2.0.p0.967373&#x2F;jars&#x2F;log4j-slf4j-impl-2.8.2.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:&#x2F;opt&#x2F;cloudera&#x2F;parcels&#x2F;CDH-6.2.0-1.cdh6.2.0.p0.967373&#x2F;jars&#x2F;slf4j-log4j12-1.7.25.jar!&#x2F;org&#x2F;slf4j&#x2F;impl&#x2F;StaticLoggerBinder.class]
SLF4J: See http:&#x2F;&#x2F;www.slf4j.org&#x2F;codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:impala:&#x2F;&#x2F;172.16.2.205:21050;AuthMech&#x3D;3;UID&#x3D;root;PWD&#x3D;;UseSasl&#x3D;0
Connected to: Impala (version 3.4.1-RELEASE)
Driver: ImpalaJDBC (version 02.06.03.1004)
Error: [Cloudera][JDBC](11975) Unsupported transaction isolation level: 4. (state&#x3D;HY000,code&#x3D;11975)
Beeline version 2.1.1-cdh6.2.0 by Apache Hive
0: jdbc:impala:&#x2F;&#x2F;172.16.2.205:21050&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看出，现在的impala是3.4.1-RELEASE版本的了<br>具体可以参考<a href="https://blog.csdn.net/weixin_45104537/article/details/121487197">CDH6.3.2升级impala3.2至impala3.4详细步骤</a></p>
<p>impala的源码里默认制定的hudi版本是<code>0.5.0-incubating</code>,这里测试了一下，把hudi的版本改成了0.10.1编译不通过<br>之后impala还会不会维护3.x版本？因为4.x不支持hive2，仅支持hive3，这样升级的代价更大</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">IMPALA_HBASE_VERSION    &#x3D; 2.1.0-cdh6.x-SNAPSHOT
IMPALA_HUDI_VERSION     &#x3D; 0.5.0-incubating
IMPALA_SENTRY_VERSION   &#x3D; 2.1.0-cdh6.x-SNAPSHOT
IMPALA_KUDU_VERSION     &#x3D; 4ed0dbbd1
IMPALA_KUDU_JAVA_VERSION&#x3D; 1.12.0-SNAPSHOT
IMPALA_RANGER_VERSION   &#x3D; 2.0.0.7.0.2.0-212<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

]]></content>
  </entry>
  <entry>
    <title>linux杂记</title>
    <url>/2021/01/16/linux%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>shell常用语法</li>
<li>shell实用命令<a id="more"></a>
<h2 id="IF-条件判断"><a href="#IF-条件判断" class="headerlink" title="IF 条件判断"></a>IF 条件判断</h2><h3 id="判断-boot-分区可用容量小于-20MB-时报警，否则显示-OK"><a href="#判断-boot-分区可用容量小于-20MB-时报警，否则显示-OK" class="headerlink" title="判断 boot 分区可用容量小于 20MB 时报警，否则显示 OK"></a>判断 boot 分区可用容量小于 20MB 时报警，否则显示 OK</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">df | grep &quot;boot&quot; | awk &#39; &#123;if ($4&lt;20000)  print &quot;Alart&quot; ; else print &quot;OK&quot;&#125;&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="While-循环"><a href="#While-循环" class="headerlink" title="While 循环"></a>While 循环</h2><h3 id="指定范围内执行动作"><a href="#指定范围内执行动作" class="headerlink" title="指定范围内执行动作"></a>指定范围内执行动作</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 语法一
awk &#39;i&#x3D;1 &#123;&#125; BEGIN &#123;while (i&lt;3) &#123;++i;print i&#125;&#125;&#39; test.txt 
# 语法二
awk &#39;BEGIN &#123;do &#123;++i;print i&#125; while (i&lt;3)&#125;&#39; test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="For-循环"><a href="#For-循环" class="headerlink" title="For 循环"></a>For 循环</h2><h3 id="for-变量；条件；计数器"><a href="#for-变量；条件；计数器" class="headerlink" title="for (变量；条件；计数器)"></a>for (变量；条件；计数器)</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">awk &#39;BEGIN &#123;for (i&#x3D;1;i&lt;3;i++) print i&#125;&#39; test.txt
awk &#39;BEGIN &#123;for (i&#x3D;3;i&gt;1;i--) print i&#125;&#39; test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
上述 While 和 For 循环语句使用的 awk 均使用 BEGIN 模式，即在未读取文档内容前就会将 BEGIN 代码执行完毕，所以输入文档可以是任意文档。<br>具体参考：<br><a href="https://blog.csdn.net/sunny_future/article/details/80287236">https://blog.csdn.net/sunny_future/article/details/80287236</a></li>
</ul>
<h2 id="查询文件下所有文件是否包含某个字符串"><a href="#查询文件下所有文件是否包含某个字符串" class="headerlink" title="查询文件下所有文件是否包含某个字符串"></a>查询文件下所有文件是否包含某个字符串</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">find .| xargs grep -ri &quot;class&quot; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="查询文件夹下所有文件既包含AAA又包含BBB字符串"><a href="#查询文件夹下所有文件既包含AAA又包含BBB字符串" class="headerlink" title="查询文件夹下所有文件既包含AAA又包含BBB字符串"></a>查询文件夹下所有文件既包含AAA又包含BBB字符串</h2><pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">find .| xargs grep -ri "AAA" -l |  xargs grep -ri "BBB"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="目录下的所有文件中查找字符串-并且只打印出含有该字符串的文件名"><a href="#目录下的所有文件中查找字符串-并且只打印出含有该字符串的文件名" class="headerlink" title="目录下的所有文件中查找字符串,并且只打印出含有该字符串的文件名"></a>目录下的所有文件中查找字符串,并且只打印出含有该字符串的文件名</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">find .| xargs grep -ri &quot;class&quot; -l <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="遍历指定文件夹下所有文件"><a href="#遍历指定文件夹下所有文件" class="headerlink" title="遍历指定文件夹下所有文件"></a>遍历指定文件夹下所有文件</h2><h3 id="采用递归的方式"><a href="#采用递归的方式" class="headerlink" title="采用递归的方式"></a>采用递归的方式</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">function scandir() &#123;
    local cur_dir parent_dir workdir
    workdir&#x3D;$1
    cd $&#123;workdir&#125;
    if [ $&#123;workdir&#125; &#x3D; &quot;&#x2F;&quot; ]
    then
        cur_dir&#x3D;&quot;&quot;
    else
        cur_dir&#x3D;$(pwd)
    fi

    for dirlist in $(ls $&#123;cur_dir&#125;)
    do
        if test -d $&#123;dirlist&#125;;then
            cd $&#123;dirlist&#125;
            scandir $&#123;cur_dir&#125;&#x2F;$&#123;dirlist&#125;
            cd ..
        else
            echo $&#123;cur_dir&#125;&#x2F;$&#123;dirlist&#125;
        fi
    done                       
&#125;

if test -d $1                  
then
    scandir $1                 
elif test -f $1                
then
    echo &quot;you input a file but not a directory,pls reinput and try again&quot;
    exit 1
else
    echo &quot;the Directory isn&#39;t exist which you input,pls input a new one!!&quot;
    exit 1
fi
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="利用命令行："><a href="#利用命令行：" class="headerlink" title="利用命令行："></a>利用命令行：</h3><p>获取bigdata下所有的以.sh结尾的文件</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">find &#x2F;home&#x2F;bigdata -name &quot;*.sh&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>参考：<br>    <a href="https://blog.csdn.net/u010801696/article/details/78913494">https://blog.csdn.net/u010801696/article/details/78913494</a></p>
<h2 id="ftp在centos下如何登陆"><a href="#ftp在centos下如何登陆" class="headerlink" title="ftp在centos下如何登陆"></a>ftp在centos下如何登陆</h2><h3 id="ftp的登陆方式"><a href="#ftp的登陆方式" class="headerlink" title="ftp的登陆方式"></a>ftp的登陆方式</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ftp
open ip port
## 输入完host以后，会弹出让输入用户名和密码，之后就登陆进去了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="sftp的登陆方式"><a href="#sftp的登陆方式" class="headerlink" title="sftp的登陆方式"></a>sftp的登陆方式</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sftp -P port user@ip
## 回车后提示输入密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="lftp（不需要手动输入用户名密码，常用于自动化脚本中）"><a href="#lftp（不需要手动输入用户名密码，常用于自动化脚本中）" class="headerlink" title="lftp（不需要手动输入用户名密码，常用于自动化脚本中）"></a>lftp（不需要手动输入用户名密码，常用于自动化脚本中）</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">lftp -u user,psw sftp:&#x2F;&#x2F;ip:host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="ftp使用模糊查询下载所有匹配的文件"><a href="#ftp使用模糊查询下载所有匹配的文件" class="headerlink" title="ftp使用模糊查询下载所有匹配的文件"></a>ftp使用模糊查询下载所有匹配的文件</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">open 192.168.1.1 10021
prompt   ##取消ftp的交互式，否则每次下载下一个文件都要回车一下，仅对当前窗口有效，ftp退出后，下次进入需要重新prompt
mget 2020-05-12*   #下载正则匹配上的所有文件
get aaa.dat    # 下载指定文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="ubuntu下替换apt-get的源"><a href="#ubuntu下替换apt-get的源" class="headerlink" title="ubuntu下替换apt-get的源"></a>ubuntu下替换apt-get的源</h3><p>参考<a href="https://www.cnblogs.com/gabin/p/6519352.html">https://www.cnblogs.com/gabin/p/6519352.html</a></p>
<h3 id="解决出现-unable-to-resolve-host-问题"><a href="#解决出现-unable-to-resolve-host-问题" class="headerlink" title="解决出现 unable to resolve host 问题"></a>解决出现 unable to resolve host 问题</h3><p>ubuntu在sudo的时候，总是出现unable to resolve host，解决步骤：</p>
<ul>
<li>修改 /etc/hosts里的127.0.0.1 localhost 后面加上主机名称（127.0.0.1 localhost aaa）</li>
<li>修改/etc/hostname，这里的名称和上面的主机名称保持一致(aaa)</li>
</ul>
<h3 id="ssh免秘钥"><a href="#ssh免秘钥" class="headerlink" title="ssh免秘钥"></a>ssh免秘钥</h3><p>用过好几次免秘钥，但是每次都会忘了应该把copy谁的公钥到另外用户的.ssh文件夹<br>这里专门记录一次</p>
<blockquote>
<p>A要使用ssh免密登录到B用户下（可以使远程服务器），就把A的用户下的.ssh文件的id_rsa.pub 内容 cat到远程服务器B 的.ssh的authorized_keys 文件里</p>
</blockquote>
<blockquote>
<p>说明白点就是，A用户如果想免秘钥登录B用户，那么就需要把公钥先让B用户知道。这样就是自己人了。</p>
</blockquote>
<p>还有一个注意点：<br>如果希望ssh公钥生效需满足至少下面两个条件：</p>
<ul>
<li>.ssh目录的权限必须是700 </li>
<li>.ssh/authorized_keys文件权限必须是600</li>
</ul>
<p>具体可以参考<br><a href="https://www.jb51.net/article/94599.htm">https://www.jb51.net/article/94599.htm</a></p>
<h3 id="awk实现sql中group-by，count的功能"><a href="#awk实现sql中group-by，count的功能" class="headerlink" title="awk实现sql中group by，count的功能"></a>awk实现sql中group by，count的功能</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">awk -F &quot; &quot; &#39;&#123; w[$2]+&#x3D;1&#125; END&#123; for (a in w)  print a, w[a]&#125;&#39; detail.csv  &gt; aaa.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>可以参考<br><a href="https://www.cnblogs.com/ginvip/p/6352157.html">https://www.cnblogs.com/ginvip/p/6352157.html</a><br><a href="http://www.blogjava.net/henry14/archive/2012/01/15/368560.html">http://www.blogjava.net/henry14/archive/2012/01/15/368560.html</a></p>
<h3 id="自动输入账号密码"><a href="#自动输入账号密码" class="headerlink" title="自动输入账号密码"></a>自动输入账号密码</h3><p>借助exact<br>公司的gitlab禁用了ssh协议，每次pull代码都需要输入账号密码，这里写个脚本自动输入：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;usr&#x2F;bin&#x2F;expect
set timeout 30
spawn git pull origin master
expect &quot;Username for &#39;https:&#x2F;&#x2F;xxxx.xxxx.com.cn&#39;:&quot;
send &quot;aaa\r&quot;
expect &quot;Password for &#39;https:&#x2F;&#x2F;xxxx@xxxx.xxxx.com.cn&#39;:&quot;
send &quot;**********\r&quot;
interact<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里注意，不用sh这个脚本，需要给这个脚本执行权限，然后./pull.sh</p>
<h3 id="sed命令替换文件内容"><a href="#sed命令替换文件内容" class="headerlink" title="sed命令替换文件内容"></a>sed命令替换文件内容</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sed -i &#39;s&#x2F;\r&#x2F;&#x2F;g&#39; $&#123;fileName&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="linux转换文件编码"><a href="#linux转换文件编码" class="headerlink" title="linux转换文件编码"></a>linux转换文件编码</h3><p>windows下的文件类型为dos，转换成linux，并且把文件编码改成utf-8，否则中文是乱码的</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">iconv -f GB2312 -t utf8 ima_file.csv -o 1_ima_file.csv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>有部分文件报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conv: illegal input sequence at position 14876089<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这是由于你之前的做的假定有问题。GB2312 是国标里面一个最小也是最早的中文编码标准。其中，只涵盖了 6,763 个汉字。所以你需要转换的文件的原始的格式可能并不是 GB2312 编码。<br>这个时候，你可以用 GB18030 做为源格式来进行转换。 GB18030 是最新的国家标准，包含了 27,564 个汉字，而且向下兼容 GB2312 和 GBK。</p>
<pre class="line-numbers language-none"><code class="language-none">iconv -f GB18030 -t utf8 ima_file.csv -o 1_ima_file.csv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="vim打开文件中每行末尾都带有-M"><a href="#vim打开文件中每行末尾都带有-M" class="headerlink" title="vim打开文件中每行末尾都带有 ^M"></a>vim打开文件中每行末尾都带有 ^M</h3><p>因为windows下换行符是\r\n，linux下是\n，多了一个\r</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sed -i &#39;s&#x2F;\r&#x2F;&#x2F;g&#39; $&#123;fileName&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>maven编译Hudi与Flink源码</title>
    <url>/2022/03/10/maven%E7%BC%96%E8%AF%91Hudi%E4%B8%8EFlink%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>maven编译Hudi与Flink源码</li>
</ul>
<a id="more"></a>


<h2 id="maven编译hudi源码"><a href="#maven编译hudi源码" class="headerlink" title="maven编译hudi源码"></a>maven编译hudi源码</h2><p>到github上下载hudi源码，本文选择0.11.0版本</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;hudi.git -b release-0.11.0 <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h3><p>Flink-1.13.6<br>Scala-2.12<br>CDH-6.2.0<br>Hadoop-3.0.0<br>Hive-2.1.1<br>Hudi-0.11(release-0.11.0 )<br>maven-3.6.3<br>jdk-1.8</p>
<h3 id="配置maven并编译源代码"><a href="#配置maven并编译源代码" class="headerlink" title="配置maven并编译源代码"></a>配置maven并编译源代码</h3><p>为了加快下载速度，修改maven的settings.xml，添加aliyun远程仓库</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirror</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>alimaven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirrorOf</span><span class="token punctuation">></span></span>central<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirrorOf</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>aliyun maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>https://maven.aliyun.com/nexus/content/groups/public/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirror</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>注意：</strong> 这里是https，原本从自己电脑上复制下来是http，然后一直报如下错误：<br><img src="/uploads/202203/maven%E7%BC%96%E8%AF%91hudi%E6%8A%A5%E9%94%99%E6%97%A5%E5%BF%971.png" alt="maven编译hudi报错日志1"><br>编译时报错，显示连接中央仓库501<br>经过百度得知，原来中央仓库不再支持http访问，需要将路径更改为https</p>
<p>进入hudi源代码目录，并执行一下语句：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mvn clean install -DskipTests -Dmaven.test.skip&#x3D;true -Dscala-2.12 -Dhadoop.version&#x3D;3.0.0-cdh6.2.0 -Pflink1.13 -Pflink-bundle-shade-hive2 -T20C<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>开始的时候没有指定跳过检查，导致一直报错，编译的时候，一定要跳过检查</p>
<ul>
<li>-DskipTests</li>
<li>-Dmaven.test.skip=true</li>
</ul>
<p>hudi-0.11.0默认用的flink版本是1.14.4,但是，官方给留了一个参数，可以在编译的时候指定flink版本为1.13<br>即加上参数<code>-Pflink1.13</code></p>
<p>这里的参数可以在hudi最外层的pom文件里看到，配置如下：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>profile</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>flink1.13<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.version</span><span class="token punctuation">></span></span>$&#123;flink1.13.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.runtime.artifactId</span><span class="token punctuation">></span></span>flink-runtime_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.runtime.artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.table.runtime.artifactId</span><span class="token punctuation">></span></span>flink-table-runtime-blink_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.table.runtime.artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.table.planner.artifactId</span><span class="token punctuation">></span></span>flink-table-planner-blink_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.table.planner.artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>hudi.flink.module</span><span class="token punctuation">></span></span>hudi-flink1.13.x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>hudi.flink.module</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.bundle.version</span><span class="token punctuation">></span></span>1.13<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.bundle.version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>skipITs</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>skipITs</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>activation</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>flink1.13<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>activation</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>profile</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这种profile在编译的时候，就可以指定-P，后面跟<id></id>的内容</p>
<h3 id="报错与踩坑"><a href="#报错与踩坑" class="headerlink" title="报错与踩坑"></a>报错与踩坑</h3><ol>
<li><p>找不到合适的构造器 [ERROR] 构造器</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.8.0:compile (default-compile) on project hudi-common: Compilation failure [ERROR] &#x2F;opt&#x2F;hudi&#x2F;hudi-common&#x2F;src&#x2F;main&#x2F;java&#x2F;org&#x2F;apache&#x2F;hudi&#x2F;common&#x2F;table&#x2F;log&#x2F;block&#x2F;HoodieParquetDataBlock.java:[111,44] 对于FSDataOutputStream(java.io.ByteArrayOutputStream), 找不到合适的构造器 [ERROR] 构造器 org.apache.hadoop.fs.FSDataOutputStream.FSDataOutputStream(java.io.OutputStream,org.apache.hadoop.fs.FileSystem.Statistics)不适用 [ERROR] (实际参数列表和形式参数列表<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>解决办法：<br>FSDataOutputStream outputStream = new FSDataOutputStream(baos, null) 把报错的地方第二个参数加上</p>
</li>
<li><p>java.lang.NoSuchMethodError: org.apache.parquet.bytes.BytesInput.toInputStream()Lorg/apache/parquet/bytes/ByteBufferInputStream;</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2022-05-10 15:41:49,463 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - split_reader -&gt; NotNullEnforcer(fields&#x3D;[uuid]) (3&#x2F;4)#0 (de4312b557275e636b33cacdeca84148) switched from RUNNING to FAILED with failure cause: java.lang.NoSuchMethodError: org.apache.parquet.bytes.BytesInput.toInputStream()Lorg&#x2F;apache&#x2F;parquet&#x2F;bytes&#x2F;ByteBufferInputStream;
	at org.apache.flink.formats.parquet.vector.reader.AbstractColumnReader.readPageV1(AbstractColumnReader.java:211)
	at org.apache.flink.formats.parquet.vector.reader.AbstractColumnReader.readToVector(AbstractColumnReader.java:156)
	at org.apache.hudi.table.format.cow.vector.reader.ParquetColumnarRowSplitReader.nextBatch(ParquetColumnarRowSplitReader.java:311)
	at org.apache.hudi.table.format.cow.vector.reader.ParquetColumnarRowSplitReader.ensureBatch(ParquetColumnarRowSplitReader.java:287)
	at org.apache.hudi.table.format.cow.vector.reader.ParquetColumnarRowSplitReader.reachedEnd(ParquetColumnarRowSplitReader.java:266)
	at org.apache.hudi.table.format.mor.MergeOnReadInputFormat$BaseFileOnlyFilteringIterator.reachedEnd(MergeOnReadInputFormat.java:509)
	at org.apache.hudi.table.format.mor.MergeOnReadInputFormat.reachedEnd(MergeOnReadInputFormat.java:245)
	at org.apache.hudi.source.StreamReadOperator.consumeAsMiniBatch(StreamReadOperator.java:186)
	at org.apache.hudi.source.StreamReadOperator.processSplits(StreamReadOperator.java:166)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:359)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:323)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:202)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:684)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.executeInvoke(StreamTask.java:639)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>flink写数据到hudi没有问题，数据同步到hive也没问题，从hive里可以正常查询，但是，通过flink查询就会报以上错误。<br>这里很明显可以看出，这个报错是parquet jar包冲突了<br>解决办法：<br>修改packaging/hudi-flink-bundle/pom.xml<br>在relocations里添加以下参数：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>relocation</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pattern</span><span class="token punctuation">></span></span>org.apache.parquet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pattern</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>shadedPattern</span><span class="token punctuation">></span></span>$&#123;flink.bundle.shade.prefix&#125;org.apache.parquet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>shadedPattern</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>relocation</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>问题解决</p>
</li>
</ol>
<p>最终编译成功：<br><img src="/uploads/202203/Hudi%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E6%88%90%E5%8A%9F.png" alt="Hudi源码编译成功"></p>
<h3 id="编译结果说明"><a href="#编译结果说明" class="headerlink" title="编译结果说明"></a>编译结果说明</h3><p>packaging/hudi-flink-bundle/target下的hudi-flink-bundle jar 是 flink 用来写入和读取数据</p>
<h3 id="补充maven相关知识"><a href="#补充maven相关知识" class="headerlink" title="补充maven相关知识"></a>补充maven相关知识</h3><h4 id="Maven如何配置多个远程仓库"><a href="#Maven如何配置多个远程仓库" class="headerlink" title="Maven如何配置多个远程仓库"></a>Maven如何配置多个远程仓库</h4><p>常用配置：我们常用的配置是在maven的配置文件的 mirrors 标签中去配置远程仓库，但是 mirrors 标签中配置多个远程仓库的时候，只有第一个会生效，只有第一个仓库无法访问的时候才会使用第二个仓库，如果第一个仓库能访问，但是没有你所需要的依赖，那它是不会去第二个仓库中下载依赖的。所以如果在这里配置远程仓库的话，因为不同项目用到的依赖不一样，不是每个仓库中都有，这时候就需要你手动切换远程仓库。</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirror</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>alimaven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirrorOf</span><span class="token punctuation">></span></span>central,!cloudera<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirrorOf</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>aliyun maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>http://maven.aliyun.com/nexus/content/groups/public/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirror</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>多个远程仓库配置：在Maven的配置文件中的 profiles 标签下面配置多个远程仓库，这样配置之后，如果第一个仓库中如果没有你需要的依赖，或者第一个仓库无法访问，那么会自动的去第二个仓库中下载你需要的依赖，就不需要手动切换远程仓库了。</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>profiles</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>profile</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>myProfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repositories</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repository</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>myRepository<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>Repository for me<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>http://172.172.177.240:8081/nexus/content/groups/public<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repository</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repository</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>deploymentRepo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>deploymentRepo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>https://repo.digiwincloud.com.cn/maven/repository/releases/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repository</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repositories</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>profile</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>profiles</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>activeProfiles</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>activeProfile</span><span class="token punctuation">></span></span>myProfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>activeProfile</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>activeProfiles</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>注意：</strong></p>
<ul>
<li>在 profiles 标签中配置过远程仓库之后，mirrors 标签中就不需要再配置了，原先配置过也可以删掉或者注释掉。</li>
<li>settings.xml配置文件中最好不要写中文注释，一定要记得将中文注释删掉。</li>
</ul>
<h2 id="maven编译Flink源码"><a href="#maven编译Flink源码" class="headerlink" title="maven编译Flink源码"></a>maven编译Flink源码</h2><p>环境还是上面的环境，这里选用flink-1.13.6进行编译</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wget https:&#x2F;&#x2F;dlcdn.apache.org&#x2F;flink&#x2F;flink-1.13.6&#x2F;flink-1.13.6-src.tgz --no-check-certificate
tar zxvf flink-1.13.6-src.tgz -C .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>以前需要先编译flink-shaded-hadoop这个包，将hadoop和hive指定你对应生产的版本编译出flink-shaded-hadoop-2-uber_xxx包，然后将这个包放在lib的目录下，flink启动任务的时候去lib加载。<br>自从1.11.0版本以后，Flink官方为了让Flink变得Hadoop Free，现在能支持hadoop2和hadoop3，同时可以指定不同的Hadoop环境<br>为了达到这一目标，通过设置export HADOOP_CLASSPATH=<code>hadoop classpath</code>即可，不用编译flink-shaded包。<br><strong>重点：</strong> 编译好的Flink的jar里面是没有包含Hadoop和Hive的代码。当Flink任务启动的时候，JM和TM都是通过HADOOP_CLASSPATH环境变量获取Hadoop的相关变量。</p>
<p>因为之前都已经配置过maven环境了，所以编译起来还是很方便的，直接运行编译代码：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mvn clean install -DskipTests -Dfast -Drat.skip&#x3D;true -Dhaoop.version&#x3D;3.0.0-cdh6.2.0 -Pvendor-repos -Dinclude-hadoop -Dscala-2.12 -T10C

# -Dfast  #在flink根目录下pom.xml文件中fast配置项目中含快速设置,其中包含了多项构建时的跳过参数. #例如apache的文件头(rat)合法校验，代码风格检查，javadoc生成的跳过等，详细可阅读pom.xml
# install maven的安装命令
# -T10C #支持多处理器或者处理器核数参数,加快构建速度,推荐Maven3.3及以上
# -Pinclude-hadoop  将hadoop的 jar包，打入到lib&#x2F;中
# -Pvendor-repos   # 如果需要指定hadoop的发行商，如CDH，需要使用-Pvendor-repos
# -Dscala-2.12     # 指定scala的版本为2.12
# -Dhadoop.version&#x3D;3.0.0-cdh6.2.0  指定 hadoop 的版本，这里的版本与CDH集群版本的Hadoop一致就行<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="maven-编译Flink-1-15-0"><a href="#maven-编译Flink-1-15-0" class="headerlink" title="maven 编译Flink-1.15.0"></a>maven 编译Flink-1.15.0</h3><p>总是报如下错误</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Running &#39;npm install --cache-max&#x3D;0 --no-save&#39; in &#x2F;opt&#x2F;gitrepo&#x2F;flink-runtime-web&#x2F;web-dashboard<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在flink的源码里，找到flink-runtime-web模块，里面的README.md有单独的编译方法,按照如下流程编译</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd flink-runtime-web&#x2F;web-dashboard
npm install
npm run build<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>但是，在执行npm install的时候，一直报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">npm ERR! path &#x2F;root&#x2F;flink&#x2F;flink-runtime-web&#x2F;web-dashboard&#x2F;node_modules&#x2F;@angular&#x2F;cli
npm ERR! command failed
npm ERR! command sh -c node .&#x2F;bin&#x2F;postinstall&#x2F;script.js
npm ERR! node:internal&#x2F;modules&#x2F;cjs&#x2F;loader:936
npm ERR!   throw err;
npm ERR!   ^
npm ERR!
npm ERR! Error: Cannot find module &#39;&#x2F;root&#x2F;flink&#x2F;flink-runtime-web&#x2F;web-dashboard&#x2F;node_modules&#x2F;@angular&#x2F;cli&#x2F;bin&#x2F;postinstall&#x2F;script.js&#39;
npm ERR!     at Function.Module._resolveFilename (node:internal&#x2F;modules&#x2F;cjs&#x2F;loader:933:15)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这是因为这里用的是root权限编译的。npm对root权限管控很厉害。不能使用root权限编译<br>这里切换到非root用户重新编译flink源码（不需要单独执行flink-runtime-web/web-dashboard了）</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mvn clean install -DskipTests -Dfast -Drat.skip&#x3D;true -Dhaoop.version&#x3D;3.0.0-cdh6.2.0 -Pvendor-repos -Dinclude-hadoop -Dscala-2.12 -T10C<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<p>解决办法：<br>修改flink源码flink-runtime-web的pom，把里面的npm.proflile给成以下内容<br>-registry=<a href="https://registry.npm.taobao.org/">https://registry.npm.taobao.org</a> </p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Hudi</tag>
      </tags>
  </entry>
  <entry>
    <title>org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient报错，问题排查</title>
    <url>/2021/01/16/org-apache-hadoop-hive-ql-metadata-SessionHiveMetaStoreClient%E6%8A%A5%E9%94%99%EF%BC%8C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient报错，问题排查<a id="more"></a>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2>最近在整合pyspark与hive，新安装spark-2.3.3以客户端的方式访问hive数据，运行方式使用spark on yarn，但是在配置spark读取hive数据的时候，这里直接把hive下的hive-site.xml复制到spark目录下，启动了一次spark，上面的问题就出现了。</li>
</ul>
<h2 id="网上的说法："><a href="#网上的说法：" class="headerlink" title="网上的说法："></a>网上的说法：</h2><p>hive元数据问题，需要重新初始化hive的元数据<br>但是这个方法肯定不适合我，因为仓库里的表不能受影响，上千张表呢，如果初始化了，所有表都要重新创建。</p>
<h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><ul>
<li><p>首先查看服务器上/tmp/${user}/hive.log文件，这个是公司服务器当时配置的详细的hive执行日志。<br>在日志中，有一段报错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2019-07-06T10:01:53,737 ERROR [370c0a81-c922-4c61-8315-264c39b372c3 main] metastore.RetryingHMSHandler: MetaException(message:Hive Schema version 3.1.0 does not match metastore&#39;s schema version 1.2.0 Metastore is not upgraded or corrupt)
        at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:9063)
        at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:9027)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里的意思是，hive的版本是3.1.0，但是元数据中的版本信息是1.2.0，因此报错。</p>
</li>
<li><p>到hive的元数据库里查了下version表里的数据，确实版本是1.2.0</p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>这里猜测，spark在读取hive元数据的时候，因为spark是直接从官网上下载的，可能官网上的spark是用hive1.2.0版本编译的，所以，它默认使用的1.2.0，导致在启动的时候，修改了hive的元数据<br>但是具体的原因还不知道<br>下面会拿官网上的spark源码手动编译测试一下</p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2></li>
</ul>
<ol>
<li>直接修改version表的数据<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> version<span class="token punctuation">;</span>
<span class="token keyword">update</span> VERSION <span class="token keyword">set</span> SCHEMA_VERSION<span class="token operator">=</span><span class="token string">'2.1.1'</span> <span class="token keyword">where</span>  VER_ID<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
2、在hvie-site.xml中关闭版本验证<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<img src="/uploads/20210116/ive-metadata.png" alt="hive-metadata"></li>
</ol>
<h2 id="深入研究"><a href="#深入研究" class="headerlink" title="深入研究"></a>深入研究</h2><p>   在spark官网上查看了相关的资料，发现，在官网上下载的spark安装包，默认编译的hive版本是1.2.1的，所以每次启动spark的时候，会检查hive的版本。如果采用hive的默认配置，如果不一样，<br>就会修改version<br>    <img src="/uploads/20210116/hive-version-official-website.png" alt="hive-version-official-website"><br>一开始尝试着下载spark源码重新编译spark安装包，编译执行hive的版本为3.1.1，但是，发现每次指定hive的版本，maven下载依赖的时候，都会报错。<br>报错信息如下：</p>
<p>后来想了个折中的办法，spark还是使用原始版本，但是修改一下hive-site.xml文件。<br>    注意：这里修改的是spark的conf下的hive-site.xml，原始的hive里的不需要修改</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>
    Enforce metastore schema version consistency.
    True: Verify that version information stored in metastore matches with one from Hive jars.  Also disable automatic
          schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures
          proper metastore schema migration. (Default)
    False: Warn if the version information stored in metastore doesn't match with one from in Hive jars.
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification.record.version<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>
    When true the current MS version is recorded in the VERSION table. If this is disabled and verification is
     enabled the MS will be unusable.
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这两个配置的具体含义：</p>
<ul>
<li><code>hive.metastore.schema.verification</code> 如果设置为true，那么每次启动hive或者spark的时候，都会检查hive的版本。如果为false，则会告警  </li>
<li><code>hive.metastore.schema.verification.record.version</code> 如果设置为true，每次启动spark的时候，如果检查了hive的版本和spark编译的版本不一致，那么就会修改hive的元数据</li>
</ul>
<p>这里的修改需要设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hive.metastore.schema.verification&#x3D;false   
hive.metastore.schema.verification.record.version&#x3D;false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>以下有3个反例：</p>
<ul>
<li>如过这两个都为true，那么spark会修改hive元数据</li>
<li>如果<code>hive.metastore.schema.verification=true</code>，<br>并且<code>hive.metastore.schema.verification.record.version=false</code>，这时候启动spark就会报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: MetaException(message:Hive Schema version 1.2.0 does not match metastore&#39;s schema version 3.1.0 Metastore is not upgraded or corrupt)
	at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6679)
	at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6645)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>如果设置<code>hive.metastore.schema.verification=false</code><br>且<code>hive.metastore.schema.verification.record.version=true</code>，spark还是会修改hive的元数据</li>
</ul>
<p><img src="/uploads/20210116/hive-metastore-schema-verification.png" alt="hive-metastore-schema-verification"><br><img src="/uploads/20210116/hive-metastore-latest-effect.png" alt="hive-metastore-latest-effect"></p>
<p>所以，只要设置<code>hive.metastore.schema.verification.record.version=false</code>就可以了，但是为了保险起见，我两个都设置成false了</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>python实现scp功能</title>
    <url>/2021/01/16/python%E5%AE%9E%E7%8E%B0scp%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p>最近公司有一个需求，需要把服务器A上的任务放到服务器B上，因为B上有HTTP，并且可以被外网访问，但是直接通过shell的scp，每次都需要输入密码。这里用python简单实现一下</p>
<p>直接上代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> paramiko
<span class="token keyword">import</span> sys

<span class="token keyword">def</span> <span class="token function">deleteRemoteFile</span><span class="token punctuation">(</span>dt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ssh <span class="token operator">=</span> paramiko<span class="token punctuation">.</span>SSHClient<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssh<span class="token punctuation">.</span>set_missing_host_key_policy<span class="token punctuation">(</span>paramiko<span class="token punctuation">.</span>AutoAddPolicy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#第一次登录的认证信息</span>
    ssh<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>hostname<span class="token operator">=</span><span class="token string">'192.168.72.208'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">,</span> username<span class="token operator">=</span><span class="token string">'gold'</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'gold!23'</span><span class="token punctuation">)</span> <span class="token comment"># 连接服务器</span>
    stdin<span class="token punctuation">,</span> stdout<span class="token punctuation">,</span> stderr <span class="token operator">=</span> ssh<span class="token punctuation">.</span>exec_command<span class="token punctuation">(</span><span class="token string">'rm /home/gold/data//*'</span><span class="token punctuation">)</span> <span class="token comment"># 执行命令</span>
    ssh<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">uploadFile2Remote</span><span class="token punctuation">(</span>dt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    transport <span class="token operator">=</span> paramiko<span class="token punctuation">.</span>Transport<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'192.168.72.208'</span><span class="token punctuation">,</span> <span class="token number">65522</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    transport<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>username<span class="token operator">=</span><span class="token string">'gold'</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'gold!23'</span><span class="token punctuation">)</span>
    sftp <span class="token operator">=</span> paramiko<span class="token punctuation">.</span>SFTPClient<span class="token punctuation">.</span>from_transport<span class="token punctuation">(</span>transport<span class="token punctuation">)</span>
    sftp<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">'/home/gold/data/broad.png'</span><span class="token punctuation">,</span> <span class="token string">'/home/gold/data/broad_%s.png'</span> <span class="token operator">%</span> dt<span class="token punctuation">)</span>
    transport<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    unix_ts <span class="token operator">=</span> sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    deleteRemoteFile<span class="token punctuation">(</span>unix_ts<span class="token punctuation">)</span>
    uploadFile2Remote<span class="token punctuation">(</span>unix_ts<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h2><ul>
<li>这里有一个坑，就是sftp在put的时候，需要把在208服务器上的文件名写出来，代码执行的逻辑想当于先touch 一个文件，然后往这个文件里写数据，如果不加文件名，直接到文件夹，就会报错</li>
</ul>
<p>具体的可以参考：<br><a href="https://www.cnblogs.com/fang123456/p/7235688.html">python实现ssh及sftp功能</a></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title>python杂记</title>
    <url>/2021/01/18/python%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="使用-args简化输入代码"><a href="#使用-args简化输入代码" class="headerlink" title="使用**args简化输入代码"></a>使用**args简化输入代码</h2><p>test(<strong>kwargs)</strong> 的作用则是把字典 kwargs 变成关键字参数传递。比如，如果 kwargs 等于 {‘a’:1,’b’:2,’c’:3} ，那这个代码就等价于 test(a=1,b=2,c=3) 。</p>
<h2 id="python拼接字符串的方式"><a href="#python拼接字符串的方式" class="headerlink" title="python拼接字符串的方式"></a>python拼接字符串的方式</h2><p>常用的就是<code>+</code>，还有<code>%s,%d</code>等占位符的方式，还有format()拼接方式<br>这里记录一种比较方便的方式，<code>f-string</code>方式</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">name <span class="token operator">=</span> <span class="token string">'world'</span>
myname <span class="token operator">=</span> <span class="token string">'python_cat'</span>
words <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'Hello </span><span class="token interpolation"><span class="token punctuation">&#123;</span>name<span class="token punctuation">&#125;</span></span><span class="token string">. My name is </span><span class="token interpolation"><span class="token punctuation">&#123;</span>myname<span class="token punctuation">&#125;</span></span><span class="token string">.'</span></span>
<span class="token keyword">print</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>python调用jenkinsAPI构建jenkins，并传递参数</title>
    <url>/2021/01/16/python%E8%B0%83%E7%94%A8jenkinsAPI%E6%9E%84%E5%BB%BAjenkins%EF%BC%8C%E5%B9%B6%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>安装jenkins</li>
<li>通过pythonAPI实现参数化jenkins构建</li>
</ul>
<a id="more"></a>
<h2 id="安装jenkins"><a href="#安装jenkins" class="headerlink" title="安装jenkins"></a>安装jenkins</h2><p>安装jenkins很简单，可以用多种方式安装，这里知道的有：</p>
<ul>
<li>在官网下载rpm包，手动安装，最费事</li>
<li>centos系统通过yum安装，ubuntu通过apt-get安装(不推荐，因为很多东西都使用了默认的)</li>
<li>直接下载官网上的war包：wget <a href="http://ftp-chi.osuosl.org/pub/jenkins/war-stable/2.164.2/jenkins.war">http://ftp-chi.osuosl.org/pub/jenkins/war-stable/2.164.2/jenkins.war</a></li>
</ul>
<p>我这里直接用的下载war包</p>
<h2 id="遇到的坑"><a href="#遇到的坑" class="headerlink" title="遇到的坑"></a>遇到的坑</h2><p>在安装之前，公司的服务器上已经有一个版本的jekins在运行了，所有参数都已经被设置过了，所以，重新安装的版本，虽然文件夹，用户都和以前的版本不一样，但是每次jenkins页面都是直接跳转上个版本的，并不会进入首次激活jenkins的界面</p>
<p>原因是：公司的服务器上配置了JENKINS_HOME，但是jenkins在启动的时候，会首先获取JENKINS_HOME,并读取文件夹内的配置信息。</p>
<p>解决办法：这里取了个巧，在每次启动jenkins的时候，手动指定JENKINS_HOME=/data/jenkins2,这样就不会读取上个版本的信息了</p>
<h2 id="通过pythonAPI实现参数化jenkins构建"><a href="#通过pythonAPI实现参数化jenkins构建" class="headerlink" title="通过pythonAPI实现参数化jenkins构建"></a>通过pythonAPI实现参数化jenkins构建</h2><p>这里要实现的场景是，通过前端的页面，选择相应的下拉框，传递参数到后台jenkins，然后jenkins获取相应的参数，计算以这些参数为条件的数据。</p>
<h2 id="创建jenkins项目"><a href="#创建jenkins项目" class="headerlink" title="创建jenkins项目"></a>创建jenkins项目</h2><p>这里创建的项目需要添加param</p>
<p><img src="/uploads/20210116/jenkins-param.png" alt="hive-import-data"></p>
<p>需要几个参数，就添加几个参数</p>
<h3 id="安装python-jenkins"><a href="#安装python-jenkins" class="headerlink" title="安装python-jenkins"></a>安装python-jenkins</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo pip install python-jenkins<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>直接上代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> jenkins
server <span class="token operator">=</span> jenkins<span class="token punctuation">.</span>Jenkins<span class="token punctuation">(</span><span class="token string">'http://192.168.59.149:28080'</span><span class="token punctuation">,</span> username<span class="token operator">=</span><span class="token string">'jenkins'</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'jenkins@!23'</span><span class="token punctuation">)</span>
server<span class="token punctuation">.</span>build_job<span class="token punctuation">(</span><span class="token string">'jxInstantQuery'</span><span class="token punctuation">)</span>
server<span class="token punctuation">.</span>build_job<span class="token punctuation">(</span><span class="token string">'jxInstantQuery2'</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'param1'</span><span class="token punctuation">:</span> <span class="token string">'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'</span><span class="token punctuation">,</span> <span class="token string">'param2'</span><span class="token punctuation">:</span> <span class="token string">'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>里面的执行shell：<br><img src="/uploads/20210116/jenkins-build.png" alt="hive-import-data"></p>
<p>最终的效果：<br><img src="/uploads/20210116/jenkins-console.png" alt="hive-import-data"></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>spark on yarn遇到的问题</title>
    <url>/2021/01/18/spark%20on%20yarn%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态</li>
<li>spark on yarn任务提交缓慢解决</li>
</ul>
<a id="more"></a>
<h1 id="以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态"><a href="#以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态" class="headerlink" title="以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态"></a>以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态</h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>   spark是以客户端的方式安装的，并没有启动spark的mesos集群，这时候的spark就相当与hive客户端。<br>   以local模型和yarn-cluster方式提交任务，都能正确额执行，但是一yarn-client方式就卡在ACCEPTED</p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>在网上查了资料，都说是资源不够用，需要调整<code>yarn.scheduler.capacity.maximum-am-resource-percent</code>从0.1改成0.5，<br>但是我测试数据才几k，集群内存128G，所以我直接排除了这个原因。后来想到，只有<code>yarn-client</code>方式失败，那问题应该出来driver端。<br>就查看了一下服务器的/etc/hosts，发现diver上有集群其他节点的IP等信息，但是其他节点没有driver配置信息，导致<code>driver</code>能访问到集群，<br>但是集群其他节点访问不了driver，所以<code>local</code>模式可以执行<br><code>yarn-cluster</code>上可以执行，是因为客户端只要把任务提交到yarn上，客户端就没有用了。<br>但是<code>yarn-client</code>方式，客户端是充当了<code>driver</code>，<code>driver</code>需要一直和集群有通信，所以接收不到<code>resouceManager</code>的反馈。任务就一直卡住了</p>
<h2 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h2><p>   有两个方法：<br>   1、在命令后面加上一个–conf spark.driver.host=$your_ip_address，后面直接填客户端机器的IP地址就行<br> <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark-submit \ 
        --master yarn \
        --deploy-mode client \
        --num-executors 2 \
        --executor-memory 1G \
        --executor-cores 1 \
        --conf spark.driver.host&#x3D;192.168.72.129\
         dmp_broadcast_data_day.py
 &#96;&#96;&#96;   
   2、在集群其他节点上都把driver服务器的IP加上去。

# spark on yarn任务提交缓慢解决
## 问题背景
   在使用pyspark提交任务导yarn上的时候，每次提交任务，都要等待好长时间，但是在之前公司中，提交任务导yarn上很快的，所以就调查了一下
   在提交任务的时候，有一个WARN的日志：
&#96;&#96;&#96;shell
    WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>   在网上查了一下，每一次我们运行的时候，如果没有指定 <code>spark.yarn.archive or spark.yarn.jars</code>，Spark将在安装路径下的Jar目录，将其所有的Jar包打包然后将其上传到分布式缓存<br>   官网的原话：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">To make Spark runtime jars accessible from YARN side, you can specify spark.yarn.archive or spark.yarn.jars. For details please refer to Spark Properties. If neither spark.yarn.archive nor spark.yarn.jars is specified, Spark will create a zip file with all jars under $SPARK_HOME&#x2F;jars and upload it to the distributed cache.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="调优方法"><a href="#调优方法" class="headerlink" title="调优方法"></a>调优方法</h2><ul>
<li>首先将Spark安装路径下的所有jar包上传到HDFS上</li>
<li>在spark的conf目录下的spark-defaults.conf添加<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark.yarn.archive               hdfs:&#x2F;&#x2F;ycluster-3&#x2F;data&#x2F;hadoop&#x2F;spark-jars&#x2F;*jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="有个bug"><a href="#有个bug" class="headerlink" title="有个bug"></a>有个bug</h3>我记得我当时按照这个步骤修改完，提交任务导yarn上之后，会报以下错误<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ERROR SparkContext: Error initializing SparkContext.
org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.
    at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:85)
    at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:62)
    at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:156)
    at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:509)
    at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2313)
    at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:868)
    at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:860)
    at scala.Option.getOrElse(Option.scala:121)
    at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:860)
    at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这里以前忘记怎么修复的了，现在果然又遇到了，查了很多资料，总结出两点：</li>
<li>spark-env.sh文件中的HADOOP_CONF_DIR配置错误</li>
<li>yarn的虚拟内存超限，contrainer被干杀死</li>
</ul>
<p>这里查了一下，我的是spark-end.sh配置没问题，问题出现在第二点<br>我的<code>yarn-site.xml</code>的<code>yarn.nodemanager.vmem-pmem-ratio=2.1</code>，虚拟内存最大是2.1，查看yarn上的日志，发现实际内存是2.2，所以，这里把它设置成了3.1</p>
<pre class="line-numbers language-none"><code class="language-none">&lt;!--2个配置只用配置一个即可解决问题，当然都配置也没问题--&gt;
&lt;!--虚拟内存设置是否生效,若实际虚拟内存大于设置值 &quot;--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;&#x2F;name&gt;
    &lt;value&gt;false&lt;&#x2F;value&gt;
    &lt;description&gt;Whether virtual memory limits will be enforced for containers&lt;&#x2F;description&gt;
&lt;&#x2F;property&gt;
&lt;!--配置虚拟内存&#x2F;物理内存的值，默认为2.1,物理内存默认应该是1g，所以虚拟内存是2.1g--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;&#x2F;name&gt;
    &lt;value&gt;3.1&lt;&#x2F;value&gt;
    &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers&lt;&#x2F;description&gt;
&lt;&#x2F;property&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>spark-sql使用笔记</title>
    <url>/2021/01/18/spark-sql%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>spark-sql如何使用hive的udf</li>
<li>spark-sql解决小文件问题</li>
<li>spark-sql cli 输出日志级别为warn</li>
<li>sparksql读取hive数据报错<a id="more"></a>
<h2 id="如何使用hive的udf"><a href="#如何使用hive的udf" class="headerlink" title="如何使用hive的udf"></a>如何使用hive的udf</h2></li>
<li>可以使用<code>spark-sql --jars /opt/hive/udf.jar</code>,指定udf的路径 </li>
<li>还可以在<code>spark-default.conf</code>里指定<code>spark.jars    /opt/hive/udf.jar</code></li>
</ul>
<h2 id="Truncated-the-string-representation-of-a-plan-since-it-was-too-large"><a href="#Truncated-the-string-representation-of-a-plan-since-it-was-too-large" class="headerlink" title="Truncated the string representation of a plan since it was too large"></a>Truncated the string representation of a plan since it was too large</h2><p>在<code>spark-default.conf</code>里设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark.sql.debug.maxToStringFields   2000
spark.debug.maxToStringFields   2000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决："><a href="#使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决：" class="headerlink" title="使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决："></a>使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决：</h2><ul>
<li>通过设置spark参数，<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">set spark.sql.adaptive.enabled&#x3D;true;
set set spark.sql.adaptive.shuffle.targetPostShuffleInputSize &#x3D; 134217728;
# 在sql中添加：distribute by cast(rand() * 5 as int)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
具体可以参考：<a href="https://www.jianshu.com/p/ddd2382a738a">如何避免Spark SQL做数据导入时产生大量小文件</a><br>这个方式不太靠谱，一开始设置的时候，没什么问题，但是后面不知道集群配置更改了什么，导致这个设置失效了。</li>
<li>通过REPARTITION或者COALESCE，将Hive风格的Coalesce and Repartition Hint 应用到Spark SQL</li>
</ul>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">INSERT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">SELECT</span> <span class="token comment">/*+ COALESCE(numPartitions) */</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">INSERT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">SELECT</span> <span class="token comment">/*+ REPARTITION(numPartitions) */</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>例如：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>adaptive<span class="token punctuation">.</span>enabled<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>adaptive<span class="token punctuation">.</span>shuffle<span class="token punctuation">.</span>targetPostShuffleInputSize <span class="token operator">=</span> <span class="token number">134217728</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> app<span class="token punctuation">.</span>app_prom_realtime_marketing_use_coupon_effect_da <span class="token keyword">partition</span><span class="token punctuation">(</span>dt <span class="token operator">=</span> <span class="token string">'$&#123;dt&#125;'</span><span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token comment">/*+ COALESCE(1) */</span>
       from_unixtime<span class="token punctuation">(</span>unix_timestamp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> etl_date<span class="token punctuation">,</span>
       business_id                                                                                        <span class="token punctuation">,</span><span class="token comment">--商家ID</span>
       business_name                                                                                       <span class="token comment">--商家名称</span>
<span class="token keyword">from</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>app_prom_realtime_marketing_use_coupon_effect_da_20210311_01<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意：单纯使用<code>/*+ COALESCE(1) */</code>，文件数不是1，但也不会有200个空文件了，通过设置两个<code>set</code>，保证文件数可以为1<br>这种方式对spark的版本有要求，最好在2.4.x以上<br>还可以设置一下<code>set spark.sql.hive.mergeFiles=true;</code></p>
<h2 id="spark-sql-cli-输出日志级别为warn"><a href="#spark-sql-cli-输出日志级别为warn" class="headerlink" title="spark-sql cli 输出日志级别为warn"></a>spark-sql cli 输出日志级别为warn</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark-sql --name &#39;gjc_spark_cli&#39; \
          --conf &quot;spark.driver.extraJavaOptions&#x3D;-Dlog4j.configuration&#x3D;file:configure&#x2F;log4j.properties&quot; \  ## 用自己的log4j替代客户端的。公司客户端的是info级别，垃圾信息太多
          --conf spark.ui.showConsoleProgress&#x3D;true \      ## 这个参数可以看到执行进度条
          --master yarn \
          --num-executors 20 \
          --executor-memory 6G \
          --driver-cores 4 \
          --driver-memory 6G<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="sparksql读取hive数据报错"><a href="#sparksql读取hive数据报错" class="headerlink" title="sparksql读取hive数据报错"></a>sparksql读取hive数据报错</h2><ul>
<li>问题：  <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 0
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1016)
	... 65 more
Caused by: java.lang.IndexOutOfBoundsException: Index: 0
	at java.util.Collections$EmptyList.get(Collections.java:4454)
	at org.apache.hadoop.hive.ql.io.orc.OrcProto$Type.getSubtypes(OrcProto.java:12240)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.getColumnIndicesFromNames(ReaderImpl.java:651)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.getRawDataSizeOfColumns(ReaderImpl.java:634)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.populateAndCacheStripeDetails(OrcInputFormat.java:927)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:836)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:702)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
java.lang.RuntimeException: serious problem
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1021)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getSplits(OrcInputFormat.java:1048)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:46)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>原因：<br> sparksql生成的hive表有空文件，但是sparksql读取空文件的时候，因为表示orc格式的，导致sparksql解析orc文件出错。但是用hive却可以正常读取。</li>
</ul>
<h2 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h2><p>设置<code>set spark.sql.hive.convertMetastoreOrc=true</code><br>单纯的设置以上参数还是会报错：  </p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">java.lang.IndexOutOfBoundsException
	at java.nio.Buffer.checkIndex(Buffer.java:540)
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:374)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&lt;init&gt;(ReaderImpl.java:316)
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:187)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$getFileReader$2.apply(OrcFileOperator.scala:75)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$getFileReader$2.apply(OrcFileOperator.scala:73)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.TraversableOnce$class.collectFirst(TraversableOnce.scala:145)
	at scala.collection.AbstractIterator.collectFirst(Iterator.scala:1336)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$.getFileReader(OrcFileOperator.scala:86)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$readSchema$1.apply(OrcFileOperator.scala:95)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$readSchema$1.apply(OrcFileOperator.scala:95)
	at scala.collection.immutable.Stream.flatMap(Stream.scala:489)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>需要再设置<code>set spark.sql.orc.impl=native</code><br>参考<a href="https://issues.apache.org/jira/browse/SPARK-19809">SPARK-19809</a> </p>
<h2 id="两个大表关联，报OOM"><a href="#两个大表关联，报OOM" class="headerlink" title="两个大表关联，报OOM"></a>两个大表关联，报OOM</h2><p>主表数据量6000多万，从表1亿，关联后出现OOM的情况</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">Container killed by YARN for exceeding memory limits. 6.3 GB of 6 GB physical memory used. 
Consider boosting spark.yarn.executor.memoryOverhead.

FetchFailed(null, shuffleId&#x3D;4, mapId&#x3D;-1, reduceId&#x3D;121, message&#x3D;
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867)
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>分析了一下原因，在计算主表和从表的时候，都是使用spark-sql的默认并行度，<br>所以最终都是输出200个文件，最后关联完成还是写出200个文件</p>
<p>这里设置spark-sql的默认并行度为1000，这样主表和从表的数据文件都会变成1000，每次关联的数据量就会小很多<br><code>set spark.sql.shuffle.partitions = 1000;</code><br>问题解决</p>
<h2 id="spark-sql读取hive-orc表报数组越界"><a href="#spark-sql读取hive-orc表报数组越界" class="headerlink" title="spark-sql读取hive orc表报数组越界"></a>spark-sql读取hive orc表报数组越界</h2><p>最近公司上云，spark版本切换到3.0.0，很多数据上传到腾讯云上的环境后，spark-sql报数组越界，具体报错信息如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.lang.ArrayIndexOutOfBoundsException: 11
	at org.apache.orc.mapred.OrcStruct.getFieldValue(OrcStruct.java:49)
	at org.apache.spark.sql.execution.datasources.orc.OrcDeserializer.deserialize(OrcDeserializer.scala:60)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>具体问题：使用spark-sql读取hive表，<code>select *</code>可以读取，但是<code>select</code>字段名，就会报数组越界<br>在网上查了很多办法，最终查到原因应该是spark-sql和hive引擎解析orc的方式不一样。</p>
<p>可以通过设置<code>set spark.sql.orc.impl = hive;</code>来解决<br>参考了<a href="https://support.huaweicloud.com/cmpntguide-mrs/mrs_01_1964.html">配置矢量化读取ORC数据</a><br><a href="http://support-it.huawei.com/docs/zh-cn/fusioninsight-all/maintenance-guide/zh-cn_topic_0261891154.html">spark查询ORC表失败，在hive可以正常查询</a></p>
<h2 id="Cannot-overwrite-a-path-that-is-also-being-read-from"><a href="#Cannot-overwrite-a-path-that-is-also-being-read-from" class="headerlink" title="Cannot overwrite a path that is also being read from."></a>Cannot overwrite a path that is also being read from.</h2><p>1.设置 spark.sql.hive.convertMetastoreParquet=false或者spark.sql.hive.convertMetastoreOrc=false</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>spark性能优化之序列化</title>
    <url>/2021/01/15/spark%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96/</url>
    <content><![CDATA[<h3 id="序列化是干什么的？"><a href="#序列化是干什么的？" class="headerlink" title="序列化是干什么的？"></a>序列化是干什么的？</h3><p>序列化简单来说就保存对象在内存中的状态也可以说是实例化变量。这是Java提供的用来保存 Object state，一种保存对象状态的机制。只有实现了serializable接口的类的对象才能被实例化<br>Java中，一切都是对象，在分布式环境中经常需要将Object从这一端网络或设备传递到另一端。这就需要有一种可以在两端传输数据的协议。Java序列化机制就是为了解决这个问题而产生。</p>
<h3 id="什么情况下会用到序列化？"><a href="#什么情况下会用到序列化？" class="headerlink" title="什么情况下会用到序列化？"></a>什么情况下会用到序列化？</h3><ul>
<li>当你想把内存中的对象写入到硬盘时</li>
<li>当你想用套接字在网络上传输对象时</li>
<li>当你想通过RMI调用对象时(RMI总结来说就是远程调用对象，在一个jvm上调用另一个jvm的对象)</li>
</ul>
<h3 id="Spark为什么需要序列化？"><a href="#Spark为什么需要序列化？" class="headerlink" title="Spark为什么需要序列化？"></a>Spark为什么需要序列化？</h3><p>Spark是分布式执行引擎，其核心抽象是弹性分布式数据集RDD，其代表了分布在不同节点的数据。Spark的计算是在executor上分布式执行的，所以对象在执行中需要通过网络传输，或者持久化到本地磁盘的时候必须要经过序列化。</p>
<h3 id="Spark支持的序列化"><a href="#Spark支持的序列化" class="headerlink" title="Spark支持的序列化"></a>Spark支持的序列化</h3><p>spark默认使用的是java序列化，java序列化的好处是非常灵活，开发起来很简单，缺点是速度较慢，在某些情况下序列化的结果也比较大<br>Spark也能使用Kryo（版本2）序列化对象。Kryo不但速度极快，而且产生的结果更为紧凑（通常能提高10倍）。Kryo的缺点是不支持所有类型，为了更好的性能，你需要提前注册程序中所使用的类（class）。</p>
<h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Test"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">"spark.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.spark.serializer.KryoSerializer"</span><span class="token punctuation">)</span>   <span class="token comment">//声明序列化器为KryoSerializer</span>
      <span class="token punctuation">.</span>registerKryoClasses<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>MyClass1<span class="token punctuation">]</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span>MyClass2<span class="token punctuation">]</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span>MyClass3<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">//注册要序列化的自定义类型</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>参考：<a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html">https://tech.meituan.com/2016/04/29/spark-tuning-basic.html</a><br>原则八</p>
<h3 id="spark性能调优"><a href="#spark性能调优" class="headerlink" title="spark性能调优"></a>spark性能调优</h3><p>有篇文章写得很好，可以参考下<br><a href="https://www.cnblogs.com/stillcoolme/p/10576563.html">https://www.cnblogs.com/stillcoolme/p/10576563.html</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>sqoop从mysql导数据到hive报错</title>
    <url>/2021/01/18/sqoop%E4%BB%8Emysql%E5%AF%BC%E6%95%B0%E6%8D%AE%E5%88%B0hive%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>   使用sqoop从mysql导数据到hive，从本地服务器是可以访问mysql的（本地服务器是hadoop集群的一个datanode），但是sqoop导数据的时候依然连接不上mysql<br>报错如下：<br><img src="/uploads/20210118/sqoop-import-error.png" alt="sqoop-import-error"><br>从报错可以看出，是数据库连接失败，很常见的问题，但是从本地是可以直连mysql的。</p>
<p>因为sqoop导数据的时候，默认会启动4个map task，这4个map task会随机启动在不动的datanode上，所以在想，是不是因为其他节点没有权限访问mysql导致。<br>但是需要先搞清楚，sqoop在抽取数据的时候，是不是会把4个map task随机启动在不动的datanode上</p>
<p>在官网上有如下内容：<br><img src="/uploads/20210118/sqoop-official-website.png" alt="sqoop-official-website"><br>虽然讲的不是我们要找到，但是可以判断出，sqoop导数据就是会把maptask随机启动在不通的datanode上。<br>因此，sqoop在导数据到mysql的时候，要确认，hadoop集群的每个节点都要有mysql的读权限</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Sqoop</category>
      </categories>
      <tags>
        <tag>Sqoop</tag>
      </tags>
  </entry>
  <entry>
    <title>vim使用手册</title>
    <url>/2021/01/16/vim%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>vim使用手册<a id="more"></a>
个人感觉，vim用熟了，比任何编辑器都好用，VIM的许多特性节省了时间和击键次数，并可以完成一些其他编辑器无法完成的功能，这里在网上找了几个经典案例，记录一下。</li>
</ul>
<p>与大部分其它编辑器不同，进入 Vim 后，缺省状态下键入的字符并不会插入到所编辑的文件之中。Vim 的模式（mode，可以简单地理解为“状态”）概念非常重要。需要知道，Vim 有以下几个模式：</p>
<ul>
<li>正常（normal）模式，缺省的编辑模式；下面如果不加特殊说明，提到的命令都直接在正常模式下输入；任何其它模式中都可以通过键盘上的 Esc 键回到正常模式。</li>
<li>命令（command）模式，用于执行较长、较复杂的命令；在正常模式下输入“:”（一般命令）、“/”（正向搜索）或“?”（反向搜索）即可进入该模式；命令模式下的命令要输入回车键（Enter）才算完成。</li>
<li>插入（insert）模式，输入文本时使用；在正常模式下键入“i”（insert）或“a”（append）即可进入插入模式（也有另外一些命令，如“c”，也可以进入插入模式，但这些命令有其它的作用）。</li>
<li>可视（visual）模式，用于选定文本块；可以在正常模式下输入“v”（小写）来按字符选定，输入“V”（大写）来按行选定，或输入“Ctrl-V”来按方块选定。</li>
</ul>
<p>一般的发布版中还常常带有一个简单的 30 分钟的 Vim 教程，新手在操作系统的命令行上输入<code>vimtutor</code>命令即可开始学习。除上面的简单说明外，本文并不介绍最基本的 Vim 命令，Vim 的新手应该先通过教程熟悉一下 Vim，再继续往下阅读。</p>
<h2 id="常用的指令序列"><a href="#常用的指令序列" class="headerlink" title="常用的指令序列"></a>常用的指令序列</h2><ul>
<li><p>左右交换光标处两字符的位置：xp<br>命令拆分：</p>
<ul>
<li>x剪切当前字符</li>
<li>p粘贴剪切的字符到光标后面</li>
</ul>
</li>
<li><p>上下交换光标处两行的位置： ddp<br>命令拆分：</p>
<ul>
<li>dd 剪切当前行</li>
<li>p 粘贴剪切的内容到光标的下一行</li>
</ul>
</li>
<li><p>行转列：</p>
<ul>
<li><p>第一种, 多行合并成一行,即:<br>AAAAA<br>BBBBB<br>CCCCC<br>合并为:<br>AAAAA BBBBB CCCCC<br>方法1: normal状态下 3J 其中的3是范围,可以是书签或者搜索位置等方式实现,J为合并<br>注: 如果改为3gJ的话,则合并时各行没有空白AAAAABBBBBCCCCC, 下面方法类似,不再重复这两种合并方式的区别.</p>
<p>方法2: 命令状态下 :1,3 join   或 :1,3 j    （注意j前面是空格）</p>
<p>方法3: 传统一点的,替换换行符的方式,为避免最后一行也被换掉,范围缩小了,命令状态下  :1,2s/\n/ /</p>
</li>
<li><p>第二种,隔行合并,即:</p>
<p>AAAAA<br>BBBBB<br>CCCCC<br>DDDDD</p>
<p>合并为:</p>
<p>AAAAA BBBBB<br>CCCCC DDDDD</p>
<p>方法1: 借用一下宏录制功能, normal状态下 qaJjq 实现录制, 然后在合适的区域重复执行n遍,这里2遍即可,normal状态下2@a</p>
<p>方法2: 命令状态下 :1,4g/^/ join  增加了g过滤后,合并变成了隔行处理</p>
</li>
</ul>
</li>
<li><p>在每行行首添加相同的内容<br>  :%s/^/要添加的内容</p>
</li>
<li><p>在每行行尾添加相同的内容<br>  :%s/$/要添加的内容</p>
</li>
<li><p>利用正则表达式删除代码段每行的行号<br>  :%s/^\s*[0-9]<em>\s</em>//gc</p>
</li>
<li><p>删除某一行之前的所有内容</p>
<ul>
<li>先找到这一行，复制这一行的内容，然后全文查找这一行的内容，这时候这一行是高亮的<br><img src="/uploads/20210116/vim-select.png" alt="vim-select"></li>
<li>然后gg回到第一行</li>
<li>dn<br><img src="/uploads/20210116/vim-dn.png" alt="vim-dn"></li>
</ul>
</li>
</ul>
<h2 id="在vim里使用类似Emacs里的orgmode"><a href="#在vim里使用类似Emacs里的orgmode" class="headerlink" title="在vim里使用类似Emacs里的orgmode"></a>在vim里使用类似Emacs里的orgmode</h2><ul>
<li>在.vimrc里添加配置：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Plugin &#39;jceb&#x2F;vim-orgmode&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>在vim命令行模式运行：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">:PluginInstall<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
之后就能直接用vim编辑.org文件，目前vim-orgmode有如下功能：<br>当前 vim orgmode不支持所有orgmode功能，但它非常有用。 已经支持的功能的简短列表：</li>
<li>语法高亮显示</li>
<li>标题的循环可见性( 折叠)</li>
<li>在标题之间导航</li>
<li>编辑文档的结构： 添加，移动，提升，表示标题和更多</li>
<li>vim orgmode和外部( 文件，网页，等等 ) 中的超链接</li>
<li>待办事项列表管理</li>
<li>标题标记</li>
<li>列表中的字母符号和项目符号符号和复选框支持</li>
<li>基本日期处理</li>
<li>导出到其他格式( 通过 Emacs’org模式</li>
</ul>
<h2 id="vim设置leader键"><a href="#vim设置leader键" class="headerlink" title="vim设置leader键"></a>vim设置leader键</h2><p>leader 键简单的说就是一个前缀键，可以自由设定<br>例如，绑定leader键为‘，’</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&quot; 设置 leader 键，例子为,键，也可以设置为其他的 默认为&quot;&#x2F;&quot;
let mapleader&#x3D;&quot;,&quot;
 
&quot; 设置快捷键，关闭一个窗口
map &lt;leader&gt;wq :wq&lt;CR&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个例子中，在 vim 的<code>normal-mode</code>下，按空格键+w+q 就可以保存文件退出窗口<br>在这个leader的前提下，就不会有键冲突的的情况了</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>starrocks学习笔记</title>
    <url>/2022/06/08/starrocks%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>starrocks学习笔记</li>
</ul>
<a id="more"></a>





<h2 id="starrocks简介"><a href="#starrocks简介" class="headerlink" title="starrocks简介"></a>starrocks简介</h2><p>starrocks的官网写的很好，也有中文文档，文档可以直接看<a href="https://docs.starrocks.com/zh-cn/main/introduction/StarRocks_intro">starrocks官网</a></p>
<h2 id="flinkcdc实时写starrocks"><a href="#flinkcdc实时写starrocks" class="headerlink" title="flinkcdc实时写starrocks"></a>flinkcdc实时写starrocks</h2><p>下载flink-connector-starrocks，可以直接在maven仓库里下载相应的jar包，并把它放在${FLINK_HOME}/lib下，启动flink集群以及sql-client<br>在starrocks里创建表：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"> <span class="token keyword">create</span> <span class="token keyword">table</span> gjc_test_binlog<span class="token punctuation">(</span>
    uuid <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    age <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    ts <span class="token keyword">DATETIME</span><span class="token punctuation">,</span>
    part <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> 
 <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span>uuid<span class="token punctuation">)</span>
 <span class="token keyword">DISTRIBUTED</span> <span class="token keyword">BY</span> <span class="token keyword">HASH</span><span class="token punctuation">(</span>uuid<span class="token punctuation">)</span> BUCKETS <span class="token number">1</span>
 PROPERTIES<span class="token punctuation">(</span><span class="token string">"replication_num"</span> <span class="token operator">=</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意：<br>这里需要指定replication_num，系统默认是3，但是当前集群节点只有1个be，否则插入数据会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Failed to find enough host in all backends. need: 3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在flink的sql客户端里创建映射表：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> execution<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span><span class="token keyword">interval</span><span class="token operator">=</span><span class="token number">3</span>sec<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> users_source_mysql <span class="token punctuation">(</span>
    uuid <span class="token keyword">int</span> <span class="token keyword">primary</span> <span class="token keyword">key</span><span class="token punctuation">,</span>
    name STRING<span class="token punctuation">,</span>
    age <span class="token keyword">int</span><span class="token punctuation">,</span>
    ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    part string
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'mysql-cdc'</span><span class="token punctuation">,</span>
<span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'150.158.190.192'</span><span class="token punctuation">,</span>
<span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'3306'</span><span class="token punctuation">,</span>
<span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'root'</span><span class="token punctuation">,</span>
<span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">,</span>
<span class="token string">'server-time-zone'</span> <span class="token operator">=</span> <span class="token string">'Asia/Shanghai'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.mode'</span> <span class="token operator">=</span> <span class="token string">'initial'</span><span class="token punctuation">,</span>
<span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">,</span>
<span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'users_source_mysql'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> star_gjc_test_binlog <span class="token punctuation">(</span>
  uuid <span class="token keyword">int</span> <span class="token keyword">primary</span> <span class="token keyword">key</span> <span class="token punctuation">,</span>
  name STRING<span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  part string 
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
   <span class="token string">'connector'</span><span class="token operator">=</span><span class="token string">'starrocks'</span><span class="token punctuation">,</span>
   <span class="token string">'jdbc-url'</span><span class="token operator">=</span><span class="token string">'jdbc:mysql://172.16.2.205:19030'</span><span class="token punctuation">,</span>
   <span class="token string">'load-url'</span><span class="token operator">=</span><span class="token string">'172.16.2.205:18030'</span><span class="token punctuation">,</span>
   <span class="token string">'username'</span><span class="token operator">=</span><span class="token string">'root'</span><span class="token punctuation">,</span>
   <span class="token string">'password'</span><span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span>
   <span class="token string">'database-name'</span><span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">,</span>
   <span class="token string">'table-name'</span><span class="token operator">=</span><span class="token string">'gjc_test_binlog'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> star_gjc_test_binlog <span class="token keyword">select</span> uuid<span class="token punctuation">,</span>name<span class="token punctuation">,</span>age<span class="token punctuation">,</span>ts<span class="token punctuation">,</span>part <span class="token keyword">from</span> users_source_mysql<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>和clickhouse一样，在导数据之前，需要在starrocks里提前把表创建好，否则会报错</p>
<p>注意：<br> 建表的时候一定要注意字段长度，如果字段长度不够，数据会默认置为空</p>
<h2 id="使用DataStream写Starrocks"><a href="#使用DataStream写Starrocks" class="headerlink" title="使用DataStream写Starrocks"></a>使用DataStream写Starrocks</h2><h3 id="flinkcdc采集多表并sink到starrrocks"><a href="#flinkcdc采集多表并sink到starrrocks" class="headerlink" title="flinkcdc采集多表并sink到starrrocks"></a>flinkcdc采集多表并sink到starrrocks</h3><p>这里在实现多表sink的时候，一开始想要偷懒使用jdbc的方式，自动拼接sql写入starrocks的，但是，会报<code>too many versions</code><br>原因是，starrcoks每次insert into都会生成一个version，然后会定期compaction，在采集的snapshot阶段，由于写入的数据比较大，会导致version过多<br>需要注意的是，使用jdbc的<code>pstmt.executeBatch();</code>也是不行的，数据还是一条一条的insert。<br>starrocks的微批写入，不是使用<code>pstmt.executeBatch();</code>，而是用的<code>stream load</code>方式，下面直接开发<code>stream load</code>方式<br>多个表同步需要利用flink-connector的DataStream api写入starrocks，cdc多表写入到starrocks的思路是source按cdc配置读取多表，mapfunc转化成StarRocksSinkRowDataWithMeta，然后写入到starrocks sink<br>直接上代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">runJob</span><span class="token punctuation">(</span><span class="token class-name">CommandArgs</span> commandArgs<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">String</span> checkpointPath <span class="token operator">=</span> baseCheckpintPath <span class="token operator">+</span> <span class="token class-name">DigestUtils</span><span class="token punctuation">.</span><span class="token function">md5Hex</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"."</span> <span class="token operator">+</span> commandArgs<span class="token punctuation">.</span><span class="token function">getStbn</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">trim</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toUpperCase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//设置自动获取上次的断点</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">"true"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getIsFromCK</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
            <span class="token class-name">String</span> lastCheckpintPath <span class="token operator">=</span> <span class="token class-name">CheckpointUtil</span><span class="token punctuation">.</span><span class="token function">getCkPath</span><span class="token punctuation">(</span>checkpointPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
            LOG<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"&lt;=======  断点续传：自动从 &#123;&#125; 恢复 =======>"</span><span class="token punctuation">,</span>lastCheckpintPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">//断点续传，获取最近一次的checkpoint路径，如果路径为空，那么告警并退出</span>
            <span class="token comment">//todo 这里需要检查一下当前flink job的状态是否已完成，如果是running，直接退出</span>
            conf<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token string">"execution.savepoint.path"</span><span class="token punctuation">,</span> lastCheckpintPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
            <span class="token comment">//不断点续传，删除目标表并重新创建目标表</span>
            LOG<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"&lt;=======  非断点续传：删除目标表并重建 =======>"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">String</span> jdbcUrl <span class="token operator">=</span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"jdbc:mysql://%s:%s/%s"</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getThost</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getTport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getTdb</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">StarRocksUtil</span> starRocksUtil <span class="token operator">=</span> <span class="token class-name">StarRocksUtil</span><span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">StarRocksJdbcConnectionOptions</span><span class="token punctuation">(</span>jdbcUrl<span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getTuser</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getTpsw</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">SqlConstructorUtils</span> sqlConstructorUtils <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SqlConstructorUtils</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> sqlCreateList <span class="token operator">=</span> sqlConstructorUtils<span class="token punctuation">.</span><span class="token function">getStarrocksCreateSql</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> sqlDropList <span class="token operator">=</span> sqlConstructorUtils<span class="token punctuation">.</span><span class="token function">getStarrocksDropSql</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> sqlCreateList<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                LOG<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"&lt;=======  非断点续传：删除目标表 &#123;&#125; =======>"</span><span class="token punctuation">,</span>sqlDropList<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                starRocksUtil<span class="token punctuation">.</span><span class="token function">excuteSql</span><span class="token punctuation">(</span>sqlDropList<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                LOG<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"&lt;=======  非断点续传：创建目标表 &#123;&#125; =======>"</span><span class="token punctuation">,</span>sqlCreateList<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                starRocksUtil<span class="token punctuation">.</span><span class="token function">excuteSql</span><span class="token punctuation">(</span>sqlCreateList<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>

        <span class="token punctuation">&#125;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//配置ck的状态后端</span>
        env<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HashMapStateBackend</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//设置系统异常退出或人为 Cancel 掉，不删除checkpoint数据</span>
        env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setExternalizedCheckpointCleanup</span><span class="token punctuation">(</span><span class="token class-name">CheckpointConfig</span><span class="token punctuation">.</span><span class="token class-name">ExternalizedCheckpointCleanup</span><span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//设置checkpoint存储目录</span>
        env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setCheckpointStorage</span><span class="token punctuation">(</span>checkpointPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">enableCheckpointing</span><span class="token punctuation">(</span>checkpointInterval<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//设置num值来调整任务允许Checkpoint失败的次数。num需要为0或正整数。如果num为0时，则表示不允许存在任何Checkpoint异常或者失败。</span>
        env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setTolerableCheckpointFailureNumber</span><span class="token punctuation">(</span><span class="token number">1000000000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//每隔2秒重试一次，一共重启2147483647次</span>
        env<span class="token punctuation">.</span><span class="token function">setRestartStrategy</span><span class="token punctuation">(</span><span class="token class-name">RestartStrategies</span><span class="token punctuation">.</span><span class="token function">failureRateRestart</span><span class="token punctuation">(</span>
                <span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment">// 每个时间间隔的最大故障次数</span>
                <span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token class-name">TimeUnit</span><span class="token punctuation">.</span>MINUTES<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">// 测量故障率的时间间隔</span>
                <span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token class-name">TimeUnit</span><span class="token punctuation">.</span>SECONDS<span class="token punctuation">)</span> <span class="token comment">// 延时</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> dbName <span class="token operator">=</span> commandArgs<span class="token punctuation">.</span><span class="token function">getTdb</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> schama <span class="token operator">=</span> commandArgs<span class="token punctuation">.</span><span class="token function">getSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> tableName <span class="token operator">=</span> <span class="token punctuation">(</span>schama  <span class="token operator">+</span> <span class="token string">"."</span> <span class="token operator">+</span> commandArgs<span class="token punctuation">.</span><span class="token function">getStbn</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">,</span><span class="token string">","</span> <span class="token operator">+</span> schama  <span class="token operator">+</span> <span class="token string">"."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> tableArr <span class="token operator">=</span>tableName<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Properties</span> dbzProperty <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.strategy"</span><span class="token punctuation">,</span> <span class="token string">"online_catalog"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.continuous.mine"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"poll.interval.ms"</span><span class="token punctuation">,</span><span class="token string">"5"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"database.tablename.case.insensitive"</span><span class="token punctuation">,</span><span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.batch.size.min"</span><span class="token punctuation">,</span><span class="token string">"50"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.batch.size.default"</span><span class="token punctuation">,</span><span class="token string">"100"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.batch.size.max"</span><span class="token punctuation">,</span><span class="token string">"10000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.sleep.time.default.ms"</span><span class="token punctuation">,</span><span class="token string">"10"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.sleep.time.max.ms"</span><span class="token punctuation">,</span><span class="token string">"200"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.sleep.time.increment.ms"</span><span class="token punctuation">,</span><span class="token string">"50"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"log.mining.view.fetch.size"</span><span class="token punctuation">,</span><span class="token string">"10000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"lob.enabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"snapshot.fetch.size"</span><span class="token punctuation">,</span><span class="token string">"8000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        dbzProperty<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"snapshot.delay.ms"</span><span class="token punctuation">,</span><span class="token string">"3000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">SourceFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> sourceFunction <span class="token operator">=</span> <span class="token class-name">OracleSource</span><span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">hostname</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getShost</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">port</span><span class="token punctuation">(</span><span class="token class-name">Integer</span><span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getSport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">database</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getSdb</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">schemaList</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">tableList</span><span class="token punctuation">(</span>tableArr<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">username</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getSuser</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">password</span><span class="token punctuation">(</span>commandArgs<span class="token punctuation">.</span><span class="token function">getSpsw</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">debeziumProperties</span><span class="token punctuation">(</span>dbzProperty<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">deserializer</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">StarRocksDebeziumDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// converts SourceRecord to JSON String</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">StarRocksSinkOptions</span> sinkOptions <span class="token operator">=</span> <span class="token class-name">StarRocksSinkOptions</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"jdbc-url"</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"jdbc:mysql://%s:%s"</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getThost</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getTport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"load-url"</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%s:%s"</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getThost</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getLoadPort</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"username"</span><span class="token punctuation">,</span> commandArgs<span class="token punctuation">.</span><span class="token function">getTuser</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> commandArgs<span class="token punctuation">.</span><span class="token function">getTpsw</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"table-name"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"database-name"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.properties.format"</span><span class="token punctuation">,</span> <span class="token string">"json"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.properties.strip_outer_array"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.buffer-flush.interval-ms"</span><span class="token punctuation">,</span><span class="token string">"1000"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.properties.column_separator"</span><span class="token punctuation">,</span> <span class="token string">"\\x01"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.properties.row_delimiter"</span><span class="token punctuation">,</span> <span class="token string">"\\x02"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">SinkFunction</span> sinkFunction <span class="token operator">=</span> <span class="token class-name">StarRocksStreamLoadSink</span><span class="token punctuation">.</span><span class="token function">sink</span><span class="token punctuation">(</span>sinkOptions<span class="token punctuation">,</span>commandArgs<span class="token punctuation">.</span><span class="token function">getStbn</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>sourceFunction<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FilterFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span><span class="token class-name">String</span> row<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> operation <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"op"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">return</span> <span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>CREATE<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span>
                                <span class="token operator">||</span> <span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>READ<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span>
                                <span class="token operator">||</span> <span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>DELETE<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span>
                                <span class="token operator">||</span> <span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>UPDATE<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">RichFlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">StarRocksSinkRowDataWithMeta</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    <span class="token keyword">private</span> <span class="token class-name">SimpleDateFormat</span> sdf<span class="token punctuation">;</span>
                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                        <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        sdf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SimpleDateFormat</span><span class="token punctuation">(</span><span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>

                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">String</span> row<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">StarRocksSinkRowDataWithMeta</span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                        <span class="token class-name">JSONObject</span> rowJson <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> operation <span class="token operator">=</span> rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"op"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> afterJson <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"after"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        afterJson<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"update_time"</span><span class="token punctuation">,</span>sdf<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> beforeJson <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"before"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        beforeJson<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"update_time"</span><span class="token punctuation">,</span>sdf<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>CREATE<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>READ<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">StarRocksSinkRowDataWithMeta</span> rowData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StarRocksSinkRowDataWithMeta</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            rowData<span class="token punctuation">.</span><span class="token function">setDatabase</span><span class="token punctuation">(</span>dbName<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            rowData<span class="token punctuation">.</span><span class="token function">setTable</span><span class="token punctuation">(</span>rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"tableName"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            afterJson<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>COLUMN_KEY<span class="token punctuation">,</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>UPSERT<span class="token punctuation">.</span><span class="token function">ordinal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            rowData<span class="token punctuation">.</span><span class="token function">addDataRow</span><span class="token punctuation">(</span>afterJson<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>rowData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>DELETE<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            beforeJson<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>COLUMN_KEY<span class="token punctuation">,</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>DELETE<span class="token punctuation">.</span><span class="token function">ordinal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">StarRocksSinkRowDataWithMeta</span> rowData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StarRocksSinkRowDataWithMeta</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            rowData<span class="token punctuation">.</span><span class="token function">setDatabase</span><span class="token punctuation">(</span>dbName<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            rowData<span class="token punctuation">.</span><span class="token function">setTable</span><span class="token punctuation">(</span>rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"tableName"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            rowData<span class="token punctuation">.</span><span class="token function">addDataRow</span><span class="token punctuation">(</span>beforeJson<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>rowData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">Envelope</span><span class="token punctuation">.</span><span class="token class-name">Operation</span><span class="token punctuation">.</span>UPDATE<span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>operation<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">StarRocksSinkRowDataWithMeta</span> beforeRowData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StarRocksSinkRowDataWithMeta</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">StarRocksSinkRowDataWithMeta</span> afterRowData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StarRocksSinkRowDataWithMeta</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            beforeRowData<span class="token punctuation">.</span><span class="token function">setDatabase</span><span class="token punctuation">(</span>dbName<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            beforeRowData<span class="token punctuation">.</span><span class="token function">setTable</span><span class="token punctuation">(</span>rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"tableName"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            afterRowData<span class="token punctuation">.</span><span class="token function">setDatabase</span><span class="token punctuation">(</span>dbName<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            afterRowData<span class="token punctuation">.</span><span class="token function">setTable</span><span class="token punctuation">(</span>rowJson<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"tableName"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            beforeJson<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>COLUMN_KEY<span class="token punctuation">,</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>DELETE<span class="token punctuation">.</span><span class="token function">ordinal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            beforeRowData<span class="token punctuation">.</span><span class="token function">addDataRow</span><span class="token punctuation">(</span>beforeJson<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            afterJson<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>COLUMN_KEY<span class="token punctuation">,</span><span class="token class-name">StarRocksSinkOP</span><span class="token punctuation">.</span>UPSERT<span class="token punctuation">.</span><span class="token function">ordinal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            afterRowData<span class="token punctuation">.</span><span class="token function">addDataRow</span><span class="token punctuation">(</span>afterJson<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>beforeRowData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>afterRowData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span>sinkFunction<span class="token punctuation">)</span>
                <span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"More Table Collector Snapshot And Binlog"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>因为解析的cdc数据源转化为json了，所以必须要加上如下参数设置：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.properties.format"</span><span class="token punctuation">,</span> <span class="token string">"json"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token function">withProperty</span><span class="token punctuation">(</span><span class="token string">"sink.properties.strip_outer_array"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ol>
<li>实时写starrocks不要使用UNIQUE模型，因为UNIQUE模型不能识别delete/update操作</li>
<li>主键模型的主键长度最大是127，这里在使用的时候，把starrcoks的源码改了一下，从128改成512了</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>starrocks</tag>
      </tags>
  </entry>
  <entry>
    <title>基于githup搭建个人博客网站</title>
    <url>/2021/01/14/%E5%9F%BA%E4%BA%8Egithup%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>利用Github Pages搭建自己的个人网站</li>
<li>Next主题设置<a id="more"></a>

</li>
</ul>
<h2 id="利用Github-Pages搭建自己的个人网站"><a href="#利用Github-Pages搭建自己的个人网站" class="headerlink" title="利用Github Pages搭建自己的个人网站"></a>利用Github Pages搭建自己的个人网站</h2><p>Github Pages建立网站有多种方式</p>
<ul>
<li>创建个人或者组织网站（我们就是要建立这种）<ul>
<li>这种需要注意，项目名一定要是username<organization>.github.io，否则的话，创建的就是为每个project创建的网站了</li>
</ul>
</li>
<li>为每个project建立网站</li>
</ul>
<p>单纯的使用Githup Pages搭建自己的个人网站还是很简单的，有如下的步骤</p>
<ul>
<li>申请githup账号</li>
<li>创建Repositories<ul>
<li>项目名必须得是username.githup.io，如果不是,最终生成的个人网址就是<a href="https://username.github.io/project/">https://username.github.io/project/</a></li>
</ul>
</li>
<li>在Repositories中生成一个html文件，里面随便写点啥</li>
<li>点击Settings -&gt; GitHub Pages -&gt; 选择分支以及文件夹，上面出现绿色的’Your site is published at’就成功了</li>
</ul>
<h2 id="基于-hexo-github-的个人博客搭建"><a href="#基于-hexo-github-的个人博客搭建" class="headerlink" title="基于 hexo + github 的个人博客搭建"></a>基于 hexo + github 的个人博客搭建</h2><h3 id="nodejs安装"><a href="#nodejs安装" class="headerlink" title="nodejs安装"></a>nodejs安装</h3><p>到官网下载nodejs安装包</p>
<pre class="line-numbers language-none"><code class="language-none">xz -d xxx.tar.xz 
tar xvf xxx.tar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>配置环境变量<br>最后检验是否安装成功 </p>
<pre class="line-numbers language-none"><code class="language-none">node -v
npm -v<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="hexo安装"><a href="#hexo安装" class="headerlink" title="hexo安装"></a>hexo安装</h3><ul>
<li>首先更新apt-get的源,这里为了提高速度，把源改成了aliyun，具体可以看<a href="https://www.cnblogs.com/gabin/p/6519352.html">https://www.cnblogs.com/gabin/p/6519352.html</a><pre class="line-numbers language-none"><code class="language-none">sudo apt-get update
sudo apt-get upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>安装hexo<pre class="line-numbers language-none"><code class="language-none">npm install -g hexo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里如果安装的特别慢，可以设置一下npm的源<pre class="line-numbers language-none"><code class="language-none">npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

</li>
</ul>
<h3 id="hexo-初始化"><a href="#hexo-初始化" class="headerlink" title="hexo 初始化"></a>hexo 初始化</h3><p>在本地创建一个文件夹，也就是之后存放代码的地方，例如blog</p>
<pre class="line-numbers language-none"><code class="language-none">cd blog &amp;&amp; hexo init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/20210114/hexo-init.png" alt="hexo-init"><br>hexo会自动下载一些文件到这个目录，这个过程需要联网</p>
<pre class="line-numbers language-none"><code class="language-none">hexo g # 生成html
hexo s # 启动服务<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：<br>hexo s是开启本地预览服务，打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 即可看到内容</p>
<h3 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h3><p>这里选择的主题是next，首先下载这个主题<br>hexo版本5.0以上，可以直接使用</p>
<pre class="line-numbers language-none"><code class="language-none">npm install hexo-theme-next@latest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>启用hexo 5.0，需要nodejs版本在10.13.0以上，可以配置package.json来修改hexo的版本</p>
<pre class="line-numbers language-none"><code class="language-none"># 指定版本为^5.0.0
&quot;dependencies&quot;: &#123;
    &quot;hexo&quot;: &quot;^5.0.0&quot;,
    &quot;hexo-generator-archive&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-generator-category&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-generator-index&quot;: &quot;^2.0.0&quot;,
    &quot;hexo-generator-tag&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-renderer-ejs&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-renderer-marked&quot;: &quot;^3.0.0&quot;,
    &quot;hexo-renderer-stylus&quot;: &quot;^2.0.0&quot;,
    &quot;hexo-server&quot;: &quot;^2.0.0&quot;,
    &quot;hexo-theme-landscape&quot;: &quot;^0.0.3&quot;,
    &quot;hexo-theme-next&quot;: &quot;^8.1.0&quot;
  &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下载完成后，修改_config.yml中的theme: landscape改为theme: next</p>
<p>发布到githup上</p>
<pre class="line-numbers language-none"><code class="language-none">hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="上传到github"><a href="#上传到github" class="headerlink" title="上传到github"></a>上传到github</h3><pre class="line-numbers language-none"><code class="language-none">deploy:
  type: git
  repository: git@github.com:xxxn&#x2F;xxx.github.io.git
  branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>此时直接执行hexo d的话一般会报如下错误：</p>
<pre class="line-numbers language-none"><code class="language-none">Deployer not found: github 或者 Deployer not found: git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>原因是还需要安装一个插件：</p>
<pre class="line-numbers language-none"><code class="language-none">npm install hexo-deployer-git --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Next主题配置"><a href="#Next主题配置" class="headerlink" title="Next主题配置"></a>Next主题配置</h2><h3 id="菜单设置"><a href="#菜单设置" class="headerlink" title="菜单设置"></a>菜单设置</h3><blockquote>
<blockquote>
<p>菜单包括：首页、归档、分类、标签、关于等等  </p>
</blockquote>
</blockquote>
<p>我们刚开始默认的菜单只有首页和归档两个，不能够满足我们的要求，所以需要添加菜单，打开 主题配置文件 找到Menu Settings</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">menu:
  home: &#x2F; || fa fa-home
  #about: &#x2F;about&#x2F; || fa fa-user
  tags: &#x2F;tags&#x2F; || fa fa-tags
  categories: &#x2F;categories&#x2F; || fa fa-th
  archives: &#x2F;archives&#x2F; || fa fa-archive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Next主题样式设置"><a href="#Next主题样式设置" class="headerlink" title="Next主题样式设置"></a>Next主题样式设置</h3><p>Next有4种风格供我们选择，打开 主题配置文件 找到Scheme Settings</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># ---------------------------------------------------------------
# Scheme Settings
# ---------------------------------------------------------------

# Schemes
#scheme: Muse
scheme: Mist
#scheme: Pisces
#scheme: Gemini<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="侧栏设置"><a href="#侧栏设置" class="headerlink" title="侧栏设置"></a>侧栏设置</h3><blockquote>
<blockquote>
<p>侧栏设置包括：侧栏位置、侧栏显示与否、文章间距、返回顶部按钮等等</p>
</blockquote>
</blockquote>
<p>打开 主题配置文件 找到sidebar字段</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">sidebar:
  # Sidebar Position.
  position: right
  #position: right

  # Manual define the sidebar width. If commented, will be default for:
  # Muse | Mist: 320
  # Pisces | Gemini: 240
  #width: 300

  # Sidebar Display (only for Muse | Mist), available values:
  #  - post    expand on posts automatically. Default.
  #  - always  expand for all pages automatically.
  #  - hide    expand only when click on the sidebar toggle icon.
  #  - remove  totally remove sidebar including sidebar toggle.
  display: always

  # Sidebar padding in pixels.
  padding: 18
  # Sidebar offset from top menubar in pixels (only for Pisces | Gemini).
  offset: 12
  # Enable sidebar on narrow view (only for Muse | Mist).
  onmobile: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="头像设置"><a href="#头像设置" class="headerlink" title="头像设置"></a>头像设置</h3><p>打开 主题配置文件 找到Sidebar Avatar字段</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Sidebar Avatar
avatar:
  # Replace the default image and set the url here.
  url: &#x2F;uploads&#x2F;avatar.jpg
  # If true, the avatar will be dispalyed in circle.
  rounded: false
  # If true, the avatar will be rotated with the cursor.
  rotated: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加分类-标签模块"><a href="#添加分类-标签模块" class="headerlink" title="添加分类/标签模块"></a>添加分类/标签模块</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hexo new page categories # 分类
hexo new page tags # 标签<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="设置网站缩略图标"><a href="#设置网站缩略图标" class="headerlink" title="设置网站缩略图标"></a>设置网站缩略图标</h3><p>把图片放在themes/next/source/images里，然后打开 主题配置文件 找到favicon，将small、medium、apple_touch_icon三个字段的值都设置成/images/图片名.jpg就可以了，其他字段都注释掉</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">favicon:
  small: &#x2F;images&#x2F;favicon-16x16.png
  medium: &#x2F;images&#x2F;favicon-32x32.png
  apple_touch_icon: &#x2F;images&#x2F;apple-touch-icon.png
  safari_pinned_tab: &#x2F;images&#x2F;logo.svg
  #android_manifest: &#x2F;images&#x2F;manifest.json
  #ms_browserconfig: &#x2F;images&#x2F;browserconfig.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="设置页面宽度"><a href="#设置页面宽度" class="headerlink" title="设置页面宽度"></a>设置页面宽度</h3><p>自我感觉next主题的正文页面太窄了，这里把正文宽度调大，看得舒服点</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd hexo-theme-next&#x2F;source&#x2F;css&#x2F;_variables&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>编辑base.styl<br>修改变量值</p>
<pre class="line-numbers language-stylus" data-language="stylus"><code class="language-stylus"><span class="token comment">// Layout sizes</span>
<span class="token comment">// --------------------------------------------------</span>
<span class="token variable-declaration"><span class="token variable">$content-desktop</span>                <span class="token operator">=</span> <span class="token number">700</span><span class="token unit">px</span><span class="token punctuation">;</span></span>
<span class="token variable-declaration"><span class="token variable">$content-desktop-large</span>          <span class="token operator">=</span> <span class="token number">800</span><span class="token unit">px</span><span class="token punctuation">;</span></span>
<span class="token variable-declaration"><span class="token variable">$content-desktop-largest</span>        <span class="token operator">=</span> <span class="token number">950</span><span class="token unit">px</span><span class="token punctuation">;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="修改页面字体大小"><a href="#修改页面字体大小" class="headerlink" title="修改页面字体大小"></a>修改页面字体大小</h3><p>下载的最新版本的next主题的字体不知为啥很大，看的很不舒服。这里修改一下<br>修改hexo-theme-next/source/css/_variables/base.styl</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">&#x2F;&#x2F;以前的
&#x2F;&#x2F;$font-size-base           &#x3D; (hexo-config(&#39;font.enable&#39;) and hexo-config(&#39;font.global.size&#39;) is a &#39;unit&#39;) ? unit(hexo-config(&#39;font.global.size&#39;), em) : 1em;
&#x2F;&#x2F;修改成固定值
$font-size-base           &#x3D; 14px;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加站点访问计数"><a href="#添加站点访问计数" class="headerlink" title="添加站点访问计数"></a>添加站点访问计数</h3><pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Baidu Analytics
baidu_analytics: 730b9e375674d8f70a08061cd491e24c


# Show number of visitors of each article.
# You can visit https:&#x2F;&#x2F;leancloud.cn to get AppID and AppKey.
# AppID and AppKey are recommended to be the same as valine&#39;s for counter compatibility.
# Do not enable both &#96;valine.visitor&#96; and &#96;leancloud_visitors&#96;.
leancloud_visitors:
  enable: true
  app_id: xxxxxxxxxxxxxx
  app_key: xxx
  # Required for apps from CN region
  server_url: # &lt;your server url&gt;
  # Dependencies: https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-leancloud-counter-security
  # If you don&#39;t care about security in leancloud counter and just want to use it directly
  # (without hexo-leancloud-counter-security plugin), set &#96;security&#96; to &#96;false&#96;.
  security: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里可以到度娘上查，很多教程</p>
<h3 id="代码块风格"><a href="#代码块风格" class="headerlink" title="代码块风格"></a>代码块风格</h3><p>next主题下的_config.yml</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">codeblock:
  # Code Highlight theme
  # Available values: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic
  # See: https:&#x2F;&#x2F;github.com&#x2F;chriskempson&#x2F;tomorrow-theme
  highlight_theme: normal
  # Add copy button on codeblock
  copy_button:
    enable: true
    # Show text copy result.
    show_result: true
    # Available values: default | flat | mac
    style: default<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>hexo下的_config.yml</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">highlight:
  enable: true
  line_number: true
  auto_detect: false
  tab_replace: &#39;&#39;
  wrap: true
  hljs: false
prismjs:
  enable: true
  preprocess: true
  line_number: true
  tab_replace: &#39;&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加评论插件"><a href="#添加评论插件" class="headerlink" title="添加评论插件"></a>添加评论插件</h3><p>next主题本身就支持众多评论插件，这里综合各种插件的优劣，最终选择了valine<br>修改config.yml之前，先在本地环境安装一下valine</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># Install valine
npm install valine --save<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>因为next本身已经支持，这里只需要在_config.yml里配置下即可</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Valine
# For more information: https:&#x2F;&#x2F;valine.js.org, https:&#x2F;&#x2F;github.com&#x2F;xCss&#x2F;Valine
valine:
  enable: true
  appid: SkWNsftcFwwI7sR8WGnbm8G0-gzGzoHsz
  appkey: wHfJCMCqkaxidT5nJyOygkO7
  notify: false # Mail notifier
  verify: false # Verification code
  placeholder: Just go go # Comment box placeholder
  avatar: wavatar # Gravatar style
  guest_info: nick,mail,link # Custom comment header
  pageSize: 10 # Pagination size
  language: # Language, available values: en, zh-cn
  visitor: true # Article reading statistic
  comment_count: true # If false, comment count will only be displayed in post page, not in home page
  recordIP: false # Whether to record the commenter IP
  serverURLs: # When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)
  #post_meta_order: 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加本地搜索功能"><a href="#添加本地搜索功能" class="headerlink" title="添加本地搜索功能"></a>添加本地搜索功能</h3><p>安装搜索插件  </p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">npm install hexo-generator-searchdb --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>配置next主题_config_yml</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Local Search
# Dependencies: https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-generator-searchdb
local_search:
  enable: true
  # If auto, trigger search by changing input.
  # If manual, trigger search by pressing enter key or search button.
  trigger: auto
  # Show top n results per article, show all results by setting to -1
  top_n_per_article: 1
  # Unescape html strings to the readable one.
  unescape: false
  # Preload the search data when the page loads.
  preload: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>修改hexo项目的_config.yml，添加如下内容：</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># search
search:
  path: search.xml
  field: post
  format: html
  limit: 10000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果不添加，那么在<code>hexo s</code>可以搜索，但是deploy后，正式的网页上点击不了搜索</p>
<h3 id="首页添加阅读全文"><a href="#首页添加阅读全文" class="headerlink" title="首页添加阅读全文"></a>首页添加阅读全文</h3><p>当前首页会把正文都显示出来，所以显得首页很长，不美观。<br>在next主题_config.yml配置</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">excerpt_description: true<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>还需要手动在每篇正文添加<code>&lt;!-- more --&gt;</code>，并写一下文档摘要</p>
<h3 id="配置百度站点收录管理"><a href="#配置百度站点收录管理" class="headerlink" title="配置百度站点收录管理"></a>配置百度站点收录管理</h3><ol>
<li><p>安装插件：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">npm install hexo-baidu-url-submit --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在根目录 _config.yml 文件里加入以下代码：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">baidu_url_submit:
  count: 100                                # 提交最新的多少个链接
  host: https:&#x2F;&#x2F;gujincheng.github.io&#x2F;       # 在百度站长平台中添加的域名
  token: aaaaa                              # 秘钥
  path: baidu_urls.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>token可以在<br><a href="https://ziyuan.baidu.com/linksubmit/index?site=https://gujincheng.github.io/">https://ziyuan.baidu.com/linksubmit/index?site=https://gujincheng.github.io/</a><br>普通收录里看到</p>
</li>
<li><p>在_config.yml 加入新的deployer<br>需要修改之前的配置方式，以前没有<code>-</code>，现在需要多加一个type，所以需要加<code>-</code>,注意repository和branch要和type对其</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">deploy:
  - type: git
    repository: git@github.com:gujincheng&#x2F;gujincheng.github.com.git
    branch: main
  - type: baidu_url_submitter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>这样操作以后，以后每次的<code>hexo d</code>就会直接提交到百度收录,并会返回一下参数</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">&#123;&quot;remain&quot;:2985,&quot;success&quot;:40&#125;           #表示成功40条<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ol>
]]></content>
      <categories>
        <category>工具箱</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库-数据质量</title>
    <url>/2021/08/03/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93-%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>数据质量基本概念</li>
<li>影响因素</li>
<li>评估维度</li>
<li>实施流程<a id="more"></a>

</li>
</ul>
<h2 id="数据质量基本概念"><a href="#数据质量基本概念" class="headerlink" title="数据质量基本概念"></a>数据质量基本概念</h2><ul>
<li>数据质量管理（Data Quality Management），是指对数据从计划、获取、存储、共享、维护、应用、消亡生命周期的每个阶段里可能引发的各类数据质量问题，进行识别、度量、监控、预警等一系列管理活动，并通过改善和提高组织的管理水平使得数据质量获得进一步提高</li>
<li>数据质量管理不是一时的数据治理手段，而是循环的管理过程。其终极目标是通过可靠的数据，提升数据在使用中的价值，并最终为企业赢得经济效益</li>
</ul>
<h2 id="影响因素"><a href="#影响因素" class="headerlink" title="影响因素"></a>影响因素</h2><p>数据问题的来源可能产生于从数据源头到数据存储介质的各个环节。在数据采集阶段，数据的真实性、准确性、完整性、时效性都会影响数据质量。除此之外，数据的加工、存储过程都有可能涉及对原始数据的修改，从而引发数据的质量问题。所以，技术、流程、管理等多方面的因素都有可能会影响到数据质量。</p>
<h2 id="评估维度"><a href="#评估维度" class="headerlink" title="评估维度"></a>评估维度</h2><ul>
<li>完整性<br>数据完整性问题包含数据条目不完整，数据属性不完整等</li>
<li>一致性<br>多源数据的数据模型不一致，如命名不一致，数据编码不一致，含义不一致，生命周期不一致等</li>
<li>准确性<br>准确性也叫可靠性，不可靠的数据可能会导致严重的问题，会造成有缺陷的方法和糟糕的决策</li>
<li>唯一性<br>用于识别和度量重复数据，冗余数据，重复数据是导致业务无法协同，流程无法追溯的重要因素，也是数据治理需要解 决的最基本的数据问题</li>
<li>关联性<br>数据关联性问题是指存在数据关联的数据关系缺失或错误，例如：函数关系、相关系数、主外键关系、索引关系等。存在数据关联性问题，会直接影响数据分析的结果，进而影响管理决策。</li>
<li>真实性<br>数据必须真实准确的反映客观的实体存在或真实的业务，真实可靠的原始统计数据是企业统计工作的灵魂</li>
<li>及时性<br>数据的及时性(In-time)是指能否在需要的时候获到数据，数据的及时性与企业的数据处理速度及效率有直接的关系，是影响业务处理和管理效率的关键指标。</li>
<li>逻辑检查<br>不同表字段之间可能会有逻辑关联，需要稽核</li>
<li>离群值检查<br>部分数据可能会偏离其他数据，比如同一个商品金额大家都是100元，而有一条数据是1W</li>
<li>自定义规则<br>由需求方自定义相关规则</li>
<li>波动稽核<br>与上周环比稽核波动情况 </li>
<li>强弱规则<br>每个规则的权重应该是不一样的，需要配置优先级，这对后续的告警方式是有帮助的</li>
</ul>
]]></content>
      <categories>
        <category>数据仓库</category>
        <category>数据质量</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库面试题</title>
    <url>/2021/11/18/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>数据仓库面试题总结</li>
</ul>
<a id="more"></a>

<p><strong><font size = 5>1. 全量表(df),增量表(di),追加表(da)，拉链表(dz)的区别及使用场景？</font></strong></p>
<p><strong><font size = 5>2. 星型模型和雪花模型？</font></strong></p>
<p><strong><font size = 5>3. 缓慢变化维如何处理，几种方式？</font></strong></p>
<ol>
<li>直接覆盖历史数据</li>
<li>采用拉链表，把记录的过程都记录下来</li>
<li>增加预留资源，每次变化，把新变化的数据放到备用字段</li>
<li>字段透传，把变化的纬度透传到上层的事实表，这样就不用关联了</li>
</ol>
<p><strong><font size = 5>4. 说说你从0-1搭建数仓都做了什么？你觉得最有挑战的是什么？</font></strong></p>
<p><strong><font size = 5>5. 流批一体有什么好处？为什么要搞流批一体？</font></strong><br>传统数仓Lambda架构，数据分析需求基于流、批两套计算引擎产出，这种分离的架构不仅会带来两套开发成本，也导致数据逻辑和口径难以对齐<br><a href="https://baijiahao.baidu.com/s?id=1685957539299113384&wfr=spider&for=pc">为什么阿里云要做流批一体？</a><br>流批一体首先是架构上的流批一体，不仅仅是计算引擎流批一体，存储引擎也需要流批一体，计算引擎可以使用flink，存储引擎，现在常用的可以使用Hudi，Iceberg</p>
<p><strong><font size = 5>6. left semi join和left jion区别？</font></strong></p>
<ul>
<li><code>left semi join</code>左半连接,是 in(keySet) 的关系，遇到右表重复记录，左表会跳过；<br>当右表不存在的时候，左表数据不会显示; 相当于SQL的in语句，注意，结果中是没有B表的字段的<br>LEFT SEMI JOIN 是 IN/EXISTS 子查询的一种更高效的实现。</li>
<li><code>left join</code>:当右表不存在的时候，则会显示NULL</li>
</ul>
<p>数仓面试题可以参考<br><a href="https://blog.csdn.net/qq_28680977/article/details/108460523">2020大厂面试题-数仓篇</a></p>
<p>参考<br><a href="https://mp.weixin.qq.com/s/0mgy07WAMBYNBP6er8_hDA">(终极版)2021大数据面试真题(务必进来看一下)</a></p>
]]></content>
      <categories>
        <category>面试题</category>
        <category>大数据</category>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据湖与数据仓库</title>
    <url>/2022/04/01/%E6%95%B0%E6%8D%AE%E6%B9%96%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>数据库、数据仓库、数据湖、湖仓一体概念与区别<a id="more"></a>


</li>
</ul>
<h2 id="数据库、数据仓库、数据湖、湖仓一体概念与区别"><a href="#数据库、数据仓库、数据湖、湖仓一体概念与区别" class="headerlink" title="数据库、数据仓库、数据湖、湖仓一体概念与区别"></a>数据库、数据仓库、数据湖、湖仓一体概念与区别</h2><h3 id="什么是数据库？"><a href="#什么是数据库？" class="headerlink" title="什么是数据库？"></a>什么是数据库？</h3><p>数据库是“按照数据结构来组织、存储和管理数据的仓库”。<br>现在通常所说的数据库指的是关系型数据库。关系数据库是指采用了关系模型来组织数据的数据库，其以行和列的形式存储数据，具有结构化程度高，独立性强，冗余度低等优点。<br>关系型数据库的主要用于联机事务处理OLTP（On-Line Transaction Processing）主要进行基本的、日常的事务处理，例如银行交易等场景。</p>
<h3 id="什么是数据仓库？"><a href="#什么是数据仓库？" class="headerlink" title="什么是数据仓库？"></a>什么是数据仓库？</h3><p>随着数据库的大规模应用，使信息行业的数据爆炸式的增长。为了研究数据之间的关系，挖掘数据隐藏的价值，人们越来越多的需要使用联机分析处理OLAP（On-Line Analytical Processing）进行数据分析，探究一些深层次的关系和信息。但是不同的数据库之间很难做到数据共享，数据之间的集成与分析也存在非常大的挑战。<br>数据仓库主要功能是将OLTP经年累月所累积的大量数据，通过数据仓库特有的数据储存架构进行OLAP，最终帮助决策者能快速有效地从大量数据中，分析出有价值的信息，提供决策支持<br>数据仓库相比数据库，主要有以下两个特点：</p>
<ul>
<li>数据仓库是面向主题集成的。数据仓库是为了支撑各种业务而建立的，数据来自于分散的操作型数据。因此需要将所需数据从多个异构的数据源中抽取出来，进行加工与集成，按照主题进行重组，最终进入数据仓库。</li>
<li>数据仓库主要用于支撑企业决策分析，所涉及的数据操作主要是数据查询。因此数据仓库通过表结构优化、存储方式优化等方式提高查询速度、降低开销。</li>
</ul>
<p>数据仓库与数据库的对比： </p>
<table>
<thead>
<tr>
<th>维度</th>
<th>数据仓库</th>
<th>数据库</th>
</tr>
</thead>
<tbody><tr>
<td>应用场景</td>
<td>OLAP</td>
<td>OLTP</td>
</tr>
<tr>
<td>数据来源</td>
<td>多数据源</td>
<td>单数据源</td>
</tr>
<tr>
<td>数据标准化</td>
<td>非标准化Schema</td>
<td>高度标准化的静态Schema</td>
</tr>
<tr>
<td>数据读取优势</td>
<td>针对读操作进行优化</td>
<td>针对写操作进行优化</td>
</tr>
</tbody></table>
<blockquote>
<p>所以，数据仓库里的数据是一次写入多次读取</p>
</blockquote>
<h3 id="什么是数据湖？"><a href="#什么是数据湖？" class="headerlink" title="什么是数据湖？"></a>什么是数据湖？</h3><p>数据湖是一个集中存储各类结构化和非结构化数据的大型数据仓库，它可以存储来自多个数据源、多种数据类型的原始数据，数据无需经过结构化处理，就可以进行存取、处理、分析和传输。数据湖能帮助企业快速完成异构数据源的联邦分析、挖掘和探索数据价值。</p>
<p>数据湖的出现主要是为了解决存储全域原始数据的问题。在捕获来自业务应用程序、移动应用程序、IoT设备和互联网的结构化和非结构化数据时，实际上并没有预先定义好数据结构，这意味着可以先存储数据而无须进行精心设计，也无须明确要进行什么分析，由数据科学家和数据工程师在后续工作中探索和尝试<br>从根本上来讲，数据湖的最主要目标是尽可能保持业务的可还原度</p>
<p>对于数据仓库与数据湖的不同之处，可以类比为仓库和湖泊的区别：仓库存储着来自特定来源的货物；而湖泊的水来自河流、溪流和其他来源，并且是<strong>原始数据</strong>。<br>数据湖与数据仓库的对比：</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>数据湖</th>
<th>数据仓库</th>
</tr>
</thead>
<tbody><tr>
<td>应用场景</td>
<td>可以探索性分析所有类型的数据，包括机器学习、数据发现、特征分析、预测等</td>
<td>通过历史的结构化数据进行数据分析</td>
</tr>
<tr>
<td>使用成本</td>
<td>起步成本低，后期成本较高</td>
<td>起步成本高，后期成本较低</td>
</tr>
<tr>
<td>数据质量</td>
<td>包含大量原始数据，使用前需要清洗和标准化处理</td>
<td>质量高，可作为事实依据</td>
</tr>
<tr>
<td>适用对象</td>
<td>数据科学家、数据开发人员为主</td>
<td>业务分析师为主</td>
</tr>
</tbody></table>
<blockquote>
<p>个人理解，数据湖就是不管什么样的数据，都扔到这里，不强调数据标准，数据变化快，所以前期好发展，后期容易烟囱式发展，容易乱<br>但是它也有好处，就是什么数据都可以扔里面，而且它允许数据可以变化</p>
</blockquote>
<p>数据湖写入的时候不关心数据格式，可以这么理解，以流量为例，流量大部分都是日志，入湖的时候，我们不用去关心流量里面有啥字段，可能就是一条完整的日志存进去，等数仓需要分析的时候，按照流量的分析需求，设计好流量的表结构，然后从湖里面拿流量日志，再去解析里面的字段</p>
<h3 id="数据湖存储组件"><a href="#数据湖存储组件" class="headerlink" title="数据湖存储组件"></a>数据湖存储组件</h3><p>数据湖的建设方式有很多种，有的企业使用以Hadoop为核心的数据湖实现，有的企业以MPP为核心加上一些对象存储来实现。虽然建设方式不同，但是它们建设数据湖的目标是一致的<br>使用MPP例如Doris，需要单独搭建集群，与现有的Hadoop生态是分开的，所以从长远角度来看，使用以Hadoop为核心来实现数据湖更加靠谱<br>因为大部分公司大数据平台都是以Hadoop生态为基础的</p>
<p>目前流行的数据湖组件有hudi、iceberg、Delta </p>
<p>关于数据湖与数据仓库，可以参考<a href="https://xw.qq.com/cmsid/20210909A0ARO400">终于有人将数据湖讲明白了</a></p>
<h3 id="什么是湖仓一体？"><a href="#什么是湖仓一体？" class="headerlink" title="什么是湖仓一体？"></a>什么是湖仓一体？</h3><p>湖仓一体，又被称为Lake House，其出发点是通过数据仓库和数据湖的打通和融合，让数据流动起来，减少重复建设。Lake House架构最重要的一点，是实现数据仓库和数据湖的数据/元数据无缝打通和自由流动。湖里的“显性价值”数据可以流到仓里，甚至可以直接被数仓使用；而仓里的“隐性价值”数据，也可以流到湖里，低成本长久保存，供未来的数据挖掘使用<br><img src="/uploads/202203/%E4%BB%8E%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%88%B0%E6%8F%90%E4%BE%9B%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="从数据采集到提供数据服务的流程图"></p>
]]></content>
      <categories>
        <category>数据仓库</category>
        <category>数据湖</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据研发开发规范</title>
    <url>/2022/04/26/%E6%95%B0%E6%8D%AE%E7%A0%94%E5%8F%91%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>代码开发规范</li>
<li>调度系统使用规范</li>
<li>任务上线流程</li>
<li>数仓分层与命名规范<a id="more"></a>



</li>
</ul>
<p>众所周知，制订交通法规表面上是要限制行车权，实际上是保障公众的人身安全。试想如果没有限速，没有红绿灯，没有靠右行驶条款，谁还敢上路。消防局最主要的工作不是灭火，而是为了不发生火灾建立很多规范。如果发生火灾，说明前面的工作没有做到位。<br>同理，对于数仓开发来说，开发规范不是消灭开发的创造性、优雅性，而是限制过度个性化，推行相对标准化，以一种普遍认可的方式一起做事。<br>为此，针对数据研发而言，整理以下开发规范：</p>
<ul>
<li>代码开发规范</li>
<li>调度系统使用规范</li>
<li>任务上线流程</li>
</ul>
<p>设计开发规范的长远目标是从有到无，因为人人自觉遵守，规范和谐地融入开发整个流程，规范似乎消失了，但又无处不在。</p>
<h2 id="代码开发规范"><a href="#代码开发规范" class="headerlink" title="代码开发规范"></a>代码开发规范</h2><p>数据研发分为离线任务和实时任务，两种任务的开发流程完全不同，故开发规范需要分别定制</p>
<h3 id="离线任务"><a href="#离线任务" class="headerlink" title="离线任务"></a>离线任务</h3><h4 id="通用规范"><a href="#通用规范" class="headerlink" title="通用规范"></a>通用规范</h4><p>离线数仓的开发，主要是开发sql任务（hive sql/impala sql）,针对sql任务，制定以下规范：</p>
<ol>
<li>通过编写shell脚本来开发sql任务，一个shell脚本最终只输出一个结果表。中间生成的临时表需要在脚本最后删除</li>
<li>任务的调度使用DolphinScheduler，每天定时启动</li>
<li>默认情况下，执行引擎使用Hive-MR，除非对实效性要求很高，可以切换到Impala</li>
<li>一个hive-cli只能执行一个sql，即一个sql语句不能含有多个<code>;</code></li>
<li>脚本统一在自己本地开发，后上传到gitlab，通过DolphinScheduler的代码发布项目(projectDeploy)发布到线上</li>
<li>如果引用的hive表是分区表，必须指定分区范围，如dt = ‘20220420’</li>
<li>禁止使用<code>select *</code></li>
<li>所有的报表和模型开发必须先出设计再进行开发</li>
</ol>
<h4 id="注释规范"><a href="#注释规范" class="headerlink" title="注释规范"></a>注释规范</h4><p>脚本的开头以及每个sql语句都必须有注视</p>
<ol>
<li>注释内容要清晰明了，含义准确，避免歧义 </li>
<li>字段注释紧跟在字段后面 </li>
<li>应对不易理解的分支条件表达式加注释 </li>
<li>对重要的计算应说明其功能 </li>
<li>过长的函数实现，应将其语句按实现的功能分段加以概括性说明 </li>
<li>原则上所有表、字段、任务都需要添加注释，任务有特定的注释规范，见下文任务注释说明</li>
</ol>
<p>任务注释说明：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># # # # # # -CopyRight# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # -
#   AppName: offline_ods_bm_cust_info
#   Description: 计算售前商机_客户基本信息表，保留历史与最新的数据
#   Source Table:
#        pom.stg_bm_cust_info
#   Output Table:
#        pom.ods_bm_cust_info
#   Version 1.00
#   Language:bash shell
#   CreateDate: 2022&#x2F;04&#x2F;14 14:43
#   Author: gujc
#   ITCode: 17405
#   Email: gujc@digiwin.com
# # # # # # Update Log# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#   2022-04-15 修改history分区数据不全的问题
# # # # # # Environment# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>提供任务名，方便任务创建时任务的获取以及平台中任务查询 </li>
<li>提供创建者、创建日期、功能描述等信息，方便后期维护跟踪 </li>
<li>提供代码变更历史，便于了解代码演进历史及依据 </li>
<li>提供脚本依赖表清单，方便后续任务依赖配置 </li>
<li>提供输出表清单，方便确认是否单个目标表</li>
</ol>
<h4 id="SQL编写规范"><a href="#SQL编写规范" class="headerlink" title="SQL编写规范"></a>SQL编写规范</h4><ol>
<li>关键字最好大写，如SELECT、FROM、WHERE等，字段名不做要求</li>
<li>字段排列要求</li>
</ol>
<ul>
<li>SELECT 语句选择的字段按每行一个字段方式编排；</li>
<li>SELECT 单词后面一个空格后直接跟首个选择的字段，其他字段前”,”点后放字段名</li>
<li>建议每个SELECT的字段后面都有注释，至少在SQL的最外层的SELECT必须要有，并且多个字段的注释对其在同一列上<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> first_name               <span class="token comment">--第一个名字</span>
      <span class="token punctuation">,</span>last_name                <span class="token comment">--最后一个名字</span>
      <span class="token punctuation">,</span>salary                   <span class="token comment">--工资</span>
      <span class="token punctuation">,</span>itcode                   <span class="token comment">--工号</span>
<span class="token keyword">FROM</span> employee
<span class="token keyword">WHERE</span> salary <span class="token operator">></span> <span class="token number">35000</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
<ol start="3">
<li>SELECT子句排列要求<br>SELECT语句中所用到的FROM、WHERE、GROUP BY、HAVING、JOIN、UNION等子句</li>
</ol>
<ul>
<li>换行编写</li>
<li>与相应的SELECT语句对齐</li>
<li>WHERE子句下面的逻辑判断符AND、OR等与WHERE左对齐编排<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> cust_id
      <span class="token punctuation">,</span>num
<span class="token keyword">FROM</span> cust 
<span class="token keyword">WHERE</span> num <span class="token operator">>=</span> <span class="token number">100</span> 
  <span class="token operator">AND</span> num <span class="token operator">&lt;=</span> <span class="token number">200</span>
   <span class="token operator">OR</span> proname <span class="token operator">=</span> <span class="token string">'ORANGE'</span>
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> num<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
<ol start="3">
<li>算术运算符、逻辑运算符前后至少保留一个空格<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token function">SUM</span><span class="token punctuation">(</span>t1<span class="token punctuation">.</span>num <span class="token operator">*</span> t2<span class="token punctuation">.</span>price<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span> <span class="token keyword">AS</span> total_amt
<span class="token keyword">FROM</span> fruit_orders t1 
<span class="token keyword">INNER</span> <span class="token keyword">JOIN</span> fruit_inventory t2 
<span class="token keyword">ON</span> t1<span class="token punctuation">.</span>proid <span class="token operator">=</span> t2<span class="token punctuation">.</span>proid
<span class="token keyword">WHERE</span> t2<span class="token punctuation">.</span>proname <span class="token operator">=</span> <span class="token string">'ORANGE'</span>
  <span class="token operator">AND</span> num <span class="token operator">&lt;=</span> <span class="token number">200</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>一个sql语句最多join 3次，大于3次的，先创建临时表，关联临时表，这样可以使逻辑更清晰，并且方便调查数据问题</li>
</ol>
<p>其他规范可以参考<a href="https://zhuanlan.zhihu.com/p/453180860">HQL过程体开发规范</a></p>
<h4 id="任务脚本案例"><a href="#任务脚本案例" class="headerlink" title="任务脚本案例"></a>任务脚本案例</h4><p>数仓脚本开发统一提交到<a href="https://gitlab.digiwincloud.com.cn/data-middle-platform/DataWarehouse">DataWarehose</a><br>为了方便编码，让数据研发人员专注于业务逻辑，这里对shell异常捕捉、执行引擎的选择等做了封装，开发人员只要按照固定的模版填充sql即可：</p>
<ol>
<li>删除hive临时表：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">V_MSG&#x3D;&quot; clear Temporary table $&#123;TABLE_TMP_01&#125;,write into Temporary table&quot;
drop_tmp_table -tbn &quot;$&#123;TABLE_TMP_01&#125;&quot; -engine hive -env hwCloud<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
参数说明：</li>
</ol>
<p>-tbn：表名<br>-engine：选择执行引擎，这里目前可以选择hive和impala<br>-env: 执行环境<br>    hwCloud:华为云<br>    aliCloud：阿里云正式区<br>    aliCloudTest： 阿里云测试区<br>    azureCloud: 微软云</p>
<ol start="2">
<li>执行sql语句：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">V_MSG&#x3D;&quot;INSERT OVERWRITE TABLE partition active&quot;
V_SQL&#x3D;&quot;
INSERT OVERWRITE TABLE $&#123;TABLE_TMP_01&#125; partition(dp &#x3D; &#39;active&#39;,end_date &#x3D; &#39;99991231&#39;)
SELECT activity_id          --活动id
      ,activity_no          --活动编号
      ,activity_name        --活动名称
      ,transaction_times    --交易次数
      ,contact_times        --接触次数
      ,manage_status        --状态
      ,tenantsid            --租户id
FROM $&#123;TABLE_INPUT_01&#125; -- 因为每天取得数据都是最新的数据，所以，stg表就是最新的数据
;
&quot;
runsql -sql &quot;$&#123;V_SQL&#125;&quot; -msg &quot;$&#123;V_MSG&#125;&quot; -engine hive -env hwCloud || return $?<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
参数说明：</li>
</ol>
<p>-sql：要执行的sql语句<br>-msg：执行sql提示信息<br>-engine：选择执行引擎，这里目前可以选择hive和impala<br>-env: 执行环境<br>    hwCloud:华为云<br>    aliCloud：阿里云正式区<br>    aliCloudTest： 阿里云测试区<br>    azureCloud: 微软云<br>|| return $? : 获取代码执行状态 </p>
<p>hive脚本案例可以查看DataWarehose/public/hive_templete.sh<br>impala脚本案例可以查看DataWarehose/public/impala_templete.sh</p>
<h2 id="调度系统使用规范"><a href="#调度系统使用规范" class="headerlink" title="调度系统使用规范"></a>调度系统使用规范</h2><ul>
<li>工作流按照项目划分，理论上，一个项目的所有任务都在一个工作流内</li>
<li>一个job输出一个结果表，需要配置前置和后置依赖</li>
<li>job名称统一按照时间粒度 + 输出结果表名来命名，例如offline_ods_pom_business_work_record,代表离线计算ods_pom_business_work_record<br>具体的项目案例，可以参考华为云上的pom项目</li>
</ul>
<h2 id="任务上线流程"><a href="#任务上线流程" class="headerlink" title="任务上线流程"></a>任务上线流程</h2><ul>
<li>代码在本地开发完成后，需统一提交到<a href="https://gitlab.digiwincloud.com.cn/data-middle-platform/DataWarehouse">DataWarehose</a></li>
<li>经由管理员codeReview之后合并到master分支</li>
<li>在数据中台-项目管理-projectDeploy，选择相应的job执行代码分发<br><img src="/uploads/202204/%E6%95%B0%E4%BB%93%E9%A1%B9%E7%9B%AE%E4%B8%8A%E7%BA%BF%E6%B5%81%E7%A8%8B.png" alt="数仓项目上线流程"></li>
</ul>
]]></content>
      <categories>
        <category>数据仓库</category>
        <category>开发规范</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>日常工具软件问题</title>
    <url>/2021/01/22/%E6%97%A5%E5%B8%B8%E5%B7%A5%E5%85%B7%E8%BD%AF%E4%BB%B6%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>VMWare常见问题</li>
<li>IDEA常见问题<a id="more"></a>
<h2 id="VMWare常见问题"><a href="#VMWare常见问题" class="headerlink" title="VMWare常见问题"></a>VMWare常见问题</h2><h3 id="VMWare开启虚拟机黑屏"><a href="#VMWare开启虚拟机黑屏" class="headerlink" title="VMWare开启虚拟机黑屏"></a>VMWare开启虚拟机黑屏</h3>解决办法：</li>
<li>在windows下搜索cmd，并以管理员身份打开，输入：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">netsh winsock reset<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>重启电脑</li>
</ul>
<h2 id="IDEA常见问题"><a href="#IDEA常见问题" class="headerlink" title="IDEA常见问题"></a>IDEA常见问题</h2><h3 id="maven编译报错-source-1-5-中不支持-lambda-表达式"><a href="#maven编译报错-source-1-5-中不支持-lambda-表达式" class="headerlink" title="maven编译报错 -source 1.5 中不支持 lambda 表达式"></a>maven编译报错 -source 1.5 中不支持 lambda 表达式</h3><p><img src="/uploads/20210124/IDEA%E4%B8%AD%E7%BC%96%E8%AF%91Maven%E9%A1%B9%E7%9B%AE%E6%8A%A5%E9%94%99.png" alt="IDEA中编译Maven项目报错"><br>解决办法：<br>在pom文件中添加:</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.7.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>encoding</span><span class="token punctuation">></span></span>UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>encoding</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Maven编译时报：编码GBK的不可映射字符"><a href="#Maven编译时报：编码GBK的不可映射字符" class="headerlink" title="Maven编译时报：编码GBK的不可映射字符"></a>Maven编译时报：编码GBK的不可映射字符</h3><p>解决办法：<br><img src="/uploads/20210124/%E7%BC%96%E7%A0%81GBK%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6_1.png" alt="编码GBK的不可映射字符_1"><br><img src="/uploads/20210124/%E7%BC%96%E7%A0%81GBK%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6_2.png" alt="编码GBK的不可映射字符_2"></p>
<h3 id="IDEA常用快捷键（windows）"><a href="#IDEA常用快捷键（windows）" class="headerlink" title="IDEA常用快捷键（windows）"></a>IDEA常用快捷键（windows）</h3><ul>
<li><code>Alt + 1</code> 项目视图，可以自动关闭左边侧边栏</li>
<li><code>Crl + E</code> 最近文件列表</li>
<li>快速按两下<code>Shift</code>，全局文件搜索</li>
<li><code>Crl + Shift + N</code> 跳转到某个文件，可以直接搜索</li>
<li><code>Alt+Insert</code> 可以生成构造器/Getter/Setter等</li>
<li><code>Ctrl + W</code> 按一个word来进行选择操作，在IDEA里的这个快捷键功能是先选择光标所在字符处的单词，然后是选择源代码的扩展区域</li>
<li><code>shift + F6</code>修改文件名</li>
</ul>
<h2 id="IDEA常用快捷键（mac）"><a href="#IDEA常用快捷键（mac）" class="headerlink" title="IDEA常用快捷键（mac）"></a>IDEA常用快捷键（mac）</h2><ul>
<li>当前行注释： ctrl+/</li>
<li>撤销行注释： ctrl+/</li>
<li>块状注释： ctrl+shift+/</li>
<li>撤销块注释： ctrl+shift+/</li>
<li>实现/重写方法：command + N</li>
<li>全局查找： shift + command + f</li>
<li>全局替换： shift + command + r</li>
<li>当前文件查找： command + f</li>
<li>当前文件替换： command + r</li>
<li>最近查看过的文件： command + e</li>
<li>打开类结构： command + 7</li>
<li>前往父类/父类方法： command + u</li>
<li>呼出文件列表： command + 上方向键</li>
</ul>
<p>当用IDEA写java的时候，写匿名函数的时候，如果不知道new什么，可以在方法()里使用<code>option + /</code>会自动提示创建什么对象<br><img src="/uploads/20210520/IDEA%E7%BC%96%E5%86%99JAVA.png" alt="IDEA编写JAVA"><br>鼠标悬浮在提醒的对象名上，会提醒这个对象是什么类的，直接new就可以</p>
<h2 id="IDEA常用插件"><a href="#IDEA常用插件" class="headerlink" title="IDEA常用插件"></a>IDEA常用插件</h2><ul>
<li>leetcode editor  刷算法</li>
<li>codota ai aotocomplete for java   自动补全java，从githup上找相似的</li>
<li>easy code  自动写java实体类</li>
<li>translation  在线翻译，看源码可以使用</li>
<li>key promoter  提醒快捷键的，用的功能会自动提示</li>
<li>maven helper  解决maven依赖冲突</li>
<li>alibaba java coding   代码规范</li>
<li>codeglance  类似sublime的代码缩影。可以替代下拉框</li>
<li>GsonFormat   自动根据json创建实体类</li>
<li>ignore    git过滤</li>
<li>rainbow brackets  括号变成彩虹颜色</li>
<li>acejump  类似vim快速定位</li>
</ul>
<p>在IDEA写java的时候，如果不知道是什么类型，可以使用<code>option + shift + enter</code>来自动补全<br>例如：<br><code>map = mapState.iterator().next();</code><br>把鼠标悬浮在map变量上，然后可以点击<code>create local variable &#39;map&#39;</code>,或者<code>option + shift + enter</code>来自动补全</p>
<p><code>option + shift + enter</code>： 鼠标悬浮在倒入的无用的包上（import变灰色的），使用这个快捷键，可以自动清除无用的包</p>
<blockquote>
<p>在写java或者scala的时候，直接写=号右边的内容，然后加一个.var,然后enter，就可以自动补全左边的定义变量的操作<br>在编辑java的时候，在调用类和正在编辑的类中来回切换： option + command + 方向键</p>
</blockquote>
<h2 id="github网页可以访问，但是ping不通"><a href="#github网页可以访问，但是ping不通" class="headerlink" title="github网页可以访问，但是ping不通"></a>github网页可以访问，但是ping不通</h2><p>最近从github上拉取代码，总是报超时，ping github.com后连不通<br>一开始以为是国外ip访问不了，翻墙试了一下，还是不行<br>最后解决方法，修改hosts文件<br>原因是直接ping github.com返回的服务器ip ping不通，但是github本身是有很多ip的，我们挑一个可以ping的通的ip</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">140.82.113.4 github.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>问题解决</p>
<h2 id="idea配置lombok–idea2019不兼容问题"><a href="#idea配置lombok–idea2019不兼容问题" class="headerlink" title="idea配置lombok–idea2019不兼容问题"></a>idea配置lombok–idea2019不兼容问题</h2><p>使用idea开启配置lombok出现不兼容问题.<br>解决方法：打开lombok压缩包,修改META-INF/plugin.xml文件,直接在压缩包下用解压文件打开修改即可<br>具体步骤如下：</p>
<ol>
<li>去<a href="https://plugins.jetbrains.com/plugin/6317-lombok/versions">lombok官网</a>下载插件</li>
<li>打开编辑META-INF/plugin.xml,将版本好修改成你当前idea的版本号</li>
<li>查看idea版本号,help-&gt;about即可看到</li>
</ol>
<p>lombok开启步骤:</p>
<ol>
<li>在idea开启注解</li>
<li>下载lombok插件</li>
<li>导入lombok的jar包</li>
</ol>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
      <tags>
        <tag>VMWare</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>获取yarn上application资源占用情况</title>
    <url>/2021/12/09/%E8%8E%B7%E5%8F%96yarn%E4%B8%8Aapplication%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>根据yarn的applicationid获取应用实时资源消耗的方法</li>
<li>写python脚本调取yarn api获取实时资源消耗情况</li>
</ul>
<a id="more"></a>


<h2 id="根据yarn的applicationid获取应用实时资源消耗的方法"><a href="#根据yarn的applicationid获取应用实时资源消耗的方法" class="headerlink" title="根据yarn的applicationid获取应用实时资源消耗的方法"></a>根据yarn的applicationid获取应用实时资源消耗的方法</h2><p>这种方法是根据hadoop的配置文件，使用YarnClient来获取applicationId的资源占用情况</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">YarnListener</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">Logger</span> logger <span class="token operator">=</span> <span class="token class-name">LoggerFactory</span><span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token class-name">YarnListener</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">URL</span> resource <span class="token operator">=</span> <span class="token class-name">HDFSUtil</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getClassLoader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"config/hadoop-conf"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> resourceDir <span class="token operator">=</span> resource<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token class-name">Constants</span><span class="token punctuation">.</span>SEPARATOR<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">YarnConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resourceDir<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token string">"hdfs-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resourceDir<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token string">"core-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resourceDir<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token string">"yarn-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">YarnClient</span> yarnClient <span class="token operator">=</span> <span class="token class-name">YarnClient</span><span class="token punctuation">.</span><span class="token function">createYarnClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        yarnClient<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        yarnClient<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
        <span class="token class-name">ApplicationId</span> applicationId <span class="token operator">=</span> <span class="token class-name">ApplicationId</span><span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span><span class="token number">1577686647484L</span><span class="token punctuation">,</span><span class="token number">0001</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">ApplicationReport</span> report <span class="token operator">=</span> yarnClient<span class="token punctuation">.</span><span class="token function">getApplicationReport</span><span class="token punctuation">(</span>applicationId<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getStartTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getApplicationResourceUsageReport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getUsedResources</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getVirtualCores</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getApplicationResourceUsageReport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getUsedResources</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getMemorySize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getStartTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getApplicationResourceUsageReport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">YarnException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        yarnClient<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果如下：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json">num_used_containers<span class="token operator">:</span> <span class="token number">-1</span>
num_reserved_containers<span class="token operator">:</span> <span class="token number">-1</span>
used_resources <span class="token punctuation">&#123;</span>
  memory<span class="token operator">:</span> <span class="token number">-1</span>
  virtual_cores<span class="token operator">:</span> <span class="token number">-1</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">"Mi"</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"vcores"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">""</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
reserved_resources <span class="token punctuation">&#123;</span>
  memory<span class="token operator">:</span> <span class="token number">-1</span>
  virtual_cores<span class="token operator">:</span> <span class="token number">-1</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">"Mi"</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"vcores"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">""</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
needed_resources <span class="token punctuation">&#123;</span>
  memory<span class="token operator">:</span> <span class="token number">-1</span>
  virtual_cores<span class="token operator">:</span> <span class="token number">-1</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">"Mi"</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"vcores"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">""</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
memory_seconds<span class="token operator">:</span> <span class="token number">5549488</span>
vcore_seconds<span class="token operator">:</span> <span class="token number">5378</span>
preempted_memory_seconds<span class="token operator">:</span> <span class="token number">5549488</span>
preempted_vcore_seconds<span class="token operator">:</span> <span class="token number">5378</span>
application_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
  value<span class="token operator">:</span> <span class="token number">5549488</span>
<span class="token punctuation">&#125;</span>
application_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"vcores"</span>
  value<span class="token operator">:</span> <span class="token number">5378</span>
<span class="token punctuation">&#125;</span>
application_preempted_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
  value<span class="token operator">:</span> <span class="token number">5549488</span>
<span class="token punctuation">&#125;</span>
application_preempted_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"vcores"</span>
  value<span class="token operator">:</span> <span class="token number">5378</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>这种方法，感觉可以和hive的hook结合起来使用，在hivesql执行过程中，就把资源使用情况保存下来<br>这里的资源占用都是实时的占用，可以取一个平均资源占用来当作这个任务的资源占用情况</p>
<p>具体可以参考<a href="https://blog.csdn.net/trnanan/article/details/104986262">根据yarn的applicationid获取应用实时资源消耗的方法</a></p>
<h2 id="写python脚本调取yarn-api获取实时资源消耗情况"><a href="#写python脚本调取yarn-api获取实时资源消耗情况" class="headerlink" title="写python脚本调取yarn api获取实时资源消耗情况"></a>写python脚本调取yarn api获取实时资源消耗情况</h2><p>这种方式，就是用爬虫yarn的监控页面，取页面上的内容，其实不是很好，因为namenode在ha之后会切换，但是很方便</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> json
<span class="token keyword">import</span> time
<span class="token keyword">import</span> pymysql
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup
<span class="token keyword">import</span> os<span class="token punctuation">,</span>threading<span class="token punctuation">,</span>time

url_full<span class="token operator">=</span><span class="token string">"http://ip:port/cluster"</span>

conn <span class="token operator">=</span> pymysql<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'114.67.103.201'</span><span class="token punctuation">,</span>user <span class="token operator">=</span> <span class="token string">"root"</span><span class="token punctuation">,</span>passwd <span class="token operator">=</span> <span class="token string">"admin@123456"</span><span class="token punctuation">,</span>db <span class="token operator">=</span> <span class="token string">"myuse"</span><span class="token punctuation">)</span>
cur<span class="token operator">=</span>conn<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#获取游标</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">"GET"</span><span class="token punctuation">,</span> url_full<span class="token punctuation">,</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>url_full<span class="token punctuation">)</span>
soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span> <span class="token comment">#也可用lxml</span>
<span class="token comment">#已提交的任务</span>
apps_submit <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(1)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_submit<span class="token punctuation">)</span>
<span class="token comment">#等待中的任务</span>
apps_pending <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(2)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_pending<span class="token punctuation">)</span>
<span class="token comment">#运行中的任务</span>
apps_running <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(3)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_running<span class="token punctuation">)</span>
<span class="token comment">#已完成的任务</span>
apps_completed <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(4)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_completed<span class="token punctuation">)</span>
<span class="token comment">#运行的contaniner</span>
container_running <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(5)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>container_running<span class="token punctuation">)</span>
<span class="token comment">#一用的内存</span>
memory_used <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(6)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>memory_used<span class="token punctuation">)</span>
<span class="token comment">#总内存</span>
memory_total <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(7)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>memory_total<span class="token punctuation">)</span>
<span class="token comment">#已用的core</span>
core_used <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(9)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>core_used<span class="token punctuation">)</span>
<span class="token comment">#总的core</span>
core_total <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(10)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>core_total<span class="token punctuation">)</span>
<span class="token comment">#yarn总的节点数</span>
node_total <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#nodemetricsoverview > tbody > tr > td:nth-of-type(1) > a'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>node_total<span class="token punctuation">)</span>
<span class="token comment">#yran的调度类型</span>
yarn_scheduler_type <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#schedulermetricsoverview > tbody > tr > td:nth-of-type(1)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>yarn_scheduler_type<span class="token punctuation">)</span>

sql<span class="token operator">=</span><span class="token string">"insert into yarn_monitor(apps_submit,apps_pending,apps_running,memory_used,memory_total,core_used,node_total,yarn_scheduler_type)"</span> \
                <span class="token string">" values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)"</span>
cur<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>sql<span class="token punctuation">,</span><span class="token punctuation">(</span>apps_submit<span class="token punctuation">,</span>apps_pending<span class="token punctuation">,</span>apps_running<span class="token punctuation">,</span>memory_used<span class="token punctuation">,</span>memory_total<span class="token punctuation">,</span>core_used<span class="token punctuation">,</span>node_total<span class="token punctuation">,</span>yarn_scheduler_type<span class="token punctuation">)</span><span class="token punctuation">)</span>
conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
cur<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="根据appid获取yarn的执行日志"><a href="#根据appid获取yarn的执行日志" class="headerlink" title="根据appid获取yarn的执行日志"></a>根据appid获取yarn的执行日志</h2><p>当日志量不大的情况下，直接使用如下命令查看：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yarn logs -applicationId application_1641525781336_0011<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>但是，当日志量很大的情况下，直接执行上述命令，会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;main&quot; java.lang.RuntimeException: The total log size is too large.The log size limit is 10MB. Please specify a proper value --size option or if you really want to fetch all, please specify -1 for --size_limit_mb option.
        at org.apache.hadoop.yarn.client.cli.LogsCLI.getMatchedLogFiles(LogsCLI.java:1169)
        at org.apache.hadoop.yarn.client.cli.LogsCLI.getMatchedContainerLogFiles(LogsCLI.java:1348)
        at org.apache.hadoop.yarn.client.cli.LogsCLI.getMatchedOptionForRunningApp(LogsCLI.java:1517)
        at org.apache.hadoop.yarn.client.cli.LogsCLI.getMatchedLogTypesForRunningApp(LogsCLI.java:1537)
        at org.apache.hadoop.yarn.client.cli.LogsCLI.fetchApplicationLogs(LogsCLI.java:1090)
        at org.apache.hadoop.yarn.client.cli.LogsCLI.runCommand(LogsCLI.java:372)
        at org.apache.hadoop.yarn.client.cli.LogsCLI.run(LogsCLI.java:153)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这时候可以只取一部分日志看看里面都是什么，一般情况下，都是因为代码里有println内容了：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># -size就是获取n字节的日志
yarn logs -applicationId application_1641525781336_0011 -size 1000000000 &gt; appid.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

]]></content>
      <categories>
        <category>大数据</category>
        <category>监控</category>
      </categories>
      <tags>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title>采集写入hudi设计文档</title>
    <url>/2022/02/28/%E9%87%87%E9%9B%86%E5%86%99%E5%85%A5hudi%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>采集写入hudi设计文档</li>
</ul>
<a id="more"></a>


<h1 id="采集hudi表结构设计"><a href="#采集hudi表结构设计" class="headerlink" title="采集hudi表结构设计"></a>采集hudi表结构设计</h1><h2 id="采集hudi表目录"><a href="#采集hudi表目录" class="headerlink" title="采集hudi表目录:"></a>采集hudi表目录:</h2><ul>
<li><p>hudi表目录：/apps/hudi/warehouse/fdm/tableName</p>
</li>
<li><p>hudi删除表目录：/apps/hudi/warehouse/fdm/tableName_del</p>
</li>
</ul>
<h2 id="采集hudi表外表hive表"><a href="#采集hudi表外表hive表" class="headerlink" title="采集hudi表外表hive表"></a>采集hudi表外表hive表</h2><ul>
<li>读优化视图表：tableName_ro</li>
<li>快照视图：tableName_rt</li>
</ul>
<h2 id="按月分区表"><a href="#按月分区表" class="headerlink" title="按月分区表"></a>按月分区表</h2><p>/basePath/tableName/2021-07/</p>
<p>/basePath/tableName/2021-08/</p>
<p>/basePath/tableName/…/</p>
<p>/basePath/tableName/2021-09/</p>
<p>概述：根据创建日期所在月分区，按月分区表适合大部分业务场景，业务每天数据量不是很大，或者数据变更不是很频繁，按月分区表以dam结尾。<br>优点：减少Hdfs小文件数量，hudi表使用MOR格式。<br>缺点：数据倾斜导致一个分区数据很大，分区内更新效率低</p>
<h2 id="按日分区表"><a href="#按日分区表" class="headerlink" title="按日分区表"></a>按日分区表</h2><p>/basePath/tableName/2021-08-16/<br>/basePath/tableName/2021-08-17/<br>/basePath/tableName/…/<br>/basePath/tableName/2021-09-14/</p>
<p>概述：根据创建日期分区，按日分区表适合业务每天数据量很大，或者数据变更频繁，适用于读少写多大表场景，按日分区表以dad结尾。<br>优点：优化写入效率，hudi表使用MOR格式。<br>缺点：分区越来越多，hive查询效率低，数据倾斜导致一个分区数据量很少，带来小文件问题</p>
<h1 id="采集表元数据管理"><a href="#采集表元数据管理" class="headerlink" title="采集表元数据管理"></a>采集表元数据管理</h1><h2 id="元数据管理流程"><a href="#元数据管理流程" class="headerlink" title="元数据管理流程"></a>元数据管理流程</h2><p><img src="/uploads/202203/%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png" alt="元数据管理流程"></p>
<h2 id="hudi-schema限制"><a href="#hudi-schema限制" class="headerlink" title="hudi schema限制"></a>hudi schema限制</h2><ul>
<li>hudi支持类型有null、boolean、int、long、float、double、bytes、string、array、map、enum</li>
<li>不能删除字段，不能修改字段名</li>
<li>添加字段需要有默认值</li>
<li>字段类型修改只允许如下变化：int修改成long，int、long修改成float，int、long、float修改成double，bytes修改成string，string修改成bbytes</li>
</ul>
<h2 id="mysql-hudi字段类型映射"><a href="#mysql-hudi字段类型映射" class="headerlink" title="mysql hudi字段类型映射"></a>mysql hudi字段类型映射</h2><table>
<thead>
<tr>
<th>序号</th>
<th>mysql</th>
<th>hudi</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>VARCHAR</td>
<td>string</td>
</tr>
<tr>
<td>2</td>
<td>DATE</td>
<td>string</td>
</tr>
<tr>
<td>3</td>
<td>CHAR</td>
<td>string</td>
</tr>
<tr>
<td>4</td>
<td>TINYINT</td>
<td>int</td>
</tr>
<tr>
<td>5</td>
<td>SMALLINT</td>
<td>int</td>
</tr>
<tr>
<td>6</td>
<td>DATETIME</td>
<td>long（string）hudi不支持时间类型，可以存储时间戳</td>
</tr>
<tr>
<td>7</td>
<td>TEXT</td>
<td>string</td>
</tr>
<tr>
<td>8</td>
<td>TIMESTAMP</td>
<td>long（string）hudi不支持时间类型，可以存储时间戳</td>
</tr>
<tr>
<td>9</td>
<td>INT</td>
<td>int</td>
</tr>
<tr>
<td>10</td>
<td>BIT</td>
<td>int</td>
</tr>
<tr>
<td>11</td>
<td>VARBINARY</td>
<td>string</td>
</tr>
<tr>
<td>12</td>
<td>LONGTEXT</td>
<td>string</td>
</tr>
<tr>
<td>13</td>
<td>DECIMAL</td>
<td>string</td>
</tr>
<tr>
<td>15</td>
<td>DOUBLE</td>
<td>double</td>
</tr>
<tr>
<td>16</td>
<td>BIGINT</td>
<td>long</td>
</tr>
<tr>
<td>17</td>
<td>BLOB</td>
<td>string</td>
</tr>
<tr>
<td>18</td>
<td>TINYINT UNSIGNED</td>
<td>int</td>
</tr>
<tr>
<td>19</td>
<td>SMALLINT UNSIGNED</td>
<td>int</td>
</tr>
<tr>
<td>20</td>
<td>INT UNSIGNED</td>
<td>long</td>
</tr>
<tr>
<td>21</td>
<td>BIGINT UNSIGNED</td>
<td>long</td>
</tr>
<tr>
<td>22</td>
<td>FLOAT UNSIGNED</td>
<td>float</td>
</tr>
<tr>
<td>23</td>
<td>DOUBLE UNSIGNED</td>
<td>double</td>
</tr>
<tr>
<td>24</td>
<td>FLOAT</td>
<td>float</td>
</tr>
<tr>
<td>25</td>
<td>MEDIUMINT UNSIGNED</td>
<td>int</td>
</tr>
</tbody></table>
<ol>
<li><h1 id="采集初始化到hudi"><a href="#采集初始化到hudi" class="headerlink" title="采集初始化到hudi"></a>采集初始化到hudi</h1></li>
</ol>
<p>采集初始化根据数据创建日期采集到数据日期所在月份的分区，示意图如3-1：<br><img src="/uploads/202203/%E5%88%9D%E5%A7%8B%E5%8C%96hudi%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F.png" alt="初始化hudi分区格式"></p>
<p>采集初始化由采集模块发起，请求调度，调度触发脚本机执行初始化任务，脚本机启动使用spark任务采集关系数据库数据，spark任务使用Datax采集MySQL、MongoDB，使用Hudi-spark-client模块将数据写入Hudi，示意图如3-2<br>这里依然生成了调度任务，只是在初始化的时候用了一次，可以简化成采集直接和脚本机接入，由采集直接触发脚本机执行任务，但是这个改动量比较大。<br><img src="/uploads/202203/%E5%88%9D%E5%A7%8B%E5%8C%96%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B.png" alt="初始化采集流程"></p>
<h1 id="采集实时写入hudi"><a href="#采集实时写入hudi" class="headerlink" title="采集实时写入hudi"></a>采集实时写入hudi</h1><ul>
<li>插入数据记录，直接插入到hudi原表</li>
<li>更新数据记录，直接更新hudi原表记录</li>
<li>删除数据记录，直接删除hudi原表记录，同时插入hudi删除表</li>
<li>以分钟频率拉取kafka记录摄入hudi，减少元数据提交次数</li>
</ul>
<p><img src="/uploads/202203/%E5%88%86%E9%92%9F%E9%A2%91%E7%8E%87.png" alt="分钟频率"></p>
<p>采集实时写入hudi由采集模块发起，在启动实时写入任务的时候将采集任务分配到固定的Flink节点，通过ESF和Flink节点通信，在Flink节点启动线程执行实时写入hudi任务，任务以每分钟频率拉取，使用Hudi-flink-client模块将数据写入Hudi，示意图如4-2<br><img src="/uploads/202203/%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B.png" alt="采集流程"></p>
<h1 id="异步合并parquet任务"><a href="#异步合并parquet任务" class="headerlink" title="异步合并parquet任务"></a>异步合并parquet任务</h1><p>对于Merge-On-Read表，数据使用列式Parquet文件和行式Avro文件存储，更新被记录到增量文件，然后进行同步/异步compaction生成新版本的列式文件。Merge-On-Read表可减少数据写入延迟，因而进行不阻塞摄入的异步Compaction很有意义，流程如下图5-1<br>创建一个调度任务，调度任务每个小时触发一次合并任务<br><img src="/uploads/202203/%E5%BC%82%E6%AD%A5%E5%90%88%E5%B9%B6parquet.png" alt="异步合并parquet"></p>
<ol>
<li><h1 id="监控报警"><a href="#监控报警" class="headerlink" title="监控报警"></a>监控报警</h1></li>
</ol>
<ul>
<li>Flink节点心跳检查</li>
<li>实时摄入任务每分钟（单次）写入耗时、写入insert条数、写入update条数、写入delete条数、写入数据条数、写入数据量，上报统一监控</li>
<li>异步合并parquet任务合并log文件数、合并耗时，上报统一监控</li>
<li>实时写入失败情况下报警</li>
</ul>
<h1 id="管理界"><a href="#管理界" class="headerlink" title="管理界"></a>管理界</h1><p><img src="/uploads/202203/%E7%AE%A1%E7%90%86%E7%95%8C%E9%9D%A2.png" alt="管理界面"></p>
<ul>
<li>存储目标添加hudi存储方式</li>
<li>提供按月分区、按日分区，根据近半年每日新增数据分析初始值，可修改</li>
<li>采集频率默认1m，提供30s、2m可选项</li>
<li>分区时间字段，例如创建时间</li>
</ul>
<h1 id="FDM表（hudi）后续使用特点"><a href="#FDM表（hudi）后续使用特点" class="headerlink" title="FDM表（hudi）后续使用特点"></a>FDM表（hudi）后续使用特点</h1><ol>
<li>实时采集默认都走hudi，全量表，拉链表功能保留，有需要可以用，不建议用</li>
<li>任务使用建议走spark引擎</li>
</ol>
<h1 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h1><ol>
<li>无创建时间表分区问题</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>采集</category>
      </categories>
      <tags>
        <tag>hudi</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题总结</title>
    <url>/2021/06/30/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>spark面试题</li>
<li>hbase面试题</li>
<li>kafka面试题</li>
<li>flume面试题</li>
<li>hive面试题</li>
<li>kudu面试题</li>
<li>presto面试题</li>
<li>flink面试题</li>
<li>redis面试题</li>
<li>mongodb面试题</li>
<li>es面试题</li>
<li>数据仓库面试题</li>
<li>java面试题</li>
<li>scala面试题</li>
<li>sqoop与datax面试题<a id="more"></a>

</li>
</ul>
<h2 id="Spark面试题总结"><a href="#Spark面试题总结" class="headerlink" title="Spark面试题总结"></a>Spark面试题总结</h2><h2 id="Kafka面试题总结"><a href="#Kafka面试题总结" class="headerlink" title="Kafka面试题总结"></a>Kafka面试题总结</h2><ul>
<li><strong>Kafka 分布式的情况下，如何保证消息的顺序?</strong><pre class="line-numbers language-none"><code class="language-none">Kakfa不保证数据的整体有序，但是可以设置分区内消息有序，可以设置相同的key到同一个partition，这样就可以保证同一个key的消息，肯定是有序的<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


</li>
</ul>
<h2 id="数据仓库面试题总结"><a href="#数据仓库面试题总结" class="headerlink" title="数据仓库面试题总结"></a>数据仓库面试题总结</h2><h2 id="Hbase面试题"><a href="#Hbase面试题" class="headerlink" title="Hbase面试题"></a>Hbase面试题</h2><ul>
<li><strong>Hbase是写快还是读快？为什么？</strong><pre class="line-numbers language-none"><code class="language-none">Hbase是写快读慢。
Hbase写入速度比读取速度要快，根本原因LSM存储引擎
LSM核心思想的核心就是放弃部分读能力，换取写入的最大化能力
LSM核心思路就是假定内存足够大，因此不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在内存中，等到积累到最后多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾
将对数据的修改增量保持在内存中，达到指定的大小限制后将这些修改操作批量写入磁盘，不过读取的时候稍微麻烦，需要合并磁盘中历史数据和内存中最近修改操作，所以写入性能大大提升，读取时可能需要先看是否命中内存，否则需要访问较多的磁盘文件
LSM树原理把一棵大树拆分成N棵小树，它首先写入内存中，随着小树越来越大，内存中的小树会flush到磁盘中，磁盘中的树定期可以做merge操作，合并成一棵大树，以优化读性能<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>







</li>
</ul>
<h2 id="Sqoop与DataX面试题"><a href="#Sqoop与DataX面试题" class="headerlink" title="Sqoop与DataX面试题"></a>Sqoop与DataX面试题</h2><ul>
<li><strong>Sqoop与DataX优缺点比较？</strong>  <table>
<thead>
<tr>
<th align="center">功能</th>
<th align="center">DataX</th>
<th align="center">Sqoop</th>
</tr>
</thead>
<tbody><tr>
<td align="center">运行模型</td>
<td align="center">单进程多线程</td>
<td align="center">MapReduce</td>
</tr>
<tr>
<td align="center">Mysql读写</td>
<td align="center">单机压力大；读写粒度容易控制</td>
<td align="center">mr模式重，写出错处理麻烦</td>
</tr>
<tr>
<td align="center">hive读写</td>
<td align="center">单机压力大</td>
<td align="center">很好</td>
</tr>
<tr>
<td align="center">分布式</td>
<td align="center">不支持，可以通过调度系统规避</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center">流控</td>
<td align="center">有流控功能</td>
<td align="center">需要定制</td>
</tr>
<tr>
<td align="center">DataX是单机的，不是分布式的，但是可以通过在多台脚本机上启动任务来规避。但是DataX比较灵活，Sqoop重一点。</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">DataX虽然是单机的，但是，它的客户端是与namenode通信，走的是hdfs写数据流程，写数据的过程是并行执行的</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
</li>
</ul>
<p>Canel 是实时的，可以采集mysql的Binlog数据</p>
<h2 id="Redis面试题"><a href="#Redis面试题" class="headerlink" title="Redis面试题"></a>Redis面试题</h2><ul>
<li><strong>Redis有哪些优缺点</strong></li>
<li>*优点**</li>
<li>读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。</li>
<li>支持数据持久化，支持AOF和RDB两种持久化方式。</li>
<li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。</li>
<li>数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。</li>
<li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><p>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</p>
</li>
<li><p>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。</p>
</li>
<li><p>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</p>
</li>
<li><p>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。</p>
</li>
<li><p><strong>为什么要用 Redis 而不用 map/guava 做缓存?</strong><br>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。<br>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。</p>
</li>
</ul>
<ul>
<li><strong>Redis 的持久化机制是什么？各自的优缺点？</strong><br>Redis 提供两种持久化机制 <code>RDB（默认）</code> 和 <code>AOF 机制</code><br>RDB：是Redis DataBase缩写快照<blockquote>
<p>RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。</p>
</blockquote>
</li>
</ul>
<p>优点：<br>1、只有一个文件 dump.rdb，方便持久化。<br>2、容灾性好，一个文件可以保存到安全的磁盘。<br>3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能<br>4.相对于数据集大时，比 AOF 的启动效率更高。</p>
<p>缺点：<br>1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)</p>
<blockquote>
<p>AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。<br>当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p>
</blockquote>
<p>优点：<br>1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。<br>2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。<br>3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</p>
<p>缺点：<br>1、AOF 文件比 RDB 文件大，且恢复速度慢。<br>2、数据集大的时候，比 rdb 启动效率低。</p>
<blockquote>
<p><code>RDB（默认）</code> 和 <code>AOF 机制</code>优缺点是什么？ </p>
</blockquote>
<p>AOF文件比RDB更新频率高，优先使用AOF还原数据。<br>AOF比RDB更安全也更大<br>RDB性能比AOF好<br>如果两个都配了优先加载AOF</p>
<ul>
<li><strong>Redis的过期键的删除策略</strong><blockquote>
<p>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</p>
</blockquote>
</li>
</ul>
<p>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p>
<ul>
<li>全局的键空间选择性移除<br>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<br>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）<br>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li>
<li>设置过期时间的键空间选择性移除<br>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。<br>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。<br>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li>
</ul>
<h2 id="flink面试题"><a href="#flink面试题" class="headerlink" title="flink面试题"></a>flink面试题</h2><p>移步<a href="https://gujincheng.github.io/">Flink面试题总结</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos精简版从0到1配置</title>
    <url>/2022/03/19/Centos%E7%B2%BE%E7%AE%80%E7%89%88%E4%BB%8E0%E5%88%B01%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>系统安装与配置网络</li>
</ul>
<a id="more"></a>

<p>之前使用的Centos7，系统太大了，放到虚拟机里感觉都带不动，而且，也不需要图形化界面，这里就下载一下精简版</p>
<h2 id="系统安装与配置网络"><a href="#系统安装与配置网络" class="headerlink" title="系统安装与配置网络"></a>系统安装与配置网络</h2><p>下载Centos7精简版，<a href="http://mirror.hostlink.com.hk/centos/7.9.2009/isos/x86_64/CentOS-7-x86_64-Minimal-2009.iso">下载地址</a><br>然后使用VMware安装3台虚拟机。<br>但是，新安装的Centos7什么东西都没有，连最基本的<code>ifconfig</code>都用不了，网络也不同，所以，配置的第一步是先配置网络</p>
<h3 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h3><p><code>ip addr</code>之后发现<code>ens33</code>这块网卡没有ip地址</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd  &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts &amp;&amp; vi ifcfg-ens33

TYPE&#x3D;Ethernet
PROXY_METHOD&#x3D;none
BROWSER_ONLY&#x3D;no
BOOTPROTO&#x3D;static    ##这里变了
DEFROUTE&#x3D;yes
IPV4_FAILURE_FATAL&#x3D;no
IPV6INIT&#x3D;yes
IPV6_AUTOCONF&#x3D;yes
IPV6_DEFROUTE&#x3D;yes
IPV6_FAILURE_FATAL&#x3D;no
IPV6_ADDR_GEN_MODE&#x3D;stable-privacy
NAME&#x3D;ens33
UUID&#x3D;cd6473a5-142f-4890-b4ba-5a711764a1d9
DEVICE&#x3D;ens33
ONBOOT&#x3D;yes      ## 这里便也

## 一下变了
IPADDR&#x3D;192.168.233.130
GATEWAY&#x3D;192.168.233.2
DNS1&#x3D;192.168.233.2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>改完之后重启网络</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">systemctl restart network<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>如果还是没有网络，就是因为没有配置DNS解析服务,可以添加DNS配置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">
cd &#x2F;etc
vi resolv.conf
添加如下的配置
-------------------------------------------------------------------------------------------
search localdomain                                                          
nameserver 8.8.8.8                                                          
nameserver 8.8.4.4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>再次重启网络服务</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">systemctl restart network<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="配置时间相关"><a href="#配置时间相关" class="headerlink" title="配置时间相关"></a>配置时间相关</h3><p>可以看到，时间是不对的<br>修改如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 修改时区
ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime
## 安装ntp
yum -y install ntp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>ntp主机配置 vi /etc/ntp.conf<br>在文件里新增server ntp.aliyun.com，并把原始的server给注释掉<br>重启service ntpd restart</p>
<h3 id="SSH免秘钥并关闭防火墙"><a href="#SSH免秘钥并关闭防火墙" class="headerlink" title="SSH免秘钥并关闭防火墙"></a>SSH免秘钥并关闭防火墙</h3><ul>
<li>SSH免秘钥<br>通过<code>ssh-keygen -t rsa</code>命令，然后一直回车<br>然后把<code>id_rsa.pub</code>内容的复制到3个节点的<code>authorized_keys</code><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cd ~ &amp;&amp; chmod 700 .ssh &amp;&amp; chmod 600 .ssh&#x2F;authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
然后每台节点都ssh一遍，一共9次</li>
<li>关闭防火墙<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">systemctl stop firewalld  ## 关闭防火墙
systemctl disable firewalld ###禁止防火墙开机自启
&#96;&#96;&#96;    

### 安装必备软件
* 通过yum安装必备软件
&#96;&#96;&#96;shell
yum install net-tools.x86_64  ## 是为了安装ifconfig，没有这个包，是在net-tools里的
yum install vim
yum install <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>安装Mysql，具体参考<a href="https://gujincheng.github.io/2022/03/11/Centos%E5%AE%89%E8%A3%85Mysql/">Centos安装Mysql</a></li>
<li>安装Java、Scala、Maven，这个都比较简单，这里略过<h4 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h4></li>
<li>配置hadoop-env.sh里的JAVA_HOME使用绝对路径<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;jdk1.8.0_321<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>配置core-site.xml<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span> <span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.default.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://golden-01:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Specify the IP address and port number of the namenode<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>配置hdfs-site.xml<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>replications<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:/opt/modules/hadoop-3.2.2/yarn/yarn_data/hdfs/namenode<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:/opt/modules/hadoop-3.2.2/yarn/yarn_data/hdfs/datanode<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>配置mapred-site.xml<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span> 
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span> 
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.jobhistory.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:10020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.jobhistory.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:19888<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>配置yarn-site.xml<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
<span class="token comment">&lt;!-- Site specific YARN configuration properties --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:8032<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.scheduler.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:8030<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.resource-tracker.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:8031<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>   
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.admin.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:8033<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>   
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    　　<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-01:8088<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>   
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.mapred.ShuffleHandler<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>配置workers<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">golden-01
golden-02
golden-03<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li>将配置好的hadoop-3.2.2分发同步到各个数据节点</li>
<li>格式化NameNode<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs namenode -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
出现<code>namenode has been successfully formatted.</code>就证明成功了<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2022-03-20 03:47:54,102 INFO common.Storage: Storage directory &#x2F;opt&#x2F;modules&#x2F;hadoop-3.2.2&#x2F;yarn&#x2F;yarn_data&#x2F;hdfs&#x2F;namenode has been successfully formatted.
2022-03-20 03:47:54,124 INFO namenode.FSImageFormatProtobuf: Saving image file &#x2F;opt&#x2F;modules&#x2F;hadoop-3.2.2&#x2F;yarn&#x2F;yarn_data&#x2F;hdfs&#x2F;namenode&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 using no compression
2022-03-20 03:47:54,220 INFO namenode.FSImageFormatProtobuf: Image file &#x2F;opt&#x2F;modules&#x2F;hadoop-3.2.2&#x2F;yarn&#x2F;yarn_data&#x2F;hdfs&#x2F;namenode&#x2F;current&#x2F;fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2022-03-20 03:47:54,226 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;&#x3D; 0
2022-03-20 03:47:54,230 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid&#x3D;0 when meet shutdown.
2022-03-20 03:47:54,231 INFO namenode.NameNode: SHUTDOWN_MSG: 
&#x2F;************************************************************
SHUTDOWN_MSG: Shutting down NameNode at golden-01&#x2F;192.168.233.130
************************************************************&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这里一开始出现一个情况，我刚启动<code>hdfs namenode -format</code>，就失败了，直接就报<code>SHUTDOWN_MSG: Shutting down NameNode at golden-01/192.168.233.130</code><br>问题的原因：<blockquote>
<p>从网上复制过来的<code>hdfs namenode -format</code>，这个-format其实是减号，是不对的<br><img src="/uploads/202203/namenode%E5%88%9D%E5%A7%8B%E5%8C%96%E5%A4%B1%E8%B4%A5%E5%8E%9F%E5%9B%A0.png" alt="namenode初始化失败原因"></p>
</blockquote>
</li>
</ul>
<p>还有一种猜想，会不会是因为我用的root用户来做初始化导致的？因为，我启动集群的时候，也报错了：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Starting namenodes on [master]
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.
Starting secondary namenodes [slave1]
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里我切换到普通用户来启动了<br>也可以将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;usr&#x2F;bin&#x2F;env bash
HDFS_DATANODE_USER&#x3D;root
HADOOP_SECURE_DN_USER&#x3D;hdfs
HDFS_NAMENODE_USER&#x3D;root
HDFS_SECONDARYNAMENODE_USER&#x3D;root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>还有，start-yarn.sh，stop-yarn.sh顶部也需添加以下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#!&#x2F;usr&#x2F;bin&#x2F;env bash
YARN_RESOURCEMANAGER_USER&#x3D;root
HADOOP_SECURE_DN_USER&#x3D;yarn
YARN_NODEMANAGER_USER&#x3D;root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个猜想不是这个问题的原因。</p>
<h4 id="安装zookeper"><a href="#安装zookeper" class="headerlink" title="安装zookeper"></a>安装zookeper</h4><p>复制zoo.cfg<br>在zkk.cfg里修改如下内容</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.8.0&#x2F;zkData                                                                                   
dataLogDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.8.0&#x2F;zkDataLog
server.1&#x3D;golden-01:2888:3888                                                                                                  
server.2&#x3D;golden-02:2888:3888                                                                                                  
server.3&#x3D;golden-03:2888:3888   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>分别在三台服务上面依次执行 echo id &gt; /opt/modules/zookeeper-3.8.0/zkData/myid 命令创建zookeeper编号的myid文件<br>(notice:这里的myid要建在自己zoo.cfg文件的dataDir中)<br>zookeeper启动：<code>zkServer.sh start</code></p>
<blockquote>
<p>需要注意的是，<strong>需要在每台几点都启动一下</strong>，否则的话，会报如下错误：</p>
</blockquote>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ZooKeeper JMX enabled by default
Using config: &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.8.0&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg
Client port found: 2181. Client address: localhost. Client SSL: false.
Error contacting service. It is probably not running.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过<code>./zkServer.sh start-foreground</code>查看日志：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2022-03-20 08:29:37,669 [myid:] - WARN  [QuorumConnectionThread-[myid&#x3D;1]-1:o.a.z.s.q.QuorumCnxManager@401] - Cannot open channel to 2 at election address &#x2F;192.168.233.131:3888
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:476)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:218)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.initiateConnection(QuorumCnxManager.java:384)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$QuorumConnectionReqThread.run(QuorumCnxManager.java:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-03-20 08:29:37,669 [myid:] - WARN  [QuorumConnectionThread-[myid&#x3D;1]-2:o.a.z.s.q.QuorumCnxManager@401] - Cannot open channel to 3 at election address &#x2F;192.168.233.132:3888
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:476)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:218)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:200)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.initiateConnection(QuorumCnxManager.java:384)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$QuorumConnectionReqThread.run(QuorumCnxManager.java:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>其实就是需要在每台节点都启动一下zk服务，否则的话，端口不同</p>
<h4 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h4><p>编辑<code>config/server.properties</code></p>
<pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"><span class="token attr-name">broker.id</span><span class="token punctuation">=</span><span class="token attr-value">1</span>
<span class="token attr-name">log.dirs</span><span class="token punctuation">=</span><span class="token attr-value">/opt/modules/kafka-3.1.0/kafka-logs  ## 需要自己创建出来</span>
<span class="token attr-name">zookeeper.connect</span><span class="token punctuation">=</span><span class="token attr-value">golden-01:2181,golden-02:2181,golden-03:2181</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>kafka启动：<br><strong>需要在每台节点都启动一下</strong>：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nohup bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &gt;&gt; output.log 2&gt;&amp;1 &amp;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里编写自动化脚本来实现每台节点都启动的操作</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">echo &quot;############# 正在启动 golden-01 kafka服务 ###########&quot;
ssh -Tq golden@golden-01&lt;&lt;EOF
source &#x2F;etc&#x2F;profile 
cd &#x2F;opt&#x2F;modules&#x2F;kafka-3.1.0 
nohup bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &gt;output.log 2&gt;&amp;1 &amp; 
EOF

echo &quot;############# 正在启动 golden-02 kafka服务 ###########&quot;
ssh -Tq golden@golden-02&lt;&lt;EOF
source &#x2F;etc&#x2F;profile 
cd &#x2F;opt&#x2F;modules&#x2F;kafka-3.1.0 
nohup bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &gt;output.log 2&gt;&amp;1 &amp;
EOF

echo &quot;############# 正在启动 golden-03 kafka服务 ###########&quot;
ssh -Tq golden@golden-03&lt;&lt;EOF
source &#x2F;etc&#x2F;profile 
cd &#x2F;opt&#x2F;modules&#x2F;kafka-3.1.0
nohup bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &gt;output.log 2&gt;&amp;1 &amp;
EOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里如果不添加<code>-Tq</code>，就会报<code>Pseudo-terminal will not be allocated because stdin is not a terminal</code><br>字面意思是伪终端将无法分配，因为标准输入不是终端。<br>所以需要增加<code>-tt</code>参数来强制伪终端分配，即使标准输入不是终端。<br>或者加上<code>-Tq</code>这个参数也可以。<br><code>-tt</code>会把命令打印出来，<code>-Tq</code>只会执行命令，不会打印具体执行了什么</p>
<h4 id="安装Flink"><a href="#安装Flink" class="headerlink" title="安装Flink"></a>安装Flink</h4><h4 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h4><ol>
<li>为Hive建立相应的MySQL账户,并赋予足够的权限,执行命令如下:<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token punctuation">[</span>lighthouse<span class="token variable">@VM</span><span class="token operator">-</span><span class="token number">4</span><span class="token operator">-</span><span class="token number">14</span><span class="token operator">-</span>centos hive<span class="token operator">-</span><span class="token number">2.3</span><span class="token number">.9</span><span class="token punctuation">]</span>$ mysql <span class="token operator">-</span>uroot <span class="token operator">-</span>pmysql
mysql<span class="token operator">></span> <span class="token keyword">CREATE</span> <span class="token keyword">USER</span> <span class="token string">'hive'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'Hive123!@#'</span><span class="token punctuation">;</span>
mysql<span class="token operator">></span> <span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">PRIVILEGES</span> <span class="token keyword">ON</span> <span class="token operator">*</span><span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hive'</span><span class="token variable">@'%'</span> <span class="token keyword">WITH</span> <span class="token keyword">GRANT</span> <span class="token keyword">OPTION</span><span class="token punctuation">;</span>
mysql<span class="token operator">></span> flush <span class="token keyword">privileges</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>建立 Hive 专用的元数据库，记得创建时用刚才创建的<code>hive</code>账号登陆。<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token punctuation">[</span>lighthouse<span class="token variable">@VM</span><span class="token operator">-</span><span class="token number">4</span><span class="token operator">-</span><span class="token number">14</span><span class="token operator">-</span>centos hive<span class="token operator">-</span><span class="token number">2.3</span><span class="token number">.9</span><span class="token punctuation">]</span>$ mysql <span class="token operator">-</span>uhive <span class="token operator">-</span>pHive123<span class="token operator">!</span><span class="token comment">#</span>
mysql<span class="token operator">></span> <span class="token keyword">create</span> <span class="token keyword">database</span> hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>到官网下载hive安装包，这里下载hive-2.3.9<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar zxvf apache-hive-2.3.9-bin.tar.gz -C .
mv apache-hive-2.3.9-bin&#x2F; hive-2.3.9
cd hive-2.3.9&#x2F;conf &amp;&amp; cp hive-default.xml.template hive-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li>修改hive-site.xml配置<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.local<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionURL<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>jdbc:mysql://golden-02:3306/hive?characterEncoding=UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionDriverName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>com.mysql.jdbc.Driver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionUserName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionPassword<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mysql<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>

    <span class="token comment">&lt;!-- metastore --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.uris<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>thrift://golden-02:9083<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token comment">&lt;!-- hiveserver2 --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.server2.thrift.port<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>10000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.server2.thrift.bind.host<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>golden-02<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.server2.thrift.client.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>gujincheng<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Username to use against thrift client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.server2.thrift.client.password<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>980071<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Password to use against thrift client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.server2.enable.doAs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>去mysql官网下载jdbc-connect的jar包放到hive/lib文件夹</li>
<li>启动hive<br>报如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava&#x2F;lang&#x2F;String;Ljava&#x2F;lang&#x2F;Object;)V
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338)
	at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:536)
	at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:554)
	at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:448)
	at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:4051)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这是因为hive内依赖的guava.jar和hadoop内的版本不一致造成的。<br>删除版本低的，换成其中一个的高版本的。<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;opt&#x2F;modules&#x2F;hadoop-3.2.2&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;lib&#x2F; &amp;&amp; cp guava-27.0-jre.jar &#x2F;opt&#x2F;modules&#x2F;hive-2.3.9&#x2F;lib&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
再次启动，报如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: $&#123;system:java.io.tmpdir%7D&#x2F;$%7Bsystem:user.name%7D
	at org.apache.hadoop.fs.Path.initialize(Path.java:263)
	at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:221)
	at org.apache.hadoop.hive.ql.session.SessionState.createSessionDirs(SessionState.java:663)
	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:586)
	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:553)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:750)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:686)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: java.net.URISyntaxException: Relative path in absolute URI: $&#123;system:java.io.tmpdir%7D&#x2F;$%7Bsystem:user.name%7D
	at java.net.URI.checkPath(URI.java:1823)
	at java.net.URI.&lt;init&gt;(URI.java:745)
	at org.apache.hadoop.fs.Path.initialize(Path.java:260)
	... 12 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这是因为hive-site里的路径使用了变量，但是，系统没有获取到，这里直接把变量换成绝对路径<br>使用vim打开hive-site.xml，使用命令：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">:%s&#x2F;$&#123;system:java.io.tmpdir&#125;\&#x2F;$&#123;system:user.name&#125;&#x2F;\&#x2F;tmp\&#x2F;hive\&#x2F;lighthouse&#x2F;g
:%s&#x2F;$&#123;system:java.io.tmpdir&#125;&#x2F;\&#x2F;tmp\&#x2F;hive&#x2F;g<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
又报如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">FAILED: SemanticException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这是因为Hive2需要hive元数据库初始化<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">schematool -dbType mysql -initSchema<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
初始化好以后，hive可以使用</li>
</ol>
<p>开启hiveserver2和metastore报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;org.apache.hadoop.hive.common.JvmPauseMonitor$Monitor@1eb9bf60&quot; java.lang.IllegalAccessError: tried to access method   com.google.common.base.Stopwatch.&lt;init&gt;()V from class org.apache.hadoop.hive.common.JvmPauseMonitor$Monitor
    at org.apache.hadoop.hive.common.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:176)
    at java.lang.Thread.run(Thread.java:748)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>可以忽略这个报错，看起来像是监控报错，不影响功能 </p>
<p>使用beeline方式连接hive，报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">beeline&gt; !connect jdbc:hive2:&#x2F;&#x2F;golden-02:10000
Connecting to jdbc:hive2:&#x2F;&#x2F;golden-02:10000
Enter username for jdbc:hive2:&#x2F;&#x2F;golden-02:10000: gujincheng
Enter password for jdbc:hive2:&#x2F;&#x2F;golden-02:10000: ******
22&#x2F;04&#x2F;08 09:02:23 [main]: WARN jdbc.HiveConnection: Failed to connect to golden-02:10000
Error: Could not open client transport with JDBC Uri: jdbc:hive2:&#x2F;&#x2F;golden-02:10000: Failed to open new session: java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): User: gujincheng is not allowed to impersonate gujincheng (state&#x3D;08S01,code&#x3D;0)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里需要设置conf/hive-site.xml：<br>默认情况下HiveServer2 执行查询时使用的用户是提交查询的用户.但是如果将这个选项设置为false,查询将会使用运行hiveserver2的用户</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.server2.enable.doAs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>执行hivesql报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>解决办法：在hadoop的yarn-site.xml里添加如下配置：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.application.classpath<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/modules/hadoop-3.0.0/etc/hadoop:/opt/modules/hadoop-3.0.0/share/hadoop/common/lib/*:/opt/modules/hadoop-3.0.0/share/  hadoop/common/*:/opt/modules/hadoop-3.0.0/share/hadoop/hdfs:/opt/modules/hadoop-3.0.0/share/hadoop/hdfs/lib/*:/opt/modules/hadoop-3.0.0/share/hadoop/hdfs/*:/opt/modules/hadoop-3.0.0/share/hadoop/mapreduce/*:/opt/modules/hadoop-3.0.0/share/hadoop/yarn:/opt/    modules/hadoop-3.0.0/share/hadoop/yarn/lib/*:/opt/modules/hadoop-3.0.0/share/hadoop/yarn/*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>


<h4 id="安装SQLServer"><a href="#安装SQLServer" class="headerlink" title="安装SQLServer"></a>安装SQLServer</h4><ul>
<li>安装sqlserver<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;mssql-server.repo https:&#x2F;&#x2F;packages.microsoft.com&#x2F;config&#x2F;rhel&#x2F;7&#x2F;mssql-server-2019.repo
yum install -y mssql-server
&#x2F;opt&#x2F;mssql&#x2F;bin&#x2F;mssql-conf setup <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
这里在Centos精简版一直失败，最后在Centos7完整版里安装成功了，精简版的缺少太多基础软件了。<br>可以参考<a href="https://www.cnblogs.com/gered/p/12509367.html">sql server for linux 安装（yum、静默安装、环境变量安装、docker安装） </a></li>
<li>启用SQL Server代理<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#启用SQL Server代理
sudo &#x2F;opt&#x2F;mssql&#x2F;bin&#x2F;mssql-conf set sqlagent.enabled true
#需要重启服务生效
sudo systemctl restart mssql-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

</li>
</ul>
<h4 id="Centos如何访问sqlserver"><a href="#Centos如何访问sqlserver" class="headerlink" title="Centos如何访问sqlserver"></a>Centos如何访问sqlserver</h4><ol>
<li><p>安装sqlcmd</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;msprod.repo https:&#x2F;&#x2F;packages.microsoft.com&#x2F;config&#x2F;rhel&#x2F;7&#x2F;prod.repo
yum remove unixODBC-utf16 unixODBC-utf16-devel
yum install -y mssql-tools unixODBC-devel
echo &#39;export PATH&#x3D;&quot;$PATH:&#x2F;opt&#x2F;mssql-tools&#x2F;bin&quot;&#39; &gt;&gt; ~&#x2F;.bash_profile
echo &#39;export PATH&#x3D;&quot;$PATH:&#x2F;opt&#x2F;mssql-tools&#x2F;bin&quot;&#39; &gt;&gt; ~&#x2F;.bashrc
source ~&#x2F;.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>使用 SQL Server 名称 (-S)，用户名 (-U) 和密码 (-P) 的参数运行 sqlcmd 。 在本教程中，用户进行本地连接，因此服务器名称为 localhost。 用户名为 SA，密码是在安装过程中为 SA 帐户提供的密码。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sqlcmd -S localhost -U SA -P &#39;&lt;YourPassword&gt;&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这个工具sql不能换行，后期再看看如何调整参数</p>
</li>
<li><p>sqlserver的语法和mysql有很大的不一样，执行sql需要<code>GO</code>一下才能执行</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Centos</category>
      </categories>
      <tags>
        <tag>Centos</tag>
      </tags>
  </entry>
  <entry>
    <title>DataX学习笔记</title>
    <url>/2021/12/27/DataX%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>DataX学习笔记</li>
</ul>
<a id="more"></a>

<h2 id="DataX概览"><a href="#DataX概览" class="headerlink" title="DataX概览"></a>DataX概览</h2><h3 id="DataX-3-0概览"><a href="#DataX-3-0概览" class="headerlink" title="DataX 3.0概览"></a>DataX 3.0概览</h3><p> DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p>
<h3 id="DataX-的设计理念"><a href="#DataX-的设计理念" class="headerlink" title="DataX 的设计理念"></a>DataX 的设计理念</h3><p>为了解决异构数据源同步问题，DataX 将复杂的网状的同步链路变成了星型数据链路，DataX 作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到 DataX，便能跟已有的数据源做到无缝数据同步。<br><img src="/uploads/20211228/DataX%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF.png" alt="DataX数据链路"></p>
<h3 id="框架设计"><a href="#框架设计" class="headerlink" title="框架设计"></a>框架设计</h3><p><img src="/uploads/20211228/DataX%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1.png" alt="DataX框架设计"></p>
<ul>
<li>Reader：数据采集模块，负责采集数据源的数据，将数据发给Framework。</li>
<li>Wiriter: 数据写入模块，负责不断向Framwork取数据，并将数据写入到目的端。</li>
<li>Framework:用于连接read和writer,作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等你核心技术问题。<h3 id="运行原理"><a href="#运行原理" class="headerlink" title="运行原理"></a>运行原理</h3><img src="/uploads/20211228/DataX%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86.png" alt="DataX运行原理"></li>
<li>*核心模块介绍：**</li>
</ul>
<ol>
<li>DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。</li>
<li>DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。</li>
<li>切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。</li>
<li>每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—&gt;Channel—&gt;Writer的线程来完成任务同步工作。</li>
<li>DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0</li>
</ol>
<p><strong>DataX调度流程：</strong><br>举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。 DataX的调度决策思路是：</p>
<ol>
<li>DataXJob根据分库分表切分成了100个Task。</li>
<li>根据20个并发，DataX计算共需要分配4个TaskGroup。</li>
<li>4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。</li>
</ol>
<ul>
<li>Job：单个作业的管理节点，负责数据清理、子任务划分、TaskGroup监控管理。</li>
<li>Task：由Job切分而来，是DataX作业的最小单元，每个Task负责一部分数据的同步工作。</li>
<li>Schedule：将Task组成TaskGroup，单个TaskGroup的并发数量为5。</li>
<li>TaskGroup：负责启动Task。</li>
</ul>
<h3 id="DataX3-0插件体系"><a href="#DataX3-0插件体系" class="headerlink" title="DataX3.0插件体系"></a>DataX3.0插件体系</h3><p>经过几年积累，DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入。DataX目前支持数据如下：<br>| 类型               | 数据源                          | Reader(读) | Writer(写) | 文档                                                         |<br>| —————— | ——————————- | ———- | ———- | ———————————————————— |<br>| RDBMS 关系型数据库 | MySQL                           | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md">写</a> |<br>|                    | Oracle                          | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md">写</a> |<br>|                    | OceanBase                       | √          | √          | <a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase">读</a> 、<a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase">写</a> |<br>|                    | SQLServer                       | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md">写</a> |<br>|                    | PostgreSQL                      | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md">写</a> |<br>|                    | DRDS                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md">写</a> |<br>|                    | 通用RDBMS(支持所有关系型数据库) | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/rdbmsreader/doc/rdbmsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/rdbmswriter/doc/rdbmswriter.md">写</a> |<br>| 阿里云数仓数据存储 | ODPS                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/odpswriter/doc/odpswriter.md">写</a> |<br>|                    | ADS                             |            | √          | <a href="https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md">写</a> |<br>|                    | OSS                             | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md">写</a> |<br>|                    | OCS                             |            | √          | <a href="https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md">写</a> |<br>| NoSQL数据存储      | OTS                             | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md">写</a> |<br>|                    | Hbase0.94                       | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md">写</a> |<br>|                    | Hbase1.1                        | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase11xreader/doc/hbase11xreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md">写</a> |<br>|                    | Phoenix4.x                      | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase11xsqlreader/doc/hbase11xsqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xsqlwriter/doc/hbase11xsqlwriter.md">写</a> |<br>|                    | Phoenix5.x                      | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase20xsqlreader/doc/hbase20xsqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase20xsqlwriter/doc/hbase20xsqlwriter.md">写</a> |<br>|                    | MongoDB                         | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/mongodbreader/doc/mongodbreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md">写</a> |<br>|                    | Hive                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md">写</a> |<br>|                    | Cassandra                       | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/cassandrareader/doc/cassandrareader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/cassandrawriter/doc/cassandrawriter.md">写</a> |<br>| 无结构化数据存储   | TxtFile                         | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md">写</a> |<br>|                    | FTP                             | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md">写</a> |<br>|                    | HDFS                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md">写</a> |<br>|                    | Elasticsearch                   |            | √          | <a href="https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md">写</a> |<br>| 时间序列数据库     | OpenTSDB                        | √          |            | <a href="https://github.com/alibaba/DataX/blob/master/opentsdbreader/doc/opentsdbreader.md">读</a> |<br>|                    | TSDB                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/tsdbreader/doc/tsdbreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/tsdbwriter/doc/tsdbhttpwriter.md">写</a> |</p>
<p>DataX Framework提供了简单的接口与插件交互，提供简单的插件接入机制，只需要任意加上一种插件，就能无缝对接其他数据源。</p>
<h2 id="DataX使用案例"><a href="#DataX使用案例" class="headerlink" title="DataX使用案例"></a>DataX使用案例</h2><p>DataX通过插件机制，动态的在运行时载入reader和writer进行数据同步的执行。<br>所以在使用DataX的时候，需要指定reader和writer，确定是数据是从哪里来到哪里去<br>例如，现在需要采集mysql数据到hive。那么reader其实就是mysql，writer就是hdfs</p>
<ol>
<li>进入到<code>datax/plugin/reader</code>查看reader下插件目录，从中发现有mysqlreader</li>
<li>再进入<code>datax/plugin/writer</code>查看writer下插件目录，从中发现有hdfswriter</li>
<li>查看官方给的调用模版,执行<code>bin/datax.py -r mysqlreader -w hdfswriter</code>,得到如下json：<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
    <span class="token property">"job"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
        <span class="token property">"content"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">&#123;</span>
                <span class="token property">"reader"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"mysqlreader"</span><span class="token punctuation">,</span>
                    <span class="token property">"parameter"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                        <span class="token property">"column"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token property">"connection"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
                            <span class="token punctuation">&#123;</span>
                                <span class="token property">"jdbcUrl"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                <span class="token property">"table"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                            <span class="token punctuation">&#125;</span>
                        <span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token property">"password"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"username"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"where"</span><span class="token operator">:</span> <span class="token string">""</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
                <span class="token property">"writer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"hdfswriter"</span><span class="token punctuation">,</span>
                    <span class="token property">"parameter"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                        <span class="token property">"column"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token property">"compress"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"defaultFS"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"fieldDelimiter"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"fileName"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"fileType"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"path"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"writeMode"</span><span class="token operator">:</span> <span class="token string">""</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token property">"setting"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"speed"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                <span class="token property">"channel"</span><span class="token operator">:</span> <span class="token string">""</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<p><strong>注意：</strong> 这里的模版只会给必写的选项，非必写的，就不会在这个模版里。例如<code>hadoopConfig</code><br>如果要看全部的选项，可以在源码里找到相对应的插件目录，里面有相应的md文件，例如hdfswriter的文档在<br><code>DataX/hdfswriter/doc/hdfswriter.md</code></p>
<ol start="4">
<li>编写自己的mysql2hive.json文件，并执行<code>bin/datax.py job/mysql2hive.json</code>即可</li>
</ol>
<p>完整的mysql2hive.json案例：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
	<span class="token property">"job"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
		<span class="token property">"content"</span><span class="token operator">:</span><span class="token punctuation">[</span>
			<span class="token punctuation">&#123;</span>
				<span class="token property">"reader"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
					<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"mysqlreader"</span><span class="token punctuation">,</span>
					<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
						<span class="token property">"column"</span><span class="token operator">:</span><span class="token punctuation">[</span>
							<span class="token string">"`id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`activity_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`start_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`end_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`status`"</span><span class="token punctuation">,</span>
							<span class="token string">"`status_desc`"</span><span class="token punctuation">,</span>
							<span class="token string">"`charge_type`"</span><span class="token punctuation">,</span>
							<span class="token string">"`daily_budgets`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bid`"</span><span class="token punctuation">,</span>
							<span class="token string">"`kb_cost_task_id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`account_type`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bp_id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bp_type`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bp_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`shop_id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`shop_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`create_user`"</span><span class="token punctuation">,</span>
							<span class="token string">"`create_user_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`create_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`update_user`"</span><span class="token punctuation">,</span>
							<span class="token string">"`update_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`yn`"</span><span class="token punctuation">,</span>
							<span class="token string">"`update_user_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`sales_order_no`"</span>
						<span class="token punctuation">]</span><span class="token punctuation">,</span>
						<span class="token property">"connection"</span><span class="token operator">:</span><span class="token punctuation">[</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"customParam"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
								<span class="token property">"jdbcUrl"</span><span class="token operator">:</span><span class="token punctuation">[</span>
									<span class="token string">"jdbc:mysql://xxxx:3306/ad_star_store?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true"</span>
								<span class="token punctuation">]</span><span class="token punctuation">,</span>
								<span class="token property">"querySql"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
								<span class="token property">"table"</span><span class="token operator">:</span><span class="token punctuation">[</span>
									<span class="token string">"hbp_ad_activity"</span>
								<span class="token punctuation">]</span>
							<span class="token punctuation">&#125;</span>
						<span class="token punctuation">]</span><span class="token punctuation">,</span>
						<span class="token property">"mandatoryEncoding"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
						<span class="token property">"monthTableMode"</span><span class="token operator">:</span><span class="token string">""</span><span class="token punctuation">,</span>
						<span class="token property">"password"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"splitPk"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
						<span class="token property">"tableOrView"</span><span class="token operator">:</span><span class="token string">"1"</span><span class="token punctuation">,</span>
						<span class="token property">"username"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"version"</span><span class="token operator">:</span><span class="token string">"2"</span><span class="token punctuation">,</span>
						<span class="token property">"where"</span><span class="token operator">:</span><span class="token null keyword">null</span>
					<span class="token punctuation">&#125;</span>
				<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
				<span class="token property">"transformer"</span><span class="token operator">:</span><span class="token punctuation">[</span>
					<span class="token punctuation">&#123;</span>
						<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"proxy_transformer"</span><span class="token punctuation">,</span>
						<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
							<span class="token property">"code"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"columnIndex"</span><span class="token operator">:</span><span class="token number">-1</span><span class="token punctuation">,</span>
							<span class="token property">"extraPackage"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"paras"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"1"</span><span class="token punctuation">,</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span><span class="token string">"id"</span><span class="token punctuation">,</span><span class="token string">"activity_name"</span><span class="token punctuation">,</span><span class="token string">"start_time"</span><span class="token punctuation">,</span><span class="token string">"end_time"</span><span class="token punctuation">,</span><span class="token string">"status"</span><span class="token punctuation">,</span><span class="token string">"status_desc"</span><span class="token punctuation">,</span><span class="token string">"charge_type"</span><span class="token punctuation">,</span><span class="token string">"daily_budgets"</span><span class="token punctuation">,</span><span class="token string">"bid"</span><span class="token punctuation">,</span><span class="token string">"kb_cost_task_id"</span><span class="token punctuation">,</span><span class="token string">"account_type"</span><span class="token punctuation">,</span><span class="token string">"bp_id"</span><span class="token punctuation">,</span><span class="token string">"bp_type"</span><span class="token punctuation">,</span><span class="token string">"bp_name"</span><span class="token punctuation">,</span><span class="token string">"shop_id"</span><span class="token punctuation">,</span><span class="token string">"shop_name"</span><span class="token punctuation">,</span><span class="token string">"create_user"</span><span class="token punctuation">,</span><span class="token string">"create_user_name"</span><span class="token punctuation">,</span><span class="token string">"create_time"</span><span class="token punctuation">,</span><span class="token string">"update_user"</span><span class="token punctuation">,</span><span class="token string">"update_time"</span><span class="token punctuation">,</span><span class="token string">"yn"</span><span class="token punctuation">,</span><span class="token string">"update_user_name"</span><span class="token punctuation">,</span><span class="token string">"sales_order_no"</span><span class="token punctuation">]</span>
						<span class="token punctuation">&#125;</span>
					<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
					<span class="token punctuation">&#123;</span>
						<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"proxy_transformer"</span><span class="token punctuation">,</span>
						<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
							<span class="token property">"code"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"columnIndex"</span><span class="token operator">:</span><span class="token number">-1</span><span class="token punctuation">,</span>
							<span class="token property">"extraPackage"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"paras"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"2"</span><span class="token punctuation">,</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span><span class="token string">"id"</span><span class="token punctuation">,</span><span class="token string">"activity_name"</span><span class="token punctuation">,</span><span class="token string">"start_time"</span><span class="token punctuation">,</span><span class="token string">"end_time"</span><span class="token punctuation">,</span><span class="token string">"status"</span><span class="token punctuation">,</span><span class="token string">"status_desc"</span><span class="token punctuation">,</span><span class="token string">"charge_type"</span><span class="token punctuation">,</span><span class="token string">"daily_budgets"</span><span class="token punctuation">,</span><span class="token string">"bid"</span><span class="token punctuation">,</span><span class="token string">"kb_cost_task_id"</span><span class="token punctuation">,</span><span class="token string">"account_type"</span><span class="token punctuation">,</span><span class="token string">"bp_id"</span><span class="token punctuation">,</span><span class="token string">"bp_type"</span><span class="token punctuation">,</span><span class="token string">"bp_name"</span><span class="token punctuation">,</span><span class="token string">"shop_id"</span><span class="token punctuation">,</span><span class="token string">"shop_name"</span><span class="token punctuation">,</span><span class="token string">"create_user"</span><span class="token punctuation">,</span><span class="token string">"create_user_name"</span><span class="token punctuation">,</span><span class="token string">"create_time"</span><span class="token punctuation">,</span><span class="token string">"update_user"</span><span class="token punctuation">,</span><span class="token string">"update_time"</span><span class="token punctuation">,</span><span class="token string">"yn"</span><span class="token punctuation">,</span><span class="token string">"update_user_name"</span><span class="token punctuation">,</span><span class="token string">"sales_order_no"</span><span class="token punctuation">]</span>
						<span class="token punctuation">&#125;</span>
					<span class="token punctuation">&#125;</span>
				<span class="token punctuation">]</span><span class="token punctuation">,</span>
				<span class="token property">"writer"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
					<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"hdfswriter"</span><span class="token punctuation">,</span>
					<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
						<span class="token property">"column"</span><span class="token operator">:</span><span class="token punctuation">[</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"activity_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"start_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"end_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"status"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"status_desc"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"charge_type"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"daily_budgets"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bid"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"kb_cost_task_id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"account_type"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bp_id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bp_type"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bp_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"shop_id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"shop_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"create_user"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"create_user_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"create_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"update_user"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"update_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"yn"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"INT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"update_user_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"sales_order_no"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span>
						<span class="token punctuation">]</span><span class="token punctuation">,</span>
						<span class="token property">"compress"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
						<span class="token property">"defaultFS"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"fieldDelimiter"</span><span class="token operator">:</span><span class="token string">"\t"</span><span class="token punctuation">,</span>
						<span class="token property">"fileName"</span><span class="token operator">:</span><span class="token string">"hbp_ad_activity"</span><span class="token punctuation">,</span>
						<span class="token property">"fileType"</span><span class="token operator">:</span><span class="token string">"text"</span><span class="token punctuation">,</span>
						<span class="token property">"hadoopConfig"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>  
							<span class="token property">"fs.defaultFS"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.ha.namenodes.HZWONE"</span><span class="token operator">:</span><span class="token string">"nn1,nn2"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.nameservices"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.namenode.rpc-address.HZWONE.nn2"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx:xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.namenode.rpc-address.HZWONE.nn1"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx:xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.client.failover.proxy.provider.HZWONE"</span><span class="token operator">:</span><span class="token string">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>
						<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
						<span class="token property">"path"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"writeMode"</span><span class="token operator">:</span><span class="token string">"append"</span>
					<span class="token punctuation">&#125;</span>
				<span class="token punctuation">&#125;</span>
			<span class="token punctuation">&#125;</span>
		<span class="token punctuation">]</span><span class="token punctuation">,</span>
		<span class="token property">"setting"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
			<span class="token property">"errorLimit"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
			<span class="token property">"speed"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
				<span class="token property">"batchSize"</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>
				<span class="token property">"channel"</span><span class="token operator">:</span><span class="token number">8</span><span class="token punctuation">,</span>
				<span class="token property">"record"</span><span class="token operator">:</span><span class="token number">0</span>
			<span class="token punctuation">&#125;</span>
		<span class="token punctuation">&#125;</span>
	<span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>hadoopConfig是为了datax往hdfs写数据如何配置高可用</p>
<h2 id="DataX定制化插件开发与使用"><a href="#DataX定制化插件开发与使用" class="headerlink" title="DataX定制化插件开发与使用"></a>DataX定制化插件开发与使用</h2><h3 id="DataX为什么要使用插件机制？"><a href="#DataX为什么要使用插件机制？" class="headerlink" title="DataX为什么要使用插件机制？"></a>DataX为什么要使用插件机制？</h3><p>从设计之初，DataX就把异构数据源同步作为自身的使命，为了应对不同数据源的差异、同时提供一致的同步原语和扩展能力，DataX自然而然地采用了<code>框架 + 插件</code>的模式：</p>
<ul>
<li>插件只需关心数据的读取或者写入本身。</li>
<li>而同步的共性问题，比如：类型转换、性能、统计，则交由框架来处理。<br>作为插件开发人员，则需要关注两个问题：</li>
</ul>
<p>数据源1. 本身的读写数据正确性。<br>如何与2. 框架沟通、合理正确地使用框架。</p>
<h3 id="插件视角看框架"><a href="#插件视角看框架" class="headerlink" title="插件视角看框架"></a>插件视角看框架</h3><h4 id="逻辑执行模型"><a href="#逻辑执行模型" class="headerlink" title="逻辑执行模型"></a>逻辑执行模型</h4><p>插件开发者不用关心太多，基本只需要关注特定系统读和写，以及自己的代码在逻辑上是怎样被执行的，哪一个方法是在什么时候被调用的。在此之前，需要明确以下概念：</p>
<ul>
<li>Job: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。</li>
<li>Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。</li>
<li>TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup</li>
<li>JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker</li>
<li>TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。<br>简而言之， Job拆分成Task，在分别在框架提供的容器中执行，插件只需要实现Job和Task两部分逻辑。</li>
</ul>
<h4 id="物理执行模型"><a href="#物理执行模型" class="headerlink" title="物理执行模型"></a>物理执行模型</h4><p>框架为插件提供物理上的执行能力（线程）。DataX框架有三种运行模式：</p>
<ul>
<li>Standalone: 单进程运行，没有外部依赖。</li>
<li>Local: 单进程运行，统计信息、错误信息汇报到集中存储。</li>
<li>Distrubuted: 分布式多进程运行，依赖DataX Service服务。<br>当然，上述三种模式对插件的编写而言没有什么区别，你只需要避开一些小错误，插件就能够在单机/分布式之间无缝切换了。 当JobContainer和TaskGroupContainer运行在同一个进程内时，就是单机模式（Standalone和Local）；当它们分布在不同的进程中执行时，就是分布式（Distributed）模式。</li>
</ul>
<h4 id="编程接口"><a href="#编程接口" class="headerlink" title="编程接口"></a>编程接口</h4><p>那么，Job和Task的逻辑应是怎么对应到具体的代码中的？</p>
<p>首先，插件的入口类必须扩展Reader或Writer抽象类，并且实现分别实现Job和Task两个内部抽象类，Job和Task的实现必须是 内部类 的形式，原因见 加载原理 一节。<br>具体参考<a href="https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md">DataX插件开发宝典</a></p>
<h4 id="插件定义"><a href="#插件定义" class="headerlink" title="插件定义"></a>插件定义</h4><p>代码写好了，有没有想过框架是怎么找到插件的入口类的？框架是如何加载插件的呢？</p>
<p>在每个插件的项目中，都有一个plugin.json文件，这个文件定义了插件的相关信息，包括入口类。例如：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"mysqlwriter"</span><span class="token punctuation">,</span>
    <span class="token property">"class"</span><span class="token operator">:</span> <span class="token string">"com.alibaba.datax.plugin.writer.mysqlwriter.MysqlWriter"</span><span class="token punctuation">,</span>
    <span class="token property">"description"</span><span class="token operator">:</span> <span class="token string">"Use Jdbc connect to database, execute insert sql."</span><span class="token punctuation">,</span>
    <span class="token property">"developer"</span><span class="token operator">:</span> <span class="token string">"alibaba"</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>name: 插件名称，大小写敏感。框架根据用户在配置文件中指定的名称来搜寻插件。 十分重要 。</li>
<li>class: 入口类的全限定名称，框架通过反射插件入口类的实例。十分重要 。</li>
<li>description: 描述信息。</li>
<li>developer: 开发人员。<h4 id="打包发布"><a href="#打包发布" class="headerlink" title="打包发布"></a>打包发布</h4>DataX使用assembly打包，assembly的使用方法请咨询谷哥或者度娘。打包命令如下：<br><code>mvn clean package -DskipTests assembly:assembly</code><br>DataX插件需要遵循统一的目录结构：<pre class="line-numbers language-text" data-language="text"><code class="language-text">$&#123;DATAX_HOME&#125;
|-- bin       
|   &#96;-- datax.py
|-- conf
|   |-- core.json
|   &#96;-- logback.xml
|-- lib
|   &#96;-- datax-core-dependencies.jar
&#96;-- plugin
    |-- reader
    |   &#96;-- mysqlreader
    |       |-- libs
    |       |   &#96;-- mysql-reader-plugin-dependencies.jar
    |       |-- mysqlreader-0.0.1-SNAPSHOT.jar
    |       &#96;-- plugin.json
    &#96;-- writer
        |-- mysqlwriter
        |   |-- libs
        |   |   &#96;-- mysql-writer-plugin-dependencies.jar
        |   |-- mysqlwriter-0.0.1-SNAPSHOT.jar
        |   &#96;-- plugin.json
        |-- oceanbasewriter
        &#96;-- odpswriter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>${DATAX_HOME}/bin: 可执行程序目录。</li>
<li>${DATAX_HOME}/conf: 框架配置目录。</li>
<li>${DATAX_HOME}/lib: 框架依赖库目录。</li>
<li>${DATAX_HOME}/plugin: 插件目录。</li>
</ul>
<p>插件目录分为reader和writer子目录，读写插件分别存放。插件目录规范如下：</p>
<ul>
<li>${PLUGIN_HOME}/libs: 插件的依赖库。</li>
<li>${PLUGIN_HOME}/plugin-name-version.jar: 插件本身的jar。</li>
<li>${PLUGIN_HOME}/plugin.json: 插件描述文件。<br>尽管框架加载插件时，会把${PLUGIN_HOME}下所有的jar放到classpath，但还是推荐依赖库的jar和插件本身的jar分开存放。</li>
</ul>
<p><strong>注意</strong>： 插件的目录名字必须和plugin.json中定义的插件名称一致。</p>
<h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>DataX使用json作为配置文件的格式。<br>具体参考<a href="https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md">DataX插件开发宝典</a></p>
<h3 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h3><p>hdfswriter写到hdfs只会产生一个文件，是因为并发为1嘛？<br>这里需要确认一下</p>
<p>公司写hudi的时候，仅在实时用的是spark，在离线初始化的时候使用了datax，这里没有用spark重写datax的writer，用spark写不了data的writer</p>
<h3 id="抽取本地mysql报如下错误"><a href="#抽取本地mysql报如下错误" class="headerlink" title="抽取本地mysql报如下错误"></a>抽取本地mysql报如下错误</h3><ul>
<li><p>报mysql链接不上，报错日志如下：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">ERROR RetryUtil - Exception when calling callable, 异常Msg:DataX无法连接对应的数据库，可能原因是：
1) 配置的ip&#x2F;port&#x2F;database&#x2F;jdbc错误，无法连接。
2) 配置的username&#x2F;password错误，鉴权失败。请和DBA确认该数据库的连接信息是否正确。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>*解决办法：**<br>datax里面的mysql驱动更换成合适的8.x的版本就好了:</p>
</li>
<li><p>报值非法</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">com.alibaba.datax.common.exception.DataXException: Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 任务读取配置文件出错. 配置文件路径[job.setting.speed.channel] 值非法, 期望是整数类型: For input string: &quot;&quot;. 请检查您的配置并作出修改.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>*解决办法：**<br>channel一开始写成了 “”,改成int就可以了</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"setting"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
			<span class="token property">"errorLimit"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
			<span class="token property">"speed"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
				<span class="token property">"batchSize"</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>  ## 批提交
				<span class="token property">"channel"</span><span class="token operator">:</span><span class="token number">8</span><span class="token punctuation">,</span> ##并发量
				<span class="token property">"record"</span><span class="token operator">:</span><span class="token number">0</span>  # 对数据条数做限制
			<span class="token punctuation">&#125;</span>
		<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>DataX</category>
      </categories>
      <tags>
        <tag>DataX</tag>
      </tags>
  </entry>
  <entry>
    <title>FlinkCDC与常用CDC对比</title>
    <url>/2021/12/17/FlinkCDC%E4%B8%8E%E5%B8%B8%E7%94%A8CDC%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>CDC概述</li>
<li>CDC的种类</li>
</ul>
<a id="more"></a>

<h2 id="一、CDC概述"><a href="#一、CDC概述" class="headerlink" title="一、CDC概述"></a>一、CDC概述</h2><p>CDC在广义的概念上，Change Data Capture变更数据获取的技术，我们都可以称为 CDC。<br>CDC技术常用于：</p>
<ul>
<li>数据同步，用于备份，容灾</li>
<li>数据分发，一个数据源分发给多个下游系统</li>
<li>数据采集，面向数据仓库/数据湖的 ETL 数据集成，是非常重要的数据源</li>
</ul>
<h2 id="二、CDC的种类"><a href="#二、CDC的种类" class="headerlink" title="二、CDC的种类"></a>二、CDC的种类</h2><p>目前主流的实现方案可以分为两种：<br>1、基于查询的CDC</p>
<ul>
<li>离线调度查询作业，批处理。把一张表同步到其他系统，每次通过查询去获取查询的结果</li>
<li>无法保障数据一致性，查的过程中有可能数据已经发生了多次变更</li>
<li>不保障实时性，基于离线调度有查询延迟</li>
</ul>
<p>2、基于日志的CDC</p>
<ul>
<li>实时消费日志，流处理，例如MYSQL的BINLOG完整记录库里面的变更，可以把BINLOG当作流的数据源</li>
<li>保障数据一致性，因为BINLOG所有的历史明细都可以获得</li>
<li>提供实时数据，因为提供是流式的消费方式，所以实时性有爆炸</li>
</ul>
<h3 id="常见的开源CDC工具"><a href="#常见的开源CDC工具" class="headerlink" title="常见的开源CDC工具"></a>常见的开源CDC工具</h3><table>
<thead>
<tr>
<th></th>
<th>DataX</th>
<th>Sqoop</th>
<th>Kettle</th>
<th>Canal</th>
<th>Maxwell</th>
<th>Flink CDC</th>
<th>Debezium</th>
<th>Oracle Goldengate</th>
</tr>
</thead>
<tbody><tr>
<td>CDC机制</td>
<td>查询</td>
<td>查询</td>
<td>查询</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
</tr>
<tr>
<td>增量同步</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>断点续传</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>全量同步</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>架构</td>
<td>单机</td>
<td>分布式</td>
<td>分布式</td>
<td>单机</td>
<td>单机</td>
<td>分布式</td>
<td>单机</td>
<td>分布式</td>
</tr>
<tr>
<td>生态</td>
<td>☆☆☆</td>
<td>☆☆</td>
<td>☆</td>
<td>☆☆</td>
<td>☆☆☆</td>
<td>☆☆☆☆☆</td>
<td>☆☆☆</td>
<td>☆☆☆</td>
</tr>
</tbody></table>
<p>实际演示Canal、MaxWell、FlinkCDC比对</p>
<h2 id="三、FlinkCDC使用案例"><a href="#三、FlinkCDC使用案例" class="headerlink" title="三、FlinkCDC使用案例"></a>三、FlinkCDC使用案例</h2><h3 id="使用前提"><a href="#使用前提" class="headerlink" title="使用前提"></a>使用前提</h3><p>1、开启binlog，MySQL级别为 ROW<br>2、导入cdc依赖</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!--        Flink CDC--></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.alibaba.ververica<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-mysql-cdc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="使用DEMO"><a href="#使用DEMO" class="headerlink" title="使用DEMO"></a>使用DEMO</h3><h4 id="1、DataStream-API"><a href="#1、DataStream-API" class="headerlink" title="1、DataStream API"></a>1、DataStream API</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span></span><span class="token class-name">MySqlSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>table<span class="token punctuation">.</span></span><span class="token class-name">StartupOptions</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">DebeziumSourceFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">StringDebeziumDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>



<span class="token comment">/**
 * @author mt
 * @create 2021-10-26 20:13
 */</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkTestCDC</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DebeziumSourceFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> build <span class="token operator">=</span> <span class="token class-name">MySqlSource</span><span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">hostname</span><span class="token punctuation">(</span><span class="token string">"hadoop102"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">port</span><span class="token punctuation">(</span><span class="token number">3306</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">databaseList</span><span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">tableList</span><span class="token punctuation">(</span><span class="token string">"test.sensor"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">password</span><span class="token punctuation">(</span><span class="token string">"root"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">username</span><span class="token punctuation">(</span><span class="token string">"root"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">deserializer</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">StringDebeziumDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">startupOptions</span><span class="token punctuation">(</span><span class="token class-name">StartupOptions</span><span class="token punctuation">.</span><span class="token function">initial</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stringDataStreamSource <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>build<span class="token punctuation">)</span><span class="token punctuation">;</span>
        stringDataStreamSource<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="2、Table-API"><a href="#2、Table-API" class="headerlink" title="2、Table API"></a>2、Table API</h4><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

import org.apache.flink.table.api.Table;

import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import org.apache.flink.types.Row;


&#x2F;**
 * @author mt
 * @create 2021-09-30 11:07
 *&#x2F;
public class Test &#123;
    public static void main(String[] args) throws Exception &#123;
        StreamExecutionEnvironment env &#x3D; StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        StreamTableEnvironment tableEnvironment &#x3D; StreamTableEnvironment.create(env);
        tableEnvironment.executeSql(
                &quot;CREATE TABLE sensor_test ( &quot; +
                        &quot; id STRING NOT NULL, &quot; +
                        &quot; ts BIGINT, &quot; +
                        &quot; vc INTEGER &quot; +
                        &quot;) WITH ( &quot; +
                        &quot; &#39;connector&#39; &#x3D; &#39;mysql-cdc&#39;, &quot; +
                        &quot; &#39;hostname&#39; &#x3D; &#39;hadoop102&#39;, &quot; +
                        &quot; &#39;port&#39; &#x3D; &#39;3306&#39;, &quot; +
                        &quot; &#39;username&#39; &#x3D; &#39;root&#39;, &quot; +
                        &quot; &#39;password&#39; &#x3D; &#39;root&#39;, &quot; +
                        &quot; &#39;database-name&#39; &#x3D; &#39;test&#39;, &quot; +
                        &quot; &#39;table-name&#39; &#x3D; &#39;sensor&#39; &quot; +
                        &quot;) &quot;);
        Table table &#x3D; tableEnvironment.sqlQuery(&quot;select * from sensor_test&quot;);
        tableEnvironment.toRetractStream(table, Row.class).print();
        env.execute();
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>目前最新版本Flink CDC支持的连接器<br><img src="/uploads/20220223/FlinkCDC%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E6%BA%90.png" alt="DataX运行原理"></p>
<h1 id="四、MaxWell配置文件"><a href="#四、MaxWell配置文件" class="headerlink" title="四、MaxWell配置文件"></a>四、MaxWell配置文件</h1><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># tl;dr config
log_level&#x3D;info
producer&#x3D;kafka
kafka.bootstrap.servers&#x3D;hadoop102:9092,hadoop103:9092,hadoop104:9092
kafka_topic&#x3D;ggggg_cccc_aaaa
# mysql login info
host&#x3D;hadoop102
user&#x3D;maxwell
password&#x3D;123456

#同步历史数据时需要配置如下的
client_id&#x3D;maxwell_2
#     *** general ***
# choose where to produce data to. stdout|file|kafka|kinesis|pubsub|sqs|rabbitmq|redis
#producer&#x3D;kafka

# set the log level.  note that you can configure things further in log4j2.xml
#log_level&#x3D;DEBUG # [DEBUG, INFO, WARN, ERROR]

# if set, maxwell will look up the scoped environment variables, strip off the prefix and inject the configs
#env_config_prefix&#x3D;MAXWELL_

#     *** mysql ***
# mysql host to connect to
#host&#x3D;hostname
# mysql port to connect to
#port&#x3D;3306
# mysql user to connect as.  This user must have REPLICATION SLAVE permissions,
# as well as full access to the &#96;maxwell&#96; (or schema_database) database
#user&#x3D;maxwell
# mysql password
#password&#x3D;maxwell



# options to pass into the jdbc connection, given as opt&#x3D;val&amp;opt2&#x3D;val2
#jdbc_options&#x3D;opt1&#x3D;100&amp;opt2&#x3D;hello
# name of the mysql database where maxwell keeps its own state
#schema_database&#x3D;maxwell
# whether to use GTID or not for positioning
#gtid_mode&#x3D;true
# SSL&#x2F;TLS options
# To use VERIFY_CA or VERIFY_IDENTITY, you must set the trust store with Java opts:
#   -Djavax.net.ssl.trustStore&#x3D;&lt;truststore&gt; -Djavax.net.ssl.trustStorePassword&#x3D;&lt;password&gt;
# or import the MySQL cert into the global Java cacerts.
# MODE must be one of DISABLED, PREFERRED, REQUIRED, VERIFY_CA, or VERIFY_IDENTITY
#

# turns on ssl for the maxwell-store connection, other connections inherit this setting unless specified
#ssl&#x3D;DISABLED
# for binlog-connector
#replication_ssl&#x3D;DISABLED
# for the schema-capture connection, if used
#schema_ssl&#x3D;DISABLED


# maxwell can optionally replicate from a different server than where it stores
# schema and binlog position info.  Specify that different server here:

#replication_host&#x3D;other
#replication_user&#x3D;username
#replication_password&#x3D;password
#replication_port&#x3D;3306


# This may be useful when using MaxScale&#39;s binlog mirroring host.
# Specifies that Maxwell should capture schema from a different server than
# it replicates from:
#schema_host&#x3D;other
#schema_user&#x3D;username
#schema_password&#x3D;password
#schema_port&#x3D;3306
#       *** output format ***
# records include binlog position (default false)
#output_binlog_position&#x3D;true
# records include a gtid string (default false)
#output_gtid_position&#x3D;true
# records include fields with null values (default true).  If this is false,
# fields where the value is null will be omitted entirely from output.
#output_nulls&#x3D;true
# records include server_id (default false)
#output_server_id&#x3D;true
# records include thread_id (default false)
#output_thread_id&#x3D;true
# records include schema_id (default false)
#output_schema_id&#x3D;true
# records include row query, binlog option &quot;binlog_rows_query_log_events&quot; must be enabled&quot; (default false)
#output_row_query&#x3D;true
# DML records include list of values that make up a row&#39;s primary key (default false)
#output_primary_keys&#x3D;true
# DML records include list of columns that make up a row&#39;s primary key (default false)
#output_primary_key_columns&#x3D;true
# records include commit and xid (default true)
#output_commit_info&#x3D;true
# This controls whether maxwell will output JSON information containing
# DDL (ALTER&#x2F;CREATE TABLE&#x2F;ETC) infromation. (default: false)
# See also: ddl_kafka_topic
#output_ddl&#x3D;true
#       *** kafka ***
# list of kafka brokers
#kafka.bootstrap.servers&#x3D;hosta:9092,hostb:9092
# kafka topic to write to
# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
# in the latter case &#39;database&#39; and &#39;table&#39; will be replaced with the values for the row being processed
#kafka_topic&#x3D;maxwell
# alternative kafka topic to write DDL (alter&#x2F;create&#x2F;drop) to.  Defaults to kafka_topic
#ddl_kafka_topic&#x3D;maxwell_ddl
# hash function to use.  &quot;default&quot; is just the JVM&#39;s &#39;hashCode&#39; function.
#kafka_partition_hash&#x3D;default # [default, murmur3]


# how maxwell writes its kafka key.
#
# &#39;hash&#39; looks like:
# &#123;&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;tickets&quot;,&quot;pk.id&quot;:10001&#125;
#
# &#39;array&#39; looks like:
# [&quot;test&quot;,&quot;tickets&quot;,[&#123;&quot;id&quot;:10001&#125;]]
#
# default: &quot;hash&quot;
#kafka_key_format&#x3D;hash # [hash, array]


# extra kafka options.  Anything prefixed &quot;kafka.&quot; will get
# passed directly into the kafka-producer&#39;s config.

# a few defaults.
# These are 0.11-specific. They may or may not work with other versions.
kafka.compression.type&#x3D;snappy
kafka.retries&#x3D;0
kafka.acks&#x3D;1
#kafka.batch.size&#x3D;16384


# kafka+SSL example
# kafka.security.protocol&#x3D;SSL
# kafka.ssl.truststore.location&#x3D;&#x2F;var&#x2F;private&#x2F;ssl&#x2F;kafka.client.truststore.jks
# kafka.ssl.truststore.password&#x3D;test1234
# kafka.ssl.keystore.location&#x3D;&#x2F;var&#x2F;private&#x2F;ssl&#x2F;kafka.client.keystore.jks
# kafka.ssl.keystore.password&#x3D;test1234
# kafka.ssl.key.password&#x3D;test1234#

# controls a heuristic check that maxwell may use to detect messages that
# we never heard back from.  The heuristic check looks for &quot;stuck&quot; messages, and
# will timeout maxwell after this many milliseconds.
#
# See https:&#x2F;&#x2F;github.com&#x2F;zendesk&#x2F;maxwell&#x2F;blob&#x2F;master&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;zendesk&#x2F;maxwell&#x2F;producer&#x2F;InflightMessageList.java
# if you really want to get into it.
#producer_ack_timeout&#x3D;120000 # default 0


#           *** partitioning ***

# What part of the data do we partition by?
#producer_partition_by&#x3D;database # [database, table, primary_key, transaction_id, column]


# specify what fields to partition by when using producer_partition_by&#x3D;column
# column separated list.
#producer_partition_columns&#x3D;id,foo,bar


# when using producer_partition_by&#x3D;column, partition by this when
# the specified column(s) don&#39;t exist.
#producer_partition_by_fallback&#x3D;database


#            *** kinesis ***

#kinesis_stream&#x3D;maxwell
# AWS places a 256 unicode character limit on the max key length of a record
# http:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;kinesis&#x2F;latest&#x2F;APIReference&#x2F;API_PutRecord.html
#
# Setting this option to true enables hashing the key with the md5 algorithm
# before we send it to kinesis so all the keys work within the key size limit.
# Values: true, false
# Default: false
#kinesis_md5_keys&#x3D;true
#            *** sqs ***
#sqs_queue_uri&#x3D;aws_sqs_queue_uri
# The sqs producer will need aws credentials configured in the default
# root folder and file format. Please check below link on how to do it.
# http:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;sdk-for-java&#x2F;v1&#x2F;developer-guide&#x2F;setup-credentials.html
#            *** pub&#x2F;sub ***
#pubsub_project_id&#x3D;maxwell
#pubsub_topic&#x3D;maxwell
#ddl_pubsub_topic&#x3D;maxwell_ddl

#            *** rabbit-mq ***
#rabbitmq_host&#x3D;rabbitmq_hostname
#rabbitmq_port&#x3D;5672
#rabbitmq_user&#x3D;guest
#rabbitmq_pass&#x3D;guest
#rabbitmq_virtual_host&#x3D;&#x2F;
#rabbitmq_exchange&#x3D;maxwell
#rabbitmq_exchange_type&#x3D;fanout
#rabbitmq_exchange_durable&#x3D;false
#rabbitmq_exchange_autodelete&#x3D;false
#rabbitmq_routing_key_template&#x3D;%db%.%table%
#rabbitmq_message_persistent&#x3D;false
#rabbitmq_declare_exchange&#x3D;true

#           *** redis ***
#redis_host&#x3D;redis_host
#redis_port&#x3D;6379
#redis_auth&#x3D;redis_auth
#redis_database&#x3D;0
# name of pubsub&#x2F;list&#x2F;whatever key to publish to
#redis_key&#x3D;maxwell

# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
#redis_pub_channel&#x3D;maxwell
# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
#redis_list_key&#x3D;maxwell
# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
# Valid values for redis_type &#x3D; pubsub|lpush. Defaults to pubsub
#redis_type&#x3D;pubsub

#           *** custom producer ***
# the fully qualified class name for custom ProducerFactory
# see the following link for more details.
# http:&#x2F;&#x2F;maxwells-daemon.io&#x2F;producers&#x2F;#custom-producer
#custom_producer.factory&#x3D;
# custom producer properties can be configured using the custom_producer.* property namespace
#custom_producer.custom_prop&#x3D;foo

#          *** filtering ***
# filter rows out of Maxwell&#39;s output.  Command separated list of filter-rules, evaluated in sequence.
# A filter rule is:
#  &lt;type&gt; &quot;:&quot; &lt;db&gt; &quot;.&quot; &lt;tbl&gt; [ &quot;.&quot; &lt;col&gt; &quot;&#x3D;&quot; &lt;col_val&gt; ]
#  type    ::&#x3D; [ &quot;include&quot; | &quot;exclude&quot; | &quot;blacklist&quot; ]
#  db      ::&#x3D; [ &quot;&#x2F;regexp&#x2F;&quot; | &quot;string&quot; | &quot;&#96;string&#96;&quot; | &quot;*&quot; ]
#  tbl     ::&#x3D; [ &quot;&#x2F;regexp&#x2F;&quot; | &quot;string&quot; | &quot;&#96;string&#96;&quot; | &quot;*&quot; ]
#  col_val ::&#x3D; &quot;column_name&quot;
#  tbl     ::&#x3D; [ &quot;&#x2F;regexp&#x2F;&quot; | &quot;string&quot; | &quot;&#96;string&#96;&quot; | &quot;*&quot; ]
#
# See http:&#x2F;&#x2F;maxwells-daemon.io&#x2F;filtering for more details
#
#filter&#x3D; exclude: *.*, include: foo.*, include: bar.baz, include: foo.bar.col_eg &#x3D; &quot;value_to_match&quot;


# javascript filter
# maxwell can run a bit of javascript for each row if you need very custom filtering&#x2F;data munging.
# See http:&#x2F;&#x2F;maxwells-daemon.io&#x2F;filtering&#x2F;#javascript_filters for more details
#
#javascript&#x3D;&#x2F;path&#x2F;to&#x2F;javascript_filter_file
#       *** encryption ***
# Encryption mode. Possible values are none, data, and all. (default none)
#encrypt&#x3D;none

# Specify the secret key to be used
#secret_key&#x3D;RandomInitVector
#       *** monitoring ***
# Maxwell collects metrics via dropwizard. These can be exposed through the
# base logging mechanism (slf4j), JMX, HTTP or pushed to Datadog.
# Options: [jmx, slf4j, http, datadog]
# Supplying multiple is allowed.
#metrics_type&#x3D;jmx,slf4j
# The prefix maxwell will apply to all metrics
#metrics_prefix&#x3D;MaxwellMetrics # default MaxwellMetrics
# Enable (dropwizard) JVM metrics, default false
#metrics_jvm&#x3D;true
# When metrics_type includes slf4j this is the frequency metrics are emitted to the log, in seconds
#metrics_slf4j_interval&#x3D;60
# When metrics_type includes http or diagnostic is enabled, this is the port the server will bind to.
#http_port&#x3D;8080
# When metrics_type includes http or diagnostic is enabled, this is the http path prefix, default &#x2F;.
#http_path_prefix&#x3D;&#x2F;some&#x2F;path&#x2F;
# ** The following are Datadog specific. **
# When metrics_type includes datadog this is the way metrics will be reported.
# Options: [udp, http]
# Supplying multiple is not allowed.
#metrics_datadog_type&#x3D;udp
# datadog tags that should be supplied
#metrics_datadog_tags&#x3D;tag1:value1,tag2:value2

# The frequency metrics are pushed to datadog, in seconds
#metrics_datadog_interval&#x3D;60
# required if metrics_datadog_type &#x3D; http
#metrics_datadog_apikey&#x3D;API_KEY
# required if metrics_datadog_type &#x3D; udp
#metrics_datadog_host&#x3D;localhost # default localhost
#metrics_datadog_port&#x3D;8125 # default 8125
# Maxwell exposes http diagnostic endpoint to check below in parallel:
# 1. binlog replication lag
# 2. producer (currently kafka) lag
# To enable Maxwell diagnostic
#http_diagnostic&#x3D;true # default false
# Diagnostic check timeout in milliseconds, required if diagnostic &#x3D; true
#http_diagnostic_timeout&#x3D;10000 # default 10000
#    *** misc ***
# maxwell&#39;s bootstrapping functionality has a couple of modes.
#
# In &quot;async&quot; mode, maxwell will output the replication stream while it
# simultaneously outputs the database to the topic.  Note that it won&#39;t
# output replication data for any tables it is currently bootstrapping -- this
# data will be buffered and output after the bootstrap is complete.
#
# In &quot;sync&quot; mode, maxwell stops the replication stream while it
# outputs bootstrap data.
#
# async mode keeps ops live while bootstrapping, but carries the possibility of
# data loss (due to buffering transactions).  sync mode is safer but you
# have to stop replication.
#bootstrapper&#x3D;async [sync, async, none]
# output filename when using the &quot;file&quot; producer
#output_file&#x3D;&#x2F;path&#x2F;to&#x2F;file<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="五、Cancal配置文件"><a href="#五、Cancal配置文件" class="headerlink" title="五、Cancal配置文件"></a>五、Cancal配置文件</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#################################################
## mysql serverId , v1.0.26+ will autoGen
# canal.instance.mysql.slaveId&#x3D;0
# enable gtid use true&#x2F;false
canal.instance.gtidon&#x3D;false
# position info
canal.instance.master.address&#x3D;hadoop102:3306
canal.instance.master.journal.name&#x3D;
canal.instance.master.position&#x3D;
canal.instance.master.timestamp&#x3D;
canal.instance.master.gtid&#x3D;
# rds oss binlog
canal.instance.rds.accesskey&#x3D;
canal.instance.rds.secretkey&#x3D;
canal.instance.rds.instanceId&#x3D;
# table meta tsdb info
canal.instance.tsdb.enable&#x3D;true
#canal.instance.tsdb.url&#x3D;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;canal_tsdb
#canal.instance.tsdb.dbUsername&#x3D;canal
#canal.instance.tsdb.dbPassword&#x3D;canal
#canal.instance.standby.address &#x3D;
#canal.instance.standby.journal.name &#x3D;
#canal.instance.standby.position &#x3D;
#canal.instance.standby.timestamp &#x3D;
#canal.instance.standby.gtid&#x3D;


# username&#x2F;password
canal.instance.dbUsername&#x3D;canal
canal.instance.dbPassword&#x3D;canal
canal.instance.connectionCharset &#x3D; UTF-8
# enable druid Decrypt database password
canal.instance.enableDruid&#x3D;false
#canal.instance.pwdPublicKey&#x3D;MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5&#x2F;zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2&#x2F;JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ&#x3D;&#x3D;


# table regex
canal.instance.filter.regex&#x3D;.*\\..*
# table black regex
canal.instance.filter.black.regex&#x3D;
# table field filter(format: schema1.tableName1:field1&#x2F;field2,schema2.tableName2:field1&#x2F;field2)
#canal.instance.filter.field&#x3D;test1.t_product:id&#x2F;subject&#x2F;keywords,test2.t_company:id&#x2F;name&#x2F;contact&#x2F;ch
# table field black filter(format: schema1.tableName1:field1&#x2F;field2,schema2.tableName2:field1&#x2F;field2)
#canal.instance.filter.black.field&#x3D;test1.t_product:subject&#x2F;product_image,test2.t_company:id&#x2F;name&#x2F;contact&#x2F;ch


# mq config  
canal.mq.topic&#x3D;kkkk_ffff_aaaaa
# dynamic topic route by schema or table regex
#canal.mq.dynamicTopic&#x3D;mytest1.user,mytest2\\..*,.*\\..*
canal.mq.partition&#x3D;0
# hash partition config
#canal.mq.partitionsNum&#x3D;3
#canal.mq.partitionHash&#x3D;test.table:id^name,.*\\..*
#################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      <categories>
        <category>Flink</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（一）</title>
    <url>/2021/01/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink简介</li>
<li>Flink如何提交任务到Yarn</li>
<li>Flink任务案例</li>
</ul>
<a id="more"></a>

<h2 id="Flink简介"><a href="#Flink简介" class="headerlink" title="Flink简介"></a>Flink简介</h2><h3 id="Flink是什么？"><a href="#Flink是什么？" class="headerlink" title="Flink是什么？"></a>Flink是什么？</h3><p>Apache Flink 是一个<code>框架</code>和<code>分布式处理引擎</code>，用于在<code>无边界</code>和<code>有边界</code>数据流上进行<code>有状态</code>的计算。Flink 能在所有常见集群环境中运行，并能以<code>内存速度</code>和<code>任意规模</code>进行计算。  </p>
<blockquote>
<p>Flink是一个流计算驱动的引擎，核心是Streaming。但是，它可以基于Streaming的内核，实现流批一体更全能的架构</p>
</blockquote>
<ul>
<li>无边界数据流<br>有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果的完整性  <blockquote>
<p>纯实时数据，不存在等数据累计一定程度再处理的情况，数据生产后，立刻消费</p>
</blockquote>
</li>
<li>有边界数据流<br>有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理  <blockquote>
<p>批处理数据，需要数累积一定量以后再行处理</p>
</blockquote>
</li>
<li>有状态的计算  </li>
</ul>
<p>Flink有如下优点：</p>
<ul>
<li>真正的流处理</li>
<li>多种窗口</li>
<li>自带状态(state) </li>
<li>精确一次传输语义</li>
<li>时间管理</li>
</ul>
<h3 id="流式计算框架对比"><a href="#流式计算框架对比" class="headerlink" title="流式计算框架对比"></a>流式计算框架对比</h3><ul>
<li>模型：Storm和Flink是真正的一条一条处理数据；Spark Streaming其实是小批处理，一次处理一批数据（小批量）</li>
<li>API：Storm使用基础API进行开发，比如实现一个简单的sum求和操作；而Spark Streaming和Flink中都提供封装后的高阶函数，可以直接拿来使用</li>
<li>保证次数：在数据处理方面，Storm可以实现至少处理一次，但不能保证仅处理一次，这样就会导致数据重复处理问题，所以针对计数类的需求，可能会产生一些误差；Spark Streaming和Flink通过事务可以保证对数据实现仅一次的处理</li>
<li>容错机制：Storm通过ACK机制实现数据的容错机制，而SparkStreaming和Flink可以通过CheckPoint机制实现容错机制</li>
<li>状态管理：Storm中没有实现状态管理，Spark Streaming实现了基于DStream的状态管理，Flink实现了基于操作的状态管理</li>
<li>延时：表示数据处理的延时情况，因此Storm和Flink接收到一条数据就处理一条数据，其数据处理的延时性是很低的；而Spark Streaming是小型批处理，数据处理的延时性相对会偏高</li>
<li>吞吐量：Storm的吞吐量其实也不低，只是相对于其他几个框架而言较低；而Spark Streaming和Flink的吞吐量是比较高的</li>
</ul>
<blockquote>
<p>Strom是第一代实时处理框架，基于流处理，数据吞吐量和延迟上效果不理想，只支持at least once和at most once，不能保证精确一次性，在数据准确性上存在不足<br>Spark Streaming作为第二代实时处理框架，基于mini-batch思想，每次处理一小批数据，一小批数据包含多个事件，以接近事实处理效果，概况性来说是微批次、准实时<br>Spark Streaming说到底，还是微批处理，并不是真正的实时处理，所以它的吞吐量很好，但是实时性没有Flink好，而且Spark官方也说了，最好不要把batch设置的太小<br>第三代实时处理框架，支持有界和无界数据流上做有状态计算，以时间为单位，支持exactly once，数据的准确性得到提高，相比Strom，吞吐量更高，延迟更低，相比SparkStreaming，Flink是真正意义上的实时计算，所需计算资源更少</p>
</blockquote>
<h3 id="工作中如何选择实时计算框架"><a href="#工作中如何选择实时计算框架" class="headerlink" title="工作中如何选择实时计算框架"></a>工作中如何选择实时计算框架</h3><ul>
<li>需要关注流数据是否需要进行状态管理，如果是，那么只能SparkStreaming和Flink中选择一个。</li>
<li>需要考虑项目对At-least-once（至少一次）或者Exactly-once（仅一次）消息投递模式是否有特殊要求，如果必须要保证仅一次，也不能选择Storm。</li>
<li>对于小型独立的项目，并且需要低延迟的场景，建议使用Storm，这样比较简单。</li>
<li>如果你的项目已经使用了Spark，并且秒级别的实时处理可以满足需求的话，建议使用Spark Streaming</li>
<li>要求消息投递语义为Exactly-once；数据量较大，要求高吞吐低延迟；需要进行状态管理或窗口统计，这时建议使用Flink。</li>
</ul>
<h3 id="Flink下载安装"><a href="#Flink下载安装" class="headerlink" title="Flink下载安装"></a>Flink下载安装</h3><p>到官网上下载Flink安装包，并解压<br>这里只是要把Flink当成一个客户端，提交任务到Yarn上，所以不必配置Flink集群，只需要配置一下<code>HADOOP_CLASSPATH</code></p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export HADOOP_CLASSPATH&#x3D;&#96;hadoop classpath&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>最后，配置Flink的环境变量</p>
<h2 id="Flink如何提交任务到Yarn"><a href="#Flink如何提交任务到Yarn" class="headerlink" title="Flink如何提交任务到Yarn"></a>Flink如何提交任务到Yarn</h2><p>在官网点击<code>Documentation</code> -&gt; <code>Latest stable release</code> -&gt; <code>Deploy Flink</code> -&gt; <code> Clusters and Deployments</code> -&gt; <code>YARN</code><br><img src="/uploads/20210122/flink-yarn-deploy.png" alt="flink-yarn-deploy"><br>Flink提交任务到Yarn有3种方式：  </p>
<ul>
<li><p>Application Mode<br>Application Mode将在YARN上启动一个Flink集群，其中Application jar的main()方法将在YARN中的JobManager上执行。<br>应用程序完成后，Flink集群将立即关闭。可以使用<code>yarn application -kill &lt;ApplicationId&gt;</code>或取消Flink作业来手动停止集群</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run-application -t yarn-application .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/20210124/Application-Mode%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%88%B0Yarn.png" alt="Application-Mode提交任务到Yarn"></p>
<blockquote>
<p>这种就是直接把Flink任务注册到Yarn上，就跟Spark、Hive任务提交Yarn任务一样。</p>
</blockquote>
<p> 通过这种方式提交到Yarn上，可以与它交互以执行诸如取消、获取保存点之类的操作</p>
 <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 列举集群上的app
flink list -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY
# 取消正在执行的job
flink cancel -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY &lt;jobId&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 需要注意的是，任务取消后，Flink集群也会停止<br> 为了挖掘Application Mode的潜力，可以考虑使用<code>yarn.provided.lib.dirs</code>配置选项，将应用程序jar上传到集群中所有节点都可以访问的位置，例如HDFS上</p>
 <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">   flink run-application -t yarn-application \
-Dyarn.provided.lib.dirs&#x3D;&quot;hdfs:&#x2F;&#x2F;myhdfs&#x2F;my-remote-flink-dist-dir&quot; \
hdfs:&#x2F;&#x2F;myhdfs&#x2F;jars&#x2F;my-application.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 由于所需的Flink jar和应用程序jar将由指定的远程位置接收，而不是由客户机发送到集群，因此上面的内容将允许作业提交变得格外轻量级。</p>
<blockquote>
<p>任务启动的时候，客户端不需要再把jar上传到每个jobManager了，跑完了也不会再删除。</p>
</blockquote>
</li>
<li><p>Per-Job Cluster Mode<br>Per-Job Cluster Mode将在Yarn上启动Flink集群，然后在本地运行提供的应用程序jar，最后将JobGraph提交给YARN上的JobManager<br>如果传递–detached参数，客户端将在集群接受提交后停止。<br>提交的任务一旦停止，Flink集群也将停止</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -t yarn-per-job --detached .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>同样，通过这种方式提交的任务，也可以与它交互以执行诸如取消、获取保存点之类的操作</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 列举集群上的app
flink list -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY
# 取消正在执行的job
flink cancel -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY &lt;jobId&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>Session Mode</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 如果成功，在yarn上是可以看到application_id的
yarn-session.sh --detached
# 成功后会打印：
#JobManager Web Interface: http:&#x2F;&#x2F;golden-02:39461
#2021-01-22 17:29:31,594 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                
# [] - The Flink YARN session cluster has been started in detached mode. 
# In order to stop Flink gracefully, use the following command:
#$ echo &quot;stop&quot; | yarn-session.sh -id application_1611306127593_0001
#If this should not be possible, then you can also kill Flink via YARN&#39;s web interface or via:
#$ yarn application -kill application_1611306127593_0001
#Note that killing Flink might not clean up all job artifacts and temporary files.
# 执行一个测试job
flink run .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar
# 杀掉Flink的任务可以使用cancel
flink cancel $&#123;flink_app_id&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/20210122/flink%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%88%B0yarn%E4%B8%8A%E5%88%97%E8%A1%A8.png" alt="flink提交任务到yarn上列表"><br><img src="/uploads/20210122/yarn%E4%B8%8A%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%AF%A6%E6%83%85.png" alt="yarn上的任务详情"><br>可以看到，yarn的任务监控页面只能找到一个application_id，但是Flink的任务列表有2个</p>
<p> <code>Session Mode</code>有两种操作模式：</p>
<ul>
<li><p>attached mode (default):<code>yarn-session.sh</code>将任务提交到Yarn上以后，不会关闭，会继续与集群通信，跟踪集群任务的状态，如果任务失败，会在客户端显示错误，如果客户端被停止，它也会向集群发送关闭任务的信号                         </p>
</li>
<li><p>detached mode (-d or –detached):<code>yarn-session.sh</code>将任务提交到Yarn上以后，会直接返回，要是想停止集群中的任务，就需要调用另外一个客户端，或者使用Yarn的工具(<code>yarn application -kill</code>)<br><code>Session Mode</code>将在<code>/tmp/.YARN properties-&lt;username&gt;</code>中创建一个隐藏的<code>YARN properties</code>文件，提交作业时，命令行界面将提取该文件进行集群发现<br>提交Flink作业时，也可以在命令行界面中手动指定目标session。举个例子：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -t yarn-session -Dyarn.application.id&#x3D;application_XXXX_YY .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>这里测试了一下，只能是注册session的application_id</p>
</blockquote>
<p>可以使用<code>yarn-session.sh -id application_XXXX_YY</code>重新连接session<br>除了通过配置conf/flink-conf.yaml，还可以在提交session时将使用-Dkey=value参数配置传递给yarn-session.sh客户端。</p>
<blockquote>
<p>Flink提交任务到yarn上，需要提前启动一个application，然后后面的flink任务会共享这个application的资源？  </p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="Flink任务案例"><a href="#Flink任务案例" class="headerlink" title="Flink任务案例"></a>Flink任务案例</h2><p>公司是Flink是以java为开发语言的，这里学习也使用java</p>
<h3 id="配置Flink的Maven开发环境"><a href="#配置Flink的Maven开发环境" class="headerlink" title="配置Flink的Maven开发环境"></a>配置Flink的Maven开发环境</h3><p>到Flink的官网，点击<code>Getting Started</code> -&gt; <code>Application Development</code> -&gt; <code>DataStream API</code> -&gt; <code>Project Configuration</code><br><img src="/uploads/20210122/flink-maven-1.png" alt="flink-maven-1"><br><img src="/uploads/20210122/flink-maven-2.png" alt="flink-maven-2"><br>也可以在Flink的下载页面寻找maven的配置项<br>得到maven配置:</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-streaming-java_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="实现简单功能：Flink消费Kafka数据后再写入Kafka"><a href="#实现简单功能：Flink消费Kafka数据后再写入Kafka" class="headerlink" title="实现简单功能：Flink消费Kafka数据后再写入Kafka"></a>实现简单功能：Flink消费Kafka数据后再写入Kafka</h3><p>下面直接上代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaProducer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka2Kafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Kafka参数</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> kafkaData <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>
                inputTopic<span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                properties<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaData<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Sink</span>
        <span class="token class-name">Properties</span> prop <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        prop<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        prop<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"zookeeper.connect"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:2181"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        prop<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"flink-write"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        kafkaData<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>
                <span class="token string">"golden-02:9092"</span><span class="token punctuation">,</span>
                <span class="token string">"flink-write"</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">"flink-connectors-kafka"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// execute</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka consumer to kafka "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="IDEA本地调试Flink程序报错"><a href="#IDEA本地调试Flink程序报错" class="headerlink" title="IDEA本地调试Flink程序报错"></a>IDEA本地调试Flink程序报错</h3><p>如果直接在IDEA上执行，会报如下错误：<br><img src="/uploads/20210125/IDEA%E7%9B%B4%E6%8E%A5%E8%BF%90%E8%A1%8CFlink%E4%BB%BB%E5%8A%A1.png" alt="IDEA直接运行Flink任务"><br>本质上，这是因为没有配置java的jre环境，可以使用两种办法解决：</p>
<ul>
<li><p>导入<code>Flink</code> lib文件夹下的jar包<br>导入流程：<br>依次点击 <code>File</code> -&gt; <code>Project Structure</code> -&gt; <code>Module</code> -&gt; <code>Dependencies</code><br><img src="/uploads/20210125/IDEA%E9%85%8D%E7%BD%AEFlink-lib%E6%96%87%E4%BB%B6%E5%A4%B9.png" alt="IDEA配置Flink-lib文件夹"><br>配置完成后，右键<code>run</code>，控制台就能看到程序的运行结果了<br><img src="/uploads/20210125/IDEA%E6%89%A7%E8%A1%8CFlink%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="IDEA执行Flink程序执行结果"></p>
</li>
<li><p>通过配置java的jre环境解决：<br>配置方法：<br><img src="/uploads/20210125/IDEA%E9%85%8D%E7%BD%AEJRE.png" alt="IDEA配置JRE"><br>或者，配置JRE的环境变量</p>
</li>
</ul>
<p>通过命令行提交任务到yarn上执行：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -t yarn-per-job --class com.hzw.bigdata.flinkstudy.FlinkConsumerKafka2Kafka FlinkStudy-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>给<code>first</code>topic生产点数据：<br><img src="/uploads/20210125/Kafka%E5%8E%9F%E5%A7%8Btopic%E7%94%9F%E4%BA%A7%E6%95%B0%E6%8D%AE.png" alt="Kafka原始topic生产数据"><br>消费flink写入的另一个topic数据<br><img src="/uploads/20210125/%E6%B6%88%E8%B4%B9Flink%E5%86%99%E5%85%A5Kafka%E5%8F%A6%E4%B8%80%E4%B8%AAtopic%E6%95%B0%E6%8D%AE.png" alt="消费Flink写入Kafka另一个topic数据"></p>
<p>虽然利用<code>Per-Job Cluster Mode</code>方式提交到Yarn上执行成功了，但是使用<code>Application Mode</code>方式是报错的<br>报错信息如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot instantiate user function.
	at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:339) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.&lt;init&gt;(OperatorChain.java:143) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:509) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:565) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722) ~[FlinkStudy-1.0-SNAPSHOT-jar-with-dependencies.jar:?]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547) ~[FlinkStudy-1.0-SNAPSHOT-jar-with-dependencies.jar:?]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_201]
Caused by: java.lang.ClassCastException: cannot assign instance of org.apache.commons.collections.map.LinkedMap to field org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.pendingOffsetsToCommit of type org.apache.commons.collections.map.LinkedMap in instance of org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer
	at java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2287) ~[?:1.8.0_201]
	at java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1417) ~[?:1.8.0_201]
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2293) ~[?:1.8.0_201]
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211) ~[?:1.8.0_201]
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069) ~[?:1.8.0_201]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>报错原因：<br><code>LinkedMap cannot be cast to LinkedMap exceptions</code><br><code>LinkedMap class is being loaded from two different packages, and those are being assigned to each other.</code></li>
<li>解决办法：<br>在conf/flink-conf.yaml 添加如下内容<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">classloader.resolve-order: parent-first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

</li>
</ul>
<h3 id="实现简单功能：Flink消费Kafka数据并实现wordCount"><a href="#实现简单功能：Flink消费Kafka数据并实现wordCount" class="headerlink" title="实现简单功能：Flink消费Kafka数据并实现wordCount"></a>实现简单功能：Flink消费Kafka数据并实现wordCount</h3><p>这里遇到了问题</p>
<ul>
<li>直接消费kafka数据，不使用window函数，可以正常wordCount</li>
<li>直接copy网上的代码，使用<code>timeWindow(Time.seconds(5))</code>，kafka数据正常消费，但是没有正常计算并打印</li>
<li><code>window(EventTimeSessionWindows.withGap(Time.seconds(1L)))</code>kafka数据正常消费，但是没有正常计算并打印<br>代码如下：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">Types</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>assigners<span class="token punctuation">.</span></span><span class="token class-name">EventTimeSessionWindows</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>assigners<span class="token punctuation">.</span></span><span class="token class-name">TumblingProcessingTimeWindows</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Time</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Kafka参数</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> wordCount <span class="token operator">=</span> stream
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
                    <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> tokens <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\\s"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token comment">// 输出结果 (word, 1)</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> token <span class="token operator">:</span> tokens<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                        <span class="token keyword">if</span> <span class="token punctuation">(</span>token<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>INT<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>key <span class="token operator">-></span> key<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token comment">//.window(EventTimeSessionWindows.withGap(Time.seconds(1L)))  //无数据</span>
                <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingProcessingTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//有数据</span>
                <span class="token comment">//.timeWindow(Time.seconds(5))   //无数据</span>
                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>key <span class="token operator">-></span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>f0 <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> key<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        wordCount<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka streaming word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<img src="/uploads/20210125/Flink%E6%9C%89%E6%B6%88%E8%B4%B9%E6%97%A0%E8%BE%93%E5%87%BA.png" alt="Flink有消费无输出"><br><img src="/uploads/20210125/offset%E6%B6%88%E8%B4%B9%E6%83%85%E5%86%B5.png" alt="offset消费情况"></li>
</ul>
<h3 id="从checkpoint点重新消费kafka数据"><a href="#从checkpoint点重新消费kafka数据" class="headerlink" title="从checkpoint点重新消费kafka数据"></a>从checkpoint点重新消费kafka数据</h3><p>发现通过公司封装的Flink，虽然在配置任务的时候，选择了从某个检查点恢复，但是消费的kafka的offset还是从最新的位置开始，这里自己调研一下：</p>
<h3 id="Flink-kafka-consumer的消费模式设置"><a href="#Flink-kafka-consumer的消费模式设置" class="headerlink" title="Flink kafka consumer的消费模式设置"></a>Flink kafka consumer的消费模式设置</h3><ul>
<li>setStartFromEarliest：从队头开始，最早的记录，内部的Consumer提交到Kafka/zk中的偏移量将被忽略。</li>
<li>setStartFromLatest：从队尾开始，最新的记录，内部的Consumer提交到Kafka/zk中的偏移量将被忽略。</li>
<li>setStartFromGroupOffsets()：默认值，从当前消费组记录的偏移量开始，接着上次的偏移量消费，以Consumer提交到Kafka/zk中的偏移量最为起始位置开始消费，group.id设置在consumer的properties里;如果没找到记录的偏移量，则使用consumer的properties的auto.offset.reset设置的策略。</li>
<li>setStartFromSpecificOffsets(Map&lt;TopicPartition, Long&gt;的参数)：从指定的具体位置开始消费</li>
<li>setStartFromTimestamp(long)：从指定的时间戳开始消费，对于每个分区，时间戳大于或等于指定时间戳的记录将用作起始位置。如果一个分区的最新记录早于时间戳，那么只需要从最新记录中读取该分区。在此模式下，Kafka/zk中提交的偏移量将被忽略。<blockquote>
<p>从队头、指定offset、指定时间戳位置开始消费，会把历史数据当成批数据处理，不会有一条处理一条。</p>
</blockquote>
</li>
</ul>
<p>验证代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">Types</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//这里设置一开始总是失败，原因是token.length() &lt; 6不满足，直接exit了</span>
        <span class="token comment">//但是这里有个问题，数据不应该是来一条消费一条吗？，最开始的几条数据，是满足token.length() &lt; 6的</span>
        <span class="token comment">//看这样的情况是，flatmap执行完以后，才会触发后面的函数</span>
        consumer<span class="token punctuation">.</span><span class="token function">setStartFromEarliest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//consumer.setStartFromTimestamp(1612246518000l);</span>
        <span class="token comment">//consumer.setStartFromLatest();</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> wordCount <span class="token operator">=</span> stream
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
                    <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> tokens <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"/s"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token comment">// 输出结果 (word, 1)</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> token <span class="token operator">:</span> tokens<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                        <span class="token comment">//这里的现象是：一直没有输出结果，突然exit(1)，直接走了else，也就是说，它会把历史数据消费完/消费一个批次，再执行后面的聚合</span>
                        <span class="token comment">//但是，这里不知道是会把历史数据消费完才执行后面的聚合，还是只要消费到一定程度就会执行聚合</span>
                        <span class="token comment">//如果一定要消费所有历史数据才聚合，那么可能以后对历史数据的消费需要慎重，因为一口气读取的历史数据如果太多，绝对会出问题</span>
                        <span class="token keyword">if</span> <span class="token punctuation">(</span>token<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> token<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">6</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span><span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>INT<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>key <span class="token operator">-></span> key<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token comment">//.window(TumblingProcessingTimeWindows.of(Time.seconds(1))) //有数据</span>
                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>key <span class="token operator">-></span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>f0 <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> key<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        wordCount<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka streaming word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Flink-Standalone集群模式部署"><a href="#Flink-Standalone集群模式部署" class="headerlink" title="Flink Standalone集群模式部署"></a>Flink Standalone集群模式部署</h3><p>Flink Standalone模式部署集群是最简单的一种部署方式，不依赖于其他的组件，另外还支持YARN/Mesos/Docker等模式下的部署<br>老规矩，配置flink前必须做下面的基础准备：</p>
<ol>
<li>JDK环境，1.8.x或者更高，Oracle JDK或者OpenJDK都可以，二进制包解压的方式安装要配置好JAVA_HOME</li>
<li>主机名和hosts配置文件集群内完全对应，准确配置. </li>
<li>集群之间保证通信正常，关闭防火墙或者提前设置好规则.</li>
<li>集群所有节点配置ssh免密，否则后续启动集群的时候还需要输入密码. </li>
<li>集群配置时间同步服务，ntp或者chrony服务，这个应该是大数据组件集群的标配<br>然后准备安装flink，flink的安装目录为了便于维护所有的安装位置都要一致</li>
</ol>
<p>编辑配置文件：conf/flink-conf.yaml</p>
<pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">jobmanager.rpc.address</span><span class="token punctuation">:</span> golden<span class="token punctuation">-</span><span class="token number">01</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>编辑master、worker文件</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## master文件
golden-01:8081
## worker文件
golden-01
golden-02                      
golden-03<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>三台节点都需要配置<br>然后启动<code>bin/start-cluster.sh</code>,启动以后发现，还是只在golden-01节点启动了taskmanager，找了很久才发现，golden-02和golden-03节点的bin下的启动脚本没有添加执行权限<br><img src="/uploads/202203/Standalone%E6%A8%A1%E5%BC%8F%E5%90%AF%E5%8A%A8%E4%B8%8D%E6%88%90%E5%8A%9F%E5%8E%9F%E5%9B%A0.png" alt="Standalone模式启动不成功原因"><br>这里给bin下的脚本添加可执行权限，集群启动成功</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[golden@golden-01 flink-1.13.6]$ bin&#x2F;start-cluster.sh 
Starting cluster.
Starting standalonesession daemon on host golden-01.
Starting taskexecutor daemon on host golden-01.
Starting taskexecutor daemon on host golden-02.
Starting taskexecutor daemon on host golden-03.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h3 id="Flink-sql-client交互式命令行"><a href="#Flink-sql-client交互式命令行" class="headerlink" title="Flink sql-client交互式命令行"></a>Flink sql-client交互式命令行</h3><p>一开始以为，sql-client方式，只支持standalone模式，后来才知道，它也支持yarn-session模式<br>可以有2中方式启动：</p>
<ul>
<li><p>standalone方式启动</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 首先启动standalone集群
cd &#x2F;opt&#x2F;modules&#x2F;flink-1.13.6 &amp;&amp; .&#x2F;bin&#x2F;start-cluster.sh
## 启动sql-client
.&#x2F;bin&#x2F;sql-client.sh embedded<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>embedded模式是默认的，不加也可以，不过，建议加上规范点</p>
</li>
<li><p>yarn-session方式启动<br>如果想要把任务提交给yarn，则需要启动一个yarn-session任务，yarn-session模式其实就是在yarn上生成一个standalone集群</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">.&#x2F;bin&#x2F;yarn-session.sh -s 4  -nm cool -d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>然后flink-sql客户端连接这个集群提交SQL任务</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">.&#x2F;bin&#x2F;sql-client.sh embedded -s yarn-session<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>因为yarn-session模式默认会在/tmp/目录下维护一个会话信息，此时启动客户端指定yarn-session他会自动寻找到当前的session会话然后提交任务<br>但是，提交到yarn上只能使用yarn-session模式，无法使用per-job的方式，感觉不太实用，一般也就是测试的时候用一下，生产上肯定不会用它的</p>
</li>
</ul>
<h3 id="在IDEA上运行Flink任务"><a href="#在IDEA上运行Flink任务" class="headerlink" title="在IDEA上运行Flink任务"></a>在IDEA上运行Flink任务</h3><p>在IDEA上运行Flink任务，在网上查到，需要把<code>flink-dist_xxx.jar</code>放到代码工程的的modules里，这里提供一个更方便的方式：<br>在pom文件里，添加如下内容：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.scope</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.scope</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>$&#123;flink.scope&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>需要注意的是，通过打包的方式运行的时候，需要把scope改成provided</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（三）</title>
    <url>/2021/02/07/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink状态管理</li>
<li>Flink Checkpoint机制</li>
<li>Flink精准一次探究</li>
</ul>
<a id="more"></a>
<h2 id="Flink状态管理"><a href="#Flink状态管理" class="headerlink" title="Flink状态管理"></a>Flink状态管理</h2><p>看到一篇文章，讲述的Flink的状态管理特别详细，忍不住想记录一下，哈哈<br>具体可以参考：<br><a href="https://blog.csdn.net/qq_42596142/article/details/104097745?ops_request_misc=&request_id=&biz_id=102&utm_source=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1">Flink状态管理：Keyed State和Operator List State深度解析</a></p>
<h3 id="为什么要管理状态"><a href="#为什么要管理状态" class="headerlink" title="为什么要管理状态"></a>为什么要管理状态</h3><p>有状态的计算是流处理框架要实现的重要功能，因为稍复杂的流处理场景都需要记录状态，然后在新流入数据的基础上不断更新状态。下面的几个场景都需要使用流处理的状态功能：</p>
<ul>
<li>数据流中的数据有重复，我们想对重复数据去重，需要记录哪些数据已经流入过应用，当新数据流入时，根据已流入过的数据来判断去重。</li>
<li>检查输入流是否符合某个特定的模式，需要将之前流入的元素以状态的形式缓存下来。比如，判断一个温度传感器数据流中的温度是否在持续上升。</li>
<li>对一个时间窗口内的数据进行聚合分析，分析一个小时内某项指标的75分位或99分位的数值。</li>
<li>在线机器学习场景下，需要根据新流入数据不断更新机器学习的模型参数。</li>
</ul>
<p>我们知道，Flink的一个算子有多个子任务，每个子任务分布在不同实例上，我们可以把状态理解为某个算子子任务在其当前实例上的一个变量，变量记录了数据流的历史信息。当新数据流入时，我们可以结合历史信息来进行计算。实际上，Flink的状态是由算子的子任务来创建和管理的。一个状态更新和获取的流程如下图所示，一个算子子任务接收输入流，获取对应的状态，根据新的计算结果更新状态。一个简单的例子是对一个时间窗口内输入流的某个整数字段求和，那么当算子子任务接收到新元素时，会获取已经存储在状态中的数值，然后将当前输入加到状态上，并将状态数据更新。</p>
<p><img src="/uploads/20210208/Flink%E4%BB%BB%E5%8A%A1.png" alt="Flink任务"></p>
<p>获取和更新状态的逻辑其实并不复杂，但流处理框架还需要解决以下几类问题：</p>
<ul>
<li>数据的产出要保证实时性，延迟不能太高。</li>
<li>需要保证数据不丢不重，恰好计算一次，尤其是当状态数据非常大或者应用出现故障需要恢复时，要保证状态的计算不出任何错误。</li>
<li>一般流处理任务都是7*24小时运行的，程序的可靠性非常高。<br>基于上述要求，我们不能将状态直接交由内存管理，因为内存的容量是有限制的，当状态数据稍微大一些时，就会出现内存不够的问题。假如我们使用一个持久化的备份系统，不断将内存中的状态备份起来，当流处理作业出现故障时，需要考虑如何从备份中恢复。而且，大数据应用一般是横向分布在多个节点上，流处理框架需要保证横向的伸缩扩展性。可见，状态的管理并不那么容易。</li>
</ul>
<p>作为一个计算框架，Flink提供了有状态的计算，封装了一些底层的实现，比如状态的高效存储、Checkpoint和Savepoint持久化备份机制、计算资源扩缩容等问题。因为Flink接管了这些问题，开发者只需调用Flink API，这样可以更加专注于业务逻辑。</p>
<h3 id="Flink的几种状态类型"><a href="#Flink的几种状态类型" class="headerlink" title="Flink的几种状态类型"></a>Flink的几种状态类型</h3><h4 id="Managed-State和Raw-State"><a href="#Managed-State和Raw-State" class="headerlink" title="Managed State和Raw State"></a>Managed State和Raw State</h4><p>Flink有两种基本类型的状态：托管状态（Managed State）和原生状态（Raw State）。从名称中也能读出两者的区别：Managed State是由Flink管理的，Flink帮忙存储、恢复和优化，Raw State是开发者自己管理的，需要自己序列化。</p>
<table>
<thead>
<tr>
<th></th>
<th>Managed State</th>
<th>Raw State</th>
</tr>
</thead>
<tbody><tr>
<td>状态管理方式</td>
<td>Flink Runtime托管，自动存储、自动恢复、自动伸缩</td>
<td>用户自己管理</td>
</tr>
<tr>
<td>状态数据结构</td>
<td>Flink提供的常用数据结构，如ListState、MapState等</td>
<td>字节数组：byte[]</td>
</tr>
<tr>
<td>使用场景</td>
<td>绝大多数Flink算子</td>
<td>用户自定义算子</td>
</tr>
</tbody></table>
<p>两者的具体区别有：</p>
<ul>
<li>从状态管理的方式上来说，Managed State由Flink Runtime托管，状态是自动存储、自动恢复的，Flink在存储管理和持久化上做了一些优化。当我们横向伸缩，或者说我们修改Flink应用的并行度时，状态也能自动重新分布到多个并行实例上。Raw State是用户自定义的状态。</li>
<li>从状态的数据结构上来说，Managed State支持了一系列常见的数据结构，如ValueState、ListState、MapState等。Raw State只支持字节，任何上层数据结构需要序列化为字节数组。使用时，需要用户自己序列化，以非常底层的字节数组形式存储，Flink并不知道存储的是什么样的数据结构。</li>
<li>从具体使用场景来说，绝大多数的算子都可以通过继承Rich函数类或其他提供好的接口类，在里面使用Managed State。Raw State是在已有算子和Managed State不够用时，用户自定义算子时使用。</li>
</ul>
<p>下文将重点介绍Managed State。</p>
<h4 id="Keyed-State和Operator-State"><a href="#Keyed-State和Operator-State" class="headerlink" title="Keyed State和Operator State"></a>Keyed State和Operator State</h4><p>对Managed State继续细分，它又有两种类型：Keyed State和Operator State。这里先简单对比两种状态，后续还将展示具体的使用方法。</p>
<p>Keyed State是KeyedStream上的状态。假如输入流按照id为Key进行了keyBy分组，形成一个KeyedStream，数据流中所有id为1的数据共享一个状态，可以访问和更新这个状态，以此类推，每个Key对应一个自己的状态。下图展示了Keyed State，因为一个算子子任务可以处理一到多个Key，算子子任务1处理了两种Key，两种Key分别对应自己的状态。<br><img src="/uploads/20210208/Flink%E7%8A%B6%E6%80%81%E8%AE%A1%E7%AE%97KeyedState.png" alt="Flink状态计算KeyedState"><br>Operator State可以用在所有算子上，每个算子子任务或者说每个算子实例共享一个状态，流入这个算子子任务的数据可以访问和更新这个状态。下图展示了Operator State，算子子任务1上的所有数据可以共享第一个Operator State，以此类推，每个算子子任务上的数据共享自己的状态。<br><img src="/uploads/20210208/Flink%E7%8A%B6%E6%80%81%E8%AE%A1%E7%AE%97OperatorState.png" alt="Flink状态计算OperatorState"><br>无论是Keyed State还是Operator State，Flink的状态都是基于本地的，即每个算子子任务维护着这个算子子任务对应的状态存储，算子子任务之间的状态不能相互访问。</p>
<p>在之前各算子的介绍中曾提到，为了自定义Flink的算子，我们可以重写Rich Function接口类，比如RichFlatMapFunction。使用Keyed State时，我们也可以通过重写Rich Function接口类，在里面创建和访问状态。对于Operator State，我们还需进一步实现CheckpointedFunction接口。</p>
<table>
<thead>
<tr>
<th></th>
<th>Keyed State</th>
<th>Operator State</th>
</tr>
</thead>
<tbody><tr>
<td>适用算子类型</td>
<td>只适用于KeyedStream上的算子</td>
<td>可以用于所有算子</td>
</tr>
<tr>
<td>状态分配</td>
<td>每个Key对应一个状态</td>
<td>一个算子子任务对应一个状态</td>
</tr>
<tr>
<td>创建和访问方式</td>
<td>重写Rich Function，通过里面的RuntimeContext访问</td>
<td>实现CheckpointedFunction等接口</td>
</tr>
<tr>
<td>横向扩展</td>
<td>状态随着Key自动在多个算子子任务上迁移</td>
<td>有多种状态重新分配的方式</td>
</tr>
<tr>
<td>支持的数据结构</td>
<td>ValueState、ListState、MapState等</td>
<td>ListState、BroadcastState等</td>
</tr>
</tbody></table>
<p>上表总结了Keyed State和Operator State的区别。</p>
<h4 id="横向扩展问题"><a href="#横向扩展问题" class="headerlink" title="横向扩展问题"></a>横向扩展问题</h4><p>状态的横向扩展问题主要是指修改Flink应用的并行度，确切的说，每个算子的并行实例数或算子子任务数发生了变化，应用需要关停或启动一些算子子任务，某份在原来某个算子子任务上的状态数据需要平滑更新到新的算子子任务上。其实，Flink的Checkpoint就是一个非常好的在各算子间迁移状态数据的机制。算子的本地状态将数据生成快照（snapshot），保存到分布式存储（如HDFS）上。横向伸缩后，算子子任务个数变化，子任务重启，相应的状态从分布式存储上重建（restore）。<br><img src="/uploads/20210208/%E6%A8%AA%E5%90%91%E6%89%A9%E5%B1%95.png" alt="横向扩展"><br>对于Keyed State和Operator State这两种状态，他们的横向伸缩机制不太相同。由于每个Keyed State总是与某个Key相对应，当横向伸缩时，Key总会被自动分配到某个算子子任务上，因此Keyed State会自动在多个并行子任务之间迁移。对于一个非KeyedStream，流入算子子任务的数据可能会随着并行度的改变而改变。如上图所示，假如一个应用的并行度原来为2，那么数据会被分成两份并行地流入两个算子子任务，每个算子子任务有一份自己的状态，当并行度改为3时，数据流被拆成3支，或者并行度改为1，数据流合并为1支，此时状态的存储也相应发生了变化。对于横向伸缩问题，Operator State有两种状态分配方式：一种是均匀分配，另一种是将所有状态合并，再分发给每个实例上。</p>
<h4 id="Keyed-State的使用方法"><a href="#Keyed-State的使用方法" class="headerlink" title="Keyed State的使用方法"></a>Keyed State的使用方法</h4><p>对于Keyed State，Flink提供了几种现成的数据结构供我们使用，包括ValueState、ListState等，他们的继承关系如下图所示。首先，State主要有三种实现，分别为ValueState、MapState和AppendingState，AppendingState又可以细分为ListState、ReducingState和AggregatingState。<br><img src="/uploads/20210208/%E7%BB%A7%E6%89%BF%E5%85%B3%E7%B3%BB.png" alt="继承关系"></p>
<p>这几个状态的具体区别在于：</p>
<ul>
<li>ValueState[T]是单一变量的状态，T是某种具体的数据类型，比如Double、String，或我们自己定义的复杂数据结构。我们可以使用value()方法获取状态，使用update(value: T)更新状态。</li>
<li>MapState[K, V]存储一个Key-Value map，其功能与Java的Map几乎相同。get(key: K)可以获取某个key下的value，put(key: K, value: V)可以对某个key设置value，contains(key: K)判断某个key是否存在，remove(key: K)删除某个key以及对应的value，entries(): java.lang.Iterable[java.util.Map.Entry[K, V]]返回MapState中所有的元素，iterator(): java.util.Iterator[java.util.Map.Entry[K, V]]返回一个迭代器。需要注意的是，MapState中的key和Keyed State的key不是同一个key。</li>
<li>ListState[T]存储了一个由T类型数据组成的列表。我们可以使用add(value: T)或addAll(values: java.util.List[T])向状态中添加元素，使用get(): java.lang.Iterable[T]获取整个列表，使用update(values: java.util.List[T])来更新列表，新的列表将替换旧的列表。</li>
<li>ReducingState[T]和AggregatingState[IN, OUT]与ListState[T]同属于MergingState[T]。与ListState[T]不同的是，ReducingState[T]只有一个元素，而不是一个列表。它的原理是新元素通过add(value: T)加入后，与已有的状态元素使用ReduceFunction合并为一个元素，并更新到状态里。AggregatingState[IN, OUT]与ReducingState[T]类似，也只有一个元素，只不过AggregatingState[IN, OUT]的输入和输出类型可以不一样。ReducingState[T]和AggregatingState[IN, OUT]与窗口上进行ReduceFunction和AggregateFunction很像，都是将新元素与已有元素做聚合。</li>
</ul>
<p>注意，Flink的核心代码目前使用Java实现的，而Java的很多类型与Scala的类型不太相同，比如List和Map。这里不再详细解释Java和Scala的数据类型的异同，但是开发者在使用Scala调用这些接口，比如状态的接口，需要注意将Java的类型转为Scala的类型。对于List和Map的转换，只需要需要引用import scala.collection.JavaConversions._，并在必要的地方添加后缀asScala或asJava来进行转换。此外，Scala和Java的空对象使用习惯不太相同，Java一般使用null表示空，Scala一般使用None。</p>
<h2 id="Flink-Checkpoint机制"><a href="#Flink-Checkpoint机制" class="headerlink" title="Flink Checkpoint机制"></a>Flink Checkpoint机制</h2><h3 id="如何理解flink中state-状态"><a href="#如何理解flink中state-状态" class="headerlink" title="如何理解flink中state(状态)"></a>如何理解flink中state(状态)</h3><p>state泛指：flink中有状态函数和运算符在各个元素(element)/事件(event)的处理过程中存储的数据（注意：状态数据可以修改和查询，可以自己维护，根据自己的业务场景，保存历史数据或者中间结果到状态(state)中）；<br>使用状态计算的例子：</p>
<ul>
<li>当应用程序搜索某些事件模式时，状态将存储到目前为止遇到的事件序列。</li>
<li>在每分钟/小时/天聚合事件时，状态保存待处理的聚合。</li>
<li>当在数据点流上训练机器学习模型时，状态保持模型参数的当前版本。</li>
<li>当需要管理历史数据时，状态允许有效访问过去发生的事件。</li>
</ul>
<p>无状态计算指的是数据进入Flink后经过算子时只需要对当前数据进行处理就能得到想要的结果；<br>有状态计算就是需要和历史的一些状态或进行相关操作，才能计算出正确的结果；</p>
<h3 id="flink中checkpoint执行流程"><a href="#flink中checkpoint执行流程" class="headerlink" title="flink中checkpoint执行流程"></a>flink中checkpoint执行流程</h3><ul>
<li>checkpoint机制是Flink可靠性的基石，可以保证Flink集群在某个算子因为某些原因(如 异常退出)出现故障时，能够将整个应用流图的状态恢复到故障之前的某一状态，保 证应用流图状态的一致性。Flink的checkpoint机制原理来自“Chandy-Lamport algorithm”算法。 (分布式快照算)</li>
<li>每个需要checkpoint的应用在启动时，Flink的JobManager为其创建一个 CheckpointCoordinator，CheckpointCoordinator全权负责本应用的快照制作。</li>
<li>CheckpointCoordinator周期性的向该流应用的所有source算子发送barrier。</li>
<li>当某个source算子收到一个barrier时，便暂停数据处理过程，然后将自己的当前状 态制作成快照，并保存到指定的持久化存储中，最后向CheckpointCoordinator报告 自己快照制作情况，同时向自身所有下游算子广播该barrier，恢复数据处理</li>
<li>下游算子收到barrier之后，会暂停自己的数据处理过程，然后将自身的相关状态制作成快照，并保存到指定的持久化存储中，最后向CheckpointCoordinator报告自身 快照情况，同时向自身所有下游算子广播该barrier，恢复数据处理。</li>
<li>每个算子按照步骤3不断制作快照并向下游广播，直到最后barrier传递到sink算子，快照制作完成。</li>
<li>当CheckpointCoordinator收到所有算子的报告之后，认为该周期的快照制作成功; 否则，如果在规定的时间内没有收到所有算子的报告，则认为本周期快照制作失败 ;</li>
</ul>
<p>整个过程如下：</p>
<ol>
<li>JobManager端的 CheckPointCoordinator向 所有SourceTask发送CheckPointTrigger，Source Task会在数据流中安插CheckPoint barrier</li>
<li>当task收到所有的barrier后，向自己的下游继续传递barrier，然后自身执行快照，并将自己的状态异步写入到持久化存储中。增量CheckPoint只是把最新的一部分更新写入到 外部存储；为了下游尽快做CheckPoint，所以会先发送barrier到下游，自身再同步进行快照</li>
<li>当task完成备份后，会将备份数据的地址（state handle）通知给JobManager的CheckPointCoordinator；如果CheckPoint的持续时长超过 了CheckPoint设定的超时时间，CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator就会认为本次CheckPoint失败，会把这次CheckPoint产生的所有 状态数据全部删除。</li>
<li>最后 CheckPoint Coordinator 会把整个 StateHandle 封装成 completed CheckPoint Meta，写入到hdfs。</li>
</ol>
<h3 id="什么是barrier对齐？"><a href="#什么是barrier对齐？" class="headerlink" title="什么是barrier对齐？"></a>什么是barrier对齐？</h3><p><img src="/uploads/20211109/barrier%E5%AF%B9%E9%BD%90.png" alt="barrier对齐"></p>
<ul>
<li>一旦Operator从输入流接收到CheckPoint barrier n，它就不能处理来自该流的任何数据记录，直到它从其他所有输入接收到barrier n为止。否则，它会混合属于快照n的记录和属于快照n + 1的记录；</li>
<li>接收到barrier n的流暂时被搁置。从这些流接收的记录不会被处理，而是放入输入缓冲区。</li>
<li>上图中第2个图，虽然数字流对应的barrier已经到达了，但是barrier之后的1、2、3这些数据只能放到buffer中，等待字母流的barrier到达；</li>
<li>一旦最后所有输入流都接收到barrier n，Operator就会把缓冲区中pending 的输出数据发出去，然后把CheckPoint barrier n接着往下游发送</li>
<li>这里还会对自身进行快照；之后，Operator将继续处理来自所有输入流的记录，在处理来自流的记录之前先处理来自输入缓冲区的记录。</li>
</ul>
<h3 id="什么是barrier不对齐？"><a href="#什么是barrier不对齐？" class="headerlink" title="什么是barrier不对齐？"></a>什么是barrier不对齐？</h3><p>checkpoint 是要等到所有的barrier全部都到才算完成</p>
<ul>
<li>上述图2中，当还有其他输入流的barrier还没有到达时，会把已到达的barrier之后的数据1、2、3搁置在缓冲区，等待其他流的barrier到达后才能处理</li>
<li>barrier不对齐就是指当还有其他流的barrier还没到达时，为了不影响性能，也不用理会，直接处理barrier之后的数据。等到所有流的barrier的都到达后，就可以对该Operator做CheckPoint了；</li>
</ul>
<p>为什么要进行barrier对齐？不对齐到底行不行？<br>Exactly Once时必须barrier对齐，如果barrier不对齐就变成了At Least Once；</p>
<h3 id="checkpoint中保存的是什么信息"><a href="#checkpoint中保存的是什么信息" class="headerlink" title="checkpoint中保存的是什么信息"></a>checkpoint中保存的是什么信息</h3><p>快照里面到底保存着什么信息呢？以flink消费kafka数据wordcount为例：<br>我们从Kafka读取到一条条的日志，从日志中解析出app_id，然后将统计的结果放到内存中一个Map集合，app_id做为key，对应的pv做为value，每次只需要将相应app_id 的pv值+1后put到Map中即可；<br>kafka topic：test；<br>flink运算流程如下：<br>kakfa的testtopic的分区 —&gt; Flink的source task —&gt; flink的pv计算task</p>
<h3 id="如何自动获取最新的checkpoint？"><a href="#如何自动获取最新的checkpoint？" class="headerlink" title="如何自动获取最新的checkpoint？"></a>如何自动获取最新的checkpoint？</h3><p>现在只知道可以通过-s手动把最新的chk传入到执行程序里，那么如何在java里自动带入最新的chk呢？<br>在代码中设置如下参数：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">String</span> lastCheckpintPath <span class="token operator">=</span> <span class="token class-name">CheckpointUtil</span><span class="token punctuation">.</span><span class="token function">getCkPath</span><span class="token punctuation">(</span>checkpointPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
conf<span class="token punctuation">.</span><span class="token function">setString</span><span class="token punctuation">(</span><span class="token string">"execution.savepoint.path"</span><span class="token punctuation">,</span> lastCheckpintPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">getCkPath</span><span class="token punctuation">(</span><span class="token class-name">String</span> relativePath<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token class-name">CheckpointUtil</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getResourceAsStream</span><span class="token punctuation">(</span><span class="token string">"/core-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token class-name">CheckpointUtil</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getResourceAsStream</span><span class="token punctuation">(</span><span class="token string">"/hdfs-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">FileStatus</span><span class="token punctuation">[</span><span class="token punctuation">]</span> listStatus <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>relativePath<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">FileStatus</span><span class="token punctuation">></span></span> latestFiles <span class="token operator">=</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span>listStatus<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sorted</span><span class="token punctuation">(</span><span class="token class-name">Comparator</span><span class="token punctuation">.</span><span class="token function">comparing</span><span class="token punctuation">(</span><span class="token class-name">FileStatus</span><span class="token operator">::</span><span class="token function">getModificationTime</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">reversed</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">limit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">toList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">CollectionUtils</span><span class="token punctuation">.</span><span class="token function">isNotEmpty</span><span class="token punctuation">(</span>latestFiles<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">FileStatus</span> fileStatus <span class="token operator">=</span> latestFiles<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">FileStatus</span><span class="token punctuation">[</span><span class="token punctuation">]</span> fileStatuses <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">FileStatus</span> status <span class="token operator">:</span> fileStatuses<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">startsWith</span><span class="token punctuation">(</span><span class="token string">"chk"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> ex<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>err<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>ex<span class="token punctuation">.</span><span class="token function">getMessage</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Flink-Exactly-once语义探究"><a href="#Flink-Exactly-once语义探究" class="headerlink" title="Flink Exactly-once语义探究"></a>Flink Exactly-once语义探究</h2><p>Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义;<br>Flink不是默认就有EOS的，flink 官方推荐所有需要保证EOS的sink 逻辑都继承TwoPhaseCommitSinkFunction抽象类。它具体定义如下四个抽象方法。需要我们去在子类中实现。</p>
<pre><code class="java">protected abstract TXN beginTransaction() throws Exception;
protected abstract void preCommit(TXN transaction) throws Exception;
protected abstract void commit(TXN transaction);
protected abstract void abort(TXN transaction);</code></pre>
<p>beginTransaction(): 开始一个事务，返回事务信息的句柄。<br>preCommit :预提交（即提交请求）阶段的逻辑<br>commit():正式提交阶段的逻辑<br>abort():取消事务</p>
<h3 id="Flink实现端到端的精准一次"><a href="#Flink实现端到端的精准一次" class="headerlink" title="Flink实现端到端的精准一次"></a>Flink实现端到端的精准一次</h3><p>端到端精确一次: flink是通过两步提交的方式实现,内部和外部存储系统间的精确一次语义，即容错发生时每条输入消息依旧只会影响最终结果一次,需满足如下三点:<br>source: 支持数据可重放,即当容错发生后,支持读取上个state标记后的数据,如kafka offset<br>link内部:通设置精确一次的checkpoint保障了内部计算在容错时候的精确一次语义<br>sink:必须支持事物或者幂等操作(继承TwoPhaseCommitSinkFunction抽象类)<br>使用kafka的sink已经自动实现了，但是，自己写的sink，需要自己继承TwoPhaseCommitSinkFunction抽象类</p>
<h3 id="flink的二阶段提交"><a href="#flink的二阶段提交" class="headerlink" title="flink的二阶段提交"></a>flink的二阶段提交</h3><p>两阶段提交（two-phase commit, 2PC）是最基础的分布式一致性协议，应用广泛<br>2PC 在分布式系统中，为了让每个节点能够感知其他所有节点的事务执行情况，需要我们引入一个中心节点的凡是统一所有节点的执行逻辑和进度。这个中心节点叫做协调者（coordinator），而其中向中心节点汇报或者被中心节点调度的其他节点叫做参与者。</p>
<h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><p><strong>请求阶段</strong><br>1、协调者向所有参与者发送准备请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应。<br>2、参与者执行事务中的包含操作，并记录undo日志（用于回滚）和redo日志（用于重放），但是不真正提交。<br>3、参与者向协调者返回事务才做的执行结果，执行陈工返回yes,否则返回no.<br><strong>提交阶段（分成成功和失败两种情况）</strong><br>若所有的参与者都返回yes,说明事务可以提交。<br>1、协调者向所有参与者发送commit请求。<br>2、参与者收到commit 请求后，将事务真正的提交上去，并释放占用的事务资源，并向协调者返回ack。<br>3、协调者收到所有参与者ack消息，事务成功完成。<br><strong>事务回滚</strong><br>若有参与者返回no或者超时未返回，说明事务终端，需要回滚。<br>1、协调者向所有参与者发送rollback请求。<br>2、参与者收到rollback请求后，根据undo日志回滚到事务执行前的状态，释放占用的事务资源，并向协调者返回ack。<br>3、协调者收到所有参与者的ack消息，事务回滚完成。</p>
<h4 id="2PC-的优缺点"><a href="#2PC-的优缺点" class="headerlink" title="2PC 的优缺点"></a>2PC 的优缺点</h4><p><strong>优点</strong><br>2PC的优点在于原理非常简单，容易理解及实现。<br><strong>缺点</strong><br>缺点主要有3个，列举如下：<br>（1）协调者存在单点问题。如果协调者挂了，整个2PC逻辑就彻底不能运行。<br>（2）、执行过程是完全同步的。各参与者在等待其他参与者响应的过程中都处于阻塞状态，大并发下有性能问题。<br>（3）、仍然存在不一致风险。如果由于网络异常等意外导致只有部分参与者收到了commit请求，就会造成部分参与者提交了事务而其他参与者未提交的情况。</p>
<p>具体可以参考<a href="https://www.cnblogs.com/zhipeng-wang/p/14082806.html">flink的二阶段提交</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink使用案例（一）</title>
    <url>/2021/03/30/Flink%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>实时订单模型实现</li>
</ul>
<a id="more"></a>
<h2 id="实时订单模型实现"><a href="#实时订单模型实现" class="headerlink" title="实时订单模型实现"></a>实时订单模型实现</h2><p>公司最近要重构订单模型，需求是，把订单模型从离线完全转为实时，但是，需要解决如下几点问题：</p>
<ul>
<li>底层的订单表分为3张表，最终的模型是把3个表关联成一张表</li>
<li>底层三个表的数据不是同时产生的，时间跨度有大有小，导致时间窗口不好控制</li>
<li>订单状态随时间变化，导致数据肯定会跨天，甚至有的订单状态变成完成状态需要30天以上  </li>
<li>某个时间点，可能只会有一个表的数据更新，就会导致在处理这条数据的时候，肯定关联不上另外两个表</li>
</ul>
<p>为了解决如上问题，有如下几个思路解决：</p>
<ul>
<li>使用Flink的状态计算</li>
<li>把订单的3个表先缓存下来，每条数据来之后，先去缓存重获取另外两个表的数据</li>
</ul>
<p>考虑到，订单的生命周期太长，一个订单从产生到结束，时间跨度大部分在2周之内，但是在大促期间，有的甚至能跨好几个月，这时候用状态计算来保留订单的状态就有些不恰当了。<br>所以最终考虑使用Hbase作为缓存组件，先将3个订单表缓存到Hbase中</p>
<h3 id="数据源样例："><a href="#数据源样例：" class="headerlink" title="数据源样例："></a>数据源样例：</h3><p>数据源分为t_bdeal(fbdeal_id),t_deal(fdeal_id),t_trade(ftrade_id)表，其中，t_deal中含有fbdeal_id，t_trade表中含有fbdeal_id和fdeal_id<br>数据关系如下图：<br><img src="/uploads/20210330/%E6%95%B0%E6%8D%AE%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="数据关系图"></p>
<p>所以设置<code>Hbase</code> 3个表的<code>rowkey</code>分别是每个表的主键，并在t_bdeal表中添加${fdeal_id}_${ftrade_id}的集合<br>数据样例如下：<br>bdeal缓存数据样例如下：<br><img src="/uploads/20210330/bdeal%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B.png" alt="bdeal缓存数据样例"><br>deal缓存数据样例如下：<br><img src="/uploads/20210330/deal%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B.png" alt="bdeal缓存数据样例"><br>trade缓存数据样例如下：<br><img src="/uploads/20210330/trade%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B.png" alt="bdeal缓存数据样例"></p>
<h3 id="设计方案流程图如下："><a href="#设计方案流程图如下：" class="headerlink" title="设计方案流程图如下："></a>设计方案流程图如下：</h3><p><img src="/uploads/20210330/%E5%AE%9E%E6%97%B6%E8%AE%A2%E5%8D%95%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88.png" alt="实时订单模型设计方案"></p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>这里只贴关键部分的代码。<br>数据流都在<code>transform</code>中实现，这里只贴<code>transform</code>的代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>executor</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span></span>JSON<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span></span><span class="token class-name">JSONArray</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span></span><span class="token class-name">JSONObject</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>google<span class="token punctuation">.</span>common<span class="token punctuation">.</span>collect<span class="token punctuation">.</span></span><span class="token class-name">Maps</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>common<span class="token punctuation">.</span>base<span class="token punctuation">.</span></span><span class="token class-name">AbstractStreamExcutor</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>common<span class="token punctuation">.</span>base<span class="token punctuation">.</span></span><span class="token class-name">AbstractStreamSink</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>common<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ResourcesUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>constant<span class="token punctuation">.</span></span><span class="token class-name">UserTagConstant</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>sink<span class="token punctuation">.</span></span><span class="token class-name">OmsOrderBdealSink</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">DateUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">HBaseUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FilterFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">MapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">RichFlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple3</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">SingleOutputStreamOperator</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">StringUtils</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Serializable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>text<span class="token punctuation">.</span></span><span class="token class-name">ParseException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Map</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>regex<span class="token punctuation">.</span></span><span class="token class-name">Pattern</span><span class="token punctuation">;</span>

<span class="token comment">/**
 * Author:   gujc
 * Date:     2021/03/03 15:38
 * Description:
 * rowkey设计：
 * bdeal: Fbdeal_id
 * deal: Fdeal_id
 * trade:Ftrade_id
 * 1、Hbase的bdeal表里存deal_id和trade_id的集合（deal_id_set,trade_id_set）
 * 2、之后trade表和bdeal表数据更新，如果是新增，那么也会更新bdeal表数据
 * 3、可能需要在窗口里对数据根据update_time排序，取最新的数据
 * 4、需要考虑一下，如果两个流数据同时过来，应该先更新哪个的问题
 * 5、如果数据更新方式是delete，需要过滤掉吗？
 *
 *
 * 重要未做：
 *      订单表的预分区，你可以找杜鹏这边了解一下采集系统的做法
 *      需要考虑在查询hbase的同时，另外一个并发在更新同一条记录，这里暂时无解，可能需要用到锁
 *      3个表的每条记录都会更新一次kudu，
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">GdmFactOmsOrdersExecutor</span> <span class="token keyword">extends</span> <span class="token class-name">AbstractStreamExcutor</span> <span class="token keyword">implements</span> <span class="token class-name">Serializable</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">/**
     * OMS订单表
     */</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> T_DEAL <span class="token operator">=</span> <span class="token string">"t_deal"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> T_BDEAL <span class="token operator">=</span> <span class="token string">"t_bdeal"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> T_TRADE <span class="token operator">=</span> <span class="token string">"t_trade"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> BDEAL_MATCHES <span class="token operator">=</span> <span class="token string">"t_bdeal_[0-9]+$"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> DEAL_MATCHES <span class="token operator">=</span> <span class="token string">"t_deal_[0-9]+$"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> TRADE_MATCHES <span class="token operator">=</span> <span class="token string">"t_trade_[0-9]+$"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> HBASE_TABLE_TRADE <span class="token operator">=</span> <span class="token string">"hb_app_onedata_oms_orders_t_trade_da"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> HBASE_TABLE_DEAL <span class="token operator">=</span> <span class="token string">"hb_app_onedata_oms_orders_t_deal_da"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> HBASE_TABLE_BDEAL <span class="token operator">=</span> <span class="token string">"hb_app_onedata_oms_orders_t_bdeal_da"</span><span class="token punctuation">;</span>



    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">AbstractStreamSink</span> <span class="token function">getFlinkSink</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">OmsOrderBdealSink</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> <span class="token function">transform</span><span class="token punctuation">(</span><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> dataStream<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> singleStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">String</span> value<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">JSONObject</span> jsonObject <span class="token operator">=</span> JSON<span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> data <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> table <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"table"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> type <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>table<span class="token punctuation">,</span> data<span class="token punctuation">,</span>type<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FilterFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span><span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> value<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span> optType <span class="token operator">=</span> value<span class="token punctuation">.</span>f2<span class="token punctuation">.</span><span class="token function">toLowerCase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> value<span class="token punctuation">.</span>f1 <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>value<span class="token punctuation">.</span>f1<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token string">"delete"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>optType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>

                <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">,</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> jsonObjects <span class="token operator">=</span> JSON<span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>f1<span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> tableName <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>BDEAL_MATCHES<span class="token punctuation">,</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    tableName <span class="token operator">=</span> <span class="token class-name">UserTagConstant</span><span class="token punctuation">.</span>T_BDEAL<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>DEAL_MATCHES<span class="token punctuation">,</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    tableName <span class="token operator">=</span> <span class="token class-name">UserTagConstant</span><span class="token punctuation">.</span>T_DEAL<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>TRADE_MATCHES<span class="token punctuation">,</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    tableName <span class="token operator">=</span> <span class="token class-name">UserTagConstant</span><span class="token punctuation">.</span>T_TRADE<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span><span class="token class-name">StringUtils</span><span class="token punctuation">.</span><span class="token function">isNullOrWhitespaceOnly</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">JSONObject</span> jsonObject <span class="token operator">:</span> jsonObjects<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>tableName<span class="token punctuation">.</span><span class="token function">toLowerCase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>jsonObject<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">RichFlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">private</span> <span class="token class-name">HBaseUtil</span> hBaseUtil<span class="token punctuation">;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span><span class="token punctuation">;</span>
                hBaseUtil <span class="token operator">=</span> <span class="token class-name">HBaseUtil</span><span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token class-name">ResourcesUtil</span><span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token string">"conf"</span><span class="token punctuation">,</span> <span class="token string">"zookeeper"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>

            <span class="token keyword">private</span> <span class="token class-name">JSONArray</span> <span class="token function">mergeProp</span><span class="token punctuation">(</span><span class="token class-name">JSONArray</span> jsonArray<span class="token punctuation">,</span> <span class="token class-name">String</span> prop<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>jsonArray <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    jsonArray <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JSONArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>jsonArray<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span>prop<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    jsonArray<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>prop<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">return</span> jsonArray<span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>


            <span class="token comment">/**
             * 更新Hbase表数据
             * 如果数据已经存在，判断update时间是否在历史数据之后，是则更新
             * 数据需要清洗后才能入Hbase
             * Hbase数据结构：
             * rowkey -> Map&lt;orderData,updateTime>
             * 如果是trade数据，那么还需要再更新一下bdeal数据，为了存储tradeArray
             * @param data
             * @return updateRes,更新true，未更新false
             */</span>
            <span class="token keyword">private</span> <span class="token class-name">Boolean</span> <span class="token function">updateHbase</span><span class="token punctuation">(</span><span class="token class-name">JSONObject</span> data<span class="token punctuation">,</span><span class="token class-name">String</span> tableName<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">ParseException</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span> updateTime <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> cacheTableName <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> rowkey <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> updateTimeCache <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> cacheMap <span class="token operator">=</span> <span class="token class-name">Maps</span><span class="token punctuation">.</span><span class="token function">newHashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span>T_DEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    updateTime <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Flast_update_time"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheTableName <span class="token operator">=</span> HBASE_TABLE_DEAL<span class="token punctuation">;</span>
                    rowkey <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_BDEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    updateTime <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_update_time"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheTableName <span class="token operator">=</span> HBASE_TABLE_BDEAL<span class="token punctuation">;</span>
                    rowkey <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_TRADE<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    updateTime <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_update_time"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheTableName <span class="token operator">=</span> HBASE_TABLE_TRADE<span class="token punctuation">;</span>
                    rowkey <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                    <span class="token comment">//更新fbdeal缓存的tradeArray</span>
                    <span class="token class-name">String</span> bdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token class-name">String</span> dealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> bdealDataMap <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>bdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token class-name">JSONArray</span> tradeArrayTemp <span class="token operator">=</span> <span class="token keyword">null</span> <span class="token operator">==</span> bdealDataMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span> <span class="token operator">?</span>
                            <span class="token keyword">new</span> <span class="token class-name">JSONArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealDataMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                    tradeArrayTemp <span class="token operator">=</span> <span class="token function">mergeProp</span><span class="token punctuation">(</span>tradeArrayTemp<span class="token punctuation">,</span>dealId <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> rowkey<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token keyword">if</span><span class="token punctuation">(</span>bdealDataMap<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token comment">//如果bdeal还没有数据,不加updateTime，为了让bdeal数据来了以后，能够更新数据</span>
                        bdealDataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">,</span>bdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        bdealDataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArrayTemp<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                        <span class="token comment">//如果bdeal已经有数据</span>
                        bdealDataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArrayTemp<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                    hBaseUtil<span class="token punctuation">.</span><span class="token function">insertOrderData</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span> bdealId<span class="token punctuation">,</span>bdealDataMap<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>

                updateTimeCache <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>cacheTableName<span class="token punctuation">,</span>rowkey<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"updateTime"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token comment">//如果更新时间大于缓存的时间，则更新数据，否则不更新</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">StringUtils</span><span class="token punctuation">.</span><span class="token function">isNullOrWhitespaceOnly</span><span class="token punctuation">(</span>updateTimeCache<span class="token punctuation">)</span> <span class="token operator">||</span>  <span class="token class-name">DateUtil</span><span class="token punctuation">.</span><span class="token function">dateDiffMilliSecond</span><span class="token punctuation">(</span>updateTimeCache<span class="token punctuation">,</span>updateTime<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        data<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArray<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"updateTime"</span><span class="token punctuation">,</span>updateTime<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    hBaseUtil<span class="token punctuation">.</span><span class="token function">insertOrderData</span><span class="token punctuation">(</span>cacheTableName<span class="token punctuation">,</span> rowkey<span class="token punctuation">,</span> cacheMap<span class="token punctuation">)</span><span class="token punctuation">;</span>

                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">DateUtil</span><span class="token punctuation">.</span><span class="token function">dateDiffMilliSecond</span><span class="token punctuation">(</span>updateTimeCache<span class="token punctuation">,</span>updateTime<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token comment">//如果这个数据已经在hbase里存在了，那么不更新hbase，但是需要处理后面的逻辑</span>
                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>


            <span class="token comment">/**
             * 主逻辑：
             * updateHbase返回值，更新了数据则继续，否则结束
             * 按照3个订单表的不同，处理逻辑不同：
             *
             * 1. 交易单执行逻辑（bdeal）
             * 1.1 根据tradeArray获取Hbase中trade的数据
             * 1.2 从trade表中获取Fdeal_id，以此获取Hbase中deal的数据
             * 1.3 拼接结果数据，并返回
             *
             * 2. 商品单数据更新处理逻辑(trade)
             * 2.1. 根据Fdeal_id获取Hbase中deal的数据
             * 2.2. 根据Fbdeal_id获取Hbase中bdeal中的数据,并拼接tradeArray，写入bdeal表
             * 2.3. 拼接结果数据，并返回
             *
             * 3. 包裹单数据更新处理逻辑(deal)
             * 3.1 根据Fbdeal_id获取Hbase中bdeal的数据,
             * 3.2 并根据bdeal表的tradeArray获取trade表数据
             * 3.3 拼接结果数据，并返回
             *
             * 需要解决一个问题:
             * 如果trade数据先进来，只会更新trade缓存。那么等到bdeal数据来之后，因为没有tradeArray，数据就没法处理了
             * 所以，在更新trade缓存的时候，也需要更新bdeal的缓存。
             * @param data
             */</span>
            <span class="token keyword">private</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> <span class="token function">handle</span><span class="token punctuation">(</span><span class="token class-name">JSONObject</span> data<span class="token punctuation">,</span><span class="token class-name">String</span> tableName<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">ParseException</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> resArr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">boolean</span> flag <span class="token operator">=</span> <span class="token function">updateHbase</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>tableName<span class="token punctuation">)</span><span class="token punctuation">;</span>

                <span class="token keyword">if</span><span class="token punctuation">(</span>flag<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">if</span><span class="token punctuation">(</span>T_BDEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> fbdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token comment">//根据Fbdeal_id获取Hbase中bdeal的数据('data',jsonObject)</span>
                        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> bdealCacheData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> bdealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> dealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> tradeOrderCacheData <span class="token operator">=</span>  <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            bdealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"=========== bdeal:bdeal:"</span> <span class="token operator">+</span> fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                        <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token comment">//根据trade_id获取trade和deal表信息</span>
                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                <span class="token class-name">String</span> dealId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> tradeId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> orderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> tradeExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                                <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                    tradeOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>orderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>orderDataStr <span class="token operator">+</span> <span class="token string">"=========== bdeal:trade:"</span> <span class="token operator">+</span> tradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span>

                                <span class="token class-name">String</span> dealOrderStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>dealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> dealExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>dealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                                <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                    dealOrderCacheData <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>dealOrderStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>dealOrderStr <span class="token operator">+</span> <span class="token string">"=========== bdeal:deal:"</span> <span class="token operator">+</span> dealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span>


                                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> dealOrderCacheData <span class="token operator">&amp;&amp;</span> <span class="token keyword">null</span> <span class="token operator">!=</span> tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    tradeOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">,</span>tradeExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    dealOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">,</span>dealExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> unionOrders <span class="token operator">=</span> <span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">.</span><span class="token function">mergeResult</span><span class="token punctuation">(</span>bdealOrderCacheData<span class="token punctuation">,</span>dealOrderCacheData<span class="token punctuation">,</span>tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    resArr<span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>unionOrders<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span>
                            <span class="token punctuation">&#125;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_DEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> fdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> fbdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token comment">//根据Fdeal_id获取Hbase中bdeal的数据('data',jsonObject)</span>
                        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> bdealCacheData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> bdealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> dealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> tradeOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            bdealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"=========== deal:bdeal:"</span> <span class="token operator">+</span> fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token comment">/**
                         * 这里是可以省略一次查询Hbase的。之后做优化。
                         */</span>
                        <span class="token class-name">String</span> dealOrderStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> dealExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            dealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>dealOrderStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>dealOrderStr <span class="token operator">+</span> <span class="token string">"=========== deal:deal"</span> <span class="token operator">+</span> fdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                        dealOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">,</span>dealExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> bdealOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                <span class="token comment">//根据trade_id获取trade和deal表信息</span>
                                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    <span class="token class-name">String</span> dealId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                    <span class="token class-name">String</span> tradeId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                    <span class="token class-name">String</span> tradeExtData <span class="token operator">=</span> <span class="token string">"&#123;&#125;"</span><span class="token punctuation">;</span>
                                    <span class="token keyword">if</span><span class="token punctuation">(</span>dealId<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                        <span class="token class-name">String</span> orderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        tradeExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                            tradeOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>orderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>orderDataStr <span class="token operator">+</span> <span class="token string">"=========== deal:trade:"</span> <span class="token operator">+</span> tradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        <span class="token punctuation">&#125;</span>
                                    <span class="token punctuation">&#125;</span>

                                    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                        tradeOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">,</span>tradeExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> unionOrders <span class="token operator">=</span> <span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">.</span><span class="token function">mergeResult</span><span class="token punctuation">(</span>bdealOrderCacheData<span class="token punctuation">,</span>dealOrderCacheData<span class="token punctuation">,</span>tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        resArr<span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>unionOrders<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token punctuation">&#125;</span>
                                <span class="token punctuation">&#125;</span>
                            <span class="token punctuation">&#125;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_TRADE<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> fdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> fbdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> ftradeId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> bdealCacheData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> bdealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span> <span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> dealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> tradeOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            bdealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"=========== trade:bdeal:"</span> <span class="token operator">+</span> fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>


                        <span class="token class-name">String</span> orderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> dealExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            dealOrderCacheData <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>orderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>orderDataStr <span class="token operator">+</span> <span class="token string">"=========== trade:deal:"</span> <span class="token operator">+</span> fdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>


                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> bdealOrderCacheData <span class="token operator">&amp;&amp;</span> <span class="token keyword">null</span> <span class="token operator">!=</span> dealOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            dealOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">,</span>dealExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">==</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                tradeArray <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JSONArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token punctuation">&#125;</span>
                            tradeArray <span class="token operator">=</span> <span class="token function">mergeProp</span><span class="token punctuation">(</span>tradeArray<span class="token punctuation">,</span>fdealId <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> ftradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            bdealCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArray<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//tradeArray</span>
                            hBaseUtil<span class="token punctuation">.</span><span class="token function">insertOrderData</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span> fbdealId<span class="token punctuation">,</span> bdealCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token comment">//根据trade_id获取trade和deal表信息</span>
                            <span class="token class-name">String</span> tradeOrderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>ftradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">String</span> tradeExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>ftradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                            <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                tradeOrderCacheData <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>tradeOrderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>tradeOrderDataStr <span class="token operator">+</span> <span class="token string">"=========== trade:trade:"</span> <span class="token operator">+</span> ftradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token punctuation">&#125;</span>

                            tradeOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">,</span>tradeExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>

                            <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> unionOrders <span class="token operator">=</span> <span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">.</span><span class="token function">mergeResult</span><span class="token punctuation">(</span>bdealOrderCacheData<span class="token punctuation">,</span>dealOrderCacheData<span class="token punctuation">,</span>tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            resArr<span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>unionOrders<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                    <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>

            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span> tableName <span class="token operator">=</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">;</span>
                <span class="token class-name">JSONObject</span> data <span class="token operator">=</span> value<span class="token punctuation">.</span>f1<span class="token punctuation">;</span>
                <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> list <span class="token operator">=</span> <span class="token function">handle</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>tableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span>list<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i <span class="token operator">++</span> <span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>list<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> singleStream<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个方案的好处是，任务挂掉以后，不用担心丢数据。重新消费即可</p>
<p>经过测试，此方案完全可行，但是这个方案有如下几点问题：</p>
<ul>
<li>3个表每条数据更新都会更新一次kudu，造成下游的Kudu压力有些大。</li>
<li>在高并发的情况下，Hbase的压力不知道能否抗住，理论上应该没事，后期观察</li>
</ul>
<p>虽然没有用到Flink的状态计算，但是，还是很想研究一下Flink的状态计算，想测试一个案例：<br>实现如下功能：</p>
<ul>
<li>3个kafka输入源，并且实现这3个数据源关联，模仿3个表join</li>
<li>改变其中一个表的字段值，使用状态计算更新最终的结果</li>
<li>增加大时间跨度大于1天，7天，30天。</li>
</ul>
<p>Flink读取kafka多个topic遇到的问题：<br>如果要读取的Topic列表中，其中一个在Topic中没有数据，而你又基于Event Time提取Timestamp并且设置Watermark，<br>会导致整个Topic列表都没法基于时间窗口触发操作，解决方案：<br>先rebalance，然后再设置水位：</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> monitorSampling <span class="token operator">=</span> env
    <span class="token punctuation">.</span>addSource<span class="token punctuation">(</span>kafkaConsumer<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>rebalance
    <span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> MyWatermarkGenerator<span class="token punctuation">[</span>MyRecord<span class="token punctuation">]</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span>config<span class="token punctuation">.</span>latencyDuration<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="Flink反压"><a href="#Flink反压" class="headerlink" title="Flink反压"></a>Flink反压</h2><p>反压（backpressure）是实时计算应用开发中，特别是流式计算中，十分常见的问题。反压意味着数据管道中某个节点成为瓶颈，处理速率跟不上上游发送数据的速率，而需要对上游进行限速。</p>
<h3 id="反压的影响"><a href="#反压的影响" class="headerlink" title="反压的影响"></a>反压的影响</h3><p>反压并不会直接影响作业的可用性，它表明作业处于亚健康的状态，有潜在的性能瓶颈并可能导致更大的数据处理延迟。通常来说，对于一些对延迟要求不太高或者数据量比较小的应用来说，反压的影响可能并不明显，然而对于规模比较大的 Flink 作业来说反压可能会导致严重的问题。</p>
<p>这是因为 Flink 的 checkpoint 机制，反压还会影响到两项指标: checkpoint 时长和 state 大小。</p>
<ul>
<li>前者是因为 checkpoint barrier 是不会越过普通数据的，数据处理被阻塞也会导致 checkpoint barrier 流经整个数据管道的时长变长，因而 checkpoint 总体时间（End to End Duration）变长。</li>
<li>后者是因为为保证 EOS（Exactly-Once-Semantics，准确一次），对于有两个以上输入管道的 Operator，checkpoint barrier 需要对齐（Alignment），接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到state 里面，导致 checkpoint 变大。</li>
</ul>
<p>这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint 超时失败，而 state 大小同样可能拖慢 checkpoint 甚至导致 OOM （使用 Heap-based StateBackend）或者物理内存使用超出容器资源（使用 RocksDBStateBackend）的稳定性问题。</p>
<h3 id="定位反压节点"><a href="#定位反压节点" class="headerlink" title="定位反压节点"></a>定位反压节点</h3><p>要解决反压首先要做的是定位到造成反压的节点，这主要有两种办法:</p>
<ul>
<li>通过 Flink Web UI 自带的反压监控面板；</li>
<li>通过 Flink Task Metrics。<br>前者比较容易上手，适合简单分析，后者则提供了更加丰富的信息，适合用于监控系统。因为反压会向上游传导，这两种方式都要求我们从 Source 节点到 Sink 的逐一排查，直到找到造成反压的根源原因。下面分别介绍这两种办法。</li>
</ul>
<p>反压监控面板</p>
<p>Flink Web UI 的反压监控提供了 SubTask 级别的反压监控，原理是通过周期性对 Task 线程的栈信息采样，得到线程被阻塞在请求 Buffer（意味着被下游队列阻塞）的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1 以下则为 OK，0.1 至 0.5 为 LOW，而超过 0.5 则为 HIGH。</p>
<p>如果处于反压状态，那么有两种可能性：</p>
<ul>
<li>该节点的发送速率跟不上它的产生数据速率。这一般会发生在一条输入多条输出的 Operator（比如 flatmap）。</li>
<li>下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率。<br>如果是第一种状况，那么该节点则为反压的根源节点，它是从 Source Task 到 Sink Task 的第一个出现反压的节点。如果是第二种情况，则需要继续排查下游节点。</li>
</ul>
<p>具体可以参考<a href="https://zhuanlan.zhihu.com/p/92743373">如何分析及处理 Flink 反压？</a><br><a href="https://www.jianshu.com/p/2779e73abcb8">一文搞懂 Flink 网络流控与反压机制</a></p>
<h2 id="FlinkCDC-采集mysql-写Hbase并从Hive内读取"><a href="#FlinkCDC-采集mysql-写Hbase并从Hive内读取" class="headerlink" title="FlinkCDC 采集mysql 写Hbase并从Hive内读取"></a>FlinkCDC 采集mysql 写Hbase并从Hive内读取</h2><p>java代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在hive里创建hbase外表，CDH集群原生支持Hive与Hbase打通，如果是自己搭建的集群，需要自己打通一下Hive与Hbase，这个网上很多，照着操作一下就好<br>在hive里创建外表，映射hbase表</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> flume_mqtt<span class="token punctuation">(</span>
rowkey string<span class="token punctuation">,</span>
id <span class="token keyword">int</span><span class="token punctuation">,</span>
name string<span class="token punctuation">,</span>
age <span class="token keyword">int</span><span class="token punctuation">)</span>
STORED <span class="token keyword">BY</span> 
<span class="token string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span>
<span class="token keyword">WITH</span> SERDEPROPERTIES <span class="token punctuation">(</span><span class="token string">"hbase.columns.mapping"</span> <span class="token operator">=</span> 
<span class="token string">":key,f1:id,f1:name,f1:age"</span><span class="token punctuation">)</span> 
TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">"hbase.table.name"</span> <span class="token operator">=</span> <span class="token string">"flume_mqtt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ol>
<li><code>hbase-default.xml file seems to be for an older version of HBase (2.2.3), this version is 2.1.0-cdh6.2.0</code><br>问题原因：因为${FLINK_HOME}/lib下放了一个<code>flink-sql-connector-hbase-2.2_2.12-1.13.6.jar</code>，与项目里的hbase依赖的版本冲突了，删除${FLINK_HOME}/lib下的文件</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink面试题总结</title>
    <url>/2021/11/11/Flink%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink面试题总结</li>
</ul>
<a id="more"></a>



<p><strong><font size = 5>1. Flink是如何支持批流一体的？</font></strong><br>    Flink的开发者认为批处理是流处理的一种特殊情况。批处理是有限的流处理。Flink 使用一个引擎支持了DataSet API 和 DataStream API<br>    在1.12.x以后，DataSet API会逐渐废弃，DataStream API已经既可以处理流也可以处理批了<br>    具体可以参考<a href="https://www.cnblogs.com/binbingg/p/14330354.html">Apache Flink 1.12.0 正式发布，DataSet API 将被弃用，真正的流批一体</a></p>
<p><strong><font size = 5>2. Flink 相比传统的 Spark Streaming 有什么区别?</font></strong><br>    Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型<br>    1. 架构模型Spark Streaming 在运行时的主要角色包括：Master、Worker、Driver、Executor;<br>       Flink 在运行时主要包含：Jobmanager、Taskmanager和Slot。<br>    2. 任务调度Spark Streaming 连续不断的生成微小的数据批次，构建有向无环图DAG，Spark Streaming 会依次创建 DStreamGraph、JobGenerator、JobScheduler。<br>       Flink 根据用户提交的代码生成 StreamGraph，经过优化生成 JobGraph，然后提交给 JobManager进行处理，JobManager 会根据 JobGraph 生成 ExecutionGraph，ExecutionGraph 是 Flink 调度最核心的数据结构，JobManager 根据 ExecutionGraph 对 Job 进行调度。<br>    3. 时间机制Spark Streaming 支持的时间机制有限，只支持处理时间。<br>       Flink 支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间。同时也支持 watermark 机制来处理滞后数据。<br>    4. 容错机制对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰好一次处理语义。<br>       Flink 则使用两阶段提交协议来解决这个问题</p>
<p><strong><font size = 5>3. Flink集群有哪些角色？各自有什么作用？</font></strong><br>    Flink 程序在运行时主要有 TaskManager，JobManager，Client三种角色。<br>    1. JobManager是一个进程，主要负责申请资源，协调以及控制整个job的执行过程，具体包括，调度任务、处理checkpoint、容错等等，在接收到JobClient提交的执行计划之后，针对收到的执行计划，继续解析，因为JobClient只是形成一个operaor层面的执行计划，所以JobManager继续解析执行计划（根据算子的并发度，划分task），形成一个可以被实际调度的由task组成的拓扑图，如上图被解析之后形成下图的执行计划，最后向集群申请资源，一旦资源就绪，就调度task到TaskManager。<br>    2. TaskManager是一个进程，及一个JVM（Flink用java实现）。主要作用是接收并执行JobManager发送的task，并且与JobManager通信，反馈任务状态信息，比如任务分执行中，执行完等状态，上文提到的checkpoint的部分信息也是TaskManager反馈给JobManager的。如果说JobManager是master的话，那么TaskManager就是worker主要用来执行任务。在TaskManager内可以运行多个task。多个task运行在一个JVM内有几个好处，首先task可以通过多路复用的方式TCP连接，其次task可以共享节点之间的心跳信息，减少了网络传输。<br>    3. Client是Flink程序提交的客户端，当用户提交一个Flink程序时，会首先创建一个Client，该Client首先会对用户提交的Flink程序进行预处理，并提交到Flink集群中处理，所以Client需要从用户提交的Flink程序配置中获取JobManager的地址，并建立到JobManager的连接，将Flink Job提交给JobManager<br>    Spark中每个Stage中的Task会被分配到一个Worker中的 -&gt; Executor容器里面的 -&gt; 一个线程池中被执行，Flink称每个Executor为一个TaskManager，每个TaskManager中会有多个slot作为内存隔离：<br>    Spark：Worker  ——&gt;   Executor  ——&gt;  线程池  ——&gt;  线程<br>    Flink：  Worker  ——&gt;   TaskManager  ——&gt;  Slot  ——&gt;  线程 </p>
<p><strong><font size = 5>4. 说说 Flink 资源管理中 Task Slot 的概念</font></strong><br>    Slot是TaskManager资源粒度的划分，每个Slot都有自己独立的内存。所有Slot平均分配TaskManger的内存，比如TaskManager分配给Solt的内存为8G，两个Slot，每个Slot的内存为4G，四个Slot，每个Slot的内存为2G，值得注意的是，Slot仅划分内存，不涉及cpu的划分。同时Slot是Flink中的任务执行器（类似Storm中Executor），每个Slot可以运行多个task，而且一个task会以单独的线程来运行。Slot主要的好处有以下几点：<br>    可以起到隔离内存的作用，防止多个不同job的task竞争内存。<br>    Slot的个数就代表了一个Flink程序的最高并行度，简化了性能调优的过程<br>    允许多个Task共享Slot，提升了资源利用率，举一个实际的例子，kafka有3个partition，对应flink的source有3个task，而keyBy我们设置的并行度为20，这个时候如果Slot不能共享的话，需要占用23个Slot，如果允许共享的话，那么只需要20个Slot即可（Slot的默认共享规则计算为20个）。</p>
<p><strong><font size = 5>5. 说说你知道的Flink分区策略？</font></strong><br>    1. GlobalPartitioner 数据会被分发到下游算子的第一个实例中进行处理。<br>    2. ShufflePartitioner 数据会被随机分发到下游算子的每一个实例中进行处理。<br>    3. RebalancePartitioner 数据会被循环发送到下游的每一个实例中进行处理。<br>    4. RescalePartitioner 这种分区器会根据上下游算子的并行度，循环的方式输出到下游算子的每个实例。<br>        这里有点难以理解，假设上游并行度为2，编号为A和B。下游并行度为4，编号为1，2，3，4。那么A则把数据循环发送给1和2，B则把数据循环发送给3和4。假设上游并行度为4，编号为A，B，C，D。下游并行度为2，编号为1，2。那么A和B则把数据发送给1，C和D则把数据发送给2。<br>    5. BroadcastPartitioner 广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做Jion的场景。<br>    6. ForwardPartitioner 用于将记录输出到下游本地的算子实例。它要求上下游算子并行度一样。简单的说，ForwardPartitioner用来做数据的控制台打印。<br>    7. KeyGroupStreamPartitioner Hash分区器。会将数据按 Key 的 Hash 值输出到下游算子实例中。<br>    8. CustomPartitionerWrapper 用户自定义分区器。需要用户自己实现Partitioner接口，来定义自己的分区逻辑</p>
<p><strong><font size = 5>6. Flink的并行度了解吗？Flink的并行度设置是怎样的？</font></strong><br>    Flink中的任务被分为多个并行任务来执行，其中每个并行的实例处理一部分数据。这些并行实例的数量被称为并行度。我们在实际生产环境中可以从四个不同层面设置并行度：<br>    操作算子层面(Operator Level)<br>    执行环境层面(Execution Environment Level)<br>    客户端层面(Client Level)<br>    系统层面(System Level)<br>    需要注意的优先级：算子层面&gt;环境层面&gt;客户端层面&gt;系统层面</p>
<p><strong><font size = 5>7. Flink的Slot和parallelism有什么区别？</font></strong><br>    slot是指taskmanager的并发执行能力，假设我们将 taskmanager.numberOfTaskSlots 配置为3 那么每一个 taskmanager 中分配3个 TaskSlot, 3个 taskmanager 一共有9个TaskSlot。<br>    parallelism是指taskmanager实际使用的并发能力。假设我们把 parallelism.default 设置为1，那么9个 TaskSlot 只能用1个，有8个空闲。</p>
<p><strong><font size = 5>8. Flink有没有重启策略？说说有哪几种？</font></strong><br>    Flink 实现了多种重启策略。<br>    固定延迟重启策略（Fixed Delay Restart Strategy）<br>    故障率重启策略（Failure Rate Restart Strategy）<br>    没有重启策略（No Restart Strategy）<br>    Fallback重启策略（Fallback Restart Strategy）</p>
<p><strong><font size = 5>9. 用过Flink中的分布式缓存吗？如何使用？</font></strong><br>    Flink实现的分布式缓存和Hadoop有异曲同工之妙。目的是在本地读取文件，并把他放在 taskmanager 节点中，防止task重复拉取。</p>
<p><strong><font size = 5>10. 说说Flink中的广播变量，使用时需要注意什么？</font></strong><br>    我们知道Flink是并行的，计算过程可能不在一个 Slot 中进行，那么有一种情况即：当我们需要访问同一份数据。那么Flink中的广播变量就是为了解决这种情况。<br>    我们可以把广播变量理解为是一个公共的共享变量，我们可以把一个dataset 数据集广播出去，然后不同的task在节点上都能够获取到，这个数据在每个节点上只会存在一份</p>
<p><strong><font size = 5>11. 说说Flink中的窗口？</font></strong><br>    Flink的窗口可以分为Keyed Windows和Non-Keyed Windows，键控窗口会按照key划分逻辑键控流，拥有键控流将允许窗口计算由多个任务并行执行，非键控流的并行度为1<br>    窗口的生命周期：当应该属于该窗口的第一个元素到达时，就会创建一个窗口，并且当时间（事件或处理时间）超过其结束时间戳加上用户指定的允许延迟时，该窗口将被完全删除<br>    窗口分配器可以分为<br>    tumbling windows：无重叠<br>    sliding windows：有重叠<br>    session windows：当会话窗口在一段时间内没有接收到元素时，即发生不活动间隙时，它会关闭<br>    global windows：全局窗口分配器将具有相同键的所有元素分配给同一个全局窗口。仅在指定自定义触发器时才有用。 否则，不会执行任何计算</p>
<p><strong><font size = 5>12. 说说Flink中的状态存储？</font></strong><br>    Flink在做计算的过程中经常需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和 checkpoint 交互。<br>    Flink提供了三种状态存储方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend</p>
<p><strong><font size = 5>13. Flink 中的时间有哪几类？</font></strong><br>    Flink 中的时间和其他流式计算系统的时间一样分为三类：事件时间，摄入时间，处理时间三种。<br>    如果以 EventTime 为基准来定义时间窗口将形成EventTimeWindow,要求消息本身就应该携带EventTime。<br>    如果以 IngesingtTime 为基准来定义时间窗口将形成 IngestingTimeWindow,以 source 的systemTime为准。<br>    如果以 ProcessingTime 基准来定义时间窗口将形成 ProcessingTimeWindow，以 operator 的systemTime 为准。</p>
<p><strong><font size = 5>14. Flink 中水印是什么概念，起到什么作用？</font></strong><br>    Watermark 是 Apache Flink 为了处理 EventTime 窗口计算提出的一种机制, 本质上是一种时间戳。 一般来讲Watermark经常和Window一起被用来处理乱序事件。</p>
<p><strong><font size = 5>15. Flink是如何做到高效的数据交换的？</font></strong><br>    在一个Flink Job中，数据需要在不同的task中进行交换，整个数据交换是有 TaskManager 负责的，TaskManager 的网络组件首先从缓冲buffer中收集records，然后再发送。<br>    Records 并不是一个一个被发送的，二是积累一个批次再发送，batch 技术可以更加高效的利用网络资源</p>
<p><strong><font size = 5>16. Flink是如何做容错的？</font></strong><br>    Flink 实现容错主要靠强大的CheckPoint机制和State机制。Checkpoint 负责定时制作分布式快照、对程序中的状态进行备份；State 用来存储计算过程中的中间状态。</p>
<p><strong><font size = 5>17. Flink 分布式快照的原理是什么？</font></strong><br>    Flink的分布式快照是根据Chandy-Lamport算法量身定做的。简单来说就是持续创建分布式数据流及其状态的一致快照。<br>    核心思想是在 input source 端插入 barrier，控制 barrier 的同步来实现 snapshot 的备份和 exactly-once 语义。</p>
<p><strong><font size = 5>18. Flink 是如何保证Exactly-once语义的？</font></strong><br>    flink会把kafka的offset作为状态存下来，并会定期的做checkpoint持久化。<br>    Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义。 分为以下几个步骤：<br>    开始事务（beginTransaction）创建一个临时文件夹，来写把数据写入到这个文件夹里面<br>    预提交（preCommit）将内存中缓存的数据写入文件并关闭<br>    正式提交（commit）将之前写完的临时文件放入目标目录下。这代表着最终的数据会有一些延迟<br>    丢弃（abort）丢弃临时文件<br>    若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。</p>
<p><strong><font size = 5>19. 说说 Flink的内存管理是如何做的?</font></strong><br>    Flink 并不是将大量对象存在堆上，而是将对象都序列化到一个预分配的内存块上。此外，Flink大量的使用了堆外内存。如果需要处理的数据超出了内存限制，则会将部分数据存储到硬盘上。<br>    Flink 为了直接操作二进制数据实现了自己的序列化框架。理论上Flink的内存管理分为三部分：<br>    Network Buffers：这个是在TaskManager启动的时候分配的，这是一组用于缓存网络数据的内存，每个块是32K，默认分配2048个，可以通过“taskmanager.network.numberOfBuffers”修改<br>    Memory Manage pool：大量的Memory Segment块，用于运行时的算法（Sort/Join/Shuffle等），这部分启动的时候就会分配。，内存的分配支持预分配和lazy load，默认懒加载的方式。<br>    User Code，这部分是除了Memory Manager之外的内存用于User code和TaskManager本身的数据结构。</p>
<p><strong><font size = 5>20. Flink中的Window出现了数据倾斜，你有什么解决办法？</font></strong><br>    window产生数据倾斜指的是数据在不同的窗口内堆积的数据量相差过多。本质上产生这种情况的原因是数据源头发送的数据量速度不同导致的。出现这种情况一般通过两种方式来解决：<br>    在数据进入窗口前做预聚合<br>    重新设计窗口聚合的key</p>
<p><strong><font size = 5>21. Flink任务延迟高，想解决这个问题，你会如何入手？</font></strong><br>    在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。作业参数调优包括：并行度的设置，State的设置，checkpoint的设置</p>
<p><strong><font size = 5>22. Flink是如何处理反压的？</font></strong><br>    Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞</p>
<p><strong><font size = 5>23. Operator Chains（算子链）这个概念你了解吗？</font></strong><br>    为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。<br>    将operators链接成task是非常有效的优化：<br>    它能减少线程之间的切换，<br>    减少消息的序列化/反序列化，<br>    减少数据在缓冲区的交换，<br>    减少了延迟的同时提高整体的吞吐量。<br>    这就是我们所说的算子链</p>
<p><strong><font size = 5>24. Flink什么情况下才会把Operator chain在一起形成算子链？</font></strong><br>    两个operator chain在一起的的条件：<br>    上下游的并行度一致<br>    下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）<br>    上下游节点都在同一个 slot group 中（下面会解释 slot group）<br>    下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）<br>    上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）<br>    两个节点间数据分区方式是 forward（参考理解数据流的分区）<br>    用户没有禁用 chain</p>
<p><strong><font size = 5>25. Flink Job的提交流程</font></strong><br>    用户提交的Flink Job会被转化成一个DAG任务运行，分别是：StreamGraph、JobGraph、ExecutionGraph，<br>    Flink中JobManager与TaskManager，JobManager与Client的交互是基于Akka工具包的，是通过消息驱动。<br>    整个Flink Job的提交还包含着ActorSystem的创建，JobManager的启动，TaskManager的启动和注册。</p>
<p><strong><font size = 5>26. Flink 计算资源的调度是如何实现的？</font></strong><br>    TaskManager中最细粒度的资源是Task slot，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。<br>    通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。<br>    每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，<br>    可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。 每个slot可以接受单个task，也可以接受多个连续task组成的pipeline</p>
<p><strong><font size = 5>27. 简述Flink的数据抽象及数据交换过程？</font></strong><br>    Flink 为了避免JVM的固有缺陷例如java对象存储密度低，FGC影响吞吐和响应等，实现了自主管理内存。MemorySegment就是Flink的内存抽象。<br>    默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。<br>    在MemorySegment这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是Buffer。<br>    对接从Java对象转为Buffer的中间对象是另一个抽象StreamRecord。</p>
<p><strong><font size = 5>28. Flink 中的分布式快照机制是如何实现的？</font></strong><br>    Flink的容错机制的核心部分是制作分布式数据流和操作算子状态的一致性快照。 这些快照充当一致性checkpoint，系统可以在发生故障时回滚。 Flink用于制作这些快照的机制在“分布式数据流的轻量级异步快照”中进行了描述。<br>    它受到分布式快照的标准Chandy-Lamport算法的启发，专门针对Flink的执行模型而定制。<br>    barriers在数据流源处被注入并行数据流中。快照n的barriers被插入的位置（我们称之为Sn）是快照所包含的数据在数据源中最大位置。<br>    例如，在Apache Kafka中，此位置将是分区中最后一条记录的偏移量。 将该位置Sn报告给checkpoint协调器（Flink的JobManager）。<br>    然后barriers向下游流动。当一个中间操作算子从其所有输入流中收到快照n的barriers时，它会为快照n发出barriers进入其所有输出流中。<br>    一旦sink操作算子（流式DAG的末端）从其所有输入流接收到barriers n，它就向checkpoint协调器确认快照n完成。在所有sink确认快照后，意味快照着已完成。<br>    一旦完成快照n，job将永远不再向数据源请求Sn之前的记录，因为此时这些记录（及其后续记录）将已经通过整个数据流拓扑，也即是已经被处理结束。</p>
<p><strong><font size = 5>28. Flink任务延迟高，想解决这个问题，你会如何入手？</font></strong><br>在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。<br>作业参数调优包括：并行度的设置，State的设置，checkpoint的设置。</p>
<p><strong><font size = 5>29. Flink任务延迟高，想解决这个问题，你会如何入手？</font></strong></p>
]]></content>
      <categories>
        <category>面试题</category>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle学习笔记</title>
    <url>/2022/06/16/Oracle%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Centos7.x安装Oracle12c</li>
<li>初尝Oracle遇到的坑</li>
<li>Ocacle基本操作</li>
<li>Oracle开启CDC功能</li>
</ul>
<a id="more"></a>

<h2 id="Centos7-x安装Oracle12c"><a href="#Centos7-x安装Oracle12c" class="headerlink" title="Centos7.x安装Oracle12c"></a>Centos7.x安装Oracle12c</h2><p>这里安装完全参考了<a href="https://www.freesion.com/article/56911167140/">CENTOS7.3静默安装ORACLE12C</a><br>需要注意的是</p>
<ol>
<li>在配置ORACLE环境变量并验证–需要把<code>export ORACLE_HOSTNAME=liuxiaobai</code>改成自己的</li>
<li>安装ORACLE–这里采取命令行安装，文档里的<code>\</code>换行不对，这里全部放到一行里成功了</li>
<li>创建数据库–<code>-gdbname</code>需要改成<code>-gdbName</code>，换行去掉，都放在一行 </li>
<li>配置数据库监听 ，这里看初尝Oracle遇到的坑</li>
</ol>
<h2 id="初尝Oracle遇到的坑"><a href="#初尝Oracle遇到的坑" class="headerlink" title="初尝Oracle遇到的坑"></a>初尝Oracle遇到的坑</h2><h3 id="配置数据库监听"><a href="#配置数据库监听" class="headerlink" title="配置数据库监听"></a>配置数据库监听</h3><p>未配置监听前执行</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">lsnrctl status
## 因为没配置过，所以会报错，具体日志看参考文档<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>使用默认的netca.rsp文件，执行命令</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">netca -silent -responseFile &#x2F;home&#x2F;oracle&#x2F;database&#x2F;response&#x2F;netca.rsp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里执行命令以后，没有出现文档里成功的日志，通过查看日志，报错如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">为此监听程序提供的端口1521当前正在使用。可以按现状继续配置,但只有在解决冲突之后才能启动该监听程序。是否仍然继续配置?<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>网上说是因为host配置不对，我这里通过<code>lsnrctl stop</code>把监听停掉,然后手动执行</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&#x2F;usr&#x2F;local&#x2F;products&#x2F;oracle12c&#x2F;bin&#x2F;lsnrctl start LISTENER<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这样虽然报日志成功了，但是并没有文档里说的会对服务<code>cdb1</code>监听的日志，这里根据文档里提示，修改listener.ora文件</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">vim &#x2F;usr&#x2F;local&#x2F;products&#x2F;oracle12c&#x2F;network&#x2F;admin&#x2F;listener.ora
## 文件内容修改如下：
# listener.ora Network Configuration File: &#x2F;usr&#x2F;local&#x2F;products&#x2F;oracle12c&#x2F;network&#x2F;admin&#x2F;listener.ora
# Generated by Oracle configuration tools.
## 这里不动
LISTENER &#x3D;
  (DESCRIPTION_LIST &#x3D;
    (DESCRIPTION &#x3D;
      (ADDRESS &#x3D; (PROTOCOL &#x3D; TCP)(HOST &#x3D; golden-cloud)(PORT &#x3D; 1539))
      (ADDRESS &#x3D; (PROTOCOL &#x3D; IPC)(KEY &#x3D; EXTPROC1521))
    )
  )
    ## 以下为新增
SID_LIST_LISTENER &#x3D;
(SID_LIST &#x3D;
  (SID_DESC &#x3D;
  (GLOBAL_DBNAME &#x3D; orcl)
  (SID_NAME &#x3D; orcl)
  )

  (SID_DESC &#x3D;
  (GLOBAL_DBNAME &#x3D; orclpdb1)
  (SID_NAME &#x3D; orclpdb1)
  )
)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>注意：<br>这里的监听需要开启2个，一个是CDB一个是PDB，否则flink连接的时候，会有问题<br>再次执行：</p>
</blockquote>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">lsnrctl stop
lsnrctl start<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>终于成功了</p>
<h3 id="使用navicat连接oracle"><a href="#使用navicat连接oracle" class="headerlink" title="使用navicat连接oracle"></a>使用navicat连接oracle</h3><p>首先在腾讯云开启端口，这次安装的端口换成1539了。<br>这里要注意，Service Name和SID都是一样的，都是之前创建的数据库cdb1，选哪个都可以的<br>密码就是之前<code>-systemPassword</code>的内容，连接界面如下：<br><img src="/uploads/202206/Navicat%E8%BF%9E%E6%8E%A5Oracle.png" alt="Navicat连接Oracle"><br>还需要注意的是，通过第三方工具连接，必须要开启监听服务，否则连不上的</p>
<h3 id="创建用户失败"><a href="#创建用户失败" class="headerlink" title="创建用户失败"></a>创建用户失败</h3><p>主要有2个问题：</p>
<ol>
<li>用户名不合法，具体可以参考<a href="https://blog.csdn.net/dling8/article/details/120000292">ORA-65096: 公用用户名或角色名无效</a></li>
<li>找不到表命名空间</li>
</ol>
<p>不管是在sqlplus还是在Navicat创建都报错，大致的意思就是用户名不合法，通过网上的资料查看，oracle12版本，普通用户名必须要以c##开头</p>
<p>找不到表命名空间的解决办法就是重启oracle服务：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 1. su – oralce                           —-切换到oracle用户
# 2.lsnrctl stop                           —-停止监听
# 3.sqlplus “&#x2F;as sysdba”                   —-以sysdba用户登录oracle
# 4.shutdown immediate                     —-关闭数据库
# 5.startup                                —-启动数据库
# 6.exit                                   —-退出sqlplus
# 7.lsnrctl start                          —-启动监听
# 3，4，5是在sqlplus里执行的<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>重启过后就可以找到命名空间了<br>通过sqlplus创建命名空间与用户的语句如下：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">tablespace</span> testspace datafile <span class="token string">'/usr/local/products/oradata/testspace.dbf'</span> size <span class="token number">300</span>m<span class="token punctuation">;</span>
<span class="token comment">--创建用户名</span>
<span class="token keyword">CREATE</span> <span class="token keyword">USER</span> c<span class="token comment">##test IDENTIFIED BY 123456 DEFAULT TABLESPACE "golden" TEMPORARY TABLESPACE TEMP;</span>
<span class="token comment">-- 查看用户名与其默认的表空间</span>
<span class="token keyword">select</span> username<span class="token punctuation">,</span> default_tablespace <span class="token keyword">from</span> dba_users <span class="token keyword">where</span> username <span class="token operator">=</span> <span class="token string">'C##TEST'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>但是还是感觉使用navicat来创建更方便</p>
<p>如果想要用新创建的用户登陆，需要给新用户授权：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--这个在navicat里也可以操作</span>
<span class="token keyword">grant</span> <span class="token keyword">connect</span><span class="token punctuation">,</span> resource <span class="token keyword">to</span> c<span class="token comment">##test; // 用户授权</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="ORA-01950-对表空间-‘golden’-无权限"><a href="#ORA-01950-对表空间-‘golden’-无权限" class="headerlink" title="ORA-01950: 对表空间 ‘golden’ 无权限"></a>ORA-01950: 对表空间 ‘golden’ 无权限</h3><p>以新用户登陆oracle，并创建表都没有问题，但是，往表里写数据的时候，报错：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">ORA<span class="token operator">-</span><span class="token number">01950</span>: 对表空间 <span class="token string">'golden'</span> 无权限<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>需要再次赋权：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">USER</span> C<span class="token comment">##TEST QUOTA UNLIMITED ON "golden"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<h2 id="Ocacle基本操作"><a href="#Ocacle基本操作" class="headerlink" title="Ocacle基本操作"></a>Ocacle基本操作</h2><p>这里操作Oracle都在Navicat里操作，通过命令行操作Oracle，太费事了<br>schema是什么？可以参考<a href="https://blog.csdn.net/afsdfq/article/details/90417355">oracle之schema</a><br>schema和用户是一一对应的。每个用户都有一个schema，并且和用户名是一样的</p>
<p>数据库的启动步骤：</p>
<ol>
<li>nomount –根据参数文件启动实例（instance）</li>
<li>mount –加载控制文件，让实例和数据库相关联</li>
<li>open –根据控制文件找到并打开数据文件和日志文件，从而打开数据库</li>
</ol>
<h2 id="Oracle开启CDC功能"><a href="#Oracle开启CDC功能" class="headerlink" title="Oracle开启CDC功能"></a>Oracle开启CDC功能</h2><p>您必须为 Oracle 数据库启用日志归档，并定义一个对 Debezium Oracle 连接器监控的所有数据库具有适当权限的 Oracle 用户<br>Oracle启用日志归档，根据数据库类型有2种方式</p>
<h3 id="对于Non-CDB-database"><a href="#对于Non-CDB-database" class="headerlink" title="对于Non-CDB database"></a>对于Non-CDB database</h3><p>Non-CDB概念：<br>Non-CDB 是指任何不是 CDB 的东西。即 12c 之前的任何数据库，或在没有启用可插入数据库子句的情况下创建的 12c 数据库。如果您创建非 CDB，则它不是 Multitentant，而是像 12c 之前的数据库一样的单实例独立数据库。<br>看网上的说法，12C之前的版本都是Non-CDB，12C之后的版本，都是CDB的<br>那么，我们这次采集的目标是12C，所以是CDB版本的</p>
<h3 id="查询Oracle数据库是CDB还是Non-CDB？"><a href="#查询Oracle数据库是CDB还是Non-CDB？" class="headerlink" title="查询Oracle数据库是CDB还是Non-CDB？"></a>查询Oracle数据库是CDB还是Non-CDB？</h3><p>您可以在V$DATABASE视图中查询 CDB 列以查看数据库是否为 CDB。如果当前数据库是 CDB，则列值为 YES，否则 CDB 列值为 NO</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SQL</span><span class="token operator">></span> <span class="token keyword">SELECT</span> CDB <span class="token keyword">FROM</span> V$<span class="token keyword">DATABASE</span><span class="token punctuation">;</span>

CDB
<span class="token comment">------</span>
YES

<span class="token comment">--您可以通过如下查询获取有关 CDB 中容器的信息。</span>
<span class="token comment">--使用 SQLPlus 连接，确保您位于根容器中，然后运行查询。</span>
<span class="token keyword">SQL</span><span class="token operator">></span> <span class="token keyword">SHOW</span> CON_NAME<span class="token punctuation">;</span>

CON_NAME
<span class="token comment">------------------------------</span>
CDB$ROOT


<span class="token keyword">SQL</span><span class="token operator">></span> <span class="token keyword">COLUMN</span> NAME FORMAT A8<span class="token punctuation">;</span>
<span class="token keyword">SQL</span><span class="token operator">></span> <span class="token keyword">SELECT</span> NAME<span class="token punctuation">,</span> CON_ID<span class="token punctuation">,</span> DBID<span class="token punctuation">,</span> CON_UID<span class="token punctuation">,</span> GUID <span class="token keyword">FROM</span> V$CONTAINERS <span class="token keyword">ORDER</span> <span class="token keyword">BY</span> CON_ID<span class="token punctuation">;</span>

NAME	     CON_ID	  DBID	  CON_UID GUID
<span class="token comment">-------- ---------- ---------- ---------- --------------------------------</span>
CDB$ROOT	  <span class="token number">1</span> <span class="token number">1081227694</span>		<span class="token number">1</span> <span class="token number">4700</span>A987085A3DFAE05387E5E50A8C7B
PDB$SEED	  <span class="token number">2</span> <span class="token number">4250516830</span> <span class="token number">4250516830</span> E187C82E49CD2E91E055000000000001
PDB1		  <span class="token number">3</span>  <span class="token number">913056142</span>	<span class="token number">913056142</span> E187D563EBD3375EE055000000000001<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到，我们的版本确实是CDB的</p>
<h3 id="CDB与PDB区别"><a href="#CDB与PDB区别" class="headerlink" title="CDB与PDB区别"></a>CDB与PDB区别</h3><p>Oracle 12C引⼊了CDB与PDB的新特性，在ORACLE 12C数据库引⼊的多租⽤户环境（Multitenant Environment）中，允许⼀个数据库容<br>器（CDB）承载多个可插拔数据库（PDB）。CDB全称为Container Database，中⽂翻译为数据库容器，PDB全称为Pluggable<br>Database，即可插拔数据库。在ORACLE 12C之前，实例与数据库是⼀对⼀或多对⼀关系（RAC）：即⼀个实例只能与⼀个数据库相关<br>联，数据库可以被多个实例所加载。⽽实例与数据库不可能是⼀对多的关系。当进⼊ORACLE 12C后，实例与数据库可以是⼀对多的关<br>系。</p>
<h3 id="公共用户与本地用户"><a href="#公共用户与本地用户" class="headerlink" title="公共用户与本地用户"></a>公共用户与本地用户</h3><p>公共用户需要以C##开头<br>具体可以参考<a href="https://www.likecs.com/show-204093510.html">Oracle 12C R2 公共用户和本地用户</a></p>
<blockquote>
<p>如果想创建非C##开头的用户名，可以设置<code>alter session set &quot;_ORACLE_SCRIPT&quot;=true;</code></p>
</blockquote>
<h3 id="数据库开启CDC功能"><a href="#数据库开启CDC功能" class="headerlink" title="数据库开启CDC功能"></a>数据库开启CDC功能</h3><p>flinkcdc是通过读取Oracle的日志来做到实时采集的，所以，这里需要了解一下Oracle的日志相关知识<br>具体可以参考<a href="https://blog.csdn.net/ai15134626825/article/details/103480564">Oracle数据库开启归档日志和补充日志</a></p>
<p>Oracle开启cdc功能，根据数据库类型有<code>CDB数据库</code>和<code>Non-CDB数据库</code>两种，<code>Non-CDB数据库</code>比较好操作，但是，CDB数据库创建用户必须要用<code>C##</code>开头，导致赋权限一直报错，而且，flinksql连接不到数据库<br>这里先使用<code>Non-CDB数据库</code>做测试。</p>
<blockquote>
<p>有点奇怪，为什么flinkcdc官网上创建<code>CDB数据库</code>的用户不需要使用<code>C##</code>开头？</p>
</blockquote>
<h4 id="Non-CDB数据库开启cdc"><a href="#Non-CDB数据库开启cdc" class="headerlink" title="Non-CDB数据库开启cdc"></a>Non-CDB数据库开启cdc</h4><ul>
<li>启用日志归档<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mkdir -p &#x2F;data&#x2F;oracle&#x2F;oradata&#x2F;recovery_area 
chown -R oracle:dba &#x2F;data&#x2F;oracle&#x2F;oradata&#x2F;recovery_area 
CONNECT sys&#x2F;Oracle123 AS SYSDBA<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">alter</span> system <span class="token keyword">set</span> db_recovery_file_dest_size <span class="token operator">=</span> <span class="token number">60</span>G<span class="token punctuation">;</span>
<span class="token keyword">alter</span> system <span class="token keyword">set</span> db_recovery_file_dest <span class="token operator">=</span> <span class="token string">'/opt/soft/oracle12c/oradata/oradb/archive_log'</span> scope<span class="token operator">=</span>spfile<span class="token punctuation">;</span>
<span class="token keyword">shutdown</span> immediate<span class="token punctuation">;</span>
startup mount<span class="token punctuation">;</span>
<span class="token keyword">alter</span> <span class="token keyword">database</span> archivelog<span class="token punctuation">;</span>
<span class="token keyword">alter</span> <span class="token keyword">database</span> <span class="token keyword">open</span><span class="token punctuation">;</span>
<span class="token comment">-- 检查是否启用了日志归档</span>
<span class="token comment">-- Should now "Database log mode: Archive Mode"</span>
archive log list<span class="token punctuation">;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
注意：</li>
<li>启用日志归档需要重启数据库，尝试时注意</li>
<li>归档日志会占用大量磁盘空间，建议定期清理过期日志</li>
<li>必须为捕获的表或数据库启用补充日志记录，以便数据更改捕获已更改数据库行的之前状态</li>
</ul>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 为特定表启用补充日志记录：</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> flinkuser<span class="token punctuation">.</span>GJC_TEST_CDC <span class="token keyword">ADD</span> SUPPLEMENTAL LOG <span class="token keyword">DATA</span> <span class="token punctuation">(</span><span class="token keyword">ALL</span><span class="token punctuation">)</span> <span class="token keyword">COLUMNS</span><span class="token punctuation">;</span>
<span class="token comment">-- 为数据库启用补充日志记录</span>
<span class="token keyword">ALTER</span> <span class="token keyword">DATABASE</span> <span class="token keyword">ADD</span> SUPPLEMENTAL LOG <span class="token keyword">DATA</span><span class="token punctuation">;</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>创建用户并赋权限<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- Create Tablespace</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLESPACE</span> logminer_tbs DATAFILE <span class="token string">'/data/oracle/oradata/orcl/logminer_tbs.dbf'</span> SIZE <span class="token number">25</span>M REUSE AUTOEXTEND <span class="token keyword">ON</span> MAXSIZE UNLIMITED<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> <span class="token keyword">USER</span> flinkuser IDENTIFIED <span class="token keyword">BY</span> flinkpw <span class="token keyword">DEFAULT</span> <span class="token keyword">TABLESPACE</span> LOGMINER_TBS QUOTA UNLIMITED <span class="token keyword">ON</span> LOGMINER_TBS<span class="token punctuation">;</span>
  <span class="token keyword">GRANT</span> <span class="token keyword">CREATE</span> <span class="token keyword">SESSION</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
  <span class="token keyword">GRANT</span> <span class="token keyword">SET</span> CONTAINER <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$<span class="token keyword">DATABASE</span> <span class="token keyword">to</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> FLASHBACK <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
  <span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> SELECT_CATALOG_ROLE <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> EXECUTE_CATALOG_ROLE <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ANY</span> <span class="token keyword">TRANSACTION</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> LOGMINING <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>

<span class="token keyword">GRANT</span> <span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">LOCK</span> <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALTER</span> <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">CREATE</span> SEQUENCE <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>

<span class="token keyword">GRANT</span> <span class="token keyword">EXECUTE</span> <span class="token keyword">ON</span> DBMS_LOGMNR <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">EXECUTE</span> <span class="token keyword">ON</span> DBMS_LOGMNR_D <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>

<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOG <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOG_HISTORY <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGMNR_LOGS <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGMNR_CONTENTS <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGMNR_PARAMETERS <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGFILE <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$ARCHIVED_LOG <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$ARCHIVE_DEST_STATUS <span class="token keyword">TO</span> flinkuser<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>在Navicat里创建Oracle表，并插入几条数据</li>
<li>在sql-client创建表映射<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 注意，这里的字段名需要和oracle里保持一样，区分大小写的</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> gjc_test_oracle <span class="token punctuation">(</span>
   id <span class="token keyword">INT</span><span class="token punctuation">,</span>
   name STRING<span class="token punctuation">,</span>
   age <span class="token keyword">INT</span><span class="token punctuation">,</span>
   <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">NOT</span> ENFORCED
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'oracle-cdc'</span><span class="token punctuation">,</span>
<span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'172.16.109.130'</span><span class="token punctuation">,</span>
<span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'1521'</span><span class="token punctuation">,</span>
<span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'flinkuser'</span><span class="token punctuation">,</span>
<span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'flinkpw'</span><span class="token punctuation">,</span>
<span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'orcl'</span><span class="token punctuation">,</span>
<span class="token string">'schema-name'</span> <span class="token operator">=</span> <span class="token string">'FLINKUSER'</span><span class="token punctuation">,</span>
<span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'GJC_TEST_CDC'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> gjc_test_oracle<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
遇到的问题：</li>
</ul>
<ol>
<li>一开始Oracle字段是小写的，但是，flinksql里创建的字段是大写的，导致数据能够识别到（日志里能看到有几条记录），但是控制台没有数据输出（其实是字段名映射不上去）</li>
<li>flinkcdc可以正常采集没有主键的表，增删改查都可以</li>
</ol>
<h4 id="CDB数据库开启cdc"><a href="#CDB数据库开启cdc" class="headerlink" title="CDB数据库开启cdc"></a>CDB数据库开启cdc</h4><ul>
<li>启用日志归档<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">sqlplus <span class="token operator">/</span>nolog
  <span class="token keyword">CONNECT</span> sys<span class="token operator">/</span>password <span class="token keyword">AS</span> SYSDBA
  <span class="token keyword">alter</span> system <span class="token keyword">set</span> db_recovery_file_dest_size <span class="token operator">=</span> <span class="token number">10</span>G<span class="token punctuation">;</span>
  <span class="token comment">-- should exist</span>
  <span class="token keyword">alter</span> system <span class="token keyword">set</span> db_recovery_file_dest <span class="token operator">=</span> <span class="token string">'/opt/soft/oracle12c/oradata/recovery_area'</span> scope<span class="token operator">=</span>spfile<span class="token punctuation">;</span>
  <span class="token keyword">alter</span> system <span class="token keyword">set</span> archive_lag_target<span class="token operator">=</span><span class="token number">600</span> scope<span class="token operator">=</span>both<span class="token punctuation">;</span>    <span class="token comment">--解决ORA-04036: 实例使用的 PGA 内存超出 PGA_AGGREGATE_LIMIT</span>
  <span class="token keyword">shutdown</span> immediate
  startup mount
  <span class="token keyword">alter</span> <span class="token keyword">database</span> archivelog<span class="token punctuation">;</span>
  <span class="token keyword">alter</span> <span class="token keyword">database</span> <span class="token keyword">open</span><span class="token punctuation">;</span>
  <span class="token comment">-- Should show "Database log mode: Archive Mode"</span>
  archive log list
  <span class="token keyword">exit</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>创建用户并赋权限<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLESPACE</span> logminer_tbs DATAFILE <span class="token string">'/opt/soft/oracle12c/oradata/orcl/logminer_tbs.dbf'</span> SIZE <span class="token number">25</span>M REUSE AUTOEXTEND <span class="token keyword">ON</span> MAXSIZE UNLIMITED<span class="token punctuation">;</span>  
<span class="token keyword">CREATE</span> <span class="token keyword">USER</span> flinkuser IDENTIFIED <span class="token keyword">BY</span> flinkpw <span class="token keyword">DEFAULT</span> <span class="token keyword">TABLESPACE</span> LOGMINER_TBS QUOTA UNLIMITED <span class="token keyword">ON</span> LOGMINER_TBS<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">CREATE</span> <span class="token keyword">SESSION</span> <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SET</span> CONTAINER <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$<span class="token keyword">DATABASE</span> <span class="token keyword">to</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> FLASHBACK <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> SELECT_CATALOG_ROLE <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> EXECUTE_CATALOG_ROLE <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ANY</span> <span class="token keyword">TRANSACTION</span> <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> LOGMINING <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">LOCK</span> <span class="token keyword">ANY</span> <span class="token keyword">TABLE</span> <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">CREATE</span> SEQUENCE <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>

<span class="token keyword">GRANT</span> <span class="token keyword">EXECUTE</span> <span class="token keyword">ON</span> DBMS_LOGMNR <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">EXECUTE</span> <span class="token keyword">ON</span> DBMS_LOGMNR_D <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>

<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOG <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOG_HISTORY <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGMNR_LOGS <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGMNR_CONTENTS <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGMNR_PARAMETERS <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$LOGFILE <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$ARCHIVED_LOG <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">SELECT</span> <span class="token keyword">ON</span> V_$ARCHIVE_DEST_STATUS <span class="token keyword">TO</span> flinkuser CONTAINER<span class="token operator">=</span><span class="token keyword">ALL</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> gjc_test_oracle <span class="token punctuation">(</span>
   id <span class="token keyword">INT</span><span class="token punctuation">,</span>
   name STRING<span class="token punctuation">,</span>
   <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> <span class="token operator">NOT</span> ENFORCED
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
<span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'oracle-cdc'</span><span class="token punctuation">,</span>
<span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'172.16.101.223'</span><span class="token punctuation">,</span>
<span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'1521'</span><span class="token punctuation">,</span>
<span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'c##flinkuser'</span><span class="token punctuation">,</span>
<span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'dbz'</span><span class="token punctuation">,</span>
<span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'orcl'</span><span class="token punctuation">,</span>
<span class="token string">'schema-name'</span> <span class="token operator">=</span> <span class="token string">'C##FLINKUSER'</span><span class="token punctuation">,</span>
<span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'GJC_TEST_CDC'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.strategy'</span> <span class="token operator">=</span> <span class="token string">'online_catalog'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.continuous.mine'</span> <span class="token operator">=</span> <span class="token string">'true'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

</li>
</ul>
<p>遇到的问题：</p>
<ul>
<li>cdb默认创建普通用户需要c##开头，如果实在不想c##开头，可以通过设置<code>alter session set &quot;_ORACLE_SCRIPT&quot;=true;</code>后再创建用户</li>
<li>创建c##用户，再flinksql中也是可以正常使用的，这个没什么关系，只是名字看起来别扭</li>
<li>默认pdb未启动，需手动启动pdb，不启动pdb，会报如下错误<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Sink: Collect table sink (1&#x2F;1)#1 (2663b9a93aca6d06f44204c23b976492) switched from RUNNING to FAILED with failure cause: com.ververica.cdc.connectors.shaded.org.apache.kafka.connect.errors.ConnectException: An exception occurred in the change event producer. This connector will be stopped.
  at io.debezium.pipeline.ErrorHandler.setProducerThrowable(ErrorHandler.java:42)
  at io.debezium.connector.oracle.logminer.LogMinerStreamingChangeEventSource.execute(LogMinerStreamingChangeEventSource.java:208)
  at io.debezium.pipeline.ChangeEventSourceCoordinator.streamEvents(ChangeEventSourceCoordinator.java:152)
  at io.debezium.pipeline.ChangeEventSourceCoordinator.lambda$start$0(ChangeEventSourceCoordinator.java:119)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
  at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: ORA-65024: 可插入数据库  未打开。
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_INTERNAL&quot;, line 7750
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_INTERNAL&quot;, line 4812
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_INTERNAL&quot;, line 4999
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_INTERNAL&quot;, line 7601
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_INTERNAL&quot;, line 7764
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_INTERNAL&quot;, line 7920
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR_D&quot;, line 12
ORA-06512: 在 line 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
启动pdb命令：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--查看数据库中pdb列表：</span>
<span class="token keyword">show</span> pdbs<span class="token punctuation">;</span>
<span class="token comment">--   CON_ID CON_NAME			  OPEN MODE  RESTRICTED</span>
<span class="token comment">---------- ------------------------------ ---------- ----------</span>
<span class="token comment">--	 2 PDB$SEED			  READ ONLY  NO</span>
<span class="token comment">--	 3 DGWORCL			  MOUNTED</span>
<span class="token comment">-- 可以看到，默认是MOUNTED,需要手动打开</span>
<span class="token keyword">alter</span> pluggable <span class="token keyword">database</span> <span class="token keyword">all</span> <span class="token keyword">open</span><span class="token punctuation">;</span>
<span class="token comment">--报错：Warning: PDB altered with errors.，这个是因为PDB$SEED</span>
<span class="token comment">--再次查看状态</span>
<span class="token keyword">show</span> pdbs<span class="token punctuation">;</span>
<span class="token comment">--    CON_ID CON_NAME			  OPEN MODE  RESTRICTED</span>
<span class="token comment">---------- ------------------------------ ---------- ----------</span>
<span class="token comment">--	 2 PDB$SEED			  READ ONLY  NO</span>
<span class="token comment">--	 3 DGWORCL			  READ WRITE YES</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
然后再在flink的sql-client里执行命令，就可以正常读取oracle数据了，数据增删改查也都可以看到</li>
</ul>
<h4 id="flinkcdc采集oracle数据延迟大"><a href="#flinkcdc采集oracle数据延迟大" class="headerlink" title="flinkcdc采集oracle数据延迟大"></a>flinkcdc采集oracle数据延迟大</h4><p>官网给出解决方案：<br>在flinksql中加入以下参数：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token string">'debezium.log.mining.strategy'</span> <span class="token operator">=</span> <span class="token string">'online_catalog'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.continuous.mine'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<blockquote>
<p>oracle-cdc会调用一个checkpoint的锁，如果checkpoint频率很慢，就会导致数据有延迟，如果想要降低数据延迟，最好是降低ck时间</p>
</blockquote>
<p>实际测试，在PDB方式的数据库，可以正常执行，并且，速度明显加快，但是，在CDB数据库，会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">com.ververica.cdc.connectors.shaded.org.apache.kafka.connect.errors.ConnectException: An exception occurred in the change event producer. This connector will be stopped.
	at io.debezium.pipeline.ErrorHandler.setProducerThrowable(ErrorHandler.java:42) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at io.debezium.connector.oracle.logminer.LogMinerStreamingChangeEventSource.execute(LogMinerStreamingChangeEventSource.java:208) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at io.debezium.pipeline.ChangeEventSourceCoordinator.streamEvents(ChangeEventSourceCoordinator.java:152) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at io.debezium.pipeline.ChangeEventSourceCoordinator.lambda$start$0(ChangeEventSourceCoordinator.java:119) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_291]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_291]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_291]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_291]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_291]
Caused by: java.sql.SQLException: ORA-01435: 用户不存在
ORA-06512: 在 &quot;SYS.DBMS_LOGMNR&quot;, line 58
ORA-06512: 在 line 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>为啥会报用户名不存在呢？而且，快照数据已经读取到了，数据能够正常输出的<br>问题原因：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">在CDB内创建用户分配表空间时，所分配的表空间必须在PDB和CDB中同时存在，否则会报错。如果是在PDB与CDB有相同表空间的情况下给CDB用户分配表空间，则会分配CDB的表空间，给用户PDB的表空间并不受影响。所以要在PDB内创建相同的表空间，然后再回CDB创建用户<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里在官网上其实是创建了2个相同的命名空间，但是，在测试的时候，把pdb的命名空间给忽略了，导致一直报错，正确的操作方法：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">sqlplus <span class="token operator">/</span> <span class="token keyword">as</span> sysdba
  <span class="token keyword">CREATE</span> <span class="token keyword">TABLESPACE</span> logminer_tbs DATAFILE <span class="token string">'/usr/local/products/oradata/orcl/logminer_tbs.dbf'</span> 
  SIZE <span class="token number">25</span>M REUSE AUTOEXTEND <span class="token keyword">ON</span> MAXSIZE UNLIMITED<span class="token punctuation">;</span>
<span class="token comment">-- 这里切换到pdb下，使用官网的方式，直接使用sqlplus sys/OraPasswd1@//150.158.190.192:1539/ORCLPDB1 as sysdba ，连接不进去，交互式输入用户名密码，其实连接还是CDB</span>
<span class="token comment">-- 切换容器 这里需要权限</span>
  <span class="token keyword">alter</span> <span class="token keyword">session</span> <span class="token keyword">set</span> container <span class="token operator">=</span> ORCLPDB1<span class="token punctuation">;</span>
<span class="token comment">--在PDB下创建相同的表空间，并且，路径要和CDB的不一样</span>
  <span class="token keyword">CREATE</span> <span class="token keyword">TABLESPACE</span> logminer_tbs DATAFILE <span class="token string">'/usr/local/products/oradata/orcl/orclpdb1/logminer_tbs.dbf'</span> 
  SIZE <span class="token number">25</span>M REUSE AUTOEXTEND <span class="token keyword">ON</span> MAXSIZE UNLIMITED<span class="token punctuation">;</span>
<span class="token comment">-- 然后再去创建用户名，给用户赋权</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="报错：ORA-00257-archiver-error-Connect-internal-only-until-freed。"><a href="#报错：ORA-00257-archiver-error-Connect-internal-only-until-freed。" class="headerlink" title="报错：ORA-00257: archiver error. Connect internal only, until freed。"></a>报错：ORA-00257: archiver error. Connect internal only, until freed。</h4><p>flink程序报错ORA-00257: archiver error. Connect internal only, until freed。<br>该错误是由于归档日志满了，造成的。<br>查看了下V$FLASH_RECOVERY_AREA_USAGE，看看归档目录使用的情况。果然是归档满了。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span>  V$FLASH_RECOVERY_AREA_USAGE<span class="token punctuation">;</span>

FILE_TYPE    PERCENT_SPACE_USED PERCENT_SPACE_RECLAIMABLE NUMBER_OF_FILES
<span class="token comment">------------ ------------------ ------------------------- ---------------</span>
CONTROLFILE                   <span class="token number">0</span>                         <span class="token number">0</span>               <span class="token number">0</span>
ONLINELOG                     <span class="token number">0</span>                         <span class="token number">0</span>               <span class="token number">0</span>
ARCHIVELOG                  <span class="token number">99.9</span>                         <span class="token number">0</span>               <span class="token number">255</span>
BACKUPPIECE                   <span class="token number">0</span>                         <span class="token number">0</span>               <span class="token number">0</span>
IMAGECOPY                     <span class="token number">0</span>                         <span class="token number">0</span>               <span class="token number">0</span>
FLASHBACKLOG                  <span class="token number">0</span>                         <span class="token number">0</span>               <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注：可以看出，ARCHIVELOG日志已经达到99.9%了。造成归档满的原因是因为有一个用户在做大量更新操作，由于更新操作产生大量重做日志，<br>归档日志切换频繁。解决方法是要把大量归档日志清除掉!<br>有两种方式可以解决该问题。<br>一使用RMAN清除归档日志。<br>二修改闪回恢复区的大小DB_RECOVERY_FILE_DEST_SIZE。</p>
<ul>
<li>第一种使用RMAN清除归档日志。<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">rman
<span class="token keyword">connect</span> target <span class="token operator">/</span>
crosscheck archivelog <span class="token keyword">all</span><span class="token punctuation">;</span>                                      <span class="token comment">-- 校验日志的可用性</span>
list expired archivelog <span class="token keyword">all</span><span class="token punctuation">;</span>                                    <span class="token comment">--->列出所有失效的归档日志</span>
<span class="token keyword">delete</span> expired archivelog <span class="token keyword">all</span><span class="token punctuation">;</span>
<span class="token keyword">delete</span> archivelog until sequence <span class="token number">16</span><span class="token punctuation">;</span>                            <span class="token comment">--->删除log sequence为16及16之前的所有归档日志</span>
<span class="token keyword">delete</span> archivelog <span class="token keyword">all</span> completed before <span class="token string">'sysdate-7'</span><span class="token punctuation">;</span>             <span class="token comment">--->删除系统时间7天以前的归档日志，不会删除闪回区有效的归档日志</span>
<span class="token keyword">delete</span> archivelog <span class="token keyword">all</span> completed before <span class="token string">'sysdate - 1'</span><span class="token punctuation">;</span>           <span class="token comment">--->同上，1天以前的</span>
<span class="token keyword">delete</span> archivelog <span class="token keyword">from</span> <span class="token keyword">time</span> <span class="token string">'sysdate-1'</span><span class="token punctuation">;</span>                        <span class="token comment">--->注意这个命令，删除系统时间1天以内到现在的归档日志</span>
<span class="token keyword">delete</span> noprompt archivelog <span class="token keyword">all</span> completed before <span class="token string">'sysdate'</span><span class="token punctuation">;</span>
<span class="token keyword">delete</span> noprompt archivelog <span class="token keyword">all</span> completed before <span class="token string">'sysdate - 3/24'</span><span class="token punctuation">;</span>      <span class="token comment">--->该命令清除所有的归档日志</span>
<span class="token keyword">delete</span> noprompt archivelog <span class="token keyword">all</span><span class="token punctuation">;</span>                                 <span class="token comment">--->同上一命令</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
删除以后再次查看使用率，正常了</li>
</ul>
<ul>
<li>第二种方法就是增大闪回恢复区的大小。如下：</li>
</ul>
<h4 id="当serivce-name与sid不一样，报错如下："><a href="#当serivce-name与sid不一样，报错如下：" class="headerlink" title="当serivce_name与sid不一样，报错如下："></a>当serivce_name与sid不一样，报错如下：</h4><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: oracle.net.ns.NetException: Listener refused the connection with the following error:
ORA-12514, TNS:listener does not currently know of service requested in connect descriptor
 
	at oracle.net.ns.NSProtocolNIO.negotiateConnection(NSProtocolNIO.java:284)
	at oracle.net.ns.NSProtocol.connect(NSProtocol.java:340)
	at oracle.jdbc.driver.T4CConnection.connect(T4CConnection.java:1596)
	at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:588)
	... 21 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="flinkcdc采集大数据量oracle数据（性能测试）"><a href="#flinkcdc采集大数据量oracle数据（性能测试）" class="headerlink" title="flinkcdc采集大数据量oracle数据（性能测试）"></a>flinkcdc采集大数据量oracle数据（性能测试）</h4><ol>
<li>实时采集oracle数据延迟过大，平均延迟在3秒左右<br>通过设置以下参数提高实时采集的速度：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--source端：</span>
   <span class="token string">'debezium.log.mining.strategy'</span> <span class="token operator">=</span> <span class="token string">'online_catalog'</span><span class="token punctuation">,</span>
   <span class="token string">'debezium.log.mining.continuous.mine'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
   <span class="token string">'debezium.log.mining.batch.size.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
   <span class="token string">'debezium.log.mining.batch.size.default'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
   <span class="token string">'debezium.log.mining.sleep.time.default.ms'</span> <span class="token operator">=</span> <span class="token string">'10'</span><span class="token punctuation">,</span>
   <span class="token string">'debezium.poll.interval.ms'</span> <span class="token operator">=</span> <span class="token string">'10'</span><span class="token punctuation">,</span>
<span class="token comment">--sink端：</span>
   <span class="token string">'sink.buffer-flush.max-rows'</span> <span class="token operator">=</span> <span class="token string">'1000000'</span><span class="token punctuation">,</span>
   <span class="token string">'sink.buffer-flush.max-bytes'</span> <span class="token operator">=</span> <span class="token string">'300000000'</span><span class="token punctuation">,</span>
   <span class="token string">'sink.buffer-flush.interval-ms'</span> <span class="token operator">=</span> <span class="token string">'1000'</span><span class="token punctuation">,</span>        <span class="token comment">--主要是这个</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>starrocks数据有换行符，数据错位：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token string">'sink.properties.row_delimiter'</span> <span class="token operator">=</span> <span class="token string">'^B'</span><span class="token punctuation">,</span>
<span class="token string">'sink.properties.column_separator'</span> <span class="token operator">=</span> <span class="token string">'^A'</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>导入大表（扫描时间很长的表），任务自动重启：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> execution<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span><span class="token keyword">interval</span> <span class="token operator">=</span> <span class="token number">2</span>min<span class="token punctuation">;</span>
<span class="token keyword">set</span> execution<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span>tolerable<span class="token operator">-</span>failed<span class="token operator">-</span>checkpoints <span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">;</span>    <span class="token comment">-- 您需要设置num值来调整任务允许Checkpoint失败的次数。num需要为0或正整数。如果num为0时，则表示不允许存在任何Checkpoint异常或者失败。</span>
<span class="token keyword">set</span> restart<span class="token operator">-</span>strategy <span class="token operator">=</span><span class="token keyword">fixed</span><span class="token operator">-</span>delay<span class="token punctuation">;</span>
<span class="token keyword">set</span> restart<span class="token operator">-</span>strategy<span class="token punctuation">.</span><span class="token keyword">fixed</span><span class="token operator">-</span>delay<span class="token punctuation">.</span>attempts <span class="token operator">=</span> <span class="token number">2147483647</span><span class="token punctuation">;</span>   <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
这里简单解释一下flink ck的重启策略：<br>flink checkpoint 的重启策略：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">假如 restart-strategy: fixed-delay
restart-strategy.fixed-delay.attempts&#x3D;3 [default]
restart-strategy.fixed-delay.delay&#x3D;2s [default]

举个栗子：
&#x3D;&#x3D;&#x3D;&gt; 假如 delay&#x3D;1s,attempts&#x3D;1,那么重启的策略就为每2秒尝试重启一次，要么重启成功，要么失败进入下一次重启尝试，如果累计重试次数达到3次但是任然没有成功，那么这个task重启就算失败<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><code>Caused by: java.sql.SQLException: ORA-04036: 实例使用的 PGA 内存超出 PGA_AGGREGATE_LIMIT</code><br>具体报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">com.ververica.cdc.connectors.shaded.org.apache.kafka.connect.errors.ConnectException: An exception occurred in the change event producer. This connector will be stopped.
	at io.debezium.pipeline.ErrorHandler.setProducerThrowable(ErrorHandler.java:42) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at io.debezium.connector.oracle.logminer.LogMinerStreamingChangeEventSource.execute(LogMinerStreamingChangeEventSource.java:208) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at io.debezium.pipeline.ChangeEventSourceCoordinator.streamEvents(ChangeEventSourceCoordinator.java:152) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at io.debezium.pipeline.ChangeEventSourceCoordinator.lambda$start$0(ChangeEventSourceCoordinator.java:119) ~[flink-sql-connector-oracle-cdc-2.2.1.jar:2.2.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_311]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_311]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_311]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_311]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_311]
Caused by: java.sql.SQLException: ORA-04036: 实例使用的 PGA 内存超出 PGA_AGGREGATE_LIMIT<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
查看oracle当前设置参数：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">show</span> parameter pga<span class="token punctuation">;</span>
<span class="token comment">--------------------------------</span>
NAME				     <span class="token keyword">TYPE</span>       <span class="token keyword">VALUE</span>
<span class="token comment">---------------   --------------- ----------------------</span>

pga_aggregate_limit	    big <span class="token keyword">integer</span>    <span class="token number">6400</span>M
pga_aggregate_target	big <span class="token keyword">integer</span>    <span class="token number">3200</span>M
<span class="token comment">--查看日志归档频率时间</span>
<span class="token keyword">show</span> parameter archive_lag<span class="token punctuation">;</span>
NAME				     <span class="token keyword">TYPE</span>   <span class="token keyword">VALUE</span>
<span class="token comment">--------------------- --------  --------------</span>
archive_lag_target   <span class="token keyword">integer</span>    <span class="token number">600</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
可以在oracle中设置：<br><code>alter system set archive_lag_target=60 scope=both;</code><br>或者设置<code>log.mining.session.max.xs = 300000</code></li>
</ol>
<p>flinkcdc引用的debeziem1.5，还没有<code>log.mining.session.max.xs</code>参数，在1.9版本才能使用。所以，还是得在oracle中设置<code>alter system set archive_lag_target=1200 scope=both;</code><br>原因：<br>对于低容量系统，当长时间使用同一会话时，LogMiner 会话可能会消耗过多的 PGA 内存。默认行为是仅在检测到日志切换时使用新的 LogMiner 会话</p>
<p>这里同时启动多个实时采集任务，还是会报这个错误，这里网上给的办法是：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#1. 设置 PGA_AGGREGATE_LIMIT &#x3D; 0 , 消除每个会话使用PGA的限制（如11g）
alter system set pga_aggregate_limit&#x3D;0 scope&#x3D;both;
#2. 增大PGA_AGGREGATE_LIMIT
alter system set pga_aggregate_limit&#x3D;16384M scope&#x3D;both;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里先把上面1200秒给更低的时间试试</p>
<p><img src="/uploads/202206/debezium%E9%87%87%E9%9B%86oracle%E5%AF%BC%E8%87%B4PGA%E5%86%85%E5%AD%98%E8%B6%85%E5%87%BA.png" alt="debezium采集oracle导致PGA内存超出"></p>
<h4 id="多个flinkcdc任务共同采集oracle，数据延迟巨大"><a href="#多个flinkcdc任务共同采集oracle，数据延迟巨大" class="headerlink" title="多个flinkcdc任务共同采集oracle，数据延迟巨大"></a>多个flinkcdc任务共同采集oracle，数据延迟巨大</h4><p>单个任务采集oracle，速度已经可以控制在1秒以内了，但是，多个任务采集oracle，这边的延迟变得很大，具体原因还不太清楚<br>但是，这里猜测有以下几种原因：</p>
<ol>
<li>每个任务都会起一个进程去读取logminer，而logminer的数据是存在pga内存里的，就会导致pga内存很高</li>
<li>这里通过查看服务器的cpu使用情况，发现每个cdc任务占用cpu特别高，19个任务就可能导致任务玩不转了</li>
</ol>
<p>根本原因：<br>oracle-cdc底层调用的是oracle的Logminer，而每个cdc任务启动以后，都会调用Logminer，这会忘redolog里写大量的日志，一开始的设置的微批步长太小了，导致在任务刚开始启动的时候，读取的日志远远追不上日志生成的速度<br>之前的设置：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token string">'debezium.log.mining.strategy'</span> <span class="token operator">=</span> <span class="token string">'online_catalog'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.continuous.mine'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.poll.interval.ms'</span> <span class="token operator">=</span> <span class="token string">'5'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.batch.size.min'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.batch.size.default'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.sleep.time.default.ms'</span> <span class="token operator">=</span> <span class="token string">'10'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.session.max.xs'</span> <span class="token operator">=</span> <span class="token string">'300000'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.lob.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.fetch.size'</span> <span class="token operator">=</span> <span class="token string">'5000'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.delay.ms'</span> <span class="token operator">=</span> <span class="token string">'3000'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>优化后的设置：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token string">'debezium.log.mining.strategy'</span> <span class="token operator">=</span> <span class="token string">'online_catalog'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.continuous.mine'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.poll.interval.ms'</span> <span class="token operator">=</span> <span class="token string">'5'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.batch.size.min'</span> <span class="token operator">=</span> <span class="token string">'50'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.batch.size.default'</span> <span class="token operator">=</span> <span class="token string">'100'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.batch.size.max'</span> <span class="token operator">=</span> <span class="token string">'10000'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.sleep.time.default.ms'</span> <span class="token operator">=</span> <span class="token string">'10'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.sleep.time.max.ms'</span> <span class="token operator">=</span> <span class="token string">'2000'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.sleep.time.increment.ms'</span> <span class="token operator">=</span> <span class="token string">'50'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.log.mining.view.fetch.size'</span> <span class="token operator">=</span> <span class="token string">'500'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.lob.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.fetch.size'</span> <span class="token operator">=</span> <span class="token string">'5000'</span><span class="token punctuation">,</span>
<span class="token string">'debezium.snapshot.delay.ms'</span> <span class="token operator">=</span> <span class="token string">'3000'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>具体可以参考<a href="https://m.php.cn/oracle/487748.html">最系统掌握Flink CDC系列之实时抽取Oracle数据（排雷和调优实践）</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>flink资源管理</title>
    <url>/2022/05/07/flink%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>flink资源管理</li>
</ul>
<a id="more"></a>


<h2 id="flink资源管理"><a href="#flink资源管理" class="headerlink" title="flink资源管理"></a>flink资源管理</h2><p>本文主要讲述flink的资源管理，flink通过yarn申请资源，通过提交的参数，如何计算出整体所消耗的资源</p>
<h3 id="Flink的Slot和并行度"><a href="#Flink的Slot和并行度" class="headerlink" title="Flink的Slot和并行度"></a>Flink的Slot和并行度</h3><h4 id="并行度"><a href="#并行度" class="headerlink" title="并行度"></a>并行度</h4><p>一个Flink程序由多个任务（Task）组成(source、transformation和 sink)。 一个任务由多个并行的实例(线程)来执行(SubTask)， 一个任务的并行实例(线程)数目就被称为该任务的并行度。<br>Flink中的程序本质上是并行的和分布式的。在执行期间，一个流具有一个或多个流分区，并且每个算子具有一个或多个算子子任务。算子子任务之间彼此独立，并可以在在不同的线程(甚至服务器)中执行,算子的并行度决定了算子子任务数量,同一程序的不同算子可设置不同的并行度。</p>
<h4 id="Slot"><a href="#Slot" class="headerlink" title="Slot"></a>Slot</h4><p>每个 worker（TaskManager）都是一个 JVM 进程，可以在单独的线程中执行一个或多个 subtask。为了控制一个 TaskManager 中接受多少个 task，就有了所谓的 task slots（至少一个）。每个 task slot 代表 TaskManager 中资源的固定子集。<br>每个 TaskManager 有一个 slot，这意味着每个 task 组都在单独的 JVM 中运行（例如，可以在单独的容器中启动）。具有多个 slot 意味着更多 subtask 共享同一 JVM。<br><strong>总结：</strong></p>
<ul>
<li>Flink中slot是任务执行所申请资源的最小单元，同一个TaskManager上的所有slot都只是做了内存分离，没有做CPU隔离。</li>
<li>每一个TaskManager都是一个JVM进程，如果某个TaskManager 上只有一个 slot，这意味着每个 task 组都在单独的 JVM 中运行，如果有多个 slot 就意味着更多 subtask 共享同一 JVM。</li>
<li>一般情况下有多少个subtask，就是有多少个并行线程，而并行执行的subtask要发布到不同的slot中去执行。</li>
<li>Flink 默认会将能链接的算子尽可能地进行链接，也就是算子链，flink 会将同一个算子链分组内的subtask都发到同一个slot去执行，也就是说一个slot可能要执行多个subtask，即多个线程。</li>
<li>flink 可以根据需要手动地将各个算子隔离到不同的 slot 中。</li>
<li>一个任务所用的总共slot为所有资源隔离组所占用的slot之和，同一个资源隔离组内，按照算子的最大并行度来分配slot。<blockquote>
<p>个人理解，flink的slot就和spark的container类型，类似一个jvm虚拟机，但是它和container的不通指出在于，它只对内存隔离，不对cpu隔离<br>可以参考<a href="https://blog.51cto.com/u_15278282/2931810">Flink 中 slot ，task，并行度的概念以及与CPU，内存的关系</a></p>
</blockquote>
</li>
</ul>
<h3 id="通过提交的参数，如何计算出整体所消耗的资源"><a href="#通过提交的参数，如何计算出整体所消耗的资源" class="headerlink" title="通过提交的参数，如何计算出整体所消耗的资源"></a>通过提交的参数，如何计算出整体所消耗的资源</h3><p>这里整理了一下资源数的计算方法，总结来说：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">taskmanager个数 &#x3D; 并行度&#x2F;slot个数
总内存 &#x3D; jobmanager的内存 + taskmanager个数*taskmanager内存<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p><strong>注意：</strong><br>参数里的-yjm和-ytm都指的是每个jobmanager/taskmanager的内存，不是整体的内存数</p>
<p>举个例子：<br>一个Flink作业，设置了20个并行度，10个slot，yjm=1G，ytm=2G，此时需要启动20/10=2个taskmanager进程，同时还需要启动一个jobmanager进程，因此需要启动2+1=3个容器，核数为并行度+1=20+1=21，对应的截图如下<br><img src="/uploads/202204/flink-on-yarn%E8%B5%84%E6%BA%90%E7%94%B3%E8%AF%B7.png" alt="flink-on-yarn资源申请"></p>
<p>总内存数：1G + 2 * 2G = 5G</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -m yarn-cluster -yjm 1024m -ytm 2048m -yqu root.users.service-cloud -ynm warning1.2 -p 3 WarningStreamAnalysisService-1.2.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这个任务申请了资源为：1G的jobmanager内存，2G的taskmanager内存，3个并行度，slot数没有指定，所以是默认1个<br>如果要指定slot数，可以使用-ys<br>所以，这里的taskmanager数为 <code>3/1 = 3</code>个<br>总内存数为： 1G + 3 * 2G = 7G，整体申请了7G</p>
<h3 id="如何降低flink任务的资源"><a href="#如何降低flink任务的资源" class="headerlink" title="如何降低flink任务的资源"></a>如何降低flink任务的资源</h3><p>公司的数据量特别小，但是，每次flink任务的启动，最低都要启动2G的内存，很浪费，这里研究一下如何把任务启动的资源降到最低<br>首先，公司线上的任务都是提交到yarn上，所以，资源管理这块，需要从yarn和flink本身两个方面来考虑</p>
<h4 id="从flink方面降低资源"><a href="#从flink方面降低资源" class="headerlink" title="从flink方面降低资源"></a>从flink方面降低资源</h4><p>通过查找官网，我们知道，Flink JVM 进程的<em>进程总内存（Total Process Memory）</em>包含了由 Flink 应用使用的内存（Flink 总内存）以及由运行 Flink 的 JVM 使用的内存。 Flink 总内存（Total Flink Memory）包括 JVM 堆内存（Heap Memory）和堆外内存（Off-Heap Memory）。 其中堆外内存包括直接内存（Direct Memory）和本地内存（Native Memory）。<br><img src="/uploads/202204/flink%E6%80%BB%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.png" alt="flink总内存模型"><br>配置 Flink 进程内存最简单的方法是指定以下两个配置项中的任意一个：</p>
<table>
<thead>
<tr>
<th>配置项</th>
<th>TaskManager 配置参数</th>
<th>JobManager 配置参数</th>
</tr>
</thead>
<tbody><tr>
<td>Flink 总内存</td>
<td>taskmanager.memory.flink.size</td>
<td>jobmanager.memory.flink.size</td>
</tr>
<tr>
<td>进程总内存</td>
<td>taskmanager.memory.process.size</td>
<td>jobmanager.memory.process.size</td>
</tr>
</tbody></table>
<p>其中，有两种内存是可以通过指定在总内存中所占比例的方式进行配置，同时受限于相应的的最大/最小值范围。</p>
<ul>
<li>JVM 开销：可以配置占用进程总内存的固定比例</li>
<li>网络内存：可以配置占用 Flink 总内存的固定比例（仅针对 TaskManager）<br>这里需要注意的是，它们不是直接通过总内存的固定比例计算的，还需要和相应的最大值和最小值做比较，这里我们想要降低使用内存，所以需要关心它们的最低内存是多少，参数如下<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## jvm开销
taskmanager.memory.jvm-overhead.min: 192 mb
jobmanager.memory.jvm-overhead.min: 192 mb
# 网络内存
taskmanager.memory.network.min: 64mb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这里，我们把他们全部设置成0mb</li>
</ul>
<p>然后执行一下命令：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$&#123;FLINK_HOME&#125;&#x2F;bin&#x2F;flink run -m yarn-cluster -yjm 512m -ytm 512m -ynm gjc_test -c com.digiwin.test.FlinkTest FlinkTest-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>然后报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: TaskManager memory configuration failed: Sum of configured Framework Heap Memory (128.000mb (134217728 bytes)), Framework Off-Heap Memory (128.000mb (134217728 bytes)), Task Off-Heap Memory (0 bytes), Managed Memory (81.920mb (85899346 bytes)) and Network Memory (20.480mb (21474836 bytes)) exceed configured Total Flink Memory (204.800mb (214748364 bytes)).<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>翻译过来就是：主方法导致错误：TaskManager内存配置失败：配置的框架堆内存（128.000mb（134217728字节））、框架堆外内存（128.000mb（134217728字节））、任务堆外内存（0字节）、托管内存（81.920mb（85899346字节））和网络内存（20.480mb（21474836字节））的总和超过配置的Flink内存总量（204.800mb（214748364字节））。<br>剩下的就是把这几个内存的参数都调整一下就好了：</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>配置参数</th>
<th>默认值</th>
</tr>
</thead>
<tbody><tr>
<td>Framework Heap Memory</td>
<td>taskmanager.memory.framework.heap.size</td>
<td>128 mb</td>
</tr>
<tr>
<td>Framework Off-Heap Memory</td>
<td>taskmanager.memory.framework.off-heap.size</td>
<td>128 mb</td>
</tr>
<tr>
<td>Task Off-Heap Memory</td>
<td>taskmanager.memory.task.off-heap.size</td>
<td>0 bytes</td>
</tr>
<tr>
<td>Managed Memory</td>
<td>taskmanager.memory.managed.size,taskmanager.memory.managed.fraction</td>
<td>(none),(0.4)</td>
</tr>
<tr>
<td>Network Memory</td>
<td>taskmanager.memory.network.min,taskmanager.memory.network.max,taskmanager.memory.network.fraction</td>
<td>64 mb/1gb/0.1</td>
</tr>
</tbody></table>
<p>所以，我们这里需要把以下几个参数调整以下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">taskmanager.memory.framework.heap.size: 32mb
taskmanager.memory.framework.off-heap.size: 32mb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>这次把tm和jm内存都调整到256m，命令如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$&#123;FLINK_HOME&#125;&#x2F;bin&#x2F;flink run -m yarn-cluster -yjm 256m -ytm 256m -ynm gjc_test -c com.digiwin.test.FlinkTest FlinkTest-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>又报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: JobManager memory configuration failed: Sum of configured JVM Metaspace (256.000mb (268435456 bytes)) and JVM Overhead (25.600mb (26843546 bytes)) exceed configured Total Process Memory (256.000mb (268435456 bytes)).<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里的意思是，主方法导致错误：JobManager内存配置失败：配置的JVM元空间（256.000mb（268435456字节））和JVM开销（25.600mb（26843546字节））的总和超过配置的总进程内存（256.000mb（268435456字节））。<br>这里主要是JVM Metaspace的内存过大，需要调整以下参数：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">jobmanager.memory.jvm-metaspace.size: 64mb
taskmanager.memory.jvm-metaspace.size: 64mb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>完整的调整参数如下 ：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">taskmanager.memory.jvm-overhead.min: 0mb
jobmanager.memory.jvm-overhead.min: 0mb
taskmanager.memory.framework.heap.size: 32mb
taskmanager.memory.framework.off-heap.size: 32mb
jobmanager.memory.jvm-metaspace.size: 64mb
taskmanager.memory.jvm-metaspace.size: 64mb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>通过如上的参数设置完成以后，任务提交到yarn上，可以看到，tm和jm的内存确实降低了，效果如图：<br>jobmanager的内存使用情况<br><img src="/uploads/202204/jobmanager%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8.png" alt="jobmanager内存使用"><br>taskmanager的内存使用情况<br><img src="/uploads/202204/taskmanager%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8.png" alt="taskmanager内存使用"></p>
<p>但是yarn上的申请竟然还是2个G，效果如图：<br><img src="/uploads/202204/yarn%E4%B8%8A%E7%94%B3%E8%AF%B7%E7%9A%84%E5%86%85%E5%AD%98.png" alt="yarn上申请的内存"></p>
<p>出现这种问题，是因为任务提交到yarn上，资源也会收到yarn的控制，yarn上有参数控制每个container的最小内存，查看当前集群的设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yarn.scheduler.minimum-allocation-mb &#x3D; 1024mb;
yarn.scheduler.minimum-allocation-vcores&#x3D;1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>所以，需要再降低一下<code>yarn.scheduler.minimum-allocation-mb</code></p>
<p>注意： yarn的这两个配置，只能在yarn的配置文件里改，貌似不能通过传惨的方式去设置，试了很多次都不行，后面再留意以下看看</p>
<h3 id="每个任务设置不同的参数提交"><a href="#每个任务设置不同的参数提交" class="headerlink" title="每个任务设置不同的参数提交"></a>每个任务设置不同的参数提交</h3><ul>
<li>设置FLINK_CONF_DIR<br>当前都是再flink-conf.yml里设置的，会导致所有的任务都会使用这些参数，在线上肯定是不能这么设置的，一开始通过提交命令-D和-yD，但是，参数提交不成功，最后在官网找到解决办法</li>
</ul>
<ol>
<li>在自己的工程目录创建一个 conf 目录</li>
<li>复制${FLINK_HOME}/conf/flink-conf.yaml以及log4j.properties/log4j-cli.properties/log4j-console.properties到该目录</li>
<li>在执行<code>flink run</code>之前，先<code>export FLINK_CONF_DIR=$&#123;myDir&#125;</code><br>完整的提交脚本：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export FLINK_CONF_DIR&#x3D;&#x2F;root&#x2F;conf
$&#123;FLINK_HOME&#125;&#x2F;bin&#x2F;flink run -m yarn-cluster -yjm 256m -ytm 256m -ynm gjc_test -c com.digiwin.test.FlinkTest FlinkTest-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li>通过命令行参数设置<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -m yarn-cluster -ys 1 -ynm MoreTableCollection -yjm 1G -ytm 3G -yqu yfdl -p 1 -sae -yD env.java.opts&#x3D;&quot;-Dfile.encoding&#x3D;UTF-8 -Dsun.jnu.encoding&#x3D;UTF-8 -XX:+UseG1GC&quot; -yD taskmanager.memory.managed.fraction&#x3D;0.1 -yD taskmanager.memory.task.heap.size&#x3D;2048m -yD taskmanager.memory.network.fraction&#x3D;0.05 -yD taskmanager.memory.jvm-overhead.min&#x3D;10m -yD taskmanager.memory.jvm-overhead.fraction&#x3D;0.05 -c com.digiwin.ocean.OceanStarter ocean-1.0.jar -shost 172.16.101.223 -sport 1521 xxx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

</li>
</ul>
<h2 id="Flink内存模型"><a href="#Flink内存模型" class="headerlink" title="Flink内存模型"></a>Flink内存模型</h2><p>具体可以参考<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/memory/mem_setup/">flink官网的内存配置</a><br>着重看一下内存配置的taskmanager的内存模型详解 和jobmanager的内存模型详解</p>
<h3 id="jobmanager内存模型"><a href="#jobmanager内存模型" class="headerlink" title="jobmanager内存模型"></a>jobmanager内存模型</h3><p>jobmanager的内存模型详解在官网的位置：<br><img src="/uploads/202204/jobmanager%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.png" alt="jobmanager内存模型详解"></p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>配置参数</th>
<th>描述</th>
<th>默认值</th>
</tr>
</thead>
<tbody><tr>
<td>JVM 堆内存</td>
<td>jobmanager.memory.heap.size</td>
<td>JobManager 的 JVM 堆内存。</td>
<td>(none)</td>
</tr>
<tr>
<td>堆外内存</td>
<td>jobmanager.memory.off-heap.size</td>
<td>JobManager 的堆外内存（直接内存或本地内存）。</td>
<td>128mb</td>
</tr>
<tr>
<td>JVM Metaspace</td>
<td>jobmanager.memory.jvm-metaspace.size</td>
<td>Flink JVM 进程的 Metaspace。</td>
<td>256mb</td>
</tr>
<tr>
<td>JVM 开销</td>
<td>jobmanager.memory.jvm-overhead.min/max/fraction</td>
<td>用于其他 JVM 开销的本地内存，例如栈空间、垃圾回收空间等。该内存部分为基于进程总内存的受限的等比内存部分。</td>
<td>192 mb/1gb/0.1</td>
</tr>
</tbody></table>
<p>这里举个例子：<br>提交flink程序的时候，-yjm 256m 代表 flink的jobmananger总内存为256m<br>在flink-conf.yaml里添加以下参数：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">jobmanager.memory.jvm-metaspace.size: 110mb
jobmanager.memory.jvm-overhead.min: 0mb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>这时候，还有默认的参数没有指定，即<code>jobmanager.memory.jvm-overhead.fraction = 0.1</code>以及<code>jobmanager.memory.off-heap.size=128mb</code><br>这时候，程序会自动计算出total memory，<br>totalMemory = JVM对内存 + 堆外内存，但是，JVM堆内存没有默认值，只有堆外内存128M。所以，这里的totalMemory不应该直接用这两者相加，而应该是：<br>totalMemory = <code>-yjm 256m</code> -  <code>JVM Metaspace</code> - <code>JVM 开销</code><br>即 <code>256mb - 110mb(metaspace) - 256*0.1(jvm-overhead)</code> = 120.4<br>但是，120.4小于堆外内存(128m)，所以会报错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.configuration.IllegalConfigurationException: JobManager memory configuration failed: The configured Total Flink Memory (120.400mb (126248550 bytes)) is less than the configured Off-heap Memory (128.000mb (134217728 bytes)).
	at org.apache.flink.runtime.jobmanager.JobManagerProcessUtils.processSpecFromConfigWithNewOptionToInterpretLegacyHeap(JobManagerProcessUtils.java:78)
	at org.apache.flink.client.deployment.AbstractContainerizedClusterClientFactory.getClusterSpecification(AbstractContainerizedClusterClientFactory.java:43)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h3 id="taskmanager内存模型"><a href="#taskmanager内存模型" class="headerlink" title="taskmanager内存模型"></a>taskmanager内存模型</h3><p>Flink JVM 进程的<em>进程总内存（Total Process Memory）</em>包含了由 Flink 应用使用的内存（Flink 总内存）以及由运行 Flink 的 JVM 使用的内存。 其中，<em>Flink 总内存（Total Flink Memory）</em>包括 JVM 堆内存（Heap Memory）、<em>托管内存（Managed Memory）</em>以及其他直接内存（Direct Memory）或本地内存（Native Memory）。</p>
<p>taskmanager的内存模型详解在官网的位置：<br><img src="/uploads/202204/tasknamager%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E8%AF%A6%E8%A7%A3.png" alt="tasknamager内存模型详解"></p>
<table>
<thead>
<tr>
<th>参数名</th>
<th>配置参数</th>
<th>描述</th>
<th>默认值</th>
</tr>
</thead>
<tbody><tr>
<td>框架堆内存（Framework Heap Memory）</td>
<td>taskmanager.memory.framework.heap.size</td>
<td>用于 Flink 框架的 JVM 堆内存（进阶配置）。</td>
<td>128mb</td>
</tr>
<tr>
<td>任务堆内存（Task Heap Memory）</td>
<td>taskmanager.memory.task.heap.size</td>
<td>用于 Flink 应用的算子及用户代码的 JVM 堆内存。</td>
<td>none</td>
</tr>
<tr>
<td>托管内存（Managed memory）</td>
<td>taskmanager.memory.managed.size/fraction</td>
<td>由 Flink 管理的用于排序、哈希表、缓存中间结果及 RocksDB State Backend 的本地内存。</td>
<td>none/0.4</td>
</tr>
<tr>
<td>框架堆外内存（Framework Off-heap Memory）</td>
<td>taskmanager.memory.framework.off-heap.size</td>
<td>用于 Flink 框架的堆外内存（直接内存或本地内存）（进阶配置）。</td>
<td>128mb</td>
</tr>
<tr>
<td>任务堆外内存（Task Off-heap Memory）</td>
<td>taskmanager.memory.task.off-heap.size</td>
<td>用于 Flink 应用的算子及用户代码的堆外内存（直接内存或本地内存）。</td>
<td>0 bytes</td>
</tr>
<tr>
<td>网络内存（Network Memory）</td>
<td>taskmanager.memory.network.min/max/fraction</td>
<td>用于任务之间数据传输的直接内存（例如网络传输缓冲）。该内存部分为基于 Flink 总内存的受限的等比内存部分。这块内存被用于分配网络缓冲</td>
<td>64 mb/1 gb/0.1</td>
</tr>
<tr>
<td>JVM Metaspace</td>
<td>taskmanager.memory.jvm-metaspace.size</td>
<td>Flink JVM 进程的 Metaspace。</td>
<td>256 mb</td>
</tr>
<tr>
<td>JVM 开销</td>
<td>taskmanager.memory.jvm-overhead.min/max/fraction</td>
<td>用于其他 JVM 开销的本地内存，例如栈空间、垃圾回收空间等。该内存部分为基于进程总内存的受限的等比内存部分。</td>
<td>192mb/1gb/0.1</td>
</tr>
</tbody></table>
<p>举个例子：<br>提交flink程序的时候，-ytm 256m 代表 flink的taskmananger总内存为256m<br>和jobmanager的内存计算方法一样，taskmanager的totalMemory计算方法应该如下：<br>totalMemory = <code>256mb - 128mb(metaspace) - 256*0.1(jvm-overhead)</code> = 102.4mb<br>然后，内存模型里的networkMem和managedMem的比例都是根据这个totalMemory计算出来的<br>即networkMem = 102.4 * 0.1 = 10.24m<br>managedMem = 102.4 * 0.4 = 40.960m<br>因此，会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.configuration.IllegalConfigurationException: Sum of configured Framework Heap Memory (32.000mb (33554432 bytes)), Framework Off-Heap Memory (32.000mb (33554432 bytes)), Task Off-Heap Memory (0 bytes), Managed Memory (40.960mb (42949673 bytes)) and Network Memory (10.240mb (10737418 bytes)) exceed configured Total Flink Memory (102.400mb (107374182 bytes)).
	at org.apache.flink.runtime.util.config.memory.taskmanager.TaskExecutorFlinkMemoryUtils.deriveFromTotalFlinkMemory(TaskExecutorFlinkMemoryUtils.java:178)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<h2 id="Flink内存调优"><a href="#Flink内存调优" class="headerlink" title="Flink内存调优"></a>Flink内存调优</h2><p>找到taskmanager的java进程id</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ps -ef | grep flink<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">jmap -heap 152481

jmap -histo:live 152481 | more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title>hive杂记</title>
    <url>/2021/01/15/hive%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hive中的复杂数据类型数据如何导入(array)</li>
<li>hive中load数据到分区和add partition的区别：</li>
<li>hive引用udf的jar报无效</li>
<li>hive实现job并发执行</li>
<li>验证hive两个join的结果是否相等<a id="more"></a>
<h2 id="hive中的复杂数据类型数据如何导入-array"><a href="#hive中的复杂数据类型数据如何导入-array" class="headerlink" title="hive中的复杂数据类型数据如何导入(array)"></a>hive中的复杂数据类型数据如何导入(array)</h2><h3 id="创建hive表"><a href="#创建hive表" class="headerlink" title="创建hive表"></a>创建hive表</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>dws_search_by_program_set_count_his<span class="token punctuation">(</span>
  program_set_id string<span class="token punctuation">,</span> 
  click_array array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'#'</span>
<span class="token keyword">lines</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\n'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
其中click_array 为array类型。</li>
</ul>
<blockquote>
<p>注意：</p>
</blockquote>
<ul>
<li>在建表的时候一定要指定row format delimited，我这里指定了列与列质检为逗号，array的元素内容为#</li>
</ul>
<p>数据格式：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">100051130,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051133,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051134,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051136,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051138,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051140,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051157,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051161,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051163,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下面来导入数据：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/gold/dws_search_by_program_set_count_his.csv'</span> overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>dws_search_by_program_set_count_his<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>效果：<br><img src="/uploads/20210114/hive-import-data.png" alt="hive-import-data"></p>
<h2 id="hive中load数据到分区和add-partition的区别："><a href="#hive中load数据到分区和add-partition的区别：" class="headerlink" title="hive中load数据到分区和add partition的区别："></a>hive中load数据到分区和add partition的区别：</h2><p>load data的方式需要移动文件路径，如果把文件就放在分区位置，这时候如果用load data的方式，就会报错，需要用add partition的方式</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> dws<span class="token punctuation">.</span>dws_device_box_info_his_v2 <span class="token keyword">ADD</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>province_alias<span class="token operator">=</span><span class="token string">'js'</span><span class="token punctuation">,</span>dt<span class="token operator">=</span><span class="token string">'20190701'</span><span class="token punctuation">)</span> 
location <span class="token string">'hdfs://ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>如果用load data的方式：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'hdfs://ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701'</span> 
overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> dws<span class="token punctuation">.</span>dws_device_box_info_his_v2 <span class="token keyword">partition</span><span class="token punctuation">(</span>province_alias<span class="token operator">=</span><span class="token string">'js'</span><span class="token punctuation">,</span>dt<span class="token operator">=</span><span class="token string">'20190701'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">`</span><span class="token punctuation">`</span><span class="token punctuation">`</span><span class="token punctuation">`</span>
就会报错：
<span class="token punctuation">`</span><span class="token punctuation">`</span><span class="token punctuation">`</span>shell
FAILED: Execution Error<span class="token punctuation">,</span> <span class="token keyword">return</span> code <span class="token number">1</span> <span class="token keyword">from</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>MoveTask<span class="token punctuation">.</span> Unable <span class="token keyword">to</span> move source hdfs:<span class="token comment">//ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701 to destination hdfs://ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看出，报错是不能移动文件位置，因为文件已经在这个路径下了</p>
<p>总结：</p>
<ul>
<li>如果文件已经在分区的位置，这时候，需要用add partition的方式</li>
<li>如果文件不在分区的位置，这时候用load data的方式</li>
</ul>
<p>具体的可以参考<br><a href="https://blog.csdn.net/worldchinalee/article/details/80278111">hive中的复杂类型struct、array、map</a>，这里struct、array、map都有</p>
<h2 id="hive引用udf的jar报无效"><a href="#hive引用udf的jar报无效" class="headerlink" title="hive引用udf的jar报无效"></a>hive引用udf的jar报无效</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>原始的hive jar包在/opt/hive/auxlib/udf.jar，因为要测试代码，就又创建了一个jar包，/opt/hive/auxlib/udf1.jar<br>但是不管怎么创建udf，新的udf的代码都没有被引用</p>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>udf1.jar和udf.jar的java 类的路径和类名都是一样的，虽然在引用udf1.jar的时候，重新add jar了，但是hive不是把原始udf.jar从资源配置里拿去，当创建udf的时候，由于引用的类在原始的udf.jar中也有，所以，hive默认会引用hive在启动的时候加载的udf.jar，而不会使用udf1.jar</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>新旧两个jar包，类名或者路径保持不一致</p>
<h2 id="hive实现job并发执行"><a href="#hive实现job并发执行" class="headerlink" title="hive实现job并发执行"></a>hive实现job并发执行</h2><p>写了个sql，job数有20多个，一直都是上一个job跑完，下一个才开始执行，需要执行40多分钟<br>最近找到个方法，可以设置hive-job并发执行，但是这样会提高资源消耗，如果读取的表都是明细表，谨慎使用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>thread<span class="token punctuation">.</span>number<span class="token operator">=</span>最大并发job数<span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>启动了5个并发，时间被控制在10分钟以内了。</p>
<h2 id="hive-两个join的结果是否相等"><a href="#hive-两个join的结果是否相等" class="headerlink" title="hive 两个join的结果是否相等"></a>hive 两个join的结果是否相等</h2><p>有3个表A(id,name) B(id,name) C(id,name)<br>其中A的name为空，B两个都非空</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">A <span class="token keyword">inner</span> <span class="token keyword">join</span> C <span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> c<span class="token punctuation">.</span>id 
<span class="token keyword">union</span> <span class="token keyword">all</span>
B <span class="token keyword">join</span> C <span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> c<span class="token punctuation">.</span>id <span class="token operator">and</span> b<span class="token punctuation">.</span>name <span class="token operator">=</span> c<span class="token punctuation">.</span>name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>是否等于</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token punctuation">(</span>A <span class="token keyword">union</span> <span class="token keyword">all</span> B<span class="token punctuation">)</span> t1
<span class="token keyword">join</span> C t2
<span class="token keyword">on</span> t1<span class="token punctuation">.</span>id <span class="token operator">=</span> t2<span class="token punctuation">.</span>id
<span class="token keyword">where</span> t1<span class="token punctuation">.</span>name <span class="token operator">is</span> <span class="token boolean">null</span> <span class="token operator">or</span> t1<span class="token punctuation">.</span>name <span class="token operator">=</span> t2<span class="token punctuation">.</span>name<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>验证过程:</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111 <span class="token keyword">values</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222 <span class="token keyword">values</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">'c'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">)</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 <span class="token keyword">values</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'c'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">)</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111 
<span class="token keyword">union</span> <span class="token keyword">all</span> 
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222<span class="token punctuation">)</span> t1
<span class="token keyword">inner</span> <span class="token keyword">join</span> 
<span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 t2
<span class="token keyword">on</span> t1<span class="token punctuation">.</span>id <span class="token operator">=</span> t2<span class="token punctuation">.</span>id
<span class="token keyword">where</span> t1<span class="token punctuation">.</span>name <span class="token operator">is</span> <span class="token boolean">null</span> <span class="token operator">or</span> t1<span class="token punctuation">.</span>name <span class="token operator">=</span> t2<span class="token punctuation">.</span>name

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111 a <span class="token keyword">inner</span> <span class="token keyword">join</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 b
<span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id
<span class="token keyword">union</span> <span class="token keyword">all</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222 a <span class="token keyword">inner</span> <span class="token keyword">join</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 c
<span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> c<span class="token punctuation">.</span>id <span class="token operator">and</span> a<span class="token punctuation">.</span>name <span class="token operator">=</span> c<span class="token punctuation">.</span>name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>经过验证，两个结果相同 </p>
<h2 id="基于python编写udf，实现判断字符串是否是标准json"><a href="#基于python编写udf，实现判断字符串是否是标准json" class="headerlink" title="基于python编写udf，实现判断字符串是否是标准json"></a>基于python编写udf，实现判断字符串是否是标准json</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment">## add file /home/19190845/udf.py</span>
<span class="token comment">## select transform(fbdeal_id,orderdata) USING 'python udf.py'  AS (fbdeal_id,orderdata) from app.app_onedata_oms_orders_t_bdeal_da;</span>
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> json

<span class="token keyword">def</span> <span class="token function">is_json</span><span class="token punctuation">(</span>myjson<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        json_object <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>myjson<span class="token punctuation">)</span>
    <span class="token keyword">except</span> ValueError<span class="token punctuation">,</span> e<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">False</span>
    <span class="token keyword">return</span> <span class="token boolean">True</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> sys<span class="token punctuation">.</span>stdin<span class="token punctuation">:</span>
    detail <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>detail<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        deal_id <span class="token operator">=</span> detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        orderData <span class="token operator">=</span> detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        isJson <span class="token operator">=</span> is_json<span class="token punctuation">(</span>orderData<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> isJson<span class="token punctuation">:</span>
            <span class="token keyword">print</span> <span class="token builtin">str</span><span class="token punctuation">(</span>deal_id<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> orderData
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">add</span> <span class="token keyword">file</span> <span class="token operator">/</span>home<span class="token operator">/</span><span class="token number">19190845</span><span class="token operator">/</span>udf<span class="token punctuation">.</span>py
<span class="token keyword">select</span> transform<span class="token punctuation">(</span>fbdeal_id<span class="token punctuation">,</span>orderdata<span class="token punctuation">)</span> <span class="token keyword">USING</span> <span class="token string">'python udf.py'</span>  <span class="token keyword">AS</span> <span class="token punctuation">(</span>fbdeal_id<span class="token punctuation">,</span>orderdata<span class="token punctuation">)</span> <span class="token keyword">from</span> app<span class="token punctuation">.</span>app_onedata_oms_orders_t_bdeal_da<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>以上语句，支持hive mr、tez引擎，并支持spark-sql命令行</p>
<h2 id="hive列转行"><a href="#hive列转行" class="headerlink" title="hive列转行"></a>hive列转行</h2><p>可以使用map和ateral view explode新造列名，很实用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span>  model_code<span class="token punctuation">,</span>
        fact_rate<span class="token punctuation">,</span>
        item_code<span class="token punctuation">,</span>
        quota_name<span class="token punctuation">,</span>
        refer_enum<span class="token punctuation">,</span>
        busi_cnt
<span class="token keyword">from</span>
<span class="token punctuation">(</span><span class="token keyword">select</span> model_code<span class="token punctuation">,</span>
       <span class="token string">'POP001'</span> <span class="token keyword">AS</span> fact_rate<span class="token punctuation">,</span>
       item_code<span class="token punctuation">,</span>
       <span class="token keyword">case</span> <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00101'</span> <span class="token keyword">then</span> <span class="token string">'商品满意度'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00103'</span> <span class="token keyword">then</span> <span class="token string">'物流配送'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00104'</span> <span class="token keyword">then</span> <span class="token string">'服务满意度'</span>
            <span class="token keyword">else</span> <span class="token string">'unknown'</span>
       <span class="token keyword">end</span> <span class="token keyword">as</span> quota_name<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">2</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">2.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt2<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">3</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">3.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt3<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">4</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">4.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt4<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">5</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">5.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt5<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">6</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">6.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt6<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">7</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">7.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt7<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">8</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">8.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt8<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">9</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt9
<span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_business_growth_comment_item_score_da
<span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;stat_date&#125;'</span>
  <span class="token operator">and</span> item_code <span class="token operator">in</span> <span class="token punctuation">(</span><span class="token string">'POP00101'</span><span class="token punctuation">,</span><span class="token string">'POP00103'</span><span class="token punctuation">,</span><span class="token string">'POP00104'</span><span class="token punctuation">)</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> model_code<span class="token punctuation">,</span>
         item_code<span class="token punctuation">)</span> a
lateral <span class="token keyword">view</span> explode<span class="token punctuation">(</span>map<span class="token punctuation">(</span><span class="token string">'2-2.99'</span><span class="token punctuation">,</span> cnt2<span class="token punctuation">,</span>
                         <span class="token string">'3-3.99'</span><span class="token punctuation">,</span> cnt3<span class="token punctuation">,</span>
                         <span class="token string">'4-4.99'</span><span class="token punctuation">,</span> cnt4<span class="token punctuation">,</span>
                         <span class="token string">'5-5.99'</span><span class="token punctuation">,</span> cnt5<span class="token punctuation">,</span>
                         <span class="token string">'6-6.99'</span><span class="token punctuation">,</span> cnt6<span class="token punctuation">,</span>
                         <span class="token string">'7-7.99'</span><span class="token punctuation">,</span> cnt7<span class="token punctuation">,</span>
                         <span class="token string">'8-8.99'</span><span class="token punctuation">,</span> cnt8<span class="token punctuation">,</span>
                         <span class="token string">'9-10'</span><span class="token punctuation">,</span> cnt9<span class="token punctuation">)</span><span class="token punctuation">)</span> b <span class="token keyword">as</span> refer_enum<span class="token punctuation">,</span> busi_cnt
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>或者使用str_to_map函数,不过感觉还不如直接用map</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span>  model_code<span class="token punctuation">,</span>
        fact_rate<span class="token punctuation">,</span>
        item_code<span class="token punctuation">,</span>
        quota_name<span class="token punctuation">,</span>
        refer_enum<span class="token punctuation">,</span>
        busi_cnt
<span class="token keyword">from</span>
<span class="token punctuation">(</span><span class="token keyword">select</span> model_code<span class="token punctuation">,</span>
       <span class="token string">'POP001'</span> <span class="token keyword">AS</span> fact_rate<span class="token punctuation">,</span>
       item_code<span class="token punctuation">,</span>
       <span class="token keyword">case</span> <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00101'</span> <span class="token keyword">then</span> <span class="token string">'商品满意度'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00103'</span> <span class="token keyword">then</span> <span class="token string">'物流配送'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00104'</span> <span class="token keyword">then</span> <span class="token string">'服务满意度'</span>
            <span class="token keyword">else</span> <span class="token string">'unknown'</span>
       <span class="token keyword">end</span> <span class="token keyword">as</span> quota_name<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">2</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">2.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt2<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">3</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">3.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt3<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">4</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">4.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt4<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">5</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">5.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt5<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">6</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">6.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt6<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">7</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">7.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt7<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">8</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">8.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt8<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">9</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt9
<span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_business_growth_comment_item_score_da
<span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;stat_date&#125;'</span>
  <span class="token operator">and</span> item_code <span class="token operator">in</span> <span class="token punctuation">(</span><span class="token string">'POP00101'</span><span class="token punctuation">,</span><span class="token string">'POP00103'</span><span class="token punctuation">,</span><span class="token string">'POP00104'</span><span class="token punctuation">)</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> model_code<span class="token punctuation">,</span>
         item_code<span class="token punctuation">)</span> a
LATERAL <span class="token keyword">VIEW</span>
    EXPLODE<span class="token punctuation">(</span>
            STR_TO_MAP<span class="token punctuation">(</span>
                    CONCAT<span class="token punctuation">(</span>
                        <span class="token string">'2-2.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt2 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;3-3.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt3 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;4-4.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt4 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;5-5.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt5 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;6-6.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt6 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;7-7.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt7 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;8-8.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt8 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;9-10='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt9 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token punctuation">)</span>
                <span class="token punctuation">,</span><span class="token string">'&amp;'</span><span class="token punctuation">,</span> <span class="token string">'='</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span> lateral_table <span class="token keyword">AS</span> refer_enum<span class="token punctuation">,</span> busi_cnt
<span class="token punctuation">;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="hive数据倾斜"><a href="#hive数据倾斜" class="headerlink" title="hive数据倾斜"></a>hive数据倾斜</h2><p>这里数据倾斜的原因是<code>partner_id = 3</code>的数据好几百万，这里的解决办法是，把<code>partner_id = 3</code>的数据单独处理，添加随机数</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 取下单前的最后的广告，提交订单的session关联到广告</span>
<span class="token keyword">drop</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_3<span class="token punctuation">;</span>
<span class="token keyword">create</span>  <span class="token keyword">table</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_3
stored <span class="token keyword">as</span> orc
<span class="token keyword">as</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token punctuation">(</span>
<span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>
       row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> ftrade_id<span class="token punctuation">,</span>partner_id <span class="token keyword">order</span> <span class="token keyword">by</span> front_time <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token keyword">as</span> rank <span class="token comment">-- 最新的广告</span>
<span class="token keyword">from</span> <span class="token punctuation">(</span>
  <span class="token keyword">select</span>
       t1<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>
       <span class="token boolean">null</span> <span class="token keyword">as</span> rand_num<span class="token punctuation">,</span>
       t2<span class="token punctuation">.</span>ad_type<span class="token punctuation">,</span><span class="token comment">-- 广告类型</span>
       t2<span class="token punctuation">.</span>ad_id<span class="token punctuation">,</span><span class="token comment">-- 广告id</span>
       t2<span class="token punctuation">.</span>keyword_id<span class="token punctuation">,</span><span class="token comment">-- 竞价关键词id</span>
       t2<span class="token punctuation">.</span>keyword_contect <span class="token punctuation">,</span><span class="token comment">-- 竞价关键词内容</span>
       t2<span class="token punctuation">.</span>sku_id <span class="token keyword">as</span> search_ad_sku_id  <span class="token punctuation">,</span><span class="token comment">-- 搜索广告商品id</span>
       t2<span class="token punctuation">.</span>is_premium                  <span class="token punctuation">,</span><span class="token comment">-- 是否溢价</span>
       front_time
  <span class="token keyword">from</span> <span class="token punctuation">(</span>
  <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_1
  <span class="token keyword">where</span> partner_id <span class="token operator">&lt;></span> <span class="token number">3</span><span class="token punctuation">)</span>  t1
  <span class="token keyword">left</span> <span class="token keyword">join</span> <span class="token punctuation">(</span>
      <span class="token keyword">select</span> ad_type<span class="token punctuation">,</span>                      <span class="token comment">-- 广告类型</span>
             ad_id<span class="token punctuation">,</span>                        <span class="token comment">-- 广告id</span>
             keyword_id<span class="token punctuation">,</span>                   <span class="token comment">-- 竞价关键词id</span>
             keyword_contect <span class="token punctuation">,</span>             <span class="token comment">-- 竞价关键词内容</span>
             sku_id                      <span class="token punctuation">,</span> <span class="token comment">-- 搜索广告商品id</span>
             is_premium                  <span class="token punctuation">,</span> <span class="token comment">-- 是否溢价</span>
             partner_id                  <span class="token punctuation">,</span>
             front_time
      <span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_tracker_ad_click_dt_de
      <span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;v_dt&#125;'</span> <span class="token operator">and</span> partner_id <span class="token operator">&lt;></span> <span class="token number">3</span>
  <span class="token punctuation">)</span> t2
    <span class="token keyword">on</span> t1<span class="token punctuation">.</span>partner_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>partner_id
 <span class="token keyword">where</span> to_unix_timestamp<span class="token punctuation">(</span>t1<span class="token punctuation">.</span>ftrade_gen_time<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1000</span> <span class="token operator">></span> t2<span class="token punctuation">.</span>front_time

 <span class="token keyword">union</span> <span class="token keyword">all</span>

  <span class="token keyword">select</span>
       t1<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>
       t2<span class="token punctuation">.</span>ad_type<span class="token punctuation">,</span><span class="token comment">-- 广告类型</span>
       t2<span class="token punctuation">.</span>ad_id<span class="token punctuation">,</span><span class="token comment">-- 广告id</span>
       t2<span class="token punctuation">.</span>keyword_id<span class="token punctuation">,</span><span class="token comment">-- 竞价关键词id</span>
       t2<span class="token punctuation">.</span>keyword_contect <span class="token punctuation">,</span><span class="token comment">-- 竞价关键词内容</span>
       t2<span class="token punctuation">.</span>sku_id <span class="token keyword">as</span> search_ad_sku_id  <span class="token punctuation">,</span><span class="token comment">-- 搜索广告商品id</span>
       t2<span class="token punctuation">.</span>is_premium                  <span class="token punctuation">,</span><span class="token comment">-- 是否溢价</span>
       front_time
  <span class="token keyword">from</span> <span class="token punctuation">(</span>
    <span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token keyword">as</span> rand_num   <span class="token comment">--数据倾斜，使用随机数重新关联</span>
    <span class="token keyword">from</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_1
    <span class="token keyword">where</span> partner_id <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>  t1
  <span class="token keyword">left</span> <span class="token keyword">join</span> <span class="token punctuation">(</span>
      <span class="token keyword">select</span> ad_type<span class="token punctuation">,</span>                      <span class="token comment">-- 广告类型</span>
             ad_id<span class="token punctuation">,</span>                        <span class="token comment">-- 广告id</span>
             keyword_id<span class="token punctuation">,</span>                   <span class="token comment">-- 竞价关键词id</span>
             keyword_contect <span class="token punctuation">,</span>             <span class="token comment">-- 竞价关键词内容</span>
             sku_id                      <span class="token punctuation">,</span> <span class="token comment">-- 搜索广告商品id</span>
             is_premium                  <span class="token punctuation">,</span> <span class="token comment">-- 是否溢价</span>
             partner_id                  <span class="token punctuation">,</span>
             front_time<span class="token punctuation">,</span>
             <span class="token punctuation">(</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token keyword">as</span> rand_num  <span class="token comment">--数据倾斜，使用随机数重新关联</span>
      <span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_tracker_ad_click_dt_de
      <span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;v_dt&#125;'</span> <span class="token operator">and</span> partner_id <span class="token operator">=</span> <span class="token number">3</span>
  <span class="token punctuation">)</span> t2
    <span class="token keyword">on</span> t1<span class="token punctuation">.</span>partner_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>partner_id
    <span class="token operator">and</span> t1<span class="token punctuation">.</span>rand_num <span class="token operator">=</span> t2<span class="token punctuation">.</span>rand_num
 <span class="token keyword">where</span> to_unix_timestamp<span class="token punctuation">(</span>t1<span class="token punctuation">.</span>ftrade_gen_time<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1000</span> <span class="token operator">></span> t2<span class="token punctuation">.</span>front_time
 <span class="token punctuation">)</span> t <span class="token punctuation">)</span> tt
 <span class="token keyword">where</span> rank <span class="token operator">=</span> <span class="token number">1</span>
<span class="token punctuation">;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Hive优化技巧"><a href="#Hive优化技巧" class="headerlink" title="Hive优化技巧"></a>Hive优化技巧</h2><h3 id="控制reducer数量"><a href="#控制reducer数量" class="headerlink" title="控制reducer数量"></a>控制reducer数量</h3><p>控制hive中reducer的数量由三种方式，分别是：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">set hive.exec.reducers.bytes.per.reducer&#x3D;&lt;number&gt; 
set hive.exec.reducers.max&#x3D;&lt;number&gt;
set mapreduce.job.reduces&#x3D;&lt;number&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>其中<code>set mapreduce.job.reduces=&lt;number&gt;</code>的方式优先级最高，<br><code>set hive.exec.reducers.max=&lt;number&gt;</code>优先级次之，<br><code>set hive.exec.reducers.bytes.per.reducer=&lt;number&gt; </code>优先级最低。<br>从hive0.14开始，一个reducer处理文件的大小的默认值是256M。<br>reducer的数量并不是越多越好，我们知道有多少个reducer就会生成多少个文件，小文件过多在hdfs中就会占用大量的空间，造成资源的浪费。<br>如果reducer数量过小，导致某个reducer处理大量的数据（数据倾斜就会出现这样的现象），没有利用hadoop的分而治之功能，甚至会产生OOM内存溢出的错误。<br>使用多少个reducer处理数据和业务场景相关，不同的业务场景处理的办法不同。</p>
<h3 id="使用Map-join"><a href="#使用Map-join" class="headerlink" title="使用Map join"></a>使用Map join</h3><p>set hive.auto.convert.join = true<br>或者使用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token comment">/*+ MAPJOIN(table_a)*/</span><span class="token punctuation">,</span>
       a<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>
       b<span class="token punctuation">.</span><span class="token operator">*</span> 
<span class="token keyword">from</span> table_a a 
<span class="token keyword">join</span> table_b b 
<span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="使用distinct-union-all代替union"><a href="#使用distinct-union-all代替union" class="headerlink" title="使用distinct + union all代替union"></a>使用distinct + union all代替union</h3><p>使用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token operator">*</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span> <span class="token punctuation">(</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'0'</span> <span class="token keyword">union</span> <span class="token keyword">all</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'1'</span> <span class="token keyword">union</span> <span class="token keyword">all</span> 
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'1'</span>
<span class="token punctuation">)</span>a<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代替</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span><span class="token punctuation">(</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'0'</span> <span class="token keyword">union</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'0'</span> <span class="token keyword">union</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">)</span>t<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="解决数据倾斜的通用办法"><a href="#解决数据倾斜的通用办法" class="headerlink" title="解决数据倾斜的通用办法"></a>解决数据倾斜的通用办法</h3><p>数据倾斜的现象：任务进度长时间维持在99%，只有少量reducer任务完成，未完成任务数据读写量非常大，超过10G。在聚合操作是经常发生。<br>通用解决方法：<code>set hive.groupby.skewindata=true;</code><br>将一个map reduce拆分成两个map reduce。</p>
<p>最常用的是，把key设置一个随机数值。保证所有数据平均的分配到所有的reducer中处理</p>
<h3 id="通过group-by代替count-distinct-使用"><a href="#通过group-by代替count-distinct-使用" class="headerlink" title="通过group by代替count(distinct)使用"></a>通过group by代替count(distinct)使用</h3><h3 id="left-semi-join替代in-exsits"><a href="#left-semi-join替代in-exsits" class="headerlink" title="left semi join替代in/exsits"></a>left semi join替代in/exsits</h3><h2 id="Hive-Join的实现原理"><a href="#Hive-Join的实现原理" class="headerlink" title="Hive Join的实现原理"></a>Hive Join的实现原理</h2><p>hive执行引擎会将HQL“翻译”成为map-reduce任务，如果多张表使用同一列做join则将被翻译成一个reduce，否则将被翻译成多个map-reduce任务<br>例如：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> a<span class="token punctuation">.</span>val<span class="token punctuation">,</span> 
       b<span class="token punctuation">.</span>val<span class="token punctuation">,</span> 
       c<span class="token punctuation">.</span>val 
<span class="token keyword">FROM</span> a 
<span class="token keyword">JOIN</span> b 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key1<span class="token punctuation">)</span> 
<span class="token keyword">JOIN</span> c 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>c<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key1<span class="token punctuation">)</span>
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>将被翻译成1个map-reduce任务</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> a<span class="token punctuation">.</span>val<span class="token punctuation">,</span> 
       b<span class="token punctuation">.</span>val<span class="token punctuation">,</span>
       c<span class="token punctuation">.</span>val 
<span class="token keyword">FROM</span> a 
<span class="token keyword">JOIN</span> b 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key1<span class="token punctuation">)</span> 
<span class="token keyword">JOIN</span> c 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>c<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key2<span class="token punctuation">)</span>
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>将被翻译成2个map-reduce任务</p>
<p>Hive中的Join可分为Common Join（Reduce阶段完成join）和Map Join（Map阶段完成join）</p>
<h3 id="Common-Join"><a href="#Common-Join" class="headerlink" title="Common Join"></a>Common Join</h3><ul>
<li><p>Map阶段<br>读取源表的数据，Map输出时候以Join on条件中的列为key，如果Join有多个关联键，则以这些关联键的组合作为key;<br>Map输出的value为join之后所关心的(select或者where中需要用到的)列；同时在value中还会包含表的Tag信息，用于标明此value对应哪个表；<br>按照key进行排序</p>
</li>
<li><p>Shuffle阶段<br>根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中</p>
</li>
<li><p>Reduce阶段<br>根据key的值完成join操作，期间通过Tag来识别不同表中的数据。</p>
</li>
</ul>
<h3 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h3><ul>
<li>首先是Task A，它是一个Local Task（在客户端本地执行的Task），负责扫描小表b的数据，将其转换成一个HashTable的数据结构，并写入本地的文件中，之后将该文件加载到DistributeCache中</li>
<li>接下来是Task B，该任务是一个没有Reduce的MR，启动MapTasks扫描大表a,在Map阶段，根据a的每一条记录去和DistributeCache中b表对应的HashTable关联，并直接输出结果。<br>由于MapJoin没有Reduce，所以由Map直接输出结果文件，有多少个Map Task，就有多少个结果文件。</li>
</ul>
<p>具体可以参考<a href="https://www.hadoopdoc.com/hive/hive-join">Hive Join 的原理与机制</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>实时采集架构设计</title>
    <url>/2022/03/07/%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>实时架构方案设计</li>
<li>实时架构方案可行性验证</li>
</ul>
<a id="more"></a>

<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>随着企业的数字化转型越来越深入，企业生产交付业务对于实时数据的需求在不断膨胀，实时数据能够帮助企业以最快速度收集来自传感器（日志）、传统数据库（业务系统）等的数据，通过管理数据实时变化迅速建立起对市场需求的形势判断，并最终将其转化为能够提升企业业绩的决策工具</p>
<h2 id="当前现状"><a href="#当前现状" class="headerlink" title="当前现状"></a>当前现状</h2><h3 id="现状描述"><a href="#现状描述" class="headerlink" title="现状描述"></a>现状描述</h3><p>当前数据采集系统，分为业务数据采集与日志数据采集，日志数据采集已经是实时采集，业务数据采集即传统数据库采集目前采用的是离线采集，技术选用datax，每天凌晨抽取一次数据到hive<br><img src="/uploads/202203/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%BD%93%E5%89%8D%E7%8E%B0%E7%8A%B6.png" alt="数据采集当前现状"></p>
<h3 id="痛点问题"><a href="#痛点问题" class="headerlink" title="痛点问题"></a>痛点问题</h3><ol>
<li>离线采集数据更新延迟，无法及时获取业务数据</li>
<li>凌晨采集任务集中，集群资源消耗大（目前公司还没这个问题，但是任务多了以后，存在隐患）</li>
</ol>
<h2 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h2><p>通过对现状和痛点问题的分析，实时采集平台的建设应实现以下目标：</p>
<ol>
<li>通过页面配置的方式创建采集任务，并支持数据的实时采集</li>
<li>支持多种数据源，例如Mysql、sqlServer、Oracle、MongoDB、PostgreSQL等</li>
<li>支持分库分表的数据源</li>
<li>数据源字段名/字段类型自动映射，并打通元信息管理</li>
<li>集成监控系统，例如实时监控Kakfa数据消费情况，是否存在堆积、背压等情况</li>
<li>业务方数据源发生变动，实时采集系统可以自动兼容，或者实时告警。例如，采集的某张Mysql表新增/修改字段，这时候目标HIve可以自动添加/修改，如果mysql表删除字段，采集系统可以及时告警，通知任务创建人员以及时修改</li>
<li>支持对敏感数据脱敏</li>
<li>实时采集的任务纳入调度系统</li>
<li>采集数据源权限管控，有项目权限的人才能创建该数据源的任务</li>
<li>资源管控，使用实时资源队列</li>
</ol>
<h2 id="架构设计原则"><a href="#架构设计原则" class="headerlink" title="架构设计原则"></a>架构设计原则</h2><p>实时采集平台是数据中台的重要组成部分，其建设、设计和系统实现过程中，应遵循如下指导原则：</p>
<ul>
<li><strong>高性能：</strong> 从计算和存储等方面考虑，如何达到更高的处理能力，例如采用分布式架构原理</li>
<li><strong>高可靠：</strong> 设计实现更高的容错能力，例如灰度设计、风险隔离、备份恢复、提供降级方案等等</li>
<li><strong>高可扩展性：</strong> 架构设计与功能划分模块化，考虑各接口的开放性、可扩展性，便于系统的快速扩展与维护，便于第三方系统的快速接入。并从集群层面对高性能和高可靠性提供支持，例如集群负载、容器化设计等等</li>
<li><strong>高安全性：</strong> 保证信息安全和系统稳定，例如传输加密、认证授权，还有防DDOS、XSS、SQL注入等等。</li>
<li><strong>高可维护性：</strong> 产品的开发只是一阵子，上线之后的运维和运营那才是一辈子的。因此，除了功能的设计，还需要考虑监控运营、运维工具、自动化运维能力等方面的设计。</li>
</ul>
<h2 id="系统技术架构"><a href="#系统技术架构" class="headerlink" title="系统技术架构"></a>系统技术架构</h2><p>本次项目根据建设目标和设计原则构建实时采集系统，在现有大数据平台基础上，新增实时采集系统，该系统通过Hadoop、Hudi/Iceberg、Kafka来存储数据，用Flink CDC采集业务库数据，集成权限管理系统、监控系统，打通元数据管理系统</p>
<h3 id="系统架构设计"><a href="#系统架构设计" class="headerlink" title="系统架构设计"></a>系统架构设计</h3><p>本次实时采集平台建设，平台结构上分为业务数据源层、数据中台stage层、以及数据中台贴源层三个层次，规划将一步到位，但具体实施将采用分期方式进行，第一期主要集中在业务数据源层到数据中台stage层的打通，整体规划如下图：<br><img src="/uploads/202203/%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%9B%BE.png" alt="实时采集架构设计图"><br>每个层次的主要功能和使用的产品：<br><strong>业务数据源层</strong><br>该层是指业务方各系统数据源，即要采集的数据源，该层数据采用的存储组件不一，包含Mysql、SQLServer、Oracle、MongoDB、PostgreSQL等<br>这里需要考虑一下在采集平台部署采集任务，如何让业务方数据源自动支持CDC？目前还没找到，只能手动操作，后期可以考虑一下</p>
<p><strong>数据中台stage层</strong><br>该层的主要作用就是缓冲业务数据源与数据中台贴源层之间的数据，以防止数据源波动较大，给上层写数据造成压力，并且可以对上下游解耦，将一个数据源分发给多个下游。考虑到数据的实时性，该层采用Kafka作为存储组件<br>这里讲解一下Kafka层的必要性：<br>业务数据源以Mysql为例，数据中台贴源层以Hudi为例：<br>MySQL 数据通过 Flink CDC 进入到 Kafka。之所以数据先入 Kafka 而不是直接入 Hudi</p>
<ul>
<li>实现多个实时任务复用 MySQL 过来的数据，避免多个任务通过 Flink CDC接 MySQL表以及Binlog，对MySQL库的性能造成影响。</li>
<li>防止数据源波动较大的情况下，会对给上层写数据造成压力</li>
</ul>
<p><strong>数据中台贴源层</strong><br>该层是数据中台贴源层，用于存储实时采集过来的数据，由于数据是实时更新，所以存储组件需要支持行级更新，这里考虑引入数据湖组件，Hudi/Iceberg，具体Hudi还是Iceberg还需后期考量<br><strong>采集监控</strong><br>为了保证系统稳定，需要对采集任务做实时监控，例如业务方数据源是否发生变动，是否加字段或者该字段，kafka数据的消费情况，是否背压等<br><strong>元数据管理</strong><br>从大数据平台的角度来看，实时采集系统只是平台的一个功能模块，采集所设计的元数据都需与大数据平台的元数据管理系统交互，例如采集的表的元数据应当被存储在元数据管理系统，上下游依赖关系也需要在元数据管理系统内体现<br><strong>权限管控</strong><br>从数据安全角度来看，业务库的权限不应该对所有人开放，应仅对有项目权限的用户开放对应库/表的权限</p>
<h3 id="技术方案选型"><a href="#技术方案选型" class="headerlink" title="技术方案选型"></a>技术方案选型</h3><h4 id="采集工具选择"><a href="#采集工具选择" class="headerlink" title="采集工具选择"></a>采集工具选择</h4><p>对于采集工具，这里需要引入一个新的概念，CDC（Change Data Capture），在广义的概念上，只要是能捕获数据变更的技术，我们都 可以称之为 CDC 。目前通常描述的 CDC 技术主要面向数据库的变更，是一种用于捕获数据库中 数据变更的技术，CDC 技术应用场景也非常广泛，包括:</p>
<ol>
<li>数据分发，将一个数据源分发给多个下游，常用于业务解耦、微服务。</li>
<li>数据集成，将分散异构的数据源集成到数据仓库中，消除数据孤岛，便于后续的分析。</li>
<li>数据迁移，常用于数据库备份、容灾等。</li>
</ol>
<p>目前业界主流的 CDC 实现机制可以分为两种:</p>
<ol>
<li>基于查询的 CDC:<br>1.1  离线调度查询作业，批处理。依赖表中的更新时间字段，每次执行查询去获取表中最新的数据; 无法捕获删除事件，从而无法保证数据一致性;<br>1.2无法保障实时性，基于离线调度存在天然的延迟。</li>
<li> 基于日志的 CDC:<br> 2.1  实时消费日志，流处理。例如<code>MySQL</code>的<code>binlog</code>日志完整记录了数据库中的变更，可以把<code>binlog</code>文件当作流的数据源;<br> 2.2 保障数据一致性，因为<code>binlog</code>文件包含了所有历史变更明细;<br> 2.3 保障实时性，因为类似<code>binlog</code>的日志文件是可以流式消费的，提供的是实时数据。<br> 对比常见的开源<code>CDC</code>方案，我们可以发现:</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>DataX</th>
<th>Sqoop</th>
<th>Kettle</th>
<th>Canal</th>
<th>Maxwell</th>
<th>Flink CDC</th>
<th>Debezium</th>
<th>Oracle Goldengate</th>
</tr>
</thead>
<tbody><tr>
<td>CDC机制</td>
<td>查询</td>
<td>查询</td>
<td>查询</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
</tr>
<tr>
<td>增量同步</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>断点续传</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>全量同步</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>架构</td>
<td>单机</td>
<td>分布式</td>
<td>分布式</td>
<td>单机</td>
<td>单机</td>
<td>分布式</td>
<td>单机</td>
<td>分布式</td>
</tr>
<tr>
<td>生态</td>
<td>☆☆☆</td>
<td>☆☆</td>
<td>☆</td>
<td>☆☆</td>
<td>☆☆☆</td>
<td>☆☆☆☆☆</td>
<td>☆☆☆</td>
<td>☆☆☆</td>
</tr>
<tr>
<td>实时采集不仅需要采集增量数据，也需要在采集之初做一次初始化，为了尽可能的统一技术栈，在采集工具的选择上，需要选择支持全量+增量一体化的工具，而在全量+增量一体化同步方面，只有<code>Flink CDC</code>、<code>Debezium</code>、<code>MaxWell</code>、<code>Oracle Goldengate</code>支持较好。</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>而<code>Oracle Goldengate</code>是商业软件，不是开源的，业内使用较少。</li>
<li><code>MaxWell</code>仅支持<code>Mysql</code>的采集，支持的数据源太少</li>
<li>而<code>Debezium</code>的锁表操作是一个挺大的痛点，在初始化数据的时候，会影响业务更新<code>Mysql</code>数据<br>综合考虑，选用<code>Flink CDC2.x</code>作为我们的采集工具</li>
</ul>
<p><code>Flink CDC</code>底层封装了<code>Debezium</code>，在<code>FlinkCDC2.x</code>出来之前，其实选择<code>Flink CDC</code>还是<code>Debezium</code>都可以，但是，<code>Flink CDC2.x</code>出来之后，解决了3个痛点问题：</p>
<ol>
<li>全量 + 增量读取的过程需要保证所有数据的一致性，因此需要通过全局锁保证，但是加锁容易 对在线业务造成影响，且<code>DBA</code>一般不给锁权限。</li>
<li>不支持水平扩展，因为<code>Flink CDC</code>底层是基于<code>Debezium</code>，其架构是单节点，所以<code>Flink CDC1.x</code>的数据源只支持单并发。在全量阶段读取阶段，如果表非常大 (亿级别)，读取时间在小时甚至天 级别，用户无法通过增加资源去提升作业速度。</li>
<li>全量读取阶段不支持<code>checkpoint:CDC</code>读取分为两个阶段，全量读取和增量读取，目前全量读取阶段是不支持<code>checkpoint</code>的，因此会存在一个问题:当我们同步全量数据时，假设需要5个小时，当我们同步了4小时的时候作业失败，这时候就需要重新开始，再读取5个小时。<h4 id="Flink-CDC支持的数据源"><a href="#Flink-CDC支持的数据源" class="headerlink" title="Flink CDC支持的数据源"></a><code>Flink CDC</code>支持的数据源</h4></li>
</ol>
<h4 id="Stage层技术选型"><a href="#Stage层技术选型" class="headerlink" title="Stage层技术选型"></a>Stage层技术选型</h4><p>考虑到Stage层的主要作用就是缓冲业务数据源与数据中台贴源层之间的数据，并且数据的实时性要求较高，这里采用Kafka作为该层的存储组件</p>
<h4 id="数据中台贴源层技术选型"><a href="#数据中台贴源层技术选型" class="headerlink" title="数据中台贴源层技术选型"></a>数据中台贴源层技术选型</h4><p>用于存储实时采集过来的数据，由于数据是实时更新，所以存储组件需要支持行级更新，还要支持SQl做ETL分析，这里考虑引入数据湖组件，<code>Hudi/Iceberg</code>，<code>Hudi/Iceberg</code>依托于<code>HDFS</code>以保证整体大数据架构的兼容性，具体<code>Hudi</code>还是<code>Iceberg</code>还需后期考量。<br><code>Hudi</code>对上下游生态的开放、对全局索引的 支持、对<code>Flink 1.13</code>版本的支持比<code>Iceberg</code>更好</p>
<h3 id="采集流程"><a href="#采集流程" class="headerlink" title="采集流程"></a>采集流程</h3><p>根据是否需要Kafka缓存有两种采集流程：</p>
<ol>
<li><p>默认情况下不接入Kafka，数据经FlinkCDC从业务库采集后直接入Hudi，具体流程图如下：<br><img src="/uploads/202203/%E9%BB%98%E8%AE%A4%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="默认采集流程图"><br>这种采集流程有如下<strong>优点：</strong><br>1）减少维护的组件，简化实时链路，减轻部署成本<br>2）减小端到端延迟<br>3）数据不落地，减少存储成本<br>有如下<strong>缺点：</strong><br>1）数据仅能做到分钟级别的准实时。对实时性要求不是特别高的，可以使用这种方式<br>2）数据源波动较大的情况下，会对给上层写数据造成压力<br>3）业务方数据和下游数据中台耦合性比较强</p>
</li>
<li><p>当用户指定需要Kafka做数据缓存时，数据经FlinkCDC先写入kafka，之后再有一个FlinkCDC程序实时读取kafka数据写入Hudi中。具体流程图如下：<br><img src="/uploads/202203/%E6%B7%BB%E5%8A%A0Kafka%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="添加Kafka采集流程图"><br>这种采集方案有如下<strong>优点：</strong><br>1）数据纯实时采集，实时性高<br>2）利用<code>Kafka</code>消息队列做解耦，<code>binlog</code>可供任何其他业务系统使用<br>3）数据量大的情况下，不会对上层写数据造成压力<br>有如下<strong>缺点：</strong><br>1）中间多了一层kafka组件，实时链路更长，部署成本稍高<br>2）数据多在kafka中存储一份，增加了存储成本<br>3）kafka的数据需要定期删除，不会存储全量的数据，只能从kafka里读取增量数据，数据源变更频率低的情况，这种不适合，会丢数据</p>
</li>
</ol>
<h3 id="系统流程"><a href="#系统流程" class="headerlink" title="系统流程"></a>系统流程</h3><p>由于本次的采集系统是支持页面可配置的，所以需要和前端页面做交互，具体的流程图如下：<br><img src="/uploads/202203/%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="实时采集整体流程图"></p>
<ol>
<li>用户检查是否有目标表所在项目权限，如无先申请项目权限</li>
<li>用户根据目标表数据波动以及是否存在多个流计算任务消费该目标表选择采集流程</li>
<li>在页面选择实时采集的必要参数</li>
<li>前端页面返回参数，在元数据系统记录该表的信息，并启动实时采集程序</li>
<li>启动监控程序</li>
</ol>
<h2 id="方案可行性验证"><a href="#方案可行性验证" class="headerlink" title="方案可行性验证"></a>方案可行性验证</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p><code>Flink CDC2.x</code>需要使用<code>Flink1.13.x</code>及以上的版本，首先需要替换集群的<code>Flink</code>版本，由于公司的大部分软件为<code>CDH</code>版本，这里的<code>Flin</code>k需要下载源码指定<code>CDH</code>版本的<code>Hadoop</code>重新编译</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mvn clean install -DskipTests -Dfast -Drat.skip&#x3D;true -Dhaoop.version&#x3D;3.0.0-cdh6.2.0 -Pvendor-repos -Dinclude-hadoop -Dscala-2.11 -T10C

# -Dfast  #在flink根目录下pom.xml文件中fast配置项目中含快速设置,其中包含了多项构建时的跳过参数. #例如apache的文件头(rat)合法校验，代码风格检查，javadoc生成的跳过等，详细可阅读pom.xml
# install maven的安装命令
# -T10C #支持多处理器或者处理器核数参数,加快构建速度,推荐Maven3.3及以上
# -Pinclude-hadoop  将hadoop的 jar包，打入到lib&#x2F;中
# -Pvendor-repos   # 如果需要指定hadoop的发行商，如CDH，需要使用-Pvendor-repos
# -Dscala-2.12     # 指定scala的版本为2.12
# -Dhadoop.version&#x3D;3.0.0-cdh6.2.0  指定 hadoop 的版本，这里的版本与CDH集群版本的Hadoop一致就行<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在集群安装编译好的Flink软件，并配置环境变量</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export FLINK_HOME&#x3D;&#x2F;opt&#x2F;soft&#x2F;flink-1.13.6
export PATH&#x3D;$PATH:$&#123;FLINK_HOME&#125;&#x2F;bin

export HADOOP_CLASSPATH&#x3D;&#96;hadoop classpath&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里可以参考我的博客<a href="https://gujincheng.github.io/2022/03/10/maven%E7%BC%96%E8%AF%91Hudi%E4%B8%8EFlink%E6%BA%90%E7%A0%81/">maven编译Hudi与Flink源码</a></p>
<h3 id="Flink-CDC实时采集Mysql入Kafka"><a href="#Flink-CDC实时采集Mysql入Kafka" class="headerlink" title="Flink CDC实时采集Mysql入Kafka"></a>Flink CDC实时采集Mysql入Kafka</h3><p>这里只是简单介绍一下测试流程和测试结果，具体可以参考我的博客<a href="https://gujincheng.github.io/2022/03/11/flink-cdc%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5Kafka/">flink-cdc实时采集数据库入Kafka</a></p>
<h4 id="Mysql开启binlog"><a href="#Mysql开启binlog" class="headerlink" title="Mysql开启binlog"></a>Mysql开启binlog</h4><p>在/etc/my.cnf中mysqld节添加开启binlog的配置：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#设置日志路径，注意路经需要mysql用户有权限写
## &#x2F;data&#x2F;mysql&#x2F;logs&#x2F;是binlog存储路径，mysql-bin是文件名
## 在该文件夹下会生成 mysql-bin.000001、 mysql-bin.index文件
log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;logs&#x2F;mysql-bin
#选择row模式
binlog_format&#x3D;ROW
##配置serverid
server_id&#x3D;1
#设置binlog清理时间
expire_logs_days &#x3D; 7
##binlog每个日志文件大小
max_binlog_size &#x3D; 100m
##binlog缓存大小
binlog_cache_size &#x3D; 4m
##最大binlog缓存大小
max_binlog_cache_size &#x3D; 512m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>修改完配置后，重启mysql。执行SHOW VARIABLES LIKE ‘log_bin’; Value 值为 ON即可</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">service mysqld restart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="通过DataStream方式编写CDC代码"><a href="#通过DataStream方式编写CDC代码" class="headerlink" title="通过DataStream方式编写CDC代码"></a>通过DataStream方式编写CDC代码</h4><ol>
<li>配置maven依赖<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.ververica<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-mysql-cdc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token comment">&lt;!-- the dependency is available only for stable releases. --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>编写java代码<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>cdc2kafka</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>source<span class="token punctuation">.</span></span><span class="token class-name">MySqlSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">JsonDebeziumDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>eventtime<span class="token punctuation">.</span></span><span class="token class-name">WatermarkStrategy</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">Logger</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">LoggerFactory</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token operator">*</span><span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Mysql2Kakfa</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Logger</span> log <span class="token operator">=</span> <span class="token class-name">LoggerFactory</span><span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token class-name">Mysql2Kakfa</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> hostName <span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> yourPort<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> dbName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> tableName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> userName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> password<span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">//parseArgs(args);</span>
        hostName <span class="token operator">=</span> <span class="token string">"localhost"</span><span class="token punctuation">;</span>
        yourPort <span class="token operator">=</span> <span class="token number">3306</span><span class="token punctuation">;</span>
        dbName <span class="token operator">=</span> <span class="token string">"test"</span><span class="token punctuation">;</span>
        tableName <span class="token operator">=</span> <span class="token string">"test.gjc_test_binlog"</span><span class="token punctuation">;</span>
        userName <span class="token operator">=</span> <span class="token string">"root"</span><span class="token punctuation">;</span>
        password <span class="token operator">=</span> <span class="token string">"Hive123!@#"</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"hostName:"</span> <span class="token operator">+</span> hostName
                <span class="token operator">+</span> <span class="token string">",port:"</span> <span class="token operator">+</span> yourPort
                <span class="token operator">+</span> <span class="token string">",dbName:"</span> <span class="token operator">+</span> dbName
                <span class="token operator">+</span> <span class="token string">",tableName:"</span> <span class="token operator">+</span> tableName
                <span class="token operator">+</span> <span class="token string">",userName:"</span> <span class="token operator">+</span> userName
                <span class="token operator">+</span> <span class="token string">",password:"</span> <span class="token operator">+</span> password
        <span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">MySqlSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> mySqlSource <span class="token operator">=</span> <span class="token class-name">MySqlSource</span><span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">hostname</span><span class="token punctuation">(</span>hostName<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">port</span><span class="token punctuation">(</span>yourPort<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">databaseList</span><span class="token punctuation">(</span>dbName<span class="token punctuation">)</span> <span class="token comment">// set captured database</span>
                <span class="token punctuation">.</span><span class="token function">tableList</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span> <span class="token comment">// set captured table</span>
                <span class="token punctuation">.</span><span class="token function">username</span><span class="token punctuation">(</span>userName<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">password</span><span class="token punctuation">(</span>password<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">startupOptions</span><span class="token punctuation">(</span><span class="token class-name">StartupOptions</span><span class="token punctuation">.</span><span class="token function">initial</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
                <span class="token punctuation">.</span><span class="token function">deserializer</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">JsonDebeziumDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// converts SourceRecord to JSON String</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
         <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> dataStreamSource <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromSource</span><span class="token punctuation">(</span>mySqlSource<span class="token punctuation">,</span> <span class="token class-name">WatermarkStrategy</span><span class="token punctuation">.</span><span class="token function">noWatermarks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"MySQL Source"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	dataStreamSource<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token string">"golden-02:9092"</span><span class="token punctuation">,</span>
                <span class="token string">"test.gjc_test_binlog"</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Print MySQL Snapshot + Binlog"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
以per-job方式提交Flink任务到yarn上<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$&#123;FLINK_HOME&#125;&#x2F;bin&#x2F;flink run -m yarn-cluster -yjm 1024 -ytm 1024 -yqu root.default -ynm gjc_test_flink-cdc-mysql -c com.digiwin.flink.cdc2kafka.Mysql2Kakfa target&#x2F;FlinkCDCTest-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
数据很成功的采集到kafka了</li>
</ol>
<h4 id="添加断点续传"><a href="#添加断点续传" class="headerlink" title="添加断点续传"></a>添加断点续传</h4><p>首先在代码里添加checkpoint相关代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">//配置ck的状态后端</span>
env<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HashMapStateBackend</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//设置系统异常退出或人为 Cancel 掉，不删除checkpoint数据</span>
env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setExternalizedCheckpointCleanup</span><span class="token punctuation">(</span><span class="token class-name">CheckpointConfig</span><span class="token punctuation">.</span><span class="token class-name">ExternalizedCheckpointCleanup</span><span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//设置checkpoint存储目录</span>
env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setCheckpointStorage</span><span class="token punctuation">(</span><span class="token string">"hdfs://flink/checkpoint/cdc/gjc_test_Mysql2Kakfa"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
env<span class="token punctuation">.</span><span class="token function">enableCheckpointing</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>启动任务后，在hdfs上查看checkpoint文件夹：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@ddp2 ~]# hadoop fs -ls &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;
Found 3 items
drwxr-xr-x   - root supergroup          0 2022-03-19 11:51 &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;chk-27
drwxr-xr-x   - root supergroup          0 2022-03-19 11:49 &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;shared
drwxr-xr-x   - root supergroup          0 2022-03-19 11:49 &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;taskowned<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>手动取消flink任务</li>
<li>重新启动flink，需要注意的是，任务启动的时候，需要指定checkopint地址<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$&#123;FLINK_HOME&#125;&#x2F;bin&#x2F;flink run -m yarn-cluster -yjm 1024 -ytm 1024 -yqu root.default -ynm gjc_test_flink-cdc-mysql -s hdfs:&#x2F;&#x2F;&#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;chk-27 -c com.digiwin.flink.cdc2kafka.Mysql2Kakfa target&#x2F;FlinkCDCTest-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>在mysql中添加数据<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> gjc_test_binlog <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token string">'2018-11-10'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> gjc_test_binlog <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token string">'2018-11-10'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>在flink监控页面查看日志<br>可以查看到，数据是从8，9开始的。断点续传测试成功</li>
</ol>
<h4 id="测试采集没有主键的表"><a href="#测试采集没有主键的表" class="headerlink" title="测试采集没有主键的表"></a>测试采集没有主键的表</h4><p>采集没有主键的表，通过DataStream的方式没找到办法，但是通过StreamTableEnvironment的方式，可以采集<br>主要是通过设置<code>scan.incremental.snapshot.enabled=false</code>来达到这种目的<br>这种方式下，在数据全量采集（初始化）阶段，会锁表，还是有风险的，尽量保证有主键</p>
<h4 id="采集分表分库"><a href="#采集分表分库" class="headerlink" title="采集分表分库"></a>采集分表分库</h4><p>这里相对简单，只要把表明和库名以正则的方式输入即可</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">dbName <span class="token operator">=</span> <span class="token string">"[a-zA-Z\\d]+_test"</span><span class="token punctuation">;</span>
tableName <span class="token operator">=</span> <span class="token string">"[a-zA-Z\\d]+_test.gjc_test_binlog_[0-9][0-9]"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="修改mysql字段，检查代码兼容性"><a href="#修改mysql字段，检查代码兼容性" class="headerlink" title="修改mysql字段，检查代码兼容性"></a>修改mysql字段，检查代码兼容性</h4><h3 id="Flink-CDC实时采集Mysql入Hudi"><a href="#Flink-CDC实时采集Mysql入Hudi" class="headerlink" title="Flink CDC实时采集Mysql入Hudi"></a>Flink CDC实时采集Mysql入Hudi</h3><p>待验证。。</p>
<h3 id="Flink-CDC实时采集Sqlserver入Kafka"><a href="#Flink-CDC实时采集Sqlserver入Kafka" class="headerlink" title="Flink CDC实时采集Sqlserver入Kafka"></a>Flink CDC实时采集Sqlserver入Kafka</h3><p>待验证。。。</p>
<h3 id="Flink-CDC实时采集Sqlserver入Hudi"><a href="#Flink-CDC实时采集Sqlserver入Hudi" class="headerlink" title="Flink CDC实时采集Sqlserver入Hudi"></a>Flink CDC实时采集Sqlserver入Hudi</h3><p>待验证。。。</p>
<h2 id="开发计划于未来规划"><a href="#开发计划于未来规划" class="headerlink" title="开发计划于未来规划"></a>开发计划于未来规划</h2><h3 id="开发计划"><a href="#开发计划" class="headerlink" title="开发计划"></a>开发计划</h3><ol>
<li>开发FlinkCDC程序，使其满足实时采集Mysql入Kafka/Hudi、断点续传、分库分表等功能</li>
<li>和服务端联调，支持可配置化</li>
<li>支持表结构改变自动同步下游目标表结构，并修改元数据系统信息</li>
<li>开发实时采集监控程序</li>
<li>开发程序支持采集SqlServer等数据源实时采集</li>
</ol>
<h3 id="未来规划"><a href="#未来规划" class="headerlink" title="未来规划"></a>未来规划</h3><p>未来规划开发FlinkSQL平台，这样采集可以直接通过在页面写SQL的方式直接入数据湖组件，并且可以在采集的过程中就把ETL做了，像一些维表的关联等等</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>实时架构</category>
      </categories>
      <tags>
        <tag>实时架构</tag>
      </tags>
  </entry>
  <entry>
    <title>Hbase学习笔记</title>
    <url>/2022/03/01/Hbase%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Hbase简介</li>
<li>Hbase安装</li>
<li>HBase命令行操作</li>
<li>Phoenix操作Hbase</li>
</ul>
<a id="more"></a>

<h2 id="Hbase简介"><a href="#Hbase简介" class="headerlink" title="Hbase简介"></a>Hbase简介</h2><p>HBASE是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBASE技术可在廉价PC Server上搭建起大规模结构化存储集群。<br>HBASE的目标是存储并处理大型的数据，更具体来说是仅需使用普通的硬件配置，就能够处理由成千上万的行和列所组成的大型数据。</p>
<p>它介于nosql和RDBMS之间，仅能通过主键(row key)和主键的range来检索数据，仅支持单行事务(可通过hive支持来实现多表join等复杂操作)。主要用来存储非结构化和半结构化的松散数据。</p>
<p>Hbase的表模型与关系型数据库的表模型不同：</p>
<ul>
<li>Hbase的表没有固定的字段定义；</li>
<li>Hbase的表中每行存储的都是一些key-value对</li>
<li>Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族</li>
<li>Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中</li>
<li>Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复</li>
<li>Hbase中的数据，包含行键，包含key，包含value，都是byte[ ]类型，hbase不负责为用户维护数据类型</li>
<li>HBASE对事务的支持很差</li>
</ul>
<p>HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：<br>Hbase的表数据存储在HDFS文件系统中，所以，hbase具备如下特性：</p>
<ul>
<li>海量存储</li>
<li>列式存储</li>
<li>数据存储的安全性可靠性极高！</li>
<li>支持高并发</li>
<li>存储容量可以线性扩展；</li>
</ul>
<h3 id="HBase存储机制"><a href="#HBase存储机制" class="headerlink" title="HBase存储机制"></a>HBase存储机制</h3><p>HBase是一个面向列的数据库，在表中它由行排序。表模式定义只能列族，也就是键值对。一个表有多个列族以及每一个列族可以有任意数量的列。后续列的值连续地存储在磁盘上。表中的每个单元格值都具有时间戳。总之，在一个HBase： - 表是行的集合。 - 行是列族的集合。 - 列族是列的集合。 - 列是键值对的集合。</p>
<p>下面给出的表中是HBase模式的一个例子。<br><img src="/uploads/202203/Hbase%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6.png" alt="Hbase存储机制"></p>
<h3 id="名词概念"><a href="#名词概念" class="headerlink" title="名词概念"></a>名词概念</h3><ul>
<li><p><strong>Rowkey的概念</strong><br>Rowkey的概念和mysql中的主键是完全一样的，Hbase使用Rowkey来唯一的区分某一行的数据。Hbase只支持3种查询方式： - 1、基于Rowkey的单行查询 - 2、基于Rowkey的范围扫描 - 3、全表扫描<br>因此，Rowkey对Hbase的性能影响非常大，Rowkey的设计就显得尤为的重要。设计的时候要兼顾基于Rowkey的单行查询也要键入Rowkey的范围扫描。<br>rowkey 行键可以是任意字符串(最大长度是64KB，实际应用中长度一般为 10-100bytes)，最好是16。在HBase 内部，rowkey 保存为字节数组。HBase会对表中的数据按照 rowkey 排序 (字典顺序)</p>
</li>
<li><p><strong>Column的概念</strong><br>列，可理解成MySQL列。</p>
</li>
<li><p><strong>ColumnFamily的概念</strong><br>Hbase通过列族划分数据的存储，列族下面可以包含任意多的列，实现灵活的数据存取。列族是由一个一个的列组成（任意多）。</p>
</li>
</ul>
<p>Hbase表的创建的时候就必须指定列族。就像关系型数据库创建的时候必须指定具体的列是一样的。</p>
<p>Hbase的列族不是越多越好，官方推荐的是列族最好小于或者等于3。我们使用的场景一般是1个列族。</p>
<ul>
<li><p><strong>TimeStamp的概念</strong><br>TimeStamp对Hbase来说至关重要，因为它是实现Hbase多版本的关键。在Hbase中使用不同的timestame来标识相同rowkey行对应的不通版本的数据。<br>在写入数据的时候，如果用户没有指定相应的timestamp，HBase会自动添加一个timestamp，timestamp和服务器时间保持一致。<br>HBase 中通过rowkey和columns确定的为一个存储单元称为cell。每个cell都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是64位整型。时间戳可以由 hbase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。<br>为了避免数据存在过多版本造成的的管理(包括存贮和索引)负担，hbase 提供了两种数据版本回收方式： - 保存数据的最后 n 个版本 - 保存最近一段时间内的版本（设置数据的生命周期 TTL）。<br>用户可以针对每个列簇进行设置。</p>
</li>
<li><p><strong>单元格（Cell）</strong><br>由{rowkey, column( = +),version}唯一确定的单元。 Cell 中的数据是没有类型的，全部是字节码形式存贮。</p>
</li>
<li><p><strong>Region</strong><br>Region的概念和关系型数据库的分区或者分片差不多。<br>Hbase会将一个大表的数据基于Rowkey的不同范围分配到不通的Region中，每个Region负责一定范围的数据访问和存储。这样即使是一张巨大的表，由于被切割到不通的region，访问起来的时延也很低。</p>
</li>
</ul>
<h2 id="Hbase安装"><a href="#Hbase安装" class="headerlink" title="Hbase安装"></a>Hbase安装</h2><p>此处略过，具体可以参考[][]</p>
<h2 id="HBase命令行操作"><a href="#HBase命令行操作" class="headerlink" title="HBase命令行操作"></a>HBase命令行操作</h2><table>
<thead>
<tr>
<th>名称</th>
<th>命令表达式</th>
</tr>
</thead>
<tbody><tr>
<td>创建表</td>
<td>create ‘表名’, ‘列族名1’,’列族名2’,’列族名N’</td>
</tr>
<tr>
<td>查看所有表</td>
<td>list</td>
</tr>
<tr>
<td>描述表</td>
<td>describe  ‘表名’</td>
</tr>
<tr>
<td>判断表存在</td>
<td>exists  ‘表名’</td>
</tr>
<tr>
<td>判断是否禁用启用表</td>
<td>is_enabled ‘表名’is_disabled ‘表名’</td>
</tr>
<tr>
<td>添加记录</td>
<td>put  ‘表名’, ‘rowKey’, ‘列族 : 列‘  ,  ‘值’</td>
</tr>
<tr>
<td>查看记录rowkey下的所有数据</td>
<td>get  ‘表名’ , ‘rowKey’</td>
</tr>
<tr>
<td>查看表中的记录总数</td>
<td>count  ‘表名’</td>
</tr>
<tr>
<td>获取某个列族</td>
<td>get ‘表名’,’rowkey’,’列族’</td>
</tr>
<tr>
<td>获取某个列族的某个列</td>
<td>get ‘表名’,’rowkey’,’列族：列’</td>
</tr>
<tr>
<td>删除记录</td>
<td>delete  ‘表名’ ,‘行名’ , ‘列族：列’</td>
</tr>
<tr>
<td>删除整行</td>
<td>deleteall ‘表名’,’rowkey’</td>
</tr>
<tr>
<td>删除一张表</td>
<td>先要屏蔽该表，才能对该表进行删除第一步 disable ‘表名’ ，第二步  drop ‘表名’</td>
</tr>
<tr>
<td>清空表</td>
<td>truncate ‘表名’</td>
</tr>
<tr>
<td>查看所有记录</td>
<td>scan “表名”</td>
</tr>
<tr>
<td>查看某个表某个列中所有数据</td>
<td>scan “表名” , {COLUMNS=&gt;’列族名:列名’}</td>
</tr>
<tr>
<td>更新记录</td>
<td>就是重写一遍，进行覆盖，hbase没有修改，都是追加</td>
</tr>
</tbody></table>
<h2 id="Phoenix操作Hbase"><a href="#Phoenix操作Hbase" class="headerlink" title="Phoenix操作Hbase"></a>Phoenix操作Hbase</h2><h3 id="Phoenix安装与配置"><a href="#Phoenix安装与配置" class="headerlink" title="Phoenix安装与配置"></a>Phoenix安装与配置</h3><p>新公司使用的CM来统一管理大数据集群，为了防止软件版本不统一导致各种问题，这里在CM上安装Phoenix</p>
<p>首先，需要确定CM平台是哪个版本的，在CM的管理页面上可以直接看出，我们的CM的6.2.0版本的<br>那么剩下的，就是要下载一个和6.2.0版本想匹配的phoenix安装包<br>但是，CM从2021.1月份开始收费，通过正常渠道无法下载到这个安装包了。这里是在百度上找了很久才找到<br>具体参考<a href="https://blog.csdn.net/hell_oword/article/details/119327354?spm=1001.2014.3001.5502">CDH 6.2 安装 Phoenix</a></p>
<p>安装包已经搞定，下面开始安装</p>
<ol>
<li><p>首先安装 CSD 文件</p>
<ol>
<li>确定 CSD(Custom Service Descriptor) 文件安装路径，公司的安装路径为/opt/cloudera/csd,这里的地址就是server的地址，即ddp1服务器的地址</li>
<li>将 CSD文件(PHOENIX-1.0.jar) 放到到本地描述符存储库路径，然后重启 Cloudera Manager 服务器</li>
<li>重启 cloudera-scm-server 服务<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">systemctl restart cloudera-scm-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>这里如果cloudera-scm-server 服务不重启，虽然phoenix安装上去了也能正常使用，但是，在主页面添加不了服务，监控不了该组件</p>
</blockquote>
</li>
</ol>
</li>
<li><p>安装Phoenix parcel</p>
<ol>
<li>上传文件到<code>/opt/cloudera/parcel-repo</code>目录下，PHOENIX-5.0.0-cdh6.2.0.p0.1308267-el7.parcel、PHOENIX-5.0.0-cdh6.2.0.p0.1308267-el7.parcel.sha 、 manifest.json</li>
<li>点击检查新 Parcel ，当出现 PHOENIX 后，点击 Distribute</li>
<li>点击激活 PHOENIX，并在弹框中点击 确认</li>
<li>集群 -&gt; 操作 -&gt; 添加服务，出现 PHOENIX 服务 </li>
<li>将 PHOENIX 服务添加到每个 Region Server 中</li>
<li>重启hbase集群，否则phoenix启动会报错</li>
</ol>
</li>
</ol>
<h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol>
<li><p>Phoenix安装完成以后，在服务里找不到选项，添加不了服务，原因是CSD文件配置好以后，CM没有重启</p>
</li>
<li><p>添加完成phoenix服务以后，监控不了，CM页面提示如下告警信息<br><img src="/uploads/202203/phoenix%E6%B7%BB%E5%8A%A0%E6%9C%8D%E5%8A%A1%E5%BC%82%E5%B8%B8.png" alt="phoenix添加服务异常"><br>在CM界面点击<code>Cloudera Management Service</code>重启后解决</p>
</li>
<li><p>Phoenix安装完成以后，直接打开phoenix-sqlline，报如下错误</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Error: org.apache.hadoop.hbase.DoNotRetryIOException: Unable to load configured region split policy &#39;org.apache.phoenix.schema.MetaDataSplitPolicy&#39; for table &#39;SYSTEM.CATALOG&#39; Set hbase.table.sanity.checks to false at conf or table descriptor if you want to bypass sanity checks
        at org.apache.hadoop.hbase.master.HMaster.warnOrThrowExceptionForFailure(HMaster.java:2232)
        at org.apache.hadoop.hbase.master.HMaster.sanityCheckTableDescriptor(HMaster.java:2079)
        at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1978)
        at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:630)
        at org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:130)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:324)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:304) (state&#x3D;08000,code&#x3D;101)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>网上的说法是，需要把phoenix的jar包放到hbase的安装路径之下，但是，那应该是自己解压phoenix安装的问题，使用CM安装，CM会把这些配置都设置好的，只需要重启一下Hbase集群即可</p>
</li>
<li><p>phoenix里查不到hbase的表</p>
<ol>
<li>这里不算是问题，phoenix创建的表hbase能看到，但是，hbase的表想要在phoenix里看到，需要做一次映射</li>
</ol>
</li>
</ol>
<h3 id="phoenix映射HBase"><a href="#phoenix映射HBase" class="headerlink" title="phoenix映射HBase"></a>phoenix映射HBase</h3><p>默认情况下，直接在hbase中创建的表，通过phoenix是查看不到的。<br>如果要在phoenix中操作由hbase创建的表，则需要在phoenix中进行表的映射。<br>映射方式有两种：</p>
<blockquote>
<p>视图映射和表映射</p>
</blockquote>
<p>两种方式的区别：</p>
<ul>
<li>视图只读，不支持新增和修改</li>
<li>如果删除视图，源数据不会发生改变</li>
<li>视图的查询效率较低（原因是：表映射会在表中创建一些空的键值对，这些空键值对的存在可以用来提高查询效率，而视图映射没有）</li>
<li>使用create table创建的关联表，如果对表进行了修改，源数据也会改变，同时如果关联表被删除，源表也会被删除。</li>
</ul>
<p>案例：<br>首先在Hbase中创建一个表，并写入几条数据</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create &#39;phoenix&#39;,&#39;info&#39;
put &#39;phoenix&#39;, &#39;row001&#39;,&#39;info:name&#39;,&#39;phoenix&#39;
put &#39;phoenix&#39;, &#39;row002&#39;,&#39;info:name&#39;,&#39;hbase&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ul>
<li>创建视图：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create view &quot;phoenix&quot;(empid varchar primary key,&quot;info&quot;.&quot;name&quot; varchar);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>*注意：**</li>
</ul>
<ol>
<li>这里一定要注意的是表名和列族以及列名需要用双引号括起来，因为HBase是区分大小写的，如果不用双引号括起来的话Phoenix在创建表的时候会自动将小写转换为大写字母，这样HBase中会创建另外一张表PHOENIX。  </li>
<li>这里查询表名需要用双引号括起来，强制不转换为大写。</li>
</ol>
<p><img src="/uploads/202203/phoenix%E5%88%9B%E5%BB%BAhbase%E8%A7%86%E5%9B%BE.png" alt="phoenix创建hbase视图"></p>
<blockquote>
<p>视图是只读的，不可以修改hbase表的内容</p>
</blockquote>
<ul>
<li>创建关联表：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create table &quot;phoenix&quot;(empid varchar primary key,&quot;info&quot;.&quot;name&quot; varchar);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
直接这么创建，从hbase端修改的数据，在phoenix里是查不到的。<br>经过阅读官方文档发现，phoenix 4.10 版本后，对列映射做了优化，采用一套新的机制，不在基于列名方式映射到 hbase。<br>如果只是想查询hbase数据，那么可以使用创建视图的方式，但是如果必须要映射到表，需要禁用列映射规则(会降低查询性能)<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create table &quot;phoenix&quot;(empid varchar primary key,&quot;info&quot;.&quot;name&quot; varchar) column_encoded_bytes&#x3D;0;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<img src="/uploads/202203/phonix%E5%88%9B%E5%BB%BA%E8%A1%A8%E6%98%A0%E5%B0%84hbase%E8%A1%A8.png" alt="phonix创建表映射hbase表"></li>
</ul>
<p>还有一个问题：<br>通过phoenix创建的表，在phoenix侧修改数据后，hbase里的数据是两条<br><img src="/uploads/202203/phoenix%E6%9B%B4%E6%96%B0hbase%E8%A1%A8%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98.png" alt="phoenix更新hbase表存在的问题"><br>不知道这种数据会不会是脏数据</p>
<h3 id="JDBC链接Phoenix"><a href="#JDBC链接Phoenix" class="headerlink" title="JDBC链接Phoenix"></a>JDBC链接Phoenix</h3><p>添加Maven依赖</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0-HBase-2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.glassfish<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>javax.el<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>java代码：</p>
<blockquote>
<p>因为jdbc调用UDF失败，需要把hbase-site.xml加入到resource文件夹下再打包</p>
</blockquote>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>escloud<span class="token punctuation">.</span>phoenix</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>jdbc<span class="token punctuation">.</span></span><span class="token class-name">PhoenixDriver</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token operator">*</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">PhoenixTest</span> <span class="token punctuation">&#123;</span>
   <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> driver <span class="token operator">=</span> <span class="token string">"org.apache.phoenix.jdbc.PhoenixDriver"</span><span class="token punctuation">;</span>
   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">SQLException</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">Class</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span>driver<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClassNotFoundException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>
      <span class="token class-name">Statement</span> stmt <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
      <span class="token class-name">ResultSet</span> rs <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
      <span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      stmt <span class="token operator">=</span> con<span class="token punctuation">.</span><span class="token function">createStatement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token class-name">String</span> sql <span class="token operator">=</span> <span class="token string">"select * from \"phoenix\""</span><span class="token punctuation">;</span>
      rs <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>sql<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"rowkey:"</span><span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"ROWKEY"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">",name:"</span><span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token class-name">String</span> s1 <span class="token operator">=</span> <span class="token string">"select CRC32('aaa') as aaa from \"phoenix\""</span><span class="token punctuation">;</span>
      rs <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"AAA:"</span><span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>
      stmt<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      con<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="遇到的问题-1"><a href="#遇到的问题-1" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol>
<li>java.lang.ClassNotFoundException: org.apache.phoenix.jdbc.PhoenixDriver</li>
</ol>
<p><strong>问题原因：</strong> maven工程打包不正确，应该把依赖也打到jar包里<br><strong>解决办法：</strong> </p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
                    <span class="token comment">&lt;!-- get all project dependencies --></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                        <span class="token comment">&lt;!-- bind to the packaging phase --></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>报找不到方法，具体报错信息<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: org.apache.hadoop.security.authentication.util.KerberosUtil.hasKerberosKeyTab(Ljavax&#x2F;security&#x2F;auth&#x2F;Subject;)Z
        at org.apache.hadoop.security.UserGroupInformation.&lt;init&gt;(UserGroupInformation.java:715)
        at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:925)
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:873)
        at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:740)
        at org.apache.hadoop.hbase.security.User$SecureHadoopUser.&lt;init&gt;(User.java:266)
        at org.apache.hadoop.hbase.security.User.getCurrent(User.java:164)
        at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo.&lt;init&gt;(PhoenixEmbeddedDriver.java:504)
        at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo.create(PhoenixEmbeddedDriver.java:312)
        at org.apache.phoenix.jdbc.PhoenixDriver.getConnectionQueryServices(PhoenixDriver.java:232)
        at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver.createConnection(PhoenixEmbeddedDriver.java:150)
        at org.apache.phoenix.jdbc.PhoenixDriver.connect(PhoenixDriver.java:221)
        at java.sql.DriverManager.getConnection(DriverManager.java:664)
        at java.sql.DriverManager.getConnection(DriverManager.java:270)
        at com.digiwin.escloud.phoenix.Phoenix.main(Phoenix.java:18)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
解决办法：添加maven依赖<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>开启<code>phoenix.schema.isNamespaceMappingEnabled=true</code>之后，再用jdbc方式连接phoenix报如下错误：<br><img src="/uploads/202203/Hbase%E5%BC%80%E5%90%AFNamespace%E6%98%A0%E5%B0%84%E5%90%8EPhoenixJDBC%E6%8A%A5%E9%94%99.png" alt="Hbase开启Namespace映射后PhoenixJDBC报错"><br>原因：<br>开启这个配置以后，sqlline的方式可以默认映射过去，但是jdbc方式需要再手动指定一下<br>解决办法：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 再代码里加配置条件</span>
<span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"phoenix.schema.isNamespaceMappingEnabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="利用Phoenix创建hbase的二级索引"><a href="#利用Phoenix创建hbase的二级索引" class="headerlink" title="利用Phoenix创建hbase的二级索引"></a>利用Phoenix创建hbase的二级索引</h3>配置:<br>安装完 Phoenix 后，需要做一些必要配置才能使用 Phoenix，CDH HBase 配置界面配置如下两处：</li>
<li>hbase-site.xml 的 HBase 服务高级配置代码段（安全阀）</li>
<li>hbase-site.xml 的 HBase 客户端高级配置代码段（安全阀）<br>添加如下参数配置：<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 二级索引支持 --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.regionserver.wal.codec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
然后，按照提示重启HBase服务并重新部署客户端配置即可。</li>
</ol>
<p>创建二级索引：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">index</span> phoneix_index <span class="token keyword">on</span> <span class="token string">"phoenix"</span> <span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">.</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>需要注意的是：<br><img src="/uploads/202203/Phoenix%E5%88%9B%E5%BB%BA%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E6%B3%A8%E6%84%8F%E7%82%B9.png" alt="Phoenix创建二级索引注意点"><br>所以如果想用hbase的二级索引，只能从phoenix中插入数据</p>
<h3 id="允许Phoenix创建namespace"><a href="#允许Phoenix创建namespace" class="headerlink" title="允许Phoenix创建namespace"></a>允许Phoenix创建namespace</h3><p>CDH HBase 配置界面配置如下两处：</p>
<ol>
<li>hbase-site.xml 的 HBase 服务高级配置代码段（安全阀）</li>
<li>hbase-site.xml 的 HBase 客户端高级配置代码段（安全阀）<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 命名空间映射开启，Phoenix4.8.0开始支持 --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.schema.isNamespaceMappingEnabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.schema.mapSystemTablesToNamespace<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
注意：<br>开启了命名空间以后，通过jdbc方式连接phoenix，需要在代码里配置一下这个参数：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 再代码里加配置条件</span>
<span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"phoenix.schema.isNamespaceMappingEnabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
如果不添加如上配置，会报如下错误：<br><img src="/uploads/202203/Hbase%E5%BC%80%E5%90%AFNamespace%E6%98%A0%E5%B0%84%E5%90%8EPhoenixJDBC%E6%8A%A5%E9%94%99.png" alt="Hbase开启Namespace映射后PhoenixJDBC报错"></li>
</ol>
<h3 id="Phoenix允许自定义UDF"><a href="#Phoenix允许自定义UDF" class="headerlink" title="Phoenix允许自定义UDF"></a>Phoenix允许自定义UDF</h3><p>CDH HBase 配置界面配置如下两处：</p>
<ol>
<li>hbase-site.xml 的 HBase 服务高级配置代码段（安全阀）</li>
<li>hbase-site.xml 的 HBase 客户端高级配置代码段（安全阀）<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 启用用户自定义函数（UDF） --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.functions.allowUserDefinedFunctions<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>enable UDF functions<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>

<span class="token comment">&lt;!-- 自定义函数，存储jar的hdfs目录 --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.dynamic.jars.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/hbase/lib/udf<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
下面写一个UDF来实现CRC32加密功能：</li>
</ol>
<ul>
<li><p>添加maven配置</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0-HBase-2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>编写java代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>escloud<span class="token punctuation">.</span>phoenix</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">ImmutableBytesWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Bytes</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>expression<span class="token punctuation">.</span></span><span class="token class-name">Expression</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>expression<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span><span class="token class-name">ScalarFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>parse<span class="token punctuation">.</span></span><span class="token class-name">FunctionParseNode</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token class-name">PDataType</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token class-name">PVarchar</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">SQLException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>zip<span class="token punctuation">.</span></span>CRC32<span class="token punctuation">;</span>

<span class="token annotation punctuation">@FunctionParseNode</span><span class="token punctuation">.</span><span class="token class-name">BuiltInFunction</span><span class="token punctuation">(</span>
        name <span class="token operator">=</span> <span class="token class-name">CRC32Function</span><span class="token punctuation">.</span>NAME<span class="token punctuation">,</span>
        args <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token annotation punctuation">@FunctionParseNode</span><span class="token punctuation">.</span><span class="token class-name">Argument</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
<span class="token punctuation">)</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CRC32Function</span> <span class="token keyword">extends</span> <span class="token class-name">ScalarFunction</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> NAME <span class="token operator">=</span> <span class="token string">"CRC32"</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Integer</span> LENGTH <span class="token operator">=</span> <span class="token number">19</span><span class="token punctuation">;</span>


    <span class="token keyword">public</span> <span class="token class-name">CRC32Function</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">SQLException</span> <span class="token punctuation">&#123;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token class-name">CRC32Function</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Expression</span><span class="token punctuation">></span></span> children<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">SQLException</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>children<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">CRC32</span> crc32 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">CRC32</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        crc32<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span><span class="token string">"lake"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>crc32<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">evaluate</span><span class="token punctuation">(</span><span class="token class-name">Tuple</span> tuple<span class="token punctuation">,</span> <span class="token class-name">ImmutableBytesWritable</span> ptr<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">getChildExpression</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">evaluate</span><span class="token punctuation">(</span>tuple<span class="token punctuation">,</span> ptr<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>ptr<span class="token punctuation">.</span><span class="token function">getLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token class-name">CRC32</span> crc32 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">CRC32</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        crc32<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span>ptr<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ptr<span class="token punctuation">.</span><span class="token function">getOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ptr<span class="token punctuation">.</span><span class="token function">getLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        ptr<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token class-name">Bytes</span><span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>crc32<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">PDataType</span> <span class="token function">getDataType</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token class-name">PVarchar</span><span class="token punctuation">.</span>INSTANCE<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">Integer</span> <span class="token function">getMaxLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> LENGTH<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isNullable</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token function">getChildExpression</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">isNullable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> NAME<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">private</span> <span class="token class-name">Expression</span> <span class="token function">getChildExpression</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> children<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>上传jar包到hdfs</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop fs -put CalculationRealtime-1.0-SNAPSHOT-jar-with-dependencies.jar &#x2F;hbase&#x2F;lib&#x2F;udf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在sqlline创建udf</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> CRC32<span class="token punctuation">(</span><span class="token keyword">varchar</span><span class="token punctuation">)</span> <span class="token keyword">returns</span> <span class="token keyword">varchar</span> <span class="token keyword">as</span> <span class="token string">'com.digiwin.escloud.phoenix.CRC32Function'</span> <span class="token keyword">using</span> jar <span class="token string">'/hbase/lib/udf/CalculationRealtime-1.0-SNAPSHOT-jar-with-dependencies.jar'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/202203/Phoenix%E5%88%9B%E5%BB%BAUDF%E6%88%90%E5%8A%9F.png" alt="Phoenix创建UDF成功"><br>注意：<br>这里的路径因为公司hadoop集群配置了hdfs的开头，所以不要以hdfs:///开头</p>
</li>
<li><p>使用udf</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> CRC32<span class="token punctuation">(</span><span class="token string">'aaa'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> <span class="token string">"phoenix"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/202203/phoenix%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89UDF.png" alt="phoenix使用自定义UDF"></p>
</li>
</ul>
<h3 id="通过JDBC使用自定义UDF"><a href="#通过JDBC使用自定义UDF" class="headerlink" title="通过JDBC使用自定义UDF"></a>通过JDBC使用自定义UDF</h3><p>如果是JDBC中使用到了UDF函数，需要在hbase-site.xml中添加参数</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.local.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/tmp/hbase-hbase/local/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>UDF 本地文件系统路径<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里虽然在CM上客户端和服务端都设置了上面的参数，但是，还是报如下错误：<br><img src="/uploads/202203/JDBC%E6%96%B9%E5%BC%8F%E8%B0%83%E7%94%A8PhoenixUDF%E6%8A%A5%E9%94%99.png" alt="JDBC方式调用PhoenixUDF报错"><br>这里不知道为啥，我把配置到hbase-site.xml的参数都通过Properties的方式加到代码里了，但是不生效<br>解决办法：<br>在代码里的resource文件夹添加hbase-site.xml，重新打包，就可以了</p>
<h3 id="解决通过Flink调用phoenix-jdbc创建schema失败"><a href="#解决通过Flink调用phoenix-jdbc创建schema失败" class="headerlink" title="解决通过Flink调用phoenix jdbc创建schema失败"></a>解决通过Flink调用phoenix jdbc创建schema失败</h3><p>原始pom文件</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;phoenix-spark.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.glassfish<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>javax.el<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>java代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>cdc2kafka</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">SingleOutputStreamOperator</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">KeyedProcessFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">Connection</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">DriverManager</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">PreparedStatement</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">SQLException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkPhoenixTest2</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> PHOENIX_DRIVER <span class="token operator">=</span> <span class="token string">"org.apache.phoenix.jdbc.PhoenixDriver"</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"ddp3.hadoop:9092,ddp4.hadoop:9092,ddp5.hadoop:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"gjc_test"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">MyKafkaDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> aaa <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> str <span class="token operator">:</span> arr<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>str<span class="token punctuation">,</span> <span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>x <span class="token operator">-></span> x<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">KeyedProcessFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    <span class="token class-name">String</span> phoenixServer <span class="token operator">=</span> <span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">;</span>

                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                        <span class="token keyword">if</span> <span class="token punctuation">(</span>phoenixServer <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span><span class="token string">"Config of phoenix server is null"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                        <span class="token class-name">Class</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span>PHOENIX_DRIVER<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"phoenix.schema.isNamespaceMappingEnabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">Connection</span> connection <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span>phoenixServer<span class="token punctuation">,</span> props<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        connection<span class="token punctuation">.</span><span class="token function">setAutoCommit</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> sql1 <span class="token operator">=</span> <span class="token string">"create schema IF NOT EXISTS \"aaa\""</span><span class="token punctuation">;</span>
                        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"-----sql1"</span><span class="token operator">+</span>sql1<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">boolean</span> execute <span class="token operator">=</span> <span class="token function">execute</span><span class="token punctuation">(</span>connection<span class="token punctuation">,</span> sql1<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"-----execute1"</span><span class="token operator">+</span>execute<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>


                    <span class="token annotation punctuation">@Override</span>
                    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processElement</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">KeyedProcessFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">.</span><span class="token class-name">Context</span> ctx<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        aaa<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> <span class="token function">execute</span><span class="token punctuation">(</span><span class="token class-name">Connection</span> connection<span class="token punctuation">,</span> <span class="token class-name">String</span> sql<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">PreparedStatement</span> preparedStatement <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
            preparedStatement <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span>sql<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">boolean</span> execute <span class="token operator">=</span> preparedStatement<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> execute<span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">throw</span> e<span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">finally</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>preparedStatement <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
                    preparedStatement<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">SQLException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>报错如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.phoenix.exception.PhoenixIOException: java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hadoop&#x2F;tracing&#x2F;SpanReceiverHost
        at org.apache.phoenix.util.ServerUtil.parseServerException(ServerUtil.java:138)
        at org.apache.phoenix.query.ConnectionQueryServicesImpl.ensureNamespaceCreated(ConnectionQueryServicesImpl.java:1046)
        at org.apache.phoenix.query.ConnectionQueryServicesImpl.createSchema(ConnectionQueryServicesImpl.java:4559)
        at org.apache.phoenix.schema.MetaDataClient.createSchema(MetaDataClient.java:4074)
        at org.apache.phoenix.compile.CreateSchemaCompiler$1.execute(CreateSchemaCompiler.java:46)
        at org.apache.phoenix.jdbc.PhoenixStatement$2.call(PhoenixStatement.java:408)
        at org.apache.phoenix.jdbc.PhoenixStatement$2.call(PhoenixStatement.java:391)
        at org.apache.phoenix.call.CallRunner.run(CallRunner.java:53)
        at org.apache.phoenix.jdbc.PhoenixStatement.executeMutation(PhoenixStatement.java:390)
        at org.apache.phoenix.jdbc.PhoenixStatement.executeMutation(PhoenixStatement.java:378)
        at org.apache.phoenix.jdbc.PhoenixPreparedStatement.execute(PhoenixPreparedStatement.java:173)
        at org.apache.phoenix.jdbc.PhoenixPreparedStatement.execute(PhoenixPreparedStatement.java:183)
        at com.digiwin.flink.cdc2kafka.FlinkPhoenixTest2.execute(FlinkPhoenixTest2.java:75)
        at com.digiwin.flink.cdc2kafka.FlinkPhoenixTest2.access$000(FlinkPhoenixTest2.java:18)
        at com.digiwin.flink.cdc2kafka.FlinkPhoenixTest2$1.open(FlinkPhoenixTest2.java:58)
        at org.apache.flink.api.common.functions.util.FunctionUtils.openFunction(FunctionUtils.java:34)
        at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.open(AbstractUdfStreamOperator.java:102)
        at org.apache.flink.streaming.api.operators.KeyedProcessOperator.open(KeyedProcessOperator.java:55)
        at org.apache.flink.streaming.runtime.tasks.OperatorChain.initializeStateAndOpenOperators(OperatorChain.java:442)
        at org.apache.flink.streaming.runtime.tasks.StreamTask.restoreGates(StreamTask.java:585)
        at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.call(StreamTaskActionExecutor.java:55)
        at org.apache.flink.streaming.runtime.tasks.StreamTask.executeRestore(StreamTask.java:565)
        at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:650)
        at org.apache.flink.streaming.runtime.tasks.StreamTask.restore(StreamTask.java:540)
        at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:759)
        at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566)
        at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hadoop&#x2F;tracing&#x2F;SpanReceiverHost
        at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.translateException(RpcRetryingCallerImpl.java:221)
        at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:120)
...
Caused by: java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hadoop&#x2F;tracing&#x2F;SpanReceiverHost
        at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:634)
        at org.apache.hadoop.hdfs.DFSClient.&lt;init&gt;(DFSClient.java:619)
        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:149)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3288)
...
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.tracing.SpanReceiverHost
        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 50 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>解决办法：<br>因为Phoenix版本是CDH版本的，但是pom文件里用的不是的，而且，仅仅需要Phoenix-client就可以了，多了，有jar包冲突<br>修改pom文件如下：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0.7.2.2.6-2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.glassfish<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>javax.el<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;hadoop-common.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>commons-cli<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>commons-cli<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>然后重新打包，完美解决</p>
<p>还有一个问题：<br>创建schema的时候，java需要使用PreparedStatement，不能使用</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
stmt <span class="token operator">=</span> con<span class="token punctuation">.</span><span class="token function">createStatement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">String</span> sql <span class="token operator">=</span> <span class="token string">"create schema if not exists \"aaa\""</span><span class="token punctuation">;</span>
rs <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>sql<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>这种方式只能查询貌似，不能操作数据库</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hbase</category>
      </categories>
      <tags>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title>flink-cdc实时采集数据库入Kafka</title>
    <url>/2022/03/11/flink-cdc%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5Kafka/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink-CDC实时采集Mysql入Kafka</li>
<li>Flink-CDC实时采集Sqlserver入Kafka</li>
</ul>
<a id="more"></a>


<h1 id="Flink-CDC实时采集Mysql入Kafka"><a href="#Flink-CDC实时采集Mysql入Kafka" class="headerlink" title="Flink-CDC实时采集Mysql入Kafka"></a>Flink-CDC实时采集Mysql入Kafka</h1><p>环境信息：<br>flink-1.13.6<br>mysql-5.7.26<br>kafka_2.11-2.1.0-cdh6.2.0</p>
<h2 id="Mysql开启binlog"><a href="#Mysql开启binlog" class="headerlink" title="Mysql开启binlog"></a>Mysql开启binlog</h2><h3 id="binlog的三种模式比较"><a href="#binlog的三种模式比较" class="headerlink" title="binlog的三种模式比较"></a>binlog的三种模式比较</h3><p>binlog的格式也有三种：<code>STATEMENT</code>、<code>ROW</code>、<code>MIXED</code>。<br><strong>STATMENT模式：</strong> 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。<br><strong>优点：</strong> 不需要记录每一条SQL语句与每行的数据变化，这样子binlog的日志也会比较少，减少了磁盘IO，提高性能。<br><strong>缺点：</strong> 在某些情况下会导致master-slave中的数据不一致 。</p>
<p><strong>ROW基于行的复制(row-based replication, RBR)格式：</strong> 不记录每一条SQL语句的上下文信息，仅需记录哪条数据被修改了，修改成了什么样子了。<br><strong>优点：</strong> 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。<br><strong>缺点：</strong> 会产生大量的日志，尤其是alter table的时候会让日志暴涨。<br>MIXED混合模式复制(mixed-based replication, MBR)：以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。<br>具体参考<a href="https://blog.csdn.net/woloqun/article/details/105657539">MySQL如何开启binlog？binlog三种模式的分析</a><br>我们实时采集mysql数据，需要开启<code>ROW</code>模式</p>
<h3 id="binlog开启步骤"><a href="#binlog开启步骤" class="headerlink" title="binlog开启步骤"></a>binlog开启步骤</h3><p>这里参考我的另外一篇博客<a href="https://gujincheng.github.io/2022/03/11/Centos%E5%AE%89%E8%A3%85Mysql/">Centos安装Mysql</a></p>
<h2 id="测试案例"><a href="#测试案例" class="headerlink" title="测试案例"></a>测试案例</h2><h3 id="通过简单的sqlClient读取mysqlBinlog数据"><a href="#通过简单的sqlClient读取mysqlBinlog数据" class="headerlink" title="通过简单的sqlClient读取mysqlBinlog数据"></a>通过简单的sqlClient读取mysqlBinlog数据</h3><p>在测试之前，需要把<code>flink-sql-connector-mysql-cdc-2.1.1.jar</code>放到<code>$&#123;FLINK_HOME&#125;\lib</code>下</p>
<ul>
<li><p>首先需要启动flink的集群，因为sqlClient貌似无法提交代码到yarn上，如果不启动集群，会报<code>Connect Refused</code>，找了很久的原因</p>
</li>
<li><p>在sqlClient创建一个表来映射mysql表<br><img src="/uploads/202203/sqlClient%E8%AF%BB%E5%8F%96mysqlBinlog%E5%BB%BA%E8%A1%A8.png" alt="sqlClient读取mysqlBinlog建表"></p>
</li>
<li><p>查询数据<br><img src="/uploads/202203/sqlClient%E8%AF%BB%E5%8F%96mysqlBinlog%E6%95%B0%E6%8D%AE.png" alt="sqlClient读取mysqlBinlog数据"><br>验证没问题</p>
<h3 id="通过DataStream方式编写CDC代码"><a href="#通过DataStream方式编写CDC代码" class="headerlink" title="通过DataStream方式编写CDC代码"></a>通过DataStream方式编写CDC代码</h3><p>pom.xml配置如下：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">></span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.example<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>FlinkCDCTest<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.version</span><span class="token punctuation">></span></span>1.13.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>java.version</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>java.version</span><span class="token punctuation">></span></span>
        <span class="token comment">&lt;!--scala版本，用于flink框架内部通信，它自己用        --></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scala.binary.version</span><span class="token punctuation">></span></span>2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scala.binary.version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>cdc.version</span><span class="token punctuation">></span></span>2.1.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>cdc.version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>slf4j.version</span><span class="token punctuation">></span></span>1.7.30<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>slf4j.version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.ververica<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-mysql-cdc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token comment">&lt;!-- the dependency is available only for stable releases. --></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;cdc.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-api-scala-bridge_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-planner_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
                    <span class="token comment">&lt;!-- get all project dependencies --></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                        <span class="token comment">&lt;!-- bind to the packaging phase --></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>编写代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>cdc2kafka</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>source<span class="token punctuation">.</span></span><span class="token class-name">MySqlSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">JsonDebeziumDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>eventtime<span class="token punctuation">.</span></span><span class="token class-name">WatermarkStrategy</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">Logger</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">LoggerFactory</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token operator">*</span><span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Mysql2Kakfa</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Logger</span> log <span class="token operator">=</span> <span class="token class-name">LoggerFactory</span><span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token class-name">Mysql2Kakfa</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> hostName <span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> yourPort<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> dbName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> tableName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> userName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> password<span class="token punctuation">;</span>

    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> isTest <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>

    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">parseArgs</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        log<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token string">"begin export data! args=&#123;&#125;"</span><span class="token punctuation">,</span> <span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> argsLeft <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> args<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-isTest"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                isTest <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                argsLeft<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            log<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">"输入参数个数异常，请检查！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token comment">//判断错误参数的标记，如果有错误参数，异常退出</span>
        <span class="token keyword">int</span> error <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> argsLeft<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-hostName"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                hostName <span class="token operator">=</span> argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-yourPort"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                yourPort <span class="token operator">=</span> <span class="token class-name">Integer</span><span class="token punctuation">.</span><span class="token function">parseInt</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-dbName"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                dbName <span class="token operator">=</span> argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-tableName"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                tableName <span class="token operator">=</span> argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-userName"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                userName <span class="token operator">=</span> argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"-password"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                password <span class="token operator">=</span> argsLeft<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>error <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">//parseArgs(args);</span>
        hostName <span class="token operator">=</span> <span class="token string">"localhost"</span><span class="token punctuation">;</span>
        yourPort <span class="token operator">=</span> <span class="token number">3306</span><span class="token punctuation">;</span>
        dbName <span class="token operator">=</span> <span class="token string">"test"</span><span class="token punctuation">;</span>
        tableName <span class="token operator">=</span> <span class="token string">"test.gjc_test_binlog"</span><span class="token punctuation">;</span>
        userName <span class="token operator">=</span> <span class="token string">"root"</span><span class="token punctuation">;</span>
        password <span class="token operator">=</span> <span class="token string">"Hive123!@#"</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"hostName:"</span> <span class="token operator">+</span> hostName
                <span class="token operator">+</span> <span class="token string">",port:"</span> <span class="token operator">+</span> yourPort
                <span class="token operator">+</span> <span class="token string">",dbName:"</span> <span class="token operator">+</span> dbName
                <span class="token operator">+</span> <span class="token string">",tableName:"</span> <span class="token operator">+</span> tableName
                <span class="token operator">+</span> <span class="token string">",userName:"</span> <span class="token operator">+</span> userName
                <span class="token operator">+</span> <span class="token string">",password:"</span> <span class="token operator">+</span> password
        <span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">MySqlSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> mySqlSource <span class="token operator">=</span> <span class="token class-name">MySqlSource</span><span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">hostname</span><span class="token punctuation">(</span>hostName<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">port</span><span class="token punctuation">(</span>yourPort<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">databaseList</span><span class="token punctuation">(</span>dbName<span class="token punctuation">)</span> <span class="token comment">// set captured database</span>
                <span class="token punctuation">.</span><span class="token function">tableList</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span> <span class="token comment">// set captured table</span>
                <span class="token punctuation">.</span><span class="token function">username</span><span class="token punctuation">(</span>userName<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">password</span><span class="token punctuation">(</span>password<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">startupOptions</span><span class="token punctuation">(</span><span class="token class-name">StartupOptions</span><span class="token punctuation">.</span><span class="token function">initial</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
                <span class="token punctuation">.</span><span class="token function">deserializer</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">JsonDebeziumDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// converts SourceRecord to JSON String</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    
        env<span class="token punctuation">.</span><span class="token function">fromSource</span><span class="token punctuation">(</span>mySqlSource<span class="token punctuation">,</span> <span class="token class-name">WatermarkStrategy</span><span class="token punctuation">.</span><span class="token function">noWatermarks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"MySQL Source"</span><span class="token punctuation">)</span>
                <span class="token comment">//.setParallelism(4)</span>
                <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Print MySQL Snapshot + Binlog"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>StartupOptions可选的模式含义:</p>
</li>
<li><p>initial:<br>第一次启动时 读取原表已有的历史数据, 操作类型为READ, 之后不断做检查点存储<br>第二次启动时 一定要指明检查点文件的具体位置, 这样就可以断点续传; 即使Flink宕机了, 重启后是从上次offset开始读, 而不是latest<br>检查点在打包部署后才有用, 因为那样才可以指明检查点的具体位置</p>
<blockquote>
<p>这种模式下，因为读取的存量数据，数据写入kafka是乱序的，但是这个应该是不受影响的，因为，每条数据都是唯一的，而且数据都是存量的，不会出现数据的值不对的情况</p>
</blockquote>
</li>
<li><p>earliest:<br>从BinLog第一行数据开始读, 最好先给这个数据库加上BinLog后, 再去读取创建数据库</p>
</li>
<li><p>latest:<br>读取最新变更数据, 从Flink程序启动后开始算</p>
</li>
<li><p>timestamp:<br>可以从BinLog某一时刻的数据开始读</p>
</li>
<li><p>specificOffset:<br>指明BinLog文件位置和从哪个offset开始读<br>这个一般来说不怎么用, 因为本地没存offset的信息, 很难知道offset读到哪了</p>
</li>
</ul>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!--在IDEA里执行需要添加以下依赖，但是，打包到yarn上执行，貌似会有问题，但是，后面又测试了几次，又可以了--></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在idea里可以执行，结果如图：<br><img src="/uploads/202203/Idea%E6%89%A7%E8%A1%8Cflinkcdc%E4%BB%A3%E7%A0%81%E6%88%90%E5%8A%9F.png" alt="Idea执行flinkcdc代码成功"></p>
<p>但是通过打成jar包上传到集群中，就开始报错了，执行命令如下</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -c com.digiwin.flink.cdc2kafka.Mysql2Kakfa FlinkCDCTest-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>报错如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.lang.RuntimeException: Failed to get driver instance for jdbcUrl&#x3D;jdbc:mysql:&#x2F;&#x2F;ddp5.hadoop:3306&#x2F;?useInformationSchema&#x3D;true&amp;nullCatalogMeansCurrent&#x3D;false&amp;useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;characterSetResults&#x3D;UTF-8&amp;zeroDateTimeBehavior&#x3D;CONVERT_TO_NULL
        at com.zaxxer.hikari.util.DriverDataSource.&lt;init&gt;(DriverDataSource.java:114)
        at com.zaxxer.hikari.pool.PoolBase.initializeDataSource(PoolBase.java:331)
        at com.zaxxer.hikari.pool.PoolBase.&lt;init&gt;(PoolBase.java:114)
        at com.zaxxer.hikari.pool.HikariPool.&lt;init&gt;(HikariPool.java:108)
        at com.zaxxer.hikari.HikariDataSource.&lt;init&gt;(HikariDataSource.java:81)
        at com.ververica.cdc.connectors.mysql.source.connection.PooledDataSourceFactory.createPooledDataSource(PooledDataSourceFactory.java:54)
        at com.ververica.cdc.connectors.mysql.source.connection.JdbcConnectionPools.getOrCreateConnectionPool(JdbcConnectionPools.java:51)
        at com.ververica.cdc.connectors.mysql.source.connection.JdbcConnectionFactory.connect(JdbcConnectionFactory.java:53)
        at io.debezium.jdbc.JdbcConnection.connection(JdbcConnection.java:872)
        at io.debezium.jdbc.JdbcConnection.connection(JdbcConnection.java:867)
        at io.debezium.jdbc.JdbcConnection.connect(JdbcConnection.java:413)
        at com.ververica.cdc.connectors.mysql.debezium.DebeziumUtils.openJdbcConnection(DebeziumUtils.java:62)
        ... 31 more
Caused by: java.sql.SQLException: No suitable driver
        at java.sql.DriverManager.getDriver(DriverManager.java:315)
        at com.zaxxer.hikari.util.DriverDataSource.&lt;init&gt;(DriverDataSource.java:106)
        ... 42 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>期间换了cdc的版本，换成2.0.0和2.1.1都可以执行，但是2.1.0就是不行就是报<code>No suitable driver</code><br>最终找到原因：</p>
<blockquote>
<p>因为${FLINK_HOME}/lib下我放的cdc jar包是2.1.1的，但是，我pom文件里写的是2.1.0，两个版本不一样导致的</p>
</blockquote>
<p>解决方法：</p>
<ol>
<li>可以把pom文件里的cdc版本换成2.1.1的</li>
<li>或者把lib文件夹下的cdc jar包换成2.1.0的（其实，如果要是使用java写代码的方式，lib下不需要放cdc的jar包，配置lib文件夹，主要是为了给sqlClient方式使用，经过测试，不配置lib下的cdc jar也能执行）</li>
</ol>
<p>中间还遇到一个问题：<br>因为代码里写了<code>setParallelism(4)</code>,然后使用的又是standalone方式启动任务，然后就报错了：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	... 33 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	... 29 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>经过测试，把<code>setParallelism(4)</code>去掉就可以了</p>
<blockquote>
<p>这里需要测试一下，以yarn的方式，设置多个并行度是否可行，总感觉设置多个并行度是可以的，应该是哪里没配置好</p>
</blockquote>
<p>解决了很多问题，终于成功消费到<code>mysql binlog</code>，不容易：<br><img src="/uploads/202203/java%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0flinkcdc%E9%87%87%E9%9B%86mysqlbinlog%E6%88%90%E5%8A%9F.png" alt="java代码实现flinkcdc采集mysqlbinlog成功"></p>
<h3 id="通过FlinkSQL方式编写CDC代码"><a href="#通过FlinkSQL方式编写CDC代码" class="headerlink" title="通过FlinkSQL方式编写CDC代码"></a>通过FlinkSQL方式编写CDC代码</h3><p>Java代码在下文 <strong>测试采集没有主键的表</strong>的位置<br>这里的pom文件需要好好考虑一下</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-table-planner_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>

<span class="token comment">&lt;!-- 在idea里执行任务，需要添加下面的依赖--></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-sql-client_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这两个依赖是和其他的依赖是互相冲突的，planner添加provided，kafka的我暂时直接去掉了</p>
<p>这里如果<code>planner</code>不provided，会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Unable to instantiate java compiler
    at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:372)
    at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:222)
    at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114)
    at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:812)
    at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:246)
    at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:1054)
    at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1132)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:422)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
    at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)
    at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1132)
Caused by: java.lang.IllegalStateException: Unable to instantiate java compiler
    at org.apache.calcite.rel.metadata.JaninoRelMetadataProvider.compile(JaninoRelMetadataProvider.java:428)
    at org.apache.calcite.rel.metadata.JaninoRelMetadataProvider.load3(JaninoRelMetadataProvider.java:374)
    at org.apache.calcite.rel.metadata.JaninoRelMetadataProvider.lambda$static$0(JaninoRelMetadataProvider.java:109)
    at org.apache.flink.calcite.shaded.com.google.common.cache.CacheLoader$FunctionToCacheLoader.load(CacheLoader.java:165)
    at org.apache.flink.calcite.shaded.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
    at org.apache.flink.calcite.shaded.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
    at org.apache.flink.calcite.shaded.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
    at org.apache.flink.calcite.shaded.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Flink 1.10把客户端的ClassLoader解析顺序调整为了Child优先，这就导致用户的Jar包不能包含Flink框架的classes，比如常见的Calcite、Flink-Planner依赖、Hive依赖等等。用户需要把有冲突classes的jar放到flink-home/lib下，或者调整策略为Parent优先<br>这里参考<a href="https://blog.csdn.net/woloqun/article/details/105657539">flink sql包冲突异常</a></p>
<p>如果不去除kafka的依赖，会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;kafka&#x2F;common&#x2F;utils&#x2F;ThreadUtils
	at com.ververica.cdc.debezium.internal.FlinkOffsetBackingStore.start(FlinkOffsetBackingStore.java:152)
	at com.ververica.cdc.debezium.internal.FlinkOffsetBackingStore.configure(FlinkOffsetBackingStore.java:71)
	at io.debezium.embedded.EmbeddedEngine.run(EmbeddedEngine.java:690)
	at io.debezium.embedded.ConvertingEngineBuilder$2.run(ConvertingEngineBuilder.java:188)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.utils.ThreadUtils
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h3 id="提交flinkcdc任务到yarn上"><a href="#提交flinkcdc任务到yarn上" class="headerlink" title="提交flinkcdc任务到yarn上"></a>提交flinkcdc任务到yarn上</h3><p>添加checkpoint<br>报错如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to create checkpoint storage at checkpoint coordinator side.
        at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.&lt;init&gt;(CheckpointCoordinator.java:325)
Caused by: java.io.IOException: Cannot instantiate file system for URI: hdfs:&#x2F;&#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa
        at org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.create(HadoopFsFactory.java:196)
        at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:526)
Caused by: java.lang.IllegalArgumentException: java.net.UnknownHostException: flink
        at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:445)
        at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:132)
Caused by: java.net.UnknownHostException: flink
        ... 34 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.sql.SQLNonTransientConnectionException: Data source rejected establishment of connection,  message from server: &quot;Too many connections&quot;
        at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:110)
        at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)
        at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
        at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:836)
        at com.mysql.cj.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:456)
        at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:246)
        at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:197)
        at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:138)
        at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:364)
        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>貌似flinkcdc没有及时关闭mysql链接,这里把mysql的最大连接数调大了，在<code>my.cnf</code>里添加<code>max_connections = 1000</code>，然后重启mysql服务</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Slot request bulk is not fulfillable! Could not allocate the required slot within slot request timeout
        at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
        at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
        at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:593)
        at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:577)
        ... 33 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Slot request bulk is not fulfillable! Could not allocate the required slot within slot request timeout
        at org.apache.flink.runtime.jobmaster.slotpool.PhysicalSlotRequestBulkCheckerImpl.lambda$schedulePendingRequestBulkWithTimestampCheck$0(PhysicalSlotRequestBulkCheckerImpl.java:86)
        ... 26 more
Caused by: java.util.concurrent.TimeoutException: Timeout has occurred: 300000 ms
        ... 27 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里乍一看，以为是资源不够，然后我加大资源，换资源队列，最后还是解决不了<br>最终在网上找到原因，是因为当时方便在idea里测试代码，在pom文件里添加了如下依赖：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_$&#123;scala.binary.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;flink.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里给依赖加上<code>&lt;scope&gt;provided&lt;/scope&gt;</code>,或者去掉clients的依赖即可</p>
<p>然后又遇到以下问题：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.yarn.YarnClusterDescriptor$YarnDeploymentException: The YARN application unexpectedly switched to state FAILED during deployment.
Diagnostics from YARN: Application application_1640152414594_2461 failed 1 times (global limit &#x3D;2; local limit is &#x3D;1) due to AM Container for appattempt_1640152414594_2461_000001 exited with  exitCode: 1
...
For more detailed output, check the application tracking page: http:&#x2F;&#x2F;ddp2.hadoop:8088&#x2F;cluster&#x2F;app&#x2F;application_1640152414594_2461 Then click on links to logs of each attempt.
. Failing the application.
If log aggregation is enabled on your cluster, use this command to further investigate the issue:
yarn logs -applicationId application_1640152414594_2461<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过查看application_1640152414594_2461的日志：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: org.apache.commons.cli.Option.builder(Ljava&#x2F;lang&#x2F;String;)Lorg&#x2F;apache&#x2F;commons&#x2F;cli&#x2F;Option$Builder;
        at org.apache.flink.runtime.entrypoint.parser.CommandLineOptions.&lt;clinit&gt;(CommandLineOptions.java:27)
        at org.apache.flink.runtime.entrypoint.DynamicParametersConfigurationParserFactory.options(DynamicParametersConfigurationParserFactory.java:43)
        at org.apache.flink.runtime.entrypoint.DynamicParametersConfigurationParserFactory.getOptions(DynamicParametersConfigurationParserFactory.java:50)
        at org.apache.flink.runtime.entrypoint.parser.CommandLineParser.parse(CommandLineParser.java:42)
        at org.apache.flink.runtime.entrypoint.ClusterEntrypointUtils.parseParametersOrExit(ClusterEntrypointUtils.java:63)
        at org.apache.flink.yarn.entrypoint.YarnJobClusterEntrypoint.main(YarnJobClusterEntrypoint.java:89)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里在网上查了以下原因，说是因为缺少commons.cli相关的jar，按照网上的说法，去下载了一个commons-cli的jar包放到${FLINK_HOME}\lib下<br>但是，还是没有解决这个问题。<br>最终解决办法：<br>去掉hadoop相关的依赖:</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;hadoop-common.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里的根本原因是，1.11.0版本之后，Flink不用编译flink-shaded包，不需要再把flink-shaded里的<code>flink-shaded-hadoop-XXX.jar</code>放入flink的lib文件夹下了<br>而是直接通过设置export HADOOP_CLASSPATH=<code>hadoop classpath</code>，但是，这种方式里就已经包含了<code>commons-cli</code>,但是，hadoop-common里也有<code>commons-cli</code>，这就导致版本冲突了<br>完美的解决方案是：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;hadoop-common.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>commons-cli<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>commons-cli<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>原先的依赖不变，但是排除<code>commons-cli</code>，这样就完美解决了</p>
<h3 id="添加断点续传"><a href="#添加断点续传" class="headerlink" title="添加断点续传"></a>添加断点续传</h3><p>首先在代码里添加checkpoint相关代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">//配置ck的状态后端</span>
env<span class="token punctuation">.</span><span class="token function">setStateBackend</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">HashMapStateBackend</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//设置系统异常退出或人为 Cancel 掉，不删除checkpoint数据</span>
env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setExternalizedCheckpointCleanup</span><span class="token punctuation">(</span><span class="token class-name">CheckpointConfig</span><span class="token punctuation">.</span><span class="token class-name">ExternalizedCheckpointCleanup</span><span class="token punctuation">.</span>RETAIN_ON_CANCELLATION<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//设置checkpoint存储目录</span>
env<span class="token punctuation">.</span><span class="token function">getCheckpointConfig</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setCheckpointStorage</span><span class="token punctuation">(</span><span class="token string">"hdfs://flink/checkpoint/cdc/gjc_test_Mysql2Kakfa"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
env<span class="token punctuation">.</span><span class="token function">enableCheckpointing</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>启动任务后，在hdfs上查看checkpoint文件夹：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@ddp2 ~]# hadoop fs -ls &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;
Found 3 items
drwxr-xr-x   - root supergroup          0 2022-03-19 11:51 &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;chk-27
drwxr-xr-x   - root supergroup          0 2022-03-19 11:49 &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;shared
drwxr-xr-x   - root supergroup          0 2022-03-19 11:49 &#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;taskowned<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol>
<li>手动取消flink任务</li>
<li>重新启动flink，需要注意的是，任务启动的时候，需要指定checkopint地址<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">$&#123;FLINK_HOME&#125;&#x2F;bin&#x2F;flink run -m yarn-cluster -yjm 1024 -ytm 1024 -yqu root.default -ynm gjc_test_flink-cdc-mysql -s hdfs:&#x2F;&#x2F;&#x2F;flink&#x2F;checkpoint&#x2F;cdc&#x2F;gjc_test_Mysql2Kakfa&#x2F;f24d4a641988987a47e2b6754b26481d&#x2F;chk-27 -c com.digiwin.flink.cdc2kafka.Mysql2Kakfa target&#x2F;FlinkCDCTest-1.0-SNAPSHOT-jar-with-dependencies.jar -hostName ddp5.hadoop -yourPort 3306 -dbName gjc_test -tableName gjc_test.gjc_test_binlog -userName root -password root123456<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>这里注意：-s 需要在jar包之前指定，在jar包之后指定就不生效了</p>
</blockquote>
</li>
<li>在mysql中添加数据<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> gjc_test_binlog <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token string">'2018-11-10'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> gjc_test_binlog <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token string">'2018-11-10'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>在flink监控页面查看日志<br><img src="/uploads/202203/%E4%BB%8ECK%E5%90%AF%E5%8A%A8Flink%E4%BB%BB%E5%8A%A1%E7%BB%93%E6%9E%9C.png" alt="从CK启动Flink任务结果"><br>可以查看到，数据是从8，9开始的。断点续传测试成功</li>
</ol>
<h3 id="数据写入Kafka"><a href="#数据写入Kafka" class="headerlink" title="数据写入Kafka"></a>数据写入Kafka</h3><p>给flink代码添加KafkaSink</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">//数据写入kafka</span>
        dataStreamSource<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token string">"golden-02:9092"</span><span class="token punctuation">,</span>
        <span class="token string">"test.gjc_test_binlog"</span><span class="token punctuation">,</span>
        <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="设置多个并行度"><a href="#设置多个并行度" class="headerlink" title="设置多个并行度"></a>设置多个并行度</h3><p>Flinkcdc任务在standalone模式下（这里只是在一台节点上启动了standalone），设置多并行度，报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.util.concurrent.CompletionException: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:308)
	at java.util.concurrent.CompletableFuture.uniApply(CompletableFuture.java:607)
	at java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:591)
	... 33 more
Caused by: org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException: Could not acquire the minimum required resources.
	... 29 more
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/202203/Standalone%E6%A8%A1%E5%BC%8F%E7%9A%84Flink%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E6%83%85%E5%86%B5.png" alt="Standalone模式的Flink集群资源情况"><br>这是因为，只有一个节点的flink集群，这里只有一个slot，启动不了3个并行度<br>这种情况在yarn上运行的时候不存在这种问题</p>
<h3 id="测试采集没有主键的表"><a href="#测试采集没有主键的表" class="headerlink" title="测试采集没有主键的表"></a>测试采集没有主键的表</h3><p>采集没有主键的表，通过DataStream的方式没找到办法，但是通过StreamTableEnvironment的方式，可以采集<br>下面是代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>cdc2kafka</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>source<span class="token punctuation">.</span></span><span class="token class-name">MySqlSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">JsonDebeziumDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>eventtime<span class="token punctuation">.</span></span><span class="token class-name">WatermarkStrategy</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">Table</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span>bridge<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span><span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token class-name">Row</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">Logger</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">LoggerFactory</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Arrays</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token comment">/**
 * 主要测试FlinkCDC采集Mysql，包含断点续传，提交任务到yarn上
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkSqlMysql2Kakfa</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Logger</span> log <span class="token operator">=</span> <span class="token class-name">LoggerFactory</span><span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token class-name">FlinkSqlMysql2Kakfa</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> hostName <span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> yourPort<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> dbName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> tableName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> userName<span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> password<span class="token punctuation">;</span>


    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        hostName <span class="token operator">=</span> <span class="token string">"golden-01"</span><span class="token punctuation">;</span>
        yourPort <span class="token operator">=</span> <span class="token number">3306</span><span class="token punctuation">;</span>
        <span class="token comment">//dbName = "[a-zA-Z\\d]+_test";</span>
        <span class="token comment">//tableName = "[a-zA-Z\\d]+_test.gjc_test_binlog_[0-9][0-9]";</span>
        dbName <span class="token operator">=</span> <span class="token string">"test"</span><span class="token punctuation">;</span>
        tableName <span class="token operator">=</span> <span class="token string">"test.gjc_test_binlog_noprimary"</span><span class="token punctuation">;</span>
        userName <span class="token operator">=</span> <span class="token string">"root"</span><span class="token punctuation">;</span>
        password <span class="token operator">=</span> <span class="token string">"123456"</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"hostName:"</span> <span class="token operator">+</span> hostName
                <span class="token operator">+</span> <span class="token string">",port:"</span> <span class="token operator">+</span> yourPort
                <span class="token operator">+</span> <span class="token string">",dbName:"</span> <span class="token operator">+</span> dbName
                <span class="token operator">+</span> <span class="token string">",tableName:"</span> <span class="token operator">+</span> tableName
                <span class="token operator">+</span> <span class="token string">",userName:"</span> <span class="token operator">+</span> userName
                <span class="token operator">+</span> <span class="token string">",password:"</span> <span class="token operator">+</span> password
        <span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">StreamTableEnvironment</span> tableEnvironment <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnvironment<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span>
                <span class="token string">"CREATE TABLE gjc_test_binlog ( "</span> <span class="token operator">+</span>
                        <span class="token string">" id INTEGER, "</span> <span class="token operator">+</span>
                        <span class="token string">" a INTEGER, "</span> <span class="token operator">+</span>
                        <span class="token string">" t_modified STRING "</span> <span class="token operator">+</span>
                        <span class="token string">") WITH ( "</span> <span class="token operator">+</span>
                        <span class="token string">" 'connector' = 'mysql-cdc', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'hostname' = 'golden-01', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'port' = '3306', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'username' = 'root', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'password' = '123456', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'database-name' = 'test', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'table-name' = 'gjc_test_binlog_noprimary', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'scan.incremental.snapshot.enabled'='false'"</span> <span class="token operator">+</span>    <span class="token comment">//主要是这个参数起的作用</span>
                <span class="token string">") "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Table</span> table <span class="token operator">=</span> tableEnvironment<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"select * from gjc_test_binlog"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tableEnvironment<span class="token punctuation">.</span><span class="token function">toRetractStream</span><span class="token punctuation">(</span>table<span class="token punctuation">,</span> <span class="token class-name">Row</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>主要是通过设置<code>scan.incremental.snapshot.enabled=false</code>来达到这种目的</p>
<h3 id="采集分表分库"><a href="#采集分表分库" class="headerlink" title="采集分表分库"></a>采集分表分库</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">dbName <span class="token operator">=</span> <span class="token string">"[a-zA-Z\\d]+_test"</span><span class="token punctuation">;</span>
tableName <span class="token operator">=</span> <span class="token string">"[a-zA-Z\\d]+_test.gjc_test_binlog_[0-9][0-9]"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>把表明和库名改成正则表达式即可，这里没啥问题</p>
<h3 id="修改mysql字段，检查代码兼容性"><a href="#修改mysql字段，检查代码兼容性" class="headerlink" title="修改mysql字段，检查代码兼容性"></a>修改mysql字段，检查代码兼容性</h3><h3 id="手动清理mysqlbinlog，测试cdc全量读取数据的能力"><a href="#手动清理mysqlbinlog，测试cdc全量读取数据的能力" class="headerlink" title="手动清理mysqlbinlog，测试cdc全量读取数据的能力"></a>手动清理mysqlbinlog，测试cdc全量读取数据的能力</h3><p>这里需要测试一下mysqlbinlog全量读取数据库的能力，因为没有清理binlog的话，就不知道程序里的数据到底是从binlog里获取到的还是从mysql里获取到的</p>
<ol>
<li>手动删除mysql之前的binlog</li>
<li>启动任务，测试是否会读取全量数据</li>
<li>往mysql里写入新的数据<blockquote>
<p>这里还没测试过，后期手动测试一下看看</p>
</blockquote>
</li>
</ol>
<h3 id="多并行度测试的各种问题"><a href="#多并行度测试的各种问题" class="headerlink" title="多并行度测试的各种问题"></a>多并行度测试的各种问题</h3><ol>
<li>把flink的并行度设置大于1，然后数据写入kafka，程序跑起来之后，能把存量的数据写入到kafka，但是，在mysql里新增的数据，貌似flinkcdc就不消费了，这种情况在并行度为1的时候没有</li>
<li>查看了一下kafka的数据是乱序的</li>
</ol>
<h3 id="数据写入Hudi"><a href="#数据写入Hudi" class="headerlink" title="数据写入Hudi"></a>数据写入Hudi</h3><h1 id="Flink-CDC实时采集Sqlserver入Kafka"><a href="#Flink-CDC实时采集Sqlserver入Kafka" class="headerlink" title="Flink-CDC实时采集Sqlserver入Kafka"></a>Flink-CDC实时采集Sqlserver入Kafka</h1><h2 id="在SQLServer上启用CDC"><a href="#在SQLServer上启用CDC" class="headerlink" title="在SQLServer上启用CDC"></a>在SQLServer上启用CDC</h2><p>具体可以参考<a href="https://www.cnblogs.com/lixie0215/p/15243832.html">sqlserver开启cdc功能</a>和<a href="https://blog.csdn.net/vkingnew/article/details/89508885">SQL server 2016 开启CDC功能 捕获变更数据</a><br>为了让<code>FlinkCDC</code>从<code>SQL Server</code>表中捕获更改事件，需要用<code>SQL Server</code>管理员权限为要采集的每个表开启一下CDC权限<br><code>SQL Server</code>管理员通过运行系统存储过程来启用 CDC。 系统存储过程可以使用 <code>SQL Server Management Studio</code> 或 <code>Transact-SQL</code>运行。<br>先决条件：</p>
<ul>
<li>您是 SQL Server 的 sysadmin 固定服务器角色的成员。 </li>
<li>您是数据库的 db_owner。 </li>
<li>SQL Server 代理正在运行。<blockquote>
<p>SQL Server CDC 功能仅处理用户创建的表中发生的更改。您不能在 SQL Server 主数据库上启用 CDC。</p>
</blockquote>
</li>
</ul>
<p>CDC适用的环境：</p>
<ol>
<li>SQL server 2008版本以上的企业版、开发版和评估版中可用；</li>
<li>需要开启代理服务（作业）。</li>
<li>CDC需要业务库之外的额外的磁盘空间。</li>
<li>CDC的表需要主键或者唯一主键。</li>
</ol>
<blockquote>
<p>CDC的表不能truncate操作，truncate是物理删除数据不能捕获变更的数据。</p>
</blockquote>
<p>启用CDC分为两步：</p>
<ol>
<li>对目标数据库启用CDC。</li>
<li>对目标表启用CDC。</li>
</ol>
<p>启动步骤：</p>
<ol>
<li>确保开启SQL server agent服务：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--若不开启的话会报错：</span>
SQLServerAgent <span class="token operator">is</span> <span class="token operator">not</span> currently running so it cannot be notified <span class="token keyword">of</span> this <span class="token keyword">action</span><span class="token punctuation">.</span>
<span class="token comment">--解决办法：</span>
sp_configure <span class="token string">'show advanced options'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">;</span>   
GO   
<span class="token keyword">RECONFIGURE</span><span class="token punctuation">;</span>   
GO   
sp_configure <span class="token string">'Agent XPs'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">;</span>   
GO   
<span class="token keyword">RECONFIGURE</span>   
GO<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这里这样设置了没有用，需要用下面的方式设置：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#启用SQL Server代理
sudo &#x2F;opt&#x2F;mssql&#x2F;bin&#x2F;mssql-conf set sqlagent.enabled true
#需要重启服务生效
sudo systemctl restart mssql-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
也可以通过图形界面操作：<br>开始–&gt; [win + R] –&gt; services.msc – 启动SQL server 代理服务。<blockquote>
<p>这里实测，如果不开启agent服务，虽然表最终能开启cdc，但是，往表里添加数据等操作，cdc并没有生效<br><img src="/uploads/202203/%E6%9C%AA%E5%BC%80%E5%90%AFagent%E6%9C%8D%E5%8A%A1CDC%E6%9C%AA%E7%94%9F%E6%95%88.png" alt="未开启agent服务CDC未生效"></p>
</blockquote>
</li>
</ol>
<p>验证agent是否开启：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 查看agent状态</span>
<span class="token keyword">EXEC</span> master<span class="token punctuation">.</span>dbo<span class="token punctuation">.</span>xp_servicecontrol N<span class="token string">'QUERYSTATE'</span><span class="token punctuation">,</span> N<span class="token string">'SQLSERVERAGENT'</span>
<span class="token comment">-- 结果为running/Stopped,running就正常了</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>开启数据库级别的CDC功能：<blockquote>
<p>想要开启表的CDC功能，就必须开启该表所在库的CDC功能</p>
</blockquote>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">if</span> <span class="token keyword">exists</span><span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token number">1</span> <span class="token keyword">from</span> sys<span class="token punctuation">.</span><span class="token keyword">databases</span> <span class="token keyword">where</span> name<span class="token operator">=</span><span class="token string">'ERP'</span> <span class="token operator">and</span> is_cdc_enabled<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">begin</span>
    <span class="token keyword">exec</span> sys<span class="token punctuation">.</span>sp_cdc_enable_db
<span class="token keyword">end</span>
 
<span class="token comment">--或者</span>
<span class="token keyword">USE</span> test
GO  
<span class="token comment">-- 开启：</span>
<span class="token keyword">EXEC</span> sys<span class="token punctuation">.</span>sp_cdc_enable_db  
<span class="token comment">-- 关闭：</span>
<span class="token keyword">EXEC</span> sys<span class="token punctuation">.</span>sp_cdc_disable_db
GO  
 
<span class="token comment">--注释： 如果在禁用变更数据捕获时为数据库定义了很多捕获实例，则长时间运行事务可能导致 sys.sp_cdc_disable_db 的执行失败。</span>
<span class="token comment">--通过在运行 sys.sp_cdc_disable_db 之前使用 sys.sp_cdc_disable_table 禁用单个捕获实例，可以避免此问题。</span>
 
<span class="token comment">--示例：</span>
<span class="token keyword">USE</span> AdventureWorks2012<span class="token punctuation">;</span> 
GO 
<span class="token keyword">EXECUTE</span> sys<span class="token punctuation">.</span>sp_cdc_disable_table 
<span class="token variable">@source_schema</span> <span class="token operator">=</span> N<span class="token string">'HumanResources'</span><span class="token punctuation">,</span> 
<span class="token variable">@source_name</span> <span class="token operator">=</span> N<span class="token string">'Employee'</span><span class="token punctuation">,</span> 
<span class="token variable">@capture_instance</span> <span class="token operator">=</span> N<span class="token string">'HumanResources_Employee'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>查询验证数据是否开启CDC功能：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--若返回的值是0 表示CDC是禁用的，1表示CDC是开启的。</span>
<span class="token keyword">select</span> is_cdc_enabled <span class="token keyword">from</span> sys<span class="token punctuation">.</span><span class="token keyword">databases</span> <span class="token keyword">where</span> name<span class="token operator">=</span><span class="token string">'test'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>添加CDC专用的文件组和文件：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 查询某个库的物理文件：</span>
<span class="token keyword">SELECT</span> name<span class="token punctuation">,</span> physical_name <span class="token keyword">FROM</span> sys<span class="token punctuation">.</span>master_files <span class="token keyword">WHERE</span> database_id <span class="token operator">=</span> DB_ID<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
go
<span class="token comment">-----------------------------</span>
<span class="token comment">--name               physical_name                 </span>
<span class="token comment">--test               /var/opt/mssql/data/test.mdf                                                                                                         </span>
<span class="token comment">--test_log           /var/opt/mssql/data/test_log.ldf  </span>
<span class="token comment">-----------------------------</span>
<span class="token comment">--1.添加文件组：</span>
<span class="token keyword">ALTER</span> <span class="token keyword">DATABASE</span> test <span class="token keyword">ADD</span> FILEGROUP CDC<span class="token punctuation">;</span>
go
<span class="token keyword">ALTER</span> <span class="token keyword">DATABASE</span> test <span class="token keyword">ADD</span> <span class="token keyword">FILE</span><span class="token punctuation">(</span>NAME<span class="token operator">=</span> <span class="token string">'TEST_CDC'</span><span class="token punctuation">,</span>FILENAME <span class="token operator">=</span> <span class="token string">'/var/opt/mssql/data/TEST_CDC.ndf'</span><span class="token punctuation">)</span> <span class="token keyword">TO</span> FILEGROUP CDC<span class="token punctuation">;</span>
go 
<span class="token comment">--再次执行SELECT name, physical_name FROM sys.master_files WHERE database_id = DB_ID('test');结果如下：</span>
<span class="token comment">--test               /var/opt/mssql/data/test.mdf                                                                                                         </span>
<span class="token comment">--test_log           /var/opt/mssql/data/test_log.ldf   </span>
<span class="token comment">--TEST_CDC           /var/opt/mssql/data/TEST_CDC.ndf</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
如果不添加CDC专用的文件组和文件，会报如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Msg 22973, Level 16, State 1, Server golden-02, Procedure sys.sp_cdc_enable_table_internal, Line 361
The specified filegroup &#39;CDC&#39; is not a valid filegroup for database &#39;test&#39;. Specify a valid existing filegroup or create the named filegroup, and retry the operation.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>开启表级别的CDC：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">EXEC</span> sys<span class="token punctuation">.</span>sp_cdc_enable_table
        <span class="token variable">@source_schema</span> <span class="token operator">=</span> <span class="token string">'dbo'</span><span class="token punctuation">,</span> <span class="token comment">-- source_schema</span>
        <span class="token variable">@source_name</span> <span class="token operator">=</span> <span class="token string">'table_name'</span><span class="token punctuation">,</span> <span class="token comment">-- table_name</span>
        <span class="token variable">@capture_instance</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token comment">-- capture_instance</span>
        <span class="token variable">@supports_net_changes</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment">-- supports_net_changes</span>
        <span class="token variable">@role_name</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token comment">-- role_name</span>
        <span class="token variable">@index_name</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token comment">-- index_name</span>
        <span class="token variable">@captured_column_list</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token comment">-- captured_column_list</span>
        <span class="token variable">@filegroup_name</span> <span class="token operator">=</span> <span class="token string">'CDC'</span> <span class="token comment">-- filegroup_name;</span>

<span class="token comment">--由于使用sqlcmd，换行会报错，这里测试的时候都写到一行里：</span>
<span class="token keyword">EXEC</span> sys<span class="token punctuation">.</span>sp_cdc_enable_table  <span class="token variable">@source_schema</span> <span class="token operator">=</span> <span class="token string">'dbo'</span><span class="token punctuation">,</span><span class="token variable">@source_name</span> <span class="token operator">=</span> <span class="token string">'gjc_test_binlog'</span><span class="token punctuation">,</span><span class="token variable">@capture_instance</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token variable">@supports_net_changes</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token variable">@role_name</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token variable">@index_name</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span><span class="token variable">@captured_column_list</span> <span class="token operator">=</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span> <span class="token variable">@filegroup_name</span> <span class="token operator">=</span> <span class="token string">'CDC'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>注意： 这里的source_schema = ‘dbo’，schema不是数据库名称</p>
</blockquote>
</li>
</ol>
<p>验证cdc成功了没？</p>
<pre class="line-numbers language-SQL" data-language="SQL"><code class="language-SQL">select * from test.cdc.dbo_gjc_test_binlog_CT;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>开启agent服务后，cdc服务正常启动了<br><img src="/uploads/202203/%E5%BC%80%E5%90%AFagent%E5%90%8ECDC%E7%94%9F%E6%95%88.png" alt="开启agent后CDC生效"></p>
<h2 id="sql-client方式验证flinkcdc读取sqlserver"><a href="#sql-client方式验证flinkcdc读取sqlserver" class="headerlink" title="sql-client方式验证flinkcdc读取sqlserver"></a>sql-client方式验证flinkcdc读取sqlserver</h2><p>和mysql一样的操作，首先把cdc的jar放到${FLINK_HOME}/lib下，并开启flink-cluster</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> gjc_test_binlog <span class="token punctuation">(</span>
  id <span class="token keyword">INT</span><span class="token punctuation">,</span>
  a <span class="token keyword">INT</span><span class="token punctuation">,</span>
  t_modified STRING
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'sqlserver-cdc'</span><span class="token punctuation">,</span>
  <span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'192.168.233.129'</span><span class="token punctuation">,</span>
  <span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'1433'</span><span class="token punctuation">,</span>
  <span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'sa'</span><span class="token punctuation">,</span>
  <span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">,</span>
  <span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">,</span>
  <span class="token string">'schema-name'</span> <span class="token operator">=</span> <span class="token string">'dbo'</span><span class="token punctuation">,</span>
  <span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'gjc_test_binlog'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span>  gjc_test_binlog<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/202203/flinkcdc%E4%BB%A5sqlclient%E6%96%B9%E5%BC%8F%E8%AF%BB%E5%8F%96sqlserver%E6%88%90%E5%8A%9F.png" alt="flinkcdc以sqlclient方式读取sqlserver成功"></p>
<h2 id="FlinkSQL方式验证flinkcdc读取sqlserver"><a href="#FlinkSQL方式验证flinkcdc读取sqlserver" class="headerlink" title="FlinkSQL方式验证flinkcdc读取sqlserver"></a>FlinkSQL方式验证flinkcdc读取sqlserver</h2><p>pom文件添加如下依赖</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.ververica<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-sqlserver-cdc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>$&#123;cdc.version&#125;<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>JAVA代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>cdc2kafka</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">EnvironmentSettings</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">Table</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>table<span class="token punctuation">.</span>api<span class="token punctuation">.</span>bridge<span class="token punctuation">.</span>java<span class="token punctuation">.</span></span><span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token class-name">Row</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">Logger</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>slf4j<span class="token punctuation">.</span></span><span class="token class-name">LoggerFactory</span><span class="token punctuation">;</span>


<span class="token comment">/**
 * 主要测试FlinkCDC采集Mysql，包含断点续传，提交任务到yarn上
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkSqlServer2Kakfa</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">EnvironmentSettings</span> settings <span class="token operator">=</span> <span class="token class-name">EnvironmentSettings</span><span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">useBlinkPlanner</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">inStreamingMode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">StreamTableEnvironment</span> tenv <span class="token operator">=</span> <span class="token class-name">StreamTableEnvironment</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> settings<span class="token punctuation">)</span><span class="token punctuation">;</span>
        tenv<span class="token punctuation">.</span><span class="token function">executeSql</span><span class="token punctuation">(</span>
                <span class="token string">"CREATE TABLE gjc_test_binlog ( "</span> <span class="token operator">+</span>
                        <span class="token string">" id INTEGER, "</span> <span class="token operator">+</span>
                        <span class="token string">" a INTEGER, "</span> <span class="token operator">+</span>
                        <span class="token string">" t_modified STRING "</span> <span class="token operator">+</span>
                        <span class="token string">") WITH ( "</span> <span class="token operator">+</span>
                        <span class="token string">" 'connector' = 'sqlserver-cdc', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'hostname' = '192.168.233.129', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'port' = '1433', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'username' = 'sa', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'password' = 'Gjc123!@#', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'database-name' = 'test', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'schema-name' = 'dbo', "</span> <span class="token operator">+</span>
                        <span class="token string">" 'table-name' = 'gjc_test_binlog' "</span> <span class="token operator">+</span>
                <span class="token string">") "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">Table</span> table <span class="token operator">=</span> tenv<span class="token punctuation">.</span><span class="token function">sqlQuery</span><span class="token punctuation">(</span><span class="token string">"select id,a,t_modified  from gjc_test_binlog "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        tenv<span class="token punctuation">.</span><span class="token function">toRetractStream</span><span class="token punctuation">(</span>table<span class="token punctuation">,</span> <span class="token class-name">Row</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>提交的standalone报如下错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"> The program finished with the following exception:
org.apache.flink.client.program.ProgramInvocationException: The main method caused an error: Unable to create a source for reading table &#39;default_catalog.default_database.gjc_test_binlog&#39;.
Table options are:
&#39;connector&#39;&#x3D;&#39;sqlserver-cdc&#39;
&#39;database-name&#39;&#x3D;&#39;test&#39;
&#39;hostname&#39;&#x3D;&#39;192.168.233.129&#39;
&#39;password&#39;&#x3D;&#39;Gjc123!@#&#39;
&#39;port&#39;&#x3D;&#39;1433&#39;
&#39;schema-name&#39;&#x3D;&#39;dbo&#39;
&#39;table-name&#39;&#x3D;&#39;gjc_test_binlog&#39;
&#39;username&#39;&#x3D;&#39;sa&#39;
	at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:372)
Caused by: org.apache.flink.table.api.ValidationException: Unable to create a source for reading table &#39;default_catalog.default_database.gjc_test_binlog&#39;.
	at org.apache.flink.table.factories.FactoryUtil.createTableSource(FactoryUtil.java:137)
	... 8 more
Caused by: org.apache.flink.table.api.ValidationException: Cannot discover a connector using option: &#39;connector&#39;&#x3D;&#39;sqlserver-cdc&#39;
Caused by: org.apache.flink.table.api.ValidationException: Could not find any factory for identifier &#39;sqlserver-cdc&#39; that implements &#39;org.apache.flink.table.factories.DynamicTableFactory&#39; in the classpath.

Available factory identifiers are:
blackhole
datagen
filesystem
mysql-cdc
print
	at org.apache.flink.table.factories.FactoryUtil.discoverFactory(FactoryUtil.java:319)
	at org.apache.flink.table.factories.FactoryUtil.enrichNoMatchingConnectorError(FactoryUtil.java:463)
	... 34 more
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里很奇怪，在idea里能直接执行，以sqlClient的方式也能正常执行，但是，写java代码就不能执行了<br>数据库配置已经读取到了，但是，还是报<code> Unable to create a source for reading table &#39;default_catalog.default_database.gjc_test_binlog&#39;.</code></p>
<p>这里开启了sqlserver的angent服务以后，就成功了<br><img src="/uploads/202203/Flinksql%E6%96%B9%E5%BC%8F%E8%AF%BB%E5%8F%96sqlserver%E6%88%90%E5%8A%9F.png" alt="Flinksql方式读取sqlserver成功"></p>
<h3 id="sqlserver中文乱码"><a href="#sqlserver中文乱码" class="headerlink" title="sqlserver中文乱码"></a>sqlserver中文乱码</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">DATABASE</span> SMESPROD <span class="token keyword">COLLATE</span> Chinese_PRC_CI_AS<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><ol>
<li><p>以flinksql方式测试mysql8.0.x,报错</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for &#39;Source: TableSourceScan(table&#x3D;[[default_catalog, default_database, gjc_test_binlog]], fields&#x3D;[id, a, t_modified]) -&gt; SinkConversionToTuple2 -&gt; Sink: Print to Std. Out&#39; (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:553)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:223)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:285)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.start(SourceCoordinator.java:133)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$DeferrableCoordinator.applyCall(RecreateOnResetOperatorCoordinator.java:291)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator.start(RecreateOnResetOperatorCoordinator.java:70)
	... 13 more
Caused by: org.apache.flink.util.FlinkRuntimeException: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password: YES)
	at com.ververica.cdc.connectors.mysql.debezium.DebeziumUtils.openJdbcConnection(DebeziumUtils.java:65)
	at com.ververica.cdc.connectors.mysql.MySqlValidator.validate(MySqlValidator.java:68)
	at com.ververica.cdc.connectors.mysql.source.MySqlSource.createEnumerator(MySqlSource.java:174)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.start(SourceCoordinator.java:129)
	... 30 more
Caused by: com.zaxxer.hikari.pool.HikariPool$PoolInitializationException: Failed to initialize pool: Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password: YES)
	at com.zaxxer.hikari.pool.HikariPool.throwPoolInitializationException(HikariPool.java:596)
	at com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:582)
	at com.ververica.cdc.connectors.mysql.debezium.DebeziumUtils.openJdbcConnection(DebeziumUtils.java:62)
	... 33 more
Caused by: java.sql.SQLException: Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password: YES)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:129)
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:97)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>但是，明明已经指定了数据库ip等信息，</p>
</li>
<li><p>navicat能连接sqlserver，但是jdbc连接不上sqlserver<br>根据网上的说法，检查了 </p>
<ol>
<li>SQL Server网络配置 –&gt; TCP/IP已启用</li>
<li>再检查windows防火墙，是关闭</li>
<li>sql server服务属性中，将默认的本账户改为“内置账户<br>这3种都正常，但是还是不行<br>最后，把jar包放到虚拟机里执行了一下，竟然成功了，问题就出在了虚拟机与本机的通信上，这里应该选用桥接模式，使用NAT模式就会出现上面的问题</li>
</ol>
</li>
</ol>
<ol start="3">
<li>驱动程序无法通过使用安全套接字层(SSL)加密与 SQL Server 建立安全连接。错误:“sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target”。 ClientConnectionId:debbc10a-0619-4955-ad09-d6e35ba5d707<br>修复完问题2，再次执行flinkcdc程序，发现竟然不能采集了。<br>报错原因：可能是因为使用的JDBC驱动版本太高，之前使用了<code>mssql-jdbc - 10.2.0.jre8</code>版本，把这里的依赖去掉，直接使用flink-cdc自带的sqlserver依赖，就可以了</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink-CDC</category>
      </categories>
      <tags>
        <tag>Flink-CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>hudi和iceberg测试比较</title>
    <url>/2022/02/28/hudi%E5%92%8Ciceberg%E6%B5%8B%E8%AF%95%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hudi和iceberg测试比较</li>
</ul>
<a id="more"></a>

<h1 id="背景和需求"><a href="#背景和需求" class="headerlink" title="背景和需求"></a>背景和需求</h1><p>当前采集系统分为实时采集、定时采集，实时采集当天数据存在Hbase中，当天以前的数据存在Hive中。定时采集只有当天以前的数据。随着业务的要求越来越高，T+1的延时已经无法满足业务的的使用场景，数据实时性是采集系统亟需改善的一个地方。<br>我们也尝试使用了Kudu来解决这个问题，Kudu是一个列式存储的存储引擎，不兼容Hdfs，其次孩子王Kudu系统也不稳定，所以没有把整个表的数据写入Kudu，而是使用Kudu替代了Hbase，解决了Hbase批量查询的性能问题，但还是没有通过一个组件解决采集的实时性问题。<br>总结下来就是，采集系统需要将原系统数据实时采入单个组件，可以达到分钟级的延迟。同时提供高性能的查询方式给业务查询。数据湖很早就进入我们的视野，目前主流的就是Iceberg和Hudi，本文就是从原理、特性、性能上对比两个数据湖组件。</p>
<h1 id="Hudi介绍"><a href="#Hudi介绍" class="headerlink" title="Hudi介绍"></a>Hudi介绍</h1><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>Hudi使用Hadoop FileSystem API与湖存储交互，Hudi充分利用了像HDFS之类的存储模式所支持的“append”特性。这有助于Hudi提供流时写入，而不会导致文件计数/表元数据激增。</p>
<h2 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h2><p>Hudi是围绕基本文件和增量日志文件的概念设计的，它们将更新 / 增量数据存储到给定的基本文件（称为文件片，file slice）。基本文件格式包括 Parquet（列访问）和 HFile（索引访问），增量日志以 Avro（面向行）。<br><img src="/uploads/202203/hudi%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F.png" alt="hudi文件格式"></p>
<h2 id="表格式"><a href="#表格式" class="headerlink" title="表格式"></a>表格式</h2><p>表格式包括表的文件布局、表的schema、表变更的元数据跟踪。Hudi使用Avro模式来存储、管理和演进表的schema。Hudi有意识地将表/分区中的文件分组，并维护记录的键与所有文件组之间的映射，所有更新都记录到特定于文件组的增量日志文件中，Hudi的设计理念基于键的快速upserts/deletes，并且只需要在每个文件组中合并delta日志<br><img src="/uploads/202203/hudi%E8%A1%A8%E6%A0%BC%E5%BC%8F.png" alt="hudi表格式"></p>
<h2 id="表类型和查询"><a href="#表类型和查询" class="headerlink" title="表类型和查询"></a>表类型和查询</h2><p>Hudi支持两种类型的表，COW（Copy-On-Write），MOR（Merge-On-Read），COW表的写放大问题严重，MOR提供了低延迟、更高效地实时写入，但读取的时候需要更高的延迟</p>
<table>
<thead>
<tr>
<th></th>
<th>COW</th>
<th>MOR</th>
</tr>
</thead>
<tbody><tr>
<td>数据延迟</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>查询延迟</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>更新成本</td>
<td>高（重写整个parquet）</td>
<td>低（添加到delta日志大小）</td>
</tr>
<tr>
<td>Parquet文件大小</td>
<td>小</td>
<td>大</td>
</tr>
<tr>
<td>写放大</td>
<td>高</td>
<td>低</td>
</tr>
</tbody></table>
<p>Hudi支持三种类型的查询，快照查询（能够查询到表的最新快照数据，如果是MOR表，会将基本文件和增量文件合并后再提供数据）、增量查询（增量查询只能查看到写入表的新数据）、读优化查询（可以查询到表的最新快照数据，它近查询最新的基本列文件，可以保证查询性能，这种方式保证了性能，但数据可能会有延迟）</p>
<table>
<thead>
<tr>
<th>表类型</th>
<th>支持的查询类型</th>
</tr>
</thead>
<tbody><tr>
<td>COW</td>
<td>快照查询、增量查询</td>
</tr>
<tr>
<td>MOR</td>
<td>快照查询、增量查询、读优化查询</td>
</tr>
</tbody></table>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>Hudi支持不同的基于主键的索引方案，以快速将采集的记录键映射到他们所在的文件组中。Hudi会自动强制执行文件大小，这有助于降低从Parquet页脚读取统计信息所需的时间。</p>
<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>定义了不同的写入器/读取器如何协调对表的访问。Hudi确保原子写入，通过将提交原子地发布到时间线，并标记一个即时时间（instant），以标记该操作具体发生的时间。Hudi明确区分了写入进程（执行用户的更新、插入、删除）、表服务（写入数据、元数据以优化执行所需的信息）和读取器（执行查询），Hudi在所有三种类型的进程之间提供快照隔离，他们都对表的一致快照进行操作。</p>
<h2 id="写入器"><a href="#写入器" class="headerlink" title="写入器"></a>写入器</h2><p>Hudi表可以用作Spark/Flink管道的接收器，upsert、delete操作都会自动处理输入流中具有相同键的记录的预合并，然后查找索引，最后调用二进制打包算法将数据打包到文件中，同时遵循预配置的目标文件大小。</p>
<h2 id="读取器"><a href="#读取器" class="headerlink" title="读取器"></a>读取器</h2><p>Hudi在写入器和读取器之间提供了快照隔离，并允许所有主流的湖查询引擎（Spark、Hive、Presto）在任何表快照上进行一致的查询，每当Hudi必须为查询合并基础文件和日志文件时，Hudi都会进行控制并采用多种机制来提高合并性能，同时还提供对数据的读优化查询，以权衡数据新鲜度与查询性能。<br>hudi支持建表、写入时将数据同步到hive元数据，生成ro、rt表，支持hive查询，支持presto使用presto连接器查询</p>
<h2 id="表服务"><a href="#表服务" class="headerlink" title="表服务"></a>表服务</h2><p>为了让Hudi能作为增量数据管道的状态存储，为其设计了内置的表服务和自我管理运行时，可以编排/触发这些服务并在内部优化一切，Hudi有几个内置的表服务，目标都是确保高性能的表存储布局和元数据管理，他们在每次写入操作后同步自动调用，或者作为单独的后台作业异步调用。</p>
<ul>
<li>归档服务：一旦事件从时间线上过期，归档服务就会清除湖缓存的任何副作用。</li>
<li>清理服务：以增量的方式，删除超过保留期限的用于增量查询的文件切片</li>
<li>压缩服务：将基本文件与一组增量日志文件合并以生成新的基本文件，同时允许对文件组进行并发写入</li>
<li>聚簇服务：用户可以通过排序键将经常查询的记录组合在一起，或者通过将较小的基本文件合并为较大的文件来控制文件大小</li>
</ul>
<h2 id="数据服务"><a href="#数据服务" class="headerlink" title="数据服务"></a>数据服务</h2><p>Hudi能对常见的端到端用例做到开箱即用，最重要的是DeltaStreamer实用程序，可以轻松基于Kafka流以及在湖存储之上的不同格式的文件来构建数据湖。支持检查点的自动管理、跟踪源检查点作为Hudi表元数据的一部分</p>
<h2 id="hudi测试案例"><a href="#hudi测试案例" class="headerlink" title="hudi测试案例"></a>hudi测试案例</h2><h3 id="Flinksql写数据入hudi"><a href="#Flinksql写数据入hudi" class="headerlink" title="Flinksql写数据入hudi"></a>Flinksql写数据入hudi</h3><p>flink以sql-client的方式启动</p>
<ol>
<li>在flinksql中创建t1表：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t1<span class="token punctuation">(</span>
  uuid <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token operator">NOT</span> ENFORCED<span class="token punctuation">,</span>
  name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  age <span class="token keyword">INT</span><span class="token punctuation">,</span>
  ts <span class="token keyword">TIMESTAMP</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">`</span><span class="token keyword">partition</span><span class="token punctuation">`</span> <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'hudi'</span><span class="token punctuation">,</span>
  <span class="token string">'path'</span> <span class="token operator">=</span> <span class="token string">'hdfs:///user/hive/warehouse/hudi.db/t1'</span><span class="token punctuation">,</span>
  <span class="token string">'table.type'</span> <span class="token operator">=</span> <span class="token string">'MERGE_ON_READ'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>向t1表插入几条数据并查询结果<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--插入数据</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> t1 <span class="token keyword">VALUES</span>
  <span class="token punctuation">(</span><span class="token string">'id1'</span><span class="token punctuation">,</span><span class="token string">'Danny'</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:01'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id2'</span><span class="token punctuation">,</span><span class="token string">'Stephen'</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:02'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id3'</span><span class="token punctuation">,</span><span class="token string">'Julian'</span><span class="token punctuation">,</span><span class="token number">53</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:03'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id4'</span><span class="token punctuation">,</span><span class="token string">'Fabian'</span><span class="token punctuation">,</span><span class="token number">31</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:04'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id5'</span><span class="token punctuation">,</span><span class="token string">'Sophia'</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:05'</span><span class="token punctuation">,</span><span class="token string">'par3'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 查询数据</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> t1<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>查询hdfs上文件记录<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop fs -ls hdfs:&#x2F;&#x2F;&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;hudi.db&#x2F;t1
-rw-r--r--   1 gujincheng supergroup       1397 2022-04-06 09:33 hdfs:&#x2F;&#x2F;&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;hudi.db&#x2F;t1&#x2F;.cbde2bbe-5097-44e9-a5b1-7419be14b63e_20220406093302182.log.1_3-4-0
drwxr-xr-x   - gujincheng supergroup          0 2022-04-06 09:33 hdfs:&#x2F;&#x2F;&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;hudi.db&#x2F;t1&#x2F;.hoodie
-rw-r--r--   1 gujincheng supergroup         96 2022-04-06 09:33 hdfs:&#x2F;&#x2F;&#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;hudi.db&#x2F;t1&#x2F;.hoodie_partition_metadata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
###同步hudi元数据到hive<br>一般来说Hudi表在用Spark或者Flink写入数据时会自动同步到Hive外部表， 此时可以直接通过beeline查询同步的外部表， 若写入引擎没有开启自动同步，则需要手动利用hudi客户端工具run_hive_sync_tool.sh 进行同步具体可以参考官网查看相关参数。<br>上述创建的表，没有开启自动同步，需要使用run_hive_sync_tool.sh进行同步<h4 id="hive环境准备"><a href="#hive环境准备" class="headerlink" title="hive环境准备"></a>hive环境准备</h4></li>
<li>将 hudi-hadoop-mr-bundle 导入 hive。在 hive 根目录下创建 auxlib/ 文件夹，并将 hudi-hadoop-mr-bundle-0.x.x-SNAPSHOT.jar 移动到 auxlib 中。 hudi-hadoop-mr-bundle-0.x.x-SNAPSHOT.jar 位于包/hudi-hadoop-mr-bundle/target。<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;opt&#x2F;modules&#x2F;hive-2.3.9&#x2F; &amp;&amp; mkdir auxlib
cp ~&#x2F;hudi&#x2F;packaging&#x2F;hudi-hadoop-mr-bundle&#x2F;target&#x2F;hudi-hadoop-mr-bundle-0.10.1.jar auxlib<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>Flink sql客户端远程连接hive metastore时，需要开启hive metastore和hiveserver2服务，并且需要正确设置端口号。开启服务的命令：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># Enable hive metastore and hiveserver2
nohup .&#x2F;bin&#x2F;hive --service metastore &amp;
nohup .&#x2F;bin&#x2F;hive --service hiveserver2 &amp;
# While modifying the jar package under auxlib, you need to restart the service.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>Flink hive sync 现在支持 hms(hive metastore sync) 和 jdbc 两种 hive 同步模式。 hms 模式只需要配置 metastore uris。对于 jdbc 模式，JDBC 属性和 Metastore uris 都需要配置<br>所以，hive的metastore是必须的</li>
</ol>
<h4 id="flinksql自动同步hive元数据"><a href="#flinksql自动同步hive元数据" class="headerlink" title="flinksql自动同步hive元数据"></a>flinksql自动同步hive元数据</h4><ol>
<li>在sql-client里创建hudi表：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t2<span class="token punctuation">(</span>
  uuid <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token operator">NOT</span> ENFORCED<span class="token punctuation">,</span>
  name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  age <span class="token keyword">INT</span><span class="token punctuation">,</span>
  ts <span class="token keyword">TIMESTAMP</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">`</span><span class="token keyword">partition</span><span class="token punctuation">`</span> <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'hudi'</span><span class="token punctuation">,</span>
  <span class="token string">'path'</span> <span class="token operator">=</span> <span class="token string">'hdfs:///user/hive/warehouse/hudi.db/t2'</span><span class="token punctuation">,</span>
  <span class="token string">'table.type'</span> <span class="token operator">=</span> <span class="token string">'MERGE_ON_READ'</span><span class="token punctuation">,</span>
  <span class="token string">'hive_sync.enable'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>     <span class="token comment">-- Required. To enable hive synchronization</span>
  <span class="token string">'hive_sync.mode'</span> <span class="token operator">=</span> <span class="token string">'hms'</span><span class="token punctuation">,</span>        <span class="token comment">-- Required. Setting hive sync mode to hms, default jdbc</span>
  <span class="token string">'hive_sync.metastore.uris'</span> <span class="token operator">=</span> <span class="token string">'thrift://golden-02:9083'</span><span class="token punctuation">,</span> <span class="token comment">-- Required. The port need set on hive-site.xml</span>
  <span class="token string">'hive_sync.table'</span><span class="token operator">=</span><span class="token string">'t2'</span><span class="token punctuation">,</span>                  <span class="token comment">-- required, hive table name</span>
  <span class="token string">'hive_sync.db'</span><span class="token operator">=</span><span class="token string">'hudi'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>向表中插入几条数据<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> t2 <span class="token keyword">VALUES</span>
  <span class="token punctuation">(</span><span class="token string">'id1'</span><span class="token punctuation">,</span><span class="token string">'Danny'</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:01'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id2'</span><span class="token punctuation">,</span><span class="token string">'Stephen'</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:02'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id3'</span><span class="token punctuation">,</span><span class="token string">'Julian'</span><span class="token punctuation">,</span><span class="token number">53</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:03'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id4'</span><span class="token punctuation">,</span><span class="token string">'Fabian'</span><span class="token punctuation">,</span><span class="token number">31</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:04'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">(</span><span class="token string">'id5'</span><span class="token punctuation">,</span><span class="token string">'Sophia'</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">,</span><span class="token keyword">TIMESTAMP</span> <span class="token string">'1970-01-01 00:00:05'</span><span class="token punctuation">,</span><span class="token string">'par3'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="flinkcdc-读取mysql并写入hudi"><a href="#flinkcdc-读取mysql并写入hudi" class="headerlink" title="flinkcdc 读取mysql并写入hudi"></a>flinkcdc 读取mysql并写入hudi</h3></li>
<li>创建mysql表<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--- 创建mysql表</span>
  <span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> users_source_mysql <span class="token punctuation">(</span>
  uuid <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">,</span>
  name <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  age <span class="token keyword">int</span><span class="token punctuation">,</span>
  ts <span class="token keyword">timestamp</span><span class="token punctuation">,</span>
  part <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">-- 向表中插入数据</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> users_source_mysql <span class="token keyword">VALUES</span>
<span class="token punctuation">(</span><span class="token string">'id1'</span><span class="token punctuation">,</span><span class="token string">'Danny'</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:00'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id2'</span><span class="token punctuation">,</span><span class="token string">'Stephen'</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:02'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id3'</span><span class="token punctuation">,</span><span class="token string">'Julian'</span><span class="token punctuation">,</span><span class="token number">53</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:03'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id4'</span><span class="token punctuation">,</span><span class="token string">'Fabian'</span><span class="token punctuation">,</span><span class="token number">31</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:04'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id5'</span><span class="token punctuation">,</span><span class="token string">'Sophia'</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:05'</span><span class="token punctuation">,</span><span class="token string">'par3'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id6'</span><span class="token punctuation">,</span><span class="token string">'Danny'</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:01'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id7'</span><span class="token punctuation">,</span><span class="token string">'Stephen'</span><span class="token punctuation">,</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:02'</span><span class="token punctuation">,</span><span class="token string">'par1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id8'</span><span class="token punctuation">,</span><span class="token string">'Julian'</span><span class="token punctuation">,</span><span class="token number">53</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:03'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id9'</span><span class="token punctuation">,</span><span class="token string">'Fabian'</span><span class="token punctuation">,</span><span class="token number">31</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:04'</span><span class="token punctuation">,</span><span class="token string">'par2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'id10'</span><span class="token punctuation">,</span><span class="token string">'Sophia'</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token string">'2021-01-01 00:00:05'</span><span class="token punctuation">,</span><span class="token string">'par3'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>在flinksql中创建映射表<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> <span class="token keyword">sql</span><span class="token operator">-</span>client<span class="token punctuation">.</span>execution<span class="token punctuation">.</span>result<span class="token operator">-</span><span class="token keyword">mode</span><span class="token operator">=</span>tableau<span class="token punctuation">;</span>
<span class="token comment">-- 因为是流式写数据，所以，必须得开启ck，否则会报错</span>
<span class="token keyword">set</span> execution<span class="token punctuation">.</span>checkpointing<span class="token punctuation">.</span><span class="token keyword">interval</span><span class="token operator">=</span><span class="token number">3</span>sec<span class="token punctuation">;</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> users_source_mysql <span class="token punctuation">(</span>
    uuid string <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token operator">NOT</span> ENFORCED<span class="token punctuation">,</span>
    name STRING<span class="token punctuation">,</span>
    age <span class="token keyword">int</span><span class="token punctuation">,</span>
    ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    part string
<span class="token punctuation">)</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
      <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'mysql-cdc'</span><span class="token punctuation">,</span>
      <span class="token string">'hostname'</span> <span class="token operator">=</span> <span class="token string">'150.158.190.192'</span><span class="token punctuation">,</span>
      <span class="token string">'port'</span> <span class="token operator">=</span> <span class="token string">'3306'</span><span class="token punctuation">,</span>
      <span class="token string">'username'</span> <span class="token operator">=</span> <span class="token string">'root'</span><span class="token punctuation">,</span>
      <span class="token string">'password'</span> <span class="token operator">=</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">,</span>
      <span class="token string">'server-time-zone'</span> <span class="token operator">=</span> <span class="token string">'Asia/Shanghai'</span><span class="token punctuation">,</span>
      <span class="token string">'debezium.snapshot.mode'</span> <span class="token operator">=</span> <span class="token string">'initial'</span><span class="token punctuation">,</span>
      <span class="token string">'database-name'</span> <span class="token operator">=</span> <span class="token string">'test'</span><span class="token punctuation">,</span>
      <span class="token string">'table-name'</span> <span class="token operator">=</span> <span class="token string">'users_source_mysql'</span>
      <span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>写数据到hudi<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--创建hudi表</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t2_tmp<span class="token punctuation">(</span>
    uuid <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token operator">NOT</span> ENFORCED<span class="token punctuation">,</span>
    name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    age <span class="token keyword">INT</span><span class="token punctuation">,</span>
    ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    part <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span>
    <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'hudi'</span><span class="token punctuation">,</span>
    <span class="token string">'path'</span> <span class="token operator">=</span> <span class="token string">'hdfs://golden-02:9000/user/hive/warehouse/hudi.db/t2'</span><span class="token punctuation">,</span>
    <span class="token string">'table.type'</span> <span class="token operator">=</span> <span class="token string">'MERGE_ON_READ'</span><span class="token punctuation">,</span>
    <span class="token string">'hoodie.datasource.write.recordkey.field'</span><span class="token operator">=</span> <span class="token string">'uuid'</span><span class="token punctuation">,</span>
    <span class="token string">'write.precombine.field'</span><span class="token operator">=</span> <span class="token string">'ts'</span><span class="token punctuation">,</span>
    <span class="token string">'write.tasks'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
    <span class="token string">'write.rate.limit'</span> <span class="token operator">=</span> <span class="token string">'2000'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.tasks'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.async.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.trigger.strategy'</span> <span class="token operator">=</span> <span class="token string">'num_commits'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.delta_commits'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
    <span class="token string">'changleog.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
    <span class="token string">'read.streaming.enabled'</span><span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
    <span class="token string">'read.streaming.check-interval'</span><span class="token operator">=</span> <span class="token string">'3'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.enable'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>     <span class="token comment">-- Required. To enable hive synchronization</span>
    <span class="token string">'hive_sync.mode'</span> <span class="token operator">=</span> <span class="token string">'hms'</span><span class="token punctuation">,</span>        <span class="token comment">-- Required. Setting hive sync mode to hms, default jdbc</span>
    <span class="token string">'hive_sync.metastore.uris'</span> <span class="token operator">=</span> <span class="token string">'thrift://golden-02:9083'</span><span class="token punctuation">,</span> <span class="token comment">-- Required. The port need set on hive-site.xml</span>
    <span class="token string">'hive_sync.jdbc_url'</span> <span class="token operator">=</span> <span class="token string">'jdbc://hive2://golden-02:10000'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.table'</span><span class="token operator">=</span><span class="token string">'t2'</span><span class="token punctuation">,</span>                  <span class="token comment">-- required, hive table name</span>
    <span class="token string">'hive_sync.db'</span><span class="token operator">=</span><span class="token string">'hudi'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.username'</span> <span class="token operator">=</span> <span class="token string">'gujincheng'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.password'</span> <span class="token operator">=</span> <span class="token string">'980071'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.support_timstamp'</span> <span class="token operator">=</span> <span class="token string">'true'</span>
    <span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">--读取视图数据并写入hudi表</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> t2_tmp <span class="token keyword">SELECT</span> uuid<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">,</span> ts<span class="token punctuation">,</span> part <span class="token keyword">FROM</span> users_source_mysql <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
数据在hive和spark中都能查询到数据</li>
</ol>
<h3 id="编写java实现flinkcdc入hudi"><a href="#编写java实现flinkcdc入hudi" class="headerlink" title="编写java实现flinkcdc入hudi"></a>编写java实现flinkcdc入hudi</h3><p>具体代码看githup，<a href="https://github.com/gujincheng/FlinkCDCTest/blob/main/src/main/java/com/digiwin/flink/cdc2kafka/FlinkMysqlCDC2Hudi.java">FlinkMysqlCDC2Hudi</a><br>这里遇到一个注意点，tenv.executeSql就是触发执行的操作，不需要再使用env.execute()再次触发一次</p>
<p>这里测试了一下，提交到standalone和提交到yarn上都是可以正常执行的。</p>
<h3 id="hudi踩坑记录"><a href="#hudi踩坑记录" class="headerlink" title="hudi踩坑记录"></a>hudi踩坑记录</h3><ol>
<li>hadoop 环境不对</li>
<li>报<code>Caused by:java.lanq.NoClassDefFoundError:org/apache/hadoop/mapred/JobConf</code>，具体信息如下：<br><img src="/uploads/202204/hudi%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95-flink%E7%BC%BA%E5%B0%91hadoop%E7%9B%B8%E5%85%B3jar.png" alt="hudi踩坑记录-flink缺少hadoop相关jar"><br>问题原因：flink缺少hadoop相关依赖<br>解决办法：把hadoop-mapreduce相关jar放到flink lib下<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 确保如下几个jar包放在了flink的lib文件夹下
-rw-r--r-- 1 wheel 787K  4  6 16:56 hadoop-mapreduce-client-common-3.2.2.jar
-rw-r--r-- 1 wheel 1.6M  4  6 16:56 hadoop-mapreduce-client-core-3.2.2.jar
-rw-r--r-- 1 wheel  84K  4  6 16:57 hadoop-mapreduce-client-jobclient-3.2.2.jar
-rw-r--r-- 1 wheel  44M  4  7 15:10 hudi-flink-bundle_2.12-0.10.1.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>报<code>java.lang.NoClassDefFoundError: org/apache/thrift/TBase</code>,具体报错如下：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;thrift&#x2F;TBase
  at java.lang.ClassLoader.defineClass1(Native Method) ~[?:1.8.0_162]
  at java.lang.ClassLoader.defineClass(ClassLoader.java:763) ~[?:1.8.0_162]
...
  at org.apache.hudi.hive.HiveSyncTool.&lt;init&gt;(HiveSyncTool.java:78) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
  at org.apache.hudi.sink.utils.HiveSyncContext.hiveSyncTool(HiveSyncContext.java:51) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
  at org.apache.hudi.sink.StreamWriteOperatorCoordinator.syncHive(StreamWriteOperatorCoordinator.java:302) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
  at org.apache.hudi.sink.utils.NonThrownExecutor.lambda$execute$0(NonThrownExecutor.java:93) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_162]
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_162]
  at java.lang.Thread.run(Thread.java:748) [?:1.8.0_162]
Caused by: java.lang.ClassNotFoundException: org.apache.thrift.TBase
  at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[?:1.8.0_162]
  at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[?:1.8.0_162]
  at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338) ~[?:1.8.0_162]
  at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[?:1.8.0_162]
  ... 19 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这个问题找了很久，总是卡在flink同步元数据到hive。<br>想了一下原因，应该是flink在连接hms的时候，缺少依赖。这里在hudi源码里编译里好多次，怎么修改都不行，最后是把hive-exec的jar放到flink lib下<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">-rw-r--r-- 1 wheel  44M  4  6 22:39 hive-exec-2.3.9.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>报<code>java.lang.NoClassDefFoundError:org/apache/hudi/org/apache/hadoop/hive/ql/metadata/Hive</code>错误 ，具体报错如下：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2022-04-06 22:59:12,854 ERROR org.apache.hudi.sink.StreamWriteOperatorCoordinator          [] - Executor executes action [sync hive metadata for instant 20220406225911632] error
java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;hudi&#x2F;org&#x2F;apache&#x2F;hadoop&#x2F;hive&#x2F;ql&#x2F;metadata&#x2F;Hive
 at org.apache.hudi.hive.ddl.HMSDDLExecutor.&lt;init&gt;(HMSDDLExecutor.java:68) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
 at org.apache.hudi.hive.HoodieHiveClient.&lt;init&gt;(HoodieHiveClient.java:76) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
 at org.apache.hudi.hive.HiveSyncTool.&lt;init&gt;(HiveSyncTool.java:78) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
 at org.apache.hudi.sink.utils.HiveSyncContext.hiveSyncTool(HiveSyncContext.java:51) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
 at org.apache.hudi.sink.StreamWriteOperatorCoordinator.syncHive(StreamWriteOperatorCoordinator.java:302) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
 at org.apache.hudi.sink.utils.NonThrownExecutor.lambda$execute$0(NonThrownExecutor.java:93) ~[hudi-flink-bundle_2.12-0.10.1.jar:0.10.1]
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_291]
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_291]
 at java.lang.Thread.run(Thread.java:748) [?:1.8.0_291]
Caused by: java.lang.ClassNotFoundException: org.apache.hudi.org.apache.hadoop.hive.ql.metadata.Hive
 at java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[?:1.8.0_291]
 at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_291]
 at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355) ~[?:1.8.0_291]
 at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_291]
 ... 9 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
问题原因：hudi对hive的代码进行了部分shade，这里在hudi的服务群里找到解决方案<br>解决办法：<br>参考master分支，修改<code>packaging/hudi-flink-bundle/pom.xml</code>，去掉hive相关的shade，把原本的<code>&lt;relocations&gt;</code>里的内容用master分支的替换掉，但是需要加上<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>relocation</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pattern</span><span class="token punctuation">></span></span>org.apache.parquet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pattern</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>shadedPattern</span><span class="token punctuation">></span></span>$&#123;flink.bundle.shade.prefix&#125;org.apache.parquet.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>shadedPattern</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>relocation</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>hive里能查到hudi的表结构，但是查不到hudi的数据<br>问题描述：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 查询不到数据</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> hudi<span class="token punctuation">.</span>t2_rt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
这里也想了很多办法，都找不到原因，最后，想了一下，hive在<code>select *</code>的时候，不会执行mr，这时候扫描不到与表结构匹配的文件不会报错<br>这里想着让它执行一下mr程序，让它必须读取一下数据文件<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">from</span> hudi<span class="token punctuation">.</span>t2_rt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这时候报如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Diagnostic Messages for this Task:
Error: java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
at java.util.ArrayList.rangeCheck(ArrayList.java:657)
at java.util.ArrayList.get(ArrayList.java:433)
at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getProjectedGroupFields(DataWritableReadSupport.java:116)
at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getSchemaByName(DataWritableReadSupport.java:176)
at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.getRequestedSchemaForIndexAccess(DataWritableReadSupport.java:289)
at org.apache.hadoop.hive.ql.io.parquet.read.DataWritableReadSupport.init(DataWritableReadSupport.java:231)
at org.apache.hadoop.hive.ql.io.parquet.ParquetRecordReaderBase.getSplit(ParquetRecordReaderBase.java:84)
at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.&lt;init&gt;(ParquetRecordReaderWrapper.java:78)
at org.apache.hadoop.hive.ql.io.parquet.read.ParquetRecordReaderWrapper.&lt;init&gt;(ParquetRecordReaderWrapper.java:63)
at org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat.getRecordReader(MapredParquetInputFormat.java:75)
at org.apache.hudi.hadoop.HoodieParquetInputFormat.getRecordReader(HoodieParquetInputFormat.java:224)
at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.&lt;init&gt;(MapTask.java:175)
at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:444)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)
at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)
at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
问题原因：<br>hive.input.format 默认是org.apache.hadoop.hive.ql.io.CombineHiveInputFormat,解析hudi表数据会存在问题<br>解决办法</li>
<li>add jar /opt/cloudera/parcels/CDH/jars/hudi-hadoop-mr-bundle-0.11.0.jar;</li>
<li>需要设置<code>set hive.input.format= org.apache.hadoop.hive.ql.io.HiveInputFormat;</code> 或者设置<code>set hive.input.format = org.apache.hudi.hadoop.hive.HoodieCombineHiveInputFormat;</code><br>如果不设置，可以直接<code>select * from hudi</code>，但是count会数据翻倍</li>
</ol>
<p>可以参考<a href="https://www.yuque.com/docs/share/879349ce-7de4-4284-9126-9c2a3c93a91d#%20%E3%80%8AHive%20On%20Hudi%E3%80%8B">Hive On Hudi</a></p>
<h3 id="hudi-0-11-0与flink整合"><a href="#hudi-0-11-0与flink整合" class="headerlink" title="hudi-0.11.0与flink整合"></a>hudi-0.11.0与flink整合</h3><p>hudi-0.11.0与flink整合简单很多，只需要把以下jar包放到flink/lib下</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">-rw-r--r--. 1 root root  35787665 5月   6 13:51 hive-exec-2.1.1-cdh6.2.0.jar
-rw-r--r--. 1 root root  83405474 5月  10 17:38 hudi-flink1.13-bundle_2.12-0.11.0.jar
-rw-r--r--. 1 root root  38046857 5月  10 15:39 hudi-hadoop-mr-bundle-0.11.0.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>不需要再把hadoop-mapreduce-client*几个jar包放到lib下了</p>
<h3 id="hudi与spark的整合"><a href="#hudi与spark的整合" class="headerlink" title="hudi与spark的整合"></a>hudi与spark的整合</h3><p>首先修改hudi源码，把pom文件夹下的spark.version改成3.1.1，然后重新编译hudi源码</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nohup mvn clean install -DskipTests -Dmaven.test.skip&#x3D;true -Dscala-2.12 -Dhadoop.version&#x3D;3.0.0-cdh6.2.0  -Dspark3 -Pflink-bundle-shade-hive2 &gt; nohup.log 2&gt;&amp;1 &amp;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里加了-Dspark3<br>复制packaging/hudi-spark-bundle/target/hudi-spark-bundle_2.12-0.10.1.jar<br>spark首先要与hive集成的，就是把hive-site.xml复制到spark/conf文件夹即可<br>spark-sql启动：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark-sql --jars hudi-spark3.1.1-bundle_2.12-0.10.1.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>spark-sql查询hudi表：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">use hudi;
select * from t2_rt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>经过检验，spark-sql可以查询flink写入hudi的表</p>
<h3 id="hudi与impala整合"><a href="#hudi与impala整合" class="headerlink" title="hudi与impala整合"></a>hudi与impala整合</h3><p>hudi与impala整合需要注意亮点</p>
<ol>
<li>需要升级impala3.4版本以上，3.4以前的版本不支持读取hudi。</li>
<li>impala仅支持读取COPY_ON_WRITE类型的hudi表</li>
<li>每次使用impala查询hudi表之前，都需要refresh该表</li>
</ol>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">--flinksql写数据进hudi</span>
<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> t2_1<span class="token punctuation">(</span>
    uuid <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token operator">NOT</span> ENFORCED<span class="token punctuation">,</span>
    name <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    age <span class="token keyword">INT</span><span class="token punctuation">,</span>
    ts <span class="token keyword">timestamp</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    part <span class="token keyword">VARCHAR</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
<span class="token keyword">WITH</span> <span class="token punctuation">(</span> 
    <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'hudi'</span><span class="token punctuation">,</span>
    <span class="token string">'path'</span> <span class="token operator">=</span> <span class="token string">'hdfs:///user/hive/warehouse/hudi.db/t2_1'</span><span class="token punctuation">,</span>
    <span class="token string">'table.type'</span> <span class="token operator">=</span> <span class="token string">'COPY_ON_WRITE'</span><span class="token punctuation">,</span>   <span class="token comment">--注意是COPY_ON_WRITE</span>
    <span class="token string">'hoodie.datasource.write.recordkey.field'</span><span class="token operator">=</span> <span class="token string">'uuid'</span><span class="token punctuation">,</span>
    <span class="token string">'write.precombine.field'</span><span class="token operator">=</span> <span class="token string">'ts'</span><span class="token punctuation">,</span>
    <span class="token string">'write.tasks'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
    <span class="token string">'write.rate.limit'</span> <span class="token operator">=</span> <span class="token string">'2000'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.tasks'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.async.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.trigger.strategy'</span> <span class="token operator">=</span> <span class="token string">'num_commits'</span><span class="token punctuation">,</span>
    <span class="token string">'compaction.delta_commits'</span> <span class="token operator">=</span> <span class="token string">'1'</span><span class="token punctuation">,</span>
    <span class="token string">'changleog.enabled'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
    <span class="token string">'read.streaming.enabled'</span><span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>
    <span class="token string">'read.streaming.check-interval'</span><span class="token operator">=</span> <span class="token string">'3'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.enable'</span> <span class="token operator">=</span> <span class="token string">'true'</span><span class="token punctuation">,</span>     <span class="token comment">-- Required. To enable hive synchronization</span>
    <span class="token string">'hive_sync.mode'</span> <span class="token operator">=</span> <span class="token string">'hms'</span><span class="token punctuation">,</span>        <span class="token comment">-- Required. Setting hive sync mode to hms, default jdbc</span>
    <span class="token string">'hive_sync.metastore.uris'</span> <span class="token operator">=</span> <span class="token string">'thrift://172.16.2.204:9083'</span><span class="token punctuation">,</span> <span class="token comment">-- Required. The port need set on hive-site.xml</span>
    <span class="token string">'hive_sync.jdbc_url'</span> <span class="token operator">=</span> <span class="token string">'jdbc://hive2://172.16.2.204:10000'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.table'</span><span class="token operator">=</span><span class="token string">'t2_1'</span><span class="token punctuation">,</span>                  <span class="token comment">-- required, hive table name</span>
    <span class="token string">'hive_sync.db'</span><span class="token operator">=</span><span class="token string">'hudi'</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.username'</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.password'</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">,</span>
    <span class="token string">'hive_sync.support_timstamp'</span> <span class="token operator">=</span> <span class="token string">'true'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> t2_1 <span class="token keyword">SELECT</span> uuid<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">,</span> ts<span class="token punctuation">,</span> part <span class="token keyword">FROM</span> users_source_mysql <span class="token punctuation">;</span>

<span class="token comment">-- 在impala中查询hudi表</span>
INVALIDATE METADATA hudi<span class="token punctuation">.</span>t2_1<span class="token punctuation">;</span>
REFRESH hudi<span class="token punctuation">.</span>t2_1<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> hudi<span class="token punctuation">.</span>t2_1<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/202204/impala%E8%AF%BB%E5%8F%96hudi%E8%A1%A8.png" alt="impala读取hudi表"></p>
<h1 id="Iceberg介绍"><a href="#Iceberg介绍" class="headerlink" title="Iceberg介绍"></a>Iceberg介绍</h1><h2 id="存储-1"><a href="#存储-1" class="headerlink" title="存储"></a>存储</h2><p>Iceberg支持使用Hadoop FileSystem API与湖存储交互，Iceberg需要文件系统支持写、读、删除操作，比如S3。Iceberg不需要随机写，一旦写入，数据文件和元数据文件在被删除之前是不可变的。</p>
<h2 id="文件格式-1"><a href="#文件格式-1" class="headerlink" title="文件格式"></a>文件格式</h2><p>Iceberg是围绕数据文件和元数据文件的概念设计的，数据文件格式支持parquet, avro, orc，数据文件可以设置大小，减少数据文件重写成本，元数据文件格式支持Json</p>
<h2 id="表格式-1"><a href="#表格式-1" class="headerlink" title="表格式"></a>表格式</h2><p>Iceerg支持创建表、删除表、修改表名、修改表属性、添加列、修改列名、修改列大小、修改列的顺序、删除列等操作。Iceberg的schema更新是元数据修改，数据文件不需要重写。<br>Iceberg分区每次都正确地生成分区值，并总是在可能的情况下用于加速查询。最重要的是，查询不再依赖于表的物理布局。通过物理和逻辑之间的分离，Iceberg表可以随着数据量的变化而发展分区方案。分区修改是一个元数据操作且不需要重写文件。<br>Iceberg排序顺序也可以在现有表中更新，在修改排序顺序时，使用较早顺序写入的旧数据将保持不变，引擎总是可以选择以最新的排序顺序。<br>快照文件列出清单列表文件。清单列表文件列出组成表快照的清单文件，以及每个分区的范围。清单文件列出组成表快照的数据文件，以及数据文件分区数据和列级别统计信息。Iceberg首先使用清单列表文件分区的范围，然后使用清单文件获取数据文件。通过这种模式，清单列表文件作为清单文件的索引，不需要扫描所有的清单文件。</p>
<p><img src="/uploads/202203/Iceberg%E8%A1%A8%E6%A0%BC%E5%BC%8F.png" alt="Iceberg表格式"></p>
<h2 id="并发控制-1"><a href="#并发控制-1" class="headerlink" title="并发控制"></a>并发控制</h2><p>一个表的元数据文件与另一个元数据文件的原子交换为可序列化隔离提供了基础。读取器在加载表元数据时使用当前的快照，并且在刷新元数据位置之前不会受到更改的影响。写入器乐观地创建表元数据文件，假设当前版本不会在写入器提交之前更改，一旦写入器创建了更新，它就通过将表的元数据文件指针从基本版本交换到新版本来提交。</p>
<h2 id="写入器-1"><a href="#写入器-1" class="headerlink" title="写入器"></a>写入器</h2><p>批量写入：</p>
<ul>
<li>insert into：向表中添加新数据</li>
<li>merge into：实现行级更新，包含更新行的数据文件会被重写</li>
<li>insert overwrite，分区数据文件会被重写<br>流式写入：Iceberg支持append和complete输出模式</li>
<li>append：将每个少量的批处理的行追加到表中</li>
<li>complete：每个少量的批处理替换表内容<br>Iceberg对分区表进行写操作之前，需要对每个任务的数据按照分区进行排序。对于批处理，鼓励执行显示排序来满足需求，但是这种方法会带来额外的延迟，因为排序被认为是流工作负载的繁重操作。为了避免额外的延迟，可以启用fanout写入器来消除这个需求<br>流式写入会快速创建新的表版本，从而创建大量的表元数据来跟踪这些版本。建议通过调优提交速率、过期旧快照和自动清理元数据文件来维护元数据</li>
</ul>
<h2 id="读取器-1"><a href="#读取器-1" class="headerlink" title="读取器"></a>读取器</h2><p>Iceberg查询不需要指定分区值查询，支持快照查询，支持表历史元数据、快照元数据、文件元数据、清单元数据查询<br>Iceber查询扫描计划会根据快照文件、清单列表文件、清单文件找出查询需要的数据文件，扫描计划能够在单节点上运行，因此任何一个客户端都可以低延迟的查询<br>Iceberg支持hive表，元数据保存在Iceberg中，支持hive查询，支持presto使用Iceberg链接起查询</p>
<h2 id="表服务-1"><a href="#表服务-1" class="headerlink" title="表服务"></a>表服务</h2><ul>
<li>过期快照：Iceberg每次写入会产生一个新的快照，快照可以被用来做时间快照查询，或者回滚，快照会聚集直到过期快照动作执行，推荐定期执行过期快照来删除不再需要数据文件，来保持较小的表元数据</li>
<li>删除旧的元数据文件：Iceberg使用Json文件跟踪表元数据，对表的每次更改都会生成一个新的元数据文件，以提供原子性，默认情况下，将保留旧的元数据文件作为历史记录。经常提交的表，比如流式任务，需要定期地清除元数据文件。</li>
<li>删除孤儿文件：在Spark或者其他分布式处理引擎中，任务或作业失败可能会留下不被表元数据引用的文件，而且在某些情况下，正常快照过期可能无法确定某个文件不再需要并删除它</li>
<li>压缩数据文件：Iceberg在一个表中跟踪每个数据文件，更多的数据文件导致清单文件中存储更多的元数据，而小的数据文件导致不必要的元数据量和文件打开成本的低效率查询，Iceberg可以并行压缩数据文件，这将把小文件合并成大文件，以减少元数据开销和运行时文件打开成本。</li>
<li>重写清单文件：Iceberg使用清单列表文件和清单文件元数据加快查询计划，并过滤不必要的数据文件，当表写的模式和查询模式不一致，元数据可以被重写。</li>
</ul>
<h2 id="iceberg测试案例"><a href="#iceberg测试案例" class="headerlink" title="iceberg测试案例"></a>iceberg测试案例</h2><h3 id="iceberg与hive整合"><a href="#iceberg与hive整合" class="headerlink" title="iceberg与hive整合"></a>iceberg与hive整合</h3><p>这个比较简单，首先到官网下载<code>iceberg-hive-runtime-0.13.1.jar</code><br>在hive-cli执行如下命令：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml">add jar /Users/gujincheng/Downloads/iceberg-hive-runtime-0.13.1.jar;
SET iceberg.engine.hive.enabled=true;

CREATE EXTERNAL TABLE test.iceberg_hive(
`id` int,
`name` string)
STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'
LOCATION 'hdfs://golden-02:9000/user/hive/warehouse/test/iceberg_hive';

INSERT INTO test.iceberg_hive values(2, 'b');
select * from test.iceberg_hive;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里测试了一下，iceberg与hive整合，不支持行级别更新，<br>iceberg在spark3.x 里支持行级别更新<br>在flink中支持行级别更新，需要指定主键，如果是分区表，改主键必须得包含分区字段，只支持insert into<br>insert overwrite 只支持批写入，流式写入不支持<br>这里因为技术选型最终选择了hudi，我们就不进一步测试了，具体的可以参考网上的博客<br><a href="https://github.com/gujincheng/FlinkCDCTest/blob/main/src/main/java/com/digiwin/flink/cdc2kafka/FlinkMysqlCDC2Hudi.java">Iceberg +Flink+CDH+Trino+Hive</a><br>写的很详细</p>
<h1 id="Hudi和Iceberg特性对比"><a href="#Hudi和Iceberg特性对比" class="headerlink" title="Hudi和Iceberg特性对比"></a>Hudi和Iceberg特性对比</h1><ol>
<li>ACID和隔离级别</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>Iceberg</th>
<th>Hudi</th>
</tr>
</thead>
<tbody><tr>
<td>ACID</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>隔离级别</td>
<td>多个写必须严格串行化，读和写可以同时跑</td>
<td>多个写的数据无交集，可以并发执行，读和写可以同时跑</td>
</tr>
<tr>
<td>并发多写</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>时间快照查询</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody></table>
<ol start="2">
<li>表格式  </li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>Iceberg</th>
<th>Hudi</th>
</tr>
</thead>
<tbody><tr>
<td>支持schema变更</td>
<td>支持，添加字段、删除字段、修改字段名称、修改字段长度</td>
<td>支持，添加、删除</td>
</tr>
<tr>
<td>文件格式</td>
<td>Parquet, ORC</td>
<td>Parquet, Avro</td>
</tr>
</tbody></table>
<ol start="3">
<li>流批接口支持</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>Iceberg</th>
<th>Hudi</th>
</tr>
</thead>
<tbody><tr>
<td>批量读</td>
<td>支持（spark、Hive、presto）</td>
<td>支持（spark、Hive、presto）</td>
</tr>
<tr>
<td>批量写</td>
<td>支持（spark）</td>
<td>支持（spark）</td>
</tr>
<tr>
<td>流式读</td>
<td>开发中</td>
<td>支持</td>
</tr>
<tr>
<td>流式写</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>Upserts/Delete/Merge/Update</td>
<td>不支持</td>
<td>支持</td>
</tr>
</tbody></table>
<ol start="4">
<li>查询性能</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>Iceberg</th>
<th>Hudi</th>
</tr>
</thead>
<tbody><tr>
<td>查询不需要指定分区</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>元数据花费</td>
<td>低</td>
<td>低</td>
</tr>
<tr>
<td>分区内索引</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>CopyOnWrite</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>MergeOnRead</td>
<td>开发中</td>
<td>支持</td>
</tr>
<tr>
<td>自动压缩</td>
<td>不支持（需手动调用压缩方法）</td>
<td>支持</td>
</tr>
<tr>
<td>自动清除</td>
<td>不支持（需手动调用清除方法）</td>
<td>支持</td>
</tr>
</tbody></table>
<ol start="5">
<li>社区现状</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>Iceberg</th>
<th>Hudi</th>
</tr>
</thead>
<tbody><tr>
<td>开源时间</td>
<td>2018.11.6</td>
<td>2019.1.17</td>
</tr>
<tr>
<td>Github watch</td>
<td>118</td>
<td>1.2k</td>
</tr>
<tr>
<td>Github star</td>
<td>1.9k</td>
<td>2.2k</td>
</tr>
<tr>
<td>Github fork</td>
<td>710</td>
<td>979</td>
</tr>
<tr>
<td>Github Issue</td>
<td>477</td>
<td>73</td>
</tr>
<tr>
<td>Github pull request</td>
<td>161</td>
<td>119</td>
</tr>
<tr>
<td>Commits</td>
<td>1822</td>
<td>1864</td>
</tr>
<tr>
<td>Contributors</td>
<td>167</td>
<td>193</td>
</tr>
</tbody></table>
<h1 id="Hudi和Iceberg性能对比"><a href="#Hudi和Iceberg性能对比" class="headerlink" title="Hudi和Iceberg性能对比"></a>Hudi和Iceberg性能对比</h1><p>生产环境100万数据量对比（Hudi推hive，Iceberg是hive表）</p>
<table>
<thead>
<tr>
<th></th>
<th>初始化插入100万</th>
<th>新增插入10万条</th>
<th>插入20万条、更新10万条、删除10万条</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>无分区表</td>
<td>有分区表</td>
<td>无分区表</td>
<td>有分区表</td>
<td>无分区表</td>
<td>有分区表</td>
</tr>
<tr>
<td>Iceberg插入耗时</td>
<td>7503</td>
<td>9295</td>
<td>10787</td>
<td>7983</td>
<td>14065</td>
<td>9648</td>
</tr>
<tr>
<td>Iceberg查询总数耗时_spark</td>
<td>2952</td>
<td>5970</td>
<td>2962</td>
<td>6170</td>
<td>2906</td>
<td>6232</td>
</tr>
<tr>
<td>iceberg查询单条耗时_spark</td>
<td>1019</td>
<td>852</td>
<td>1430</td>
<td>810</td>
<td>1007</td>
<td>831</td>
</tr>
<tr>
<td>Iceberg查询总数耗时_hive</td>
<td>10137</td>
<td>10581</td>
<td>13729</td>
<td>8753</td>
<td>9950</td>
<td>7553</td>
</tr>
<tr>
<td>Iceberg查询单条耗时_hive</td>
<td>934</td>
<td>239</td>
<td>183</td>
<td>160</td>
<td>170</td>
<td>168</td>
</tr>
<tr>
<td>Iceberg查询总数耗时_presto</td>
<td>生产上trino中的iceberg版本很低，查询报错，侧重hudi，所以跳过此测试</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Iceberg查询单条耗时_presto</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Hudi插入耗时</td>
<td>60255</td>
<td>59835</td>
<td>21868</td>
<td>29383</td>
<td>155586(96611+155586)</td>
<td>172115(69477+102638)</td>
</tr>
<tr>
<td>Hudi查询创建视图耗时_spark</td>
<td>3539</td>
<td>5213</td>
<td>3283</td>
<td>5606</td>
<td>3169</td>
<td>4803</td>
</tr>
<tr>
<td>Hudi查询总数耗时_spark</td>
<td>2660</td>
<td>2437</td>
<td>3639</td>
<td>2003</td>
<td>5234</td>
<td>3978</td>
</tr>
<tr>
<td>Hudi查询单条耗时_spark</td>
<td>4665</td>
<td>910</td>
<td>1048</td>
<td>2758</td>
<td>2323</td>
<td>2125</td>
</tr>
<tr>
<td>Hudi查询总数耗时_hive</td>
<td>11933</td>
<td>6569</td>
<td>6390</td>
<td>10721</td>
<td>5129</td>
<td>12573</td>
</tr>
<tr>
<td>Hudi查询单条耗时_hive</td>
<td>185</td>
<td>129</td>
<td>201</td>
<td>216</td>
<td>104</td>
<td>150</td>
</tr>
<tr>
<td>Hudi查询总数耗时_presto</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
<tr>
<td>Hudi查询单条耗时_presto</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
</tbody></table>
<h1 id="Hudi和Iceberg总结"><a href="#Hudi和Iceberg总结" class="headerlink" title="Hudi和Iceberg总结"></a>Hudi和Iceberg总结</h1><p>Hudi的最大的特色就是upsert和delete，upsert和delete写入增量文件，一定时间后可以将增量文件合并到基本文件中，通过这种方式可以实现行更新和流式写。<br>Iceberge的最大特色就是查询，通过快照、清单文件列表、清单实现快速过滤，Iceberg通过merge into也可以实现行更新，Iceberg也提供了流式写的接口，但是无论是行更新和流式写都是需要更新行的数据文件，并产生一个快照，这会大大增加元数据量。Iceberge的merge into也有诸多限制，原表和更新表join要有交集，否则会失败；Iceberg的更新表不能出现既更新也删除的同一条记录，否则会失败。<br>虽然在性能对比章节，Iceberg性能比Hudi好很多，但是从原理上分析，Hudi耗时高是有原因的，并且带来的是较少的IO，在Hudi更新时会根据主键合并更新数据，比如一条记录先新增后删除，合并后只留下删除的记录，然后根据主键定位到记录所在的分片，如果没有找到则插入记录，如果找到则添加到增量文件中，如果使用Hbase索引，相信性能会好一些。<br>Iceberg耗时低从原理来看，Iceberg只是将两个表join，然后原表修改的数据所在的数据文件会被重写，这种方式会在某些场景下导致大量的IO和内存消耗，在流式写测场景下支持时间旅行会产生很多文件。Iceberg的行删除目前在开发中。<br>个人觉得Hudi更适合作为采集系统的数据湖组件。Hudi最大的特色upsert和delete就已经是很大的亮点，这个功能和Kudu很相似。此外，目前Hudi功能已经完善，社区反馈的问题也比较少，已经在很多大厂应用，社区比较活跃。Iceberg很多功能还在开发中，社区反馈的问题比较多。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>采集</category>
      </categories>
      <tags>
        <tag>hudi</tag>
        <tag>iceberg</tag>
      </tags>
  </entry>
</search>
