<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>BloomFilter</title>
    <url>/2021/11/29/BloomFilter/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>布隆过滤器原理</li>
<li>布隆过滤器使用案例</li>
</ul>
<a id="more"></a>


<h2 id="布隆过滤器原理"><a href="#布隆过滤器原理" class="headerlink" title="布隆过滤器原理"></a>布隆过滤器原理</h2><p>布隆过滤器（Bloom Filter）是1970年由布隆提出的，它实际上是由一个很长的二进制向量和一系列随意映射函数组成。<br>它是一种基于概率的数据结构，主要用来判断某个元素是否在集合内，它具有运行速度快（时间效率），占用内存小的优点（空间效率），但是有一定的误识别率和删除困难的问题。它能够告诉你某个元素一定不在集合内或可能在集合内。</p>
<h3 id="算法："><a href="#算法：" class="headerlink" title="算法："></a>算法：</h3><ol>
<li>首先需要k个hash函数，每个函数可以把key散列成为1个整数</li>
<li>初始化时，需要一个长度为n比特的数组，每个比特位初始化为0</li>
<li>某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1</li>
<li>判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。</li>
</ol>
<h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><p>不需要存储key，节省空间</p>
<h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ol>
<li>算法判断key在集合中时，有一定的概率key其实不在集合中</li>
<li>无法删除</li>
</ol>
<h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><ul>
<li><p>False Position<br>集合里没有某元素，查找结果是有该元素。<br>也就是误判，这种情况在布隆过滤器中可能会出现。</p>
</li>
<li><p>False Negative<br>集合里有某元素，查找结果是没有该元素。<br>也就是少判，这种情况在布隆过滤器中一定不会出现</p>
</li>
</ul>
<blockquote>
<p>布隆过滤器只会多判不会少判。宁可错杀不可放过<br>想用布隆过滤器判断元素不存在，这个概率不是100%，<br>布隆过滤器认为不存在的情况， 确实是一定不会存在，但是，还有可能原本本身不存在，但是它会认为它存在的，比实际的要少</p>
</blockquote>
<p>Bloom Filter不会动态增长，运行过程中维护的始终只是m位的bitset，所以空间复杂度只有O(m);<br>Bloom Filter的插入与属于操作主要都是在计算k个hash，所以都是O(k)。</p>
<h2 id="个人感悟："><a href="#个人感悟：" class="headerlink" title="个人感悟："></a>个人感悟：</h2><h3 id="为什么布隆过滤器需要多个hash函数？"><a href="#为什么布隆过滤器需要多个hash函数？" class="headerlink" title="为什么布隆过滤器需要多个hash函数？"></a>为什么布隆过滤器需要多个hash函数？</h3><p>因为不同的key的hash值有可能会一样，这样误判的概率会很大，但是如果通过多个hash函数来计算，那么数据误判的概率就会低很多了</p>
<h3 id="为什么布隆过滤器不可以删除？"><a href="#为什么布隆过滤器不可以删除？" class="headerlink" title="为什么布隆过滤器不可以删除？"></a>为什么布隆过滤器不可以删除？</h3><p>如果布隆过滤器把其中一个key的值删除了，也就是把数组的值置为0了，另一个key的hash值有可能也被删除了。所以不可以删除</p>
<p>具体可以参考<a href="https://blog.csdn.net/CrankZ/article/details/84928562">布隆过滤器，原理+案例+代码实现</a></p>
<h2 id="测试案例："><a href="#测试案例：" class="headerlink" title="测试案例："></a>测试案例：</h2><ul>
<li><p>手写java代码，测试布隆过滤器误判情况</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">int</span> BF_CARDINAL_THRESHOLD <span class="token operator">=</span> <span class="token number">100000</span><span class="token punctuation">;</span>
        <span class="token keyword">double</span> BF_FALSE_POSITIVE_RATE <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">;</span>
        <span class="token class-name">BloomFilter</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Integer</span><span class="token punctuation">></span></span> subOrderFilter <span class="token operator">=</span> <span class="token class-name">BloomFilter</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token class-name">Funnels</span><span class="token punctuation">.</span><span class="token function">integerFunnel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> BF_CARDINAL_THRESHOLD<span class="token punctuation">,</span> BF_FALSE_POSITIVE_RATE<span class="token punctuation">)</span><span class="token punctuation">;</span>
        
        <span class="token class-name">HashSet</span> st <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashSet</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span> <span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> BF_CARDINAL_THRESHOLD<span class="token punctuation">;</span> i <span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>subOrderFilter<span class="token punctuation">.</span><span class="token function">mightContain</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                st<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment">//其实不存在，但是布隆过滤器认为它存在，这就是误判了</span>
            <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                subOrderFilter<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"一共误判了："</span> <span class="token operator">+</span> st<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果使用这种方式来过滤，就会导致有一部分数据其实没有出现过，但是也会被过滤掉</p>
</li>
<li><p>在flink程序中使用布隆过滤器实时过滤</p>
<blockquote>
<p>这种情况下，会丢数据，其实感觉没啥意义。。。</p>
</blockquote>
</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>shaded<span class="token punctuation">.</span>guava18<span class="token punctuation">.</span>com<span class="token punctuation">.</span>google<span class="token punctuation">.</span>common<span class="token punctuation">.</span>hash<span class="token punctuation">.</span></span><span class="token class-name">BloomFilter</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>shaded<span class="token punctuation">.</span>guava18<span class="token punctuation">.</span>com<span class="token punctuation">.</span>google<span class="token punctuation">.</span>common<span class="token punctuation">.</span>hash<span class="token punctuation">.</span></span><span class="token class-name">Funnels</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">SingleOutputStreamOperator</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">ProcessFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span></span><span class="token class-name">StandardCharsets</span><span class="token punctuation">;</span>

<span class="token comment">/**
 * 使用布隆过滤器实时去重
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkBloomFilterDemo</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> source <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream1 <span class="token operator">=</span> source<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arr <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token class-name">String</span> str <span class="token operator">:</span> arr<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>x <span class="token operator">-></span> x<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">SubOrderDeduplicateProcessFunc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">;</span>
        stream1<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token comment">// 去重用的ProcessFunction</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">class</span> <span class="token class-name">SubOrderDeduplicateProcessFunc</span> <span class="token keyword">extends</span> <span class="token class-name">ProcessFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">long</span> serialVersionUID <span class="token operator">=</span> <span class="token number">1L</span><span class="token punctuation">;</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">int</span> BF_CARDINAL_THRESHOLD <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>
        <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token keyword">double</span> BF_FALSE_POSITIVE_RATE <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">;</span>

        <span class="token keyword">private</span> <span class="token keyword">volatile</span> <span class="token class-name">BloomFilter</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> subOrderFilter<span class="token punctuation">;</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
            subOrderFilter <span class="token operator">=</span> <span class="token class-name">BloomFilter</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token class-name">Funnels</span><span class="token punctuation">.</span><span class="token function">stringFunnel</span><span class="token punctuation">(</span><span class="token class-name">StandardCharsets</span><span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">,</span> BF_CARDINAL_THRESHOLD<span class="token punctuation">,</span> BF_FALSE_POSITIVE_RATE<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>


        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processElement</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">String</span> subOrderId <span class="token operator">=</span> s<span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>subOrderFilter<span class="token punctuation">.</span><span class="token function">mightContain</span><span class="token punctuation">(</span>subOrderId<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                subOrderFilter<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>subOrderId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>


        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
            subOrderFilter <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>使用布隆过滤器防止缓存击穿</li>
<li>*不在布隆过滤器中的元素一定不存在数据库中。**<br>利用布隆过滤器的这个特点可以解决缓存穿透的问题，在服务启动的时候先把数据的查询条件，例如数据的 ID 映射到布隆过滤器上，当然如果新增数据时，除了写入到数据库中之外，也需要将数据的ID存入到布隆过滤器中。<br>我们在查询某条数据时，先判断这个查询的 ID 是否存在布隆过滤器中，如果不存在就直接返回空值，而不需要继续查询数据库和缓存，存在布隆过滤器中才继续查询数据库和缓存，这样就解决缓存穿透的问题。</li>
</ul>
]]></content>
      <categories>
        <category>Algorithm</category>
        <category>BloomFilter</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos安装Mysql</title>
    <url>/2022/03/11/Centos%E5%AE%89%E8%A3%85Mysql/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Centos安装Mysql</li>
</ul>
<a id="more"></a>

<h2 id="Centos安装Mysql"><a href="#Centos安装Mysql" class="headerlink" title="Centos安装Mysql"></a>Centos安装Mysql</h2><p>本文讲述Centos通过yum安装Mysql,yum本身没有mysql源，需要自己去官网下载</p>
<ol>
<li>去官网下载yum仓库文件<br>官网下载连接：<a href="https://dev.mysql.com/downloads/repo/yum/">https://dev.mysql.com/downloads/repo/yum/</a><br><img src="/uploads/202203/mysql-yum%E6%BA%90%E9%80%89%E6%8B%A9.png" alt="mysql-yum源选择"></li>
</ol>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#将复制的连接地址下载
[root@localhost ~]# wget https:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql80-community-release-el7-3.noarch.rpm

[root@localhost ~]# ls
anaconda-ks.cfg  mysql80-community-release-el7-3.noarch.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>安装yum仓库文件<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#可是使用rpm -ivh或者是yum localinstall 去安装，两者实质是一样的
[root@localhost ~]# rpm -ivh mysql80-community-release-el7-3.noarch.rpm
warning: mysql80-community-release-el7-3.noarch.rpm: Header V3 DSA&#x2F;SHA1 Signature, key ID 5072e1f5: NOKEY
Preparing...                          ################################# [100%]
Updating &#x2F; installing...
   1:mysql80-community-release-el7-3  ################################# [100%]

#安装完成后可以看到mysql的repo文件
[root@localhost ~]# ls &#x2F;etc&#x2F;yum.repos.d&#x2F;
CentOS-Base.repo  epel.repo  mysql-community.repo  mysql-community-source.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>版本选择<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 安装 YUM 管理工具包，此包提供了 yum-config-manager 命令工具
[root@localhost ~]# yum -y install yum-utils

[root@localhost ~]# yum-config-manager --disable mysql80-community
[root@localhost ~]# yum-config-manager --enable mysql57-community
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
查看默认启动的仓库<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@localhost ~]# yum repolist enabled | grep mysql
mysql-connectors-community&#x2F;x86_64 MySQL Connectors Community                 185
mysql-tools-community&#x2F;x86_64      MySQL Tools Community                      123
mysql57-community&#x2F;x86_64          MySQL 5.7 Community Server                 484<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>安装<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yum install -y  mysql-community-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里会报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Downloading packages:
warning: &#x2F;var&#x2F;cache&#x2F;yum&#x2F;x86_64&#x2F;7&#x2F;mysql57-community&#x2F;packages&#x2F;mysql-community-devel-5.7.37-1.el7.x86_64.rpm: Header V4 RSA&#x2F;SHA256 Signature, key ID 3a79bd29: NOKEY
Retrieving key from file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysql


The GPG keys listed for the &quot;MySQL 5.7 Community Server&quot; repository are already installed but they are not correct for this package.
Check that the correct key URLs are configured for this repository.


Failing package is: mysql-community-devel-5.7.37-1.el7.x86_64
GPG Keys are configured as: file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
报错原因：官方 MySQL 存储库的 GPG 密钥已过期，无法安装或更新 MySQL 包<br>相关报错案例可以在mysql官网查看：<a href="https://bugs.mysql.com/bug.php?id=106188">https://bugs.mysql.com/bug.php?id=106188</a><br>可以在运行安装程序之前导入密钥：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#Centos
rpm --import https:&#x2F;&#x2F;repo.mysql.com&#x2F;RPM-GPG-KEY-mysql-2022
#Ubuntu：
wget -q -O - https:&#x2F;&#x2F;repo.mysql.com&#x2F;RPM-GPG-KEY-mysql-2022 | apt-key add -<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
之后再执行<code>yum install -y  mysql-community-server</code>就over了</li>
</ol>
<ol start="5">
<li><p>设置默认配置<br>在/etc/my.cnf的文件中设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[mysqld]
#配置文件根据环境自行配置，或者保持默认
#例如添加下面几行，设置默认引擎编码和排序规则(根据情况设置合适的)
default-storage-engine&#x3D;INNODB
character-set-server &#x3D; utf8mb4
collation-server &#x3D; utf8mb4_general_ci
skip-character-set-client-handshake
secure_file_priv&#x3D;&#39;&#39;


[client]
default-character-set&#x3D;utf8mb4
[mysql]
default-character-set&#x3D;utf8mb4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>启动服务</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 启动
systemctl start mysqld

# 查看状态
systemctl status mysqld

# 开机自启动
systemctl enable mysqld

# 查看监听端口，默认 3306
ss -natl |grep 3306<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>初始化<br>MySQL服务器初始化（从MySQL 5.7开始）：<br>在 MySQL 服务器初始启动时，如果服务器的数据目录为空，则会发生以下情况：<br>MySQL 服务器已初始化。<br>在数据目录中生成SSL证书和密钥文件。<br>安装并启用该 validate_password 插件。<br>将创建一个超级用户 帐户‘root’@’localhost’。并会设置超级用户的密码，将其存储在错误日志文件/var/log/mysqld.log中。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@localhost ~]# grep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log
2021-01-25T04:26:33.010077Z 1 [Note] A temporary password is generated for root@localhost: *sH2qhGeN(eB

#本地登录的root密码: *sH2qhGeN(eB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>修改初始密码</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mysql&gt; alter user   root@localhost   identified  by  &#39;123456&#39;;
ERROR 1819 (HY000): Your password does not satisfy the current policy requirements

#太过简单的密码会失败，因为不满足密码复杂度的要求

mysql&gt; alter user   root@localhost   identified  by  &#39;Gjc123!@#&#39;;
Query OK, 0 rows affected (0.00 sec)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>要设置比较简单的密码就需要取消密码复杂度<br>编辑 my.cnf配置文件, 在 [mysqld]配置块儿中添加如下内容</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">plugin-load&#x3D;validate_password.so
validate-password&#x3D;OFF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>保存退出后，重启服务, 修改密码</p>
</li>
<li><p>远程连接<br>远程登录还需要授权远程登录<br>Mysql默认不允许远程登录，我们需要设置关闭selinux或者防火墙，不关防火墙就开放3306端口；</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mysql&gt; grant all privileges on *.* to root@localhost identified by &#39;Gjc123!@#&#39;;
 Query OK, 0 rows affected, 1 warning (0.00 sec)

#允许任意IP连接
 mysql&gt; grant all privileges on *.* to root@&#39;%&#39; identified by &#39;Gjc123!@#&#39;;
 Query OK, 0 rows affected, 1 warning (0.00 sec)
flush privileges;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>%：匹配任意长度的任意字符，常用于设置允许从任何主机登录<br>_：匹配任意单个字符</p>
</li>
</ol>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#放开3306端口
firewall-cmd --zone&#x3D;public --add-port&#x3D;3306&#x2F;tcp --permanent
firewall-cmd --reload

#关闭防火墙和selinux一劳永逸<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Cloudera Manager CDH离线安装</title>
    <url>/2022/03/11/Cloudera-Manager-CDH%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>CM离线安装<a id="more"></a>

</li>
</ul>
<h2 id="CM离线安装"><a href="#CM离线安装" class="headerlink" title="CM离线安装"></a>CM离线安装</h2><h3 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h3><p>准备3台虚拟机<br>golden-01<br>golden-02<br>golden-03<br>并设置免秘钥登录，这里忽略</p>
<p>下载cdh6.2.0，在百度网盘下载：<br><a href="https://pan.baidu.com/s/1QlWyMRSRJNcaStsZMSdmLg">https://pan.baidu.com/s/1QlWyMRSRJNcaStsZMSdmLg</a>  提取码：ietj</p>
<h3 id="关闭防火墙与关闭-SELINUX"><a href="#关闭防火墙与关闭-SELINUX" class="headerlink" title="关闭防火墙与关闭 SELINUX"></a>关闭防火墙与关闭 SELINUX</h3><ol>
<li>关闭防火墙<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">systemctl stop firewalld  ## 关闭防火墙
systemctl disable firewalld ###禁止防火墙开机自启<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>关闭SELINUX，只需要关闭一个需要配置http文件服务的虚拟机就可以<br>vim /etc/selinux/config —&gt; SELINUX=disabled (修改)<br>这里改完了需要重启虚拟机<br>这里如果不关闭SELINUX，下面视同httpd访问文件的时候，会报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">You don&#39;t have permission to access upload&#x2F; on this server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


</li>
</ol>
<h3 id="配置NTP服务（所有节点）"><a href="#配置NTP服务（所有节点）" class="headerlink" title="配置NTP服务（所有节点）"></a>配置NTP服务（所有节点）</h3><p>修改时区（改为中国标准时区）</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime
## 安装ntp
yum -y install ntp <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>ntp主机配置 vi /etc/ntp.conf<br>在文件里新增server ntp.aliyun.com，并把原始的server给注释掉<br>重启<code>service ntpd restart</code></p>
<h3 id="配置本地服务器（选定任意一台主机即可）"><a href="#配置本地服务器（选定任意一台主机即可）" class="headerlink" title="配置本地服务器（选定任意一台主机即可）"></a>配置本地服务器（选定任意一台主机即可）</h3><p>配置的本地文件服务器的目的是为了，让之后其他节点可以从这直接下载</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum install -y httpd  ##安装httpd
service httpd start 启用htttpd
cd &#x2F;var&#x2F;www&#x2F;html&#x2F;  &amp;&amp; mkdir cdh6  &amp;&amp; mkdir cm6
## 把下载的rpm放到文件服务cm6里
cp &#x2F;home&#x2F;golden&#x2F;cdh6.2.0&#x2F;cm6&#x2F;* &#x2F;var&#x2F;www&#x2F;html&#x2F;cm6&#x2F;
cp &#x2F;home&#x2F;golden&#x2F;cdh6.2.0&#x2F;oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm &#x2F;var&#x2F;www&#x2F;html&#x2F;cm6&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里注意，启用httpd服务以后，防火墙和selinux必须都关闭，否则，就会报如下错误：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">You don&#39;t have permission to access upload&#x2F; on this server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>生成yum源的描述的目录信息 可以让其他节点知道到这里下载</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum install -y createrepo  ##下载createrepo命令
## 进入到cm6安装包的httpd资源位置
cd &#x2F;var&#x2F;www&#x2F;html&#x2F;cm6
##创建yum源的描述meta
createrepo .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在<strong>所有节点上</strong>添加yum源的配置文件</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cat &gt;&gt; &#x2F;etc&#x2F;yum.repos.d&#x2F;cm6.repo &lt;&lt; EOF
[cm6-local]
name&#x3D;cm6-local
baseurl&#x3D;http:&#x2F;&#x2F;192.168.233.133&#x2F;cm6&#x2F;
enabled&#x3D;1
gpgcheck&#x3D;0
EOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>查看yum配置源是否生效</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum clean all
yum repolist
yum makecache<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h3><p>前面安装了2次，都是使用自己配置JAVA_HOME的方式，都没问题，但是，最后一次使用了CentOS7精简版的，还是使用自己配置JAVA_HOME的方式，发现cloudera-manager-server启动不成功<br>通过<code>journalctl -u cloudera-manager-server</code>以及<code>journalctl -xe</code>来查看启动日志，发现，报找不到java。但是java安装没有问题<br>最后使用了yum安装了jdk问题解决了</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">yum install -y oracle-j2sdk1.8-1.8.0+update181-1.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="clouder-server-与agent安装"><a href="#clouder-server-与agent安装" class="headerlink" title="clouder server 与agent安装"></a>clouder server 与agent安装</h3><h4 id="安装cm6相关依赖（所有节点）"><a href="#安装cm6相关依赖（所有节点）" class="headerlink" title="安装cm6相关依赖（所有节点）"></a>安装cm6相关依赖（所有节点）</h4><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">yum -y install chkconfig python bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse fuse-libs redhat-lsb httpd mod_ssl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="安装Cloudera-Manager-Server"><a href="#安装Cloudera-Manager-Server" class="headerlink" title="安装Cloudera Manager Server"></a>安装Cloudera Manager Server</h4><p>这一步只需要在CM Server节点上操作。<br>执行下面的命令：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 安装openjdk8
yum install oracle-j2sdk1.8   ##这里不知道需不需要安装，因为我本机已经安装了java了。这里先不安装，如果报错再重来
# 安装 cm manager(只需在server节点安装)
yum install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="配置本地Parcel存储库"><a href="#配置本地Parcel存储库" class="headerlink" title="配置本地Parcel存储库"></a>配置本地Parcel存储库</h3><p>Cloudera Manager Server安装完成后，进入到本地Parcel存储库目录：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cd &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo  ## Cloudera Manager Server完成以后，该目录就已经生成了<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>将第一部分下载的CDH parcels文件上传至该目录下，然后执行修改sha文件：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">mv &#x2F;data6&#x2F;upload&#x2F;parcels&#x2F;* &#x2F;opt&#x2F;cloudera&#x2F;parcel-repo&#x2F;
mv CDH-6.3.0-1.cdh6.3.0.p0.1279813-el7.parcel.sha1 CDH-6.3.0-1.cdh6.3.0.p0.1279813-el7.parcel.sha<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="配置mysql-jdbc驱动"><a href="#配置mysql-jdbc驱动" class="headerlink" title="配置mysql jdbc驱动"></a>配置mysql jdbc驱动</h3><p>从前面下载好的mysql-connector-java-5.1.47.tar.gz包中解压出mysql-connector-java-5.1.47-bin.jar文件，将mysql-connector-java-5.1.47-bin.jar文件上传至CM Server节点上的/usr/share/java/目录下并重命名为mysql-connector-java.jar（如果/usr/share/java/目录不存在，需要手动创建）：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">cd &#x2F;usr&#x2F;share&#x2F;java  &amp;&amp; mv &#x2F;home&#x2F;golden&#x2F;mysql-connector-java-5.1.47.jar .<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="创建CDH所需要的数据库"><a href="#创建CDH所需要的数据库" class="headerlink" title="创建CDH所需要的数据库"></a>创建CDH所需要的数据库</h3><p>根据所需要安装的服务参照下表创建对应的数据库以及数据库用户，数据库必须使用utf8编码，创建数据库时要记录好用户名及对应密码：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- scm</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> scm <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> scm<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'scm'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'scm'</span><span class="token punctuation">;</span>

<span class="token comment">-- amon</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> amon <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> amon<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'amon'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'amon'</span><span class="token punctuation">;</span>

<span class="token comment">-- rman</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> rman <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> rman<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'rman'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'rman'</span><span class="token punctuation">;</span>

<span class="token comment">-- hue</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> hue <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span> 
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> hue<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hue'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'hue'</span><span class="token punctuation">;</span>

<span class="token comment">-- hive</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> metastore <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> metastore<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hive'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'hive'</span><span class="token punctuation">;</span>

<span class="token comment">-- sentry</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> sentry <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>   
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> sentry<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'sentry'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'sentry'</span><span class="token punctuation">;</span>

<span class="token comment">-- nav</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> nav <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>      
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> nav<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'nav'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'nav'</span><span class="token punctuation">;</span>

<span class="token comment">-- navms</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> navms <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> navms<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'navms'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'navms'</span><span class="token punctuation">;</span>

<span class="token comment">-- oozie</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> oozie <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> oozie<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'oozie'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'oozie'</span><span class="token punctuation">;</span>

<span class="token comment">-- hive</span>
<span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> hive <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARACTER</span> <span class="token keyword">SET</span> utf8 <span class="token keyword">DEFAULT</span> <span class="token keyword">COLLATE</span> utf8_general_ci<span class="token punctuation">;</span>
<span class="token keyword">GRANT</span> <span class="token keyword">ALL</span> <span class="token keyword">ON</span> hive<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">TO</span> <span class="token string">'hive'</span><span class="token variable">@'%'</span> IDENTIFIED <span class="token keyword">BY</span> <span class="token string">'hive'</span><span class="token punctuation">;</span>
<span class="token comment">-- flush</span>
FLUSH <span class="token keyword">PRIVILEGES</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="设置Cloudera-Manager-数据库"><a href="#设置Cloudera-Manager-数据库" class="headerlink" title="设置Cloudera Manager 数据库"></a>设置Cloudera Manager 数据库</h3><p>Cloudera Manager Server包含一个配置数据库的脚本。</p>
<ul>
<li>mysql数据库与CM Server是同一台主机<br>执行命令：<code>/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm</code></li>
<li>mysql数据库与CM Server不在同一台主机上<br>执行命令：<code>/opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h &lt;mysql-host-ip&gt; --scm-host &lt;cm-server-ip&gt; scm scm</code><br>执行如下命令：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&#x2F;opt&#x2F;cloudera&#x2F;cm&#x2F;schema&#x2F;scm_prepare_database.sh mysql -uroot -h golden-02 -p&#39;Gjc123!@#&#39; --scm-host golden-01 scm scm scm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里卡了很久，报了如下错误：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ERROR Exception when creating&#x2F;dropping database with user &#39;root&#39; and jdbc url &#39;jdbc:mysql:&#x2F;&#x2F;golden-02&#x2F;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&#39;
com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure

The last packet successfully received from the server was 202 milliseconds ago.  The last packet sent successfully to the server was 197 milliseconds ago.
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)[:1.8.0_321]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)[:1.8.0_321]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)[:1.8.0_321]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)[:1.8.0_321]
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
找了很久的问题，首先是安装的mysql不支持远程连接，需要做如下配置：<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">grant</span> <span class="token keyword">all</span> <span class="token keyword">privileges</span> <span class="token keyword">on</span> <span class="token operator">*</span><span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">to</span> root<span class="token variable">@'%'</span> identified <span class="token keyword">by</span> <span class="token string">'Gjc123!@#'</span><span class="token punctuation">;</span>
flush <span class="token keyword">privileges</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
配置了以后，还是报错，找了很久，最终找到原因，是因为下载的<code>mysql-connector-java-5.1.47-bin.jar</code>有问题，重新下载了一个，问题解决</li>
</ul>
<h3 id="安装CDH节点"><a href="#安装CDH节点" class="headerlink" title="安装CDH节点"></a>安装CDH节点</h3><h4 id="启动Cloudera-Manager-Server服务"><a href="#启动Cloudera-Manager-Server服务" class="headerlink" title="启动Cloudera Manager Server服务"></a>启动Cloudera Manager Server服务</h4><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">systemctl start cloudera-scm-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>然后等待Cloudera Manager Server启动，可能需要稍等一会儿，可以通过命令<code>tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</code>去监控服务启动状态。<br>当看到<code>INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server.</code>日志打印出来后，说明服务启动成功，可以通过浏览器访问<code>Cloudera Manager WEB</code>界面了。</p>
<h4 id="访问Cloudera-Manager-WEB界面"><a href="#访问Cloudera-Manager-WEB界面" class="headerlink" title="访问Cloudera Manager WEB界面"></a>访问Cloudera Manager WEB界面</h4><ul>
<li>打开浏览器，访问地址：http://<server_host>:7180，默认账号和密码都为admin：</li>
<li>首先是Cloudera Manager的欢迎页面，点击页面右下角的【继续】按钮进行下一步</li>
<li>勾选接受条款，点击【继续】进行下一步：</li>
<li>版本选择,这里我就选择免费版了：</li>
<li>选择版本以后会出现第二个欢迎界面，不过这个是安装集群的欢迎页：</li>
<li>选择主机,这一步是要搜索并选择用于安装CDH集群的主机，在主机名称后面的输入框中输入各个节点的hostname，中间使用英文逗号分隔开，然后点击搜索，在结果列表中勾选要安装CDH的节点即可：<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E9%85%8D%E7%BD%AE%E4%B8%BB%E6%9C%BA.png" alt="CM离线安装_配置主机"></li>
<li>指定存储库<code>Cloudera Manager Agent</code>这里选择自定义，填写上面使用httpd搭建好的Cloudera Manager YUM 库URL：</li>
<li>CDH and other software 如果我们之前的【配置本地Parcel存储库】步骤操作无误的话，这里会自动选择【使用Parcel】，并加载出CDH版本，但是这里一直没有识别出来，还报了如下错误：<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E8%AF%86%E5%88%AB%E4%B8%8D%E5%88%B0parcel-repo.png" alt="CM离线安装_识别不到parcel-repo"><br>找到问题原因：是因为parcel文件的<code>.sha1</code>需要改成<code>.sha</code>，修改完以后，就能识别出来了<br>这里一开始还跟着教程先用yum安装了<code>cloudera-manager-agent</code>，安装完了更报错，这里不要安装<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E6%AD%A3%E5%B8%B8%E8%AF%86%E5%88%AB%E5%88%B0parcel-repo.png" alt="CM离线安装_正常识别到parcel-repo"></li>
<li>JDK安装选项，这里jdk已经安装了，不要勾选</li>
<li>SSH登录配置，用于配置集群主机之间的SSH登录，填写root用户的密码，根据集群配置填写合适的【同时安装数量】值即可：<br><img src="/uploads/202203/CM%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85_%E6%8F%90%E4%BE%9BSSH%E7%99%BB%E5%BD%95%E5%87%AD%E6%8D%AE.png" alt="CM离线安装_提供SSH登录凭据"></li>
<li>安装Agent</li>
<li>安装Parcels</li>
<li>主机检查，<code>Inspect Network Performance </code>和<code>Inspect Network Performance</code>需要点击的，一开始以为是自动检查，一直等着<br>然后标黄了几个选项：<br>Cloudera 建议将 /proc/sys/vm/swappiness 设置为最大值 10。当前设置为 30。使用 sysctl 命令在运行时更改该设置并编辑 /etc/sysctl.conf，以在重启后保存该设置。您可以继续进行安装，但 Cloudera Manager 可能会报告您的主机由于交换而运行状况不良。<br>已启用透明大页面压缩，可能会导致重大性能问题。请运行echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag和echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled以禁用此设置，然后将同一命令添加到 /etc/rc.local 等初始化脚本中，以便在系统重启时予以设置。<br>安装上面的提示执行即可；<br>但是有一点，报找不到java，这个有点不知道怎么解决了，这里先跳过了，点击<code>I understand this risks</code></li>
</ul>
<h3 id="安装CDH集群"><a href="#安装CDH集群" class="headerlink" title="安装CDH集群"></a>安装CDH集群</h3><h4 id="选择服务类型"><a href="#选择服务类型" class="headerlink" title="选择服务类型"></a>选择服务类型</h4><p>这里我选择自定义服务，然后选择很多组件，hdfs、zk、yarn、hbase、kafka等等</p>
<h4 id="角色分配"><a href="#角色分配" class="headerlink" title="角色分配"></a>角色分配</h4><p>这里会有默认设置，然后把需要手动设置的手动设置一下，点击继续</p>
<h4 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h4><p>这里根据要求设置即可<br>后面的步骤就没有什么问题了，可以参考下面的两篇文章。</p>
<p>这里参考了<br><a href="https://segmentfault.com/a/1190000021809645">CentOS7 Cloudera Manager6 完全离线安装 CDH6 集群</a><br><a href="https://blog.csdn.net/weixin_45682234/article/details/105844209">cdh6.2离线安装（傻瓜式安装教程）</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>CM</category>
      </categories>
      <tags>
        <tag>CM</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch学习笔记（一）</title>
    <url>/2021/06/25/Elasticsearch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Elasticsearch简介</li>
</ul>
<a id="more"></a>


<h2 id="Elasticsearch简介"><a href="#Elasticsearch简介" class="headerlink" title="Elasticsearch简介"></a>Elasticsearch简介</h2><p>Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎，有以下几个特点：</p>
<ul>
<li>一个分布式的实时文档存储，每个字段都可被索引</li>
<li>一个分布式实时搜索引擎</li>
<li>强大的横向扩展能力，并支持大数据集的结构化/非结构化数据</li>
<li>Elasticsearch是<code>面向文档</code>的，意味着它存储整个对象或文档(使用<code>JSON</code>作为文档的序列化格式)</li>
</ul>
<p>Elasticsearch 是一个开源的搜索引擎，建立在一个全文搜索引擎库 Apache Lucene™ 基础之上。 Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库—​无论是开源还是私有。</p>
<p>Elasticsearch的安装很简单，直接解压就行，访问使用restAPI，也可以使用kibana<br>kibana的安装也很简单，直接解压，配置一下ES的相关属性就可以<br>安装好后，访问<code>http://localhost:5601/</code>即可使用kibana操作ES</p>
<h2 id="Elasticsearch使用"><a href="#Elasticsearch使用" class="headerlink" title="Elasticsearch使用"></a>Elasticsearch使用</h2><h3 id="直接通过Curl操作ES"><a href="#直接通过Curl操作ES" class="headerlink" title="直接通过Curl操作ES"></a>直接通过Curl操作ES</h3><p>这种方式，是直接使用 RESTful API 通过端口 9200 和 Elasticsearch 进行通信，不过不太常用，一般都是通过kibana来操作ES</p>
<ul>
<li>操作索引<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 创建一个名称为 alibaba 的 Index（索引库）
curl -X PUT localhost:9200&#x2F;alibaba
# 删除索引
curl -X DELETE localhost:9200&#x2F;alibaba
# 列出每个 Index 包含的 Type
curl &quot;localhost:9200&#x2F;_mapping?pretty&#x3D;true&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>操作Document 文档</li>
<li><ul>
<li>新增文档<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 在 alibaba&#x2F;user 中，新增一条记录（文档），记录的 id 为 1
curl -X PUT localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1 -d &#123;\&quot;name\&quot;:\&quot;rose\&quot;&#125;
#  或者
curl -X PUT localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1 -H &quot;Content-Type: application&#x2F;json&quot; -d &#123;\&quot;name\&quot;:\&quot;rose\&quot;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
上述示例中，alibaba 代表 Index，user 代表 Type，如果它们不存在，会自动创建。1 代表记录的 id。<br>新增记录时，也可以不指定 id，这时服务器会自动生成一个随机字符串作为该记录的 id。</li>
</ul>
</li>
</ul>
<p>** 查看记录</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">
# 查看 alibaba&#x2F;user&#x2F;1 记录
curl localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1
# 查看 alibaba&#x2F;user&#x2F;1 记录（会对结果进行格式化）
curl localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1?pretty
# 查看 alibaba&#x2F;user 中的所有记录
curl localhost:9200&#x2F;alibaba&#x2F;user&#x2F;_search<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>?pretty 表示对返回结果进行格式化，以便更易于阅读。</p>
<p>** 删除记录</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">curl -X DELETE localhost:9200&#x2F;alibaba&#x2F;user&#x2F;1?pretty<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="通过kibana操作ES"><a href="#通过kibana操作ES" class="headerlink" title="通过kibana操作ES"></a>通过kibana操作ES</h3><p>kibana的访问地址：<a href="http://localhost:5601/">http://localhost:5601/</a><br>在kibana侧边栏找到Management -&gt; Dev Tool ,在Dev Tool里就可以操作ES了</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Filco圣手二代双模蓝牙机械键盘的连接方法</title>
    <url>/2021/01/18/Filco%E5%9C%A3%E6%89%8B%E4%BA%8C%E4%BB%A3%E5%8F%8C%E6%A8%A1%E8%93%9D%E7%89%99%E6%9C%BA%E6%A2%B0%E9%94%AE%E7%9B%98%E7%9A%84%E8%BF%9E%E6%8E%A5%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="常规方法"><a href="#常规方法" class="headerlink" title="常规方法"></a>常规方法</h2><ol>
<li>确认键盘的电源接通。 </li>
<li>同时按下「Ctrl」+「Alt」+「Fn」执行装置切换模式。配对LED灯（蓝）和低电量显示LED灯（红）约同时亮10秒左右。</li>
<li>想移除已登录的装置时，请从「蓝牙装置登录／切换键」①～④按下任一键</li>
</ol>
<h2 id="新添加的电脑"><a href="#新添加的电脑" class="headerlink" title="新添加的电脑"></a>新添加的电脑</h2><p>如果是新添加的电脑，会在首次配置的时候输入验证码，这时候，需要快速在键盘上按下验证码，输入后就可正常连接了<br>注意，如果失败的次数过多，那么就会提示输入PIN码</p>
<h2 id="输入PIN码的方式（亲测可用）"><a href="#输入PIN码的方式（亲测可用）" class="headerlink" title="输入PIN码的方式（亲测可用）"></a>输入PIN码的方式（亲测可用）</h2><ol>
<li>当你要连接蓝牙键盘的时电脑端出现输入PIN</li>
<li>此时先在本机键盘上输入任意六位PIN</li>
<li>接下来电脑开始验证时，迅速在你的蓝牙设备上输入刚才的六位PIN，然后回车，成功！</li>
</ol>
<h2 id="想要清楚以前绑定的设备（亲测可用）"><a href="#想要清楚以前绑定的设备（亲测可用）" class="headerlink" title="想要清楚以前绑定的设备（亲测可用）"></a>想要清楚以前绑定的设备（亲测可用）</h2><p>如果被绑定的①～④有某个想重新绑定新的电脑，可以按如下步骤：</p>
<ol>
<li>同时按下crtl+alt+Fn，红蓝灯闪烁4秒。</li>
<li>键盘背面的清除键，拿笔点住2秒。</li>
<li>再按数字键1-4的任意一个想清除配置的数字。</li>
<li>然后从想连接的设备蓝牙列表中选择键盘，点击连接。</li>
<li>该设备屏幕出现4或6位的配对码。在键盘上依次按下配对码，回车。OK，该设备与filco蓝牙键盘连接成功。</li>
</ol>
<p>这里只是为了记录一下，省的下次还要继续查度娘</p>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
  </entry>
  <entry>
    <title>Flink学习笔记（二）</title>
    <url>/2021/01/29/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink任务案例</li>
<li>Flink的slot和并行度理解<a id="more"></a>
<h2 id="Flink任务案例"><a href="#Flink任务案例" class="headerlink" title="Flink任务案例"></a>Flink任务案例</h2><h3 id="Flink消费Kafka-自定义KafkaDeserializationSchema"><a href="#Flink消费Kafka-自定义KafkaDeserializationSchema" class="headerlink" title="Flink消费Kafka:自定义KafkaDeserializationSchema"></a>Flink消费Kafka:自定义KafkaDeserializationSchema</h3>Flink已经定义好的反序列化shema:</li>
<li>SimpleStringSchema：返回的结果只有Kafka的value，没有其它信息：</li>
<li>TypeInformationKeyValueSerializationSchema：返回的结果只有Kafka的key,value，没有其它信息</li>
</ul>
<p>如果需要获得Kafka的topic或者其它信息，就需要通过实现KafkaDeserializationSchema接口来自定义返回数据的结构</p>
<ul>
<li>自定义KafkaDeserializationSchema：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">TypeHint</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">TypeInformation</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">KafkaDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span></span><span class="token class-name">Charset</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyKafkaDeserializationSchema</span> <span class="token keyword">implements</span> <span class="token class-name">KafkaDeserializationSchema</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Charset</span> UTF_8 <span class="token operator">=</span> <span class="token class-name">Charset</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span><span class="token string">"UTF-8"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isEndOfStream</span><span class="token punctuation">(</span><span class="token class-name">String</span> nextElement<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">deserialize</span><span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token operator">&lt;</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">></span> consumerRecord<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">String</span> value <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>consumerRecord<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> UTF_8<span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">long</span> offset <span class="token operator">=</span> consumerRecord<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">int</span> partition <span class="token operator">=</span> consumerRecord<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%s,%s,%s"</span><span class="token punctuation">,</span>value<span class="token punctuation">,</span>offset<span class="token punctuation">,</span>partition<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"%s,%s,%s"</span><span class="token punctuation">,</span>value<span class="token punctuation">,</span>offset<span class="token punctuation">,</span>partition<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">TypeInformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token function">getProducedType</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token class-name">TypeInformation</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TypeHint</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//return null; //会报错</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
如果不重写，会报如下错误：<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">Exception in thread &quot;main&quot; org.apache.flink.api.common.functions.InvalidTypesException: The return type of function &#39;Custom Source&#39; could not be determined automatically, due to type erasure. You can give type information hints by using the returns(...) method on the result of the transformation call, or by letting your function implement the &#39;ResultTypeQueryable&#39; interface.
	at org.apache.flink.api.dag.Transformation.getOutputType(Transformation.java:479)
	at org.apache.flink.streaming.api.datastream.DataStream.getType(DataStream.java:193)
	at org.apache.flink.streaming.api.datastream.DataStream.flatMap(DataStream.java:613)
	at com.hzw.bigdata.flinkstudy.FlinkConsumerKafka.main(FlinkConsumerKafka.java:60)
Caused by: org.apache.flink.api.common.functions.InvalidTypesException: Type of TypeVariable &#39;OUT&#39; in &#39;interface org.apache.flink.streaming.api.functions.source.ParallelSourceFunction&#39; could not be determined. This is most likely a type erasure problem. The type extraction currently supports types with generic variables only in cases where all variables in the return type can be deduced from the input type(s). Otherwise the type has to be specified explicitly using type information.
	at org.apache.flink.api.java.typeutils.TypeExtractor.createTypeInfoWithTypeHierarchy(TypeExtractor.java:923)
	at org.apache.flink.api.java.typeutils.TypeExtractor.privateCreateTypeInfo(TypeExtractor.java:828)
	at org.apache.flink.api.java.typeutils.TypeExtractor.createTypeInfo(TypeExtractor.java:787)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.getTypeInfo(StreamExecutionEnvironment.java:2287)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1681)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1668)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1637)
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.addSource(StreamExecutionEnvironment.java:1623)
	at com.hzw.bigdata.flinkstudy.FlinkConsumerKafka.main(FlinkConsumerKafka.java:58)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>主类调用：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">Types</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span></span><span class="token class-name">TimeCharacteristic</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer011</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Kafka参数</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">MyKafkaDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        consumer<span class="token punctuation">.</span><span class="token function">setStartFromEarliest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> wordCount <span class="token operator">=</span> stream
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
                    collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>line<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>INT<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>key <span class="token operator">-></span> key<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>key <span class="token operator">-></span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>f0 <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> key<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        wordCount<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka streaming word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
具体的可以参考<br><a href="https://my.oschina.net/u/2380815/blog/4453531">Flink实战：自定义KafkaDeserializationSchema(Java/Scala)</a></li>
</ul>
<h2 id="Flink的slot和并行度理解"><a href="#Flink的slot和并行度理解" class="headerlink" title="Flink的slot和并行度理解"></a>Flink的slot和并行度理解</h2><h3 id="Flink的Slot是什么？和Spark的Excutor有什么区别？"><a href="#Flink的Slot是什么？和Spark的Excutor有什么区别？" class="headerlink" title="Flink的Slot是什么？和Spark的Excutor有什么区别？"></a>Flink的Slot是什么？和Spark的Excutor有什么区别？</h3><h3 id="Slot和并行度之间有什么关系？"><a href="#Slot和并行度之间有什么关系？" class="headerlink" title="Slot和并行度之间有什么关系？"></a>Slot和并行度之间有什么关系？</h3><p>是每个slot都有几个并行度，还是说，并行度是整体任务的并行度，和每个slot没什么关系？</p>
<h3 id="假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据"><a href="#假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据" class="headerlink" title="假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据"></a>假设kafka有10个分区，flink设置的并行度只有1，会启动几个线程来读这10个分区的数据</h3>]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（四）</title>
    <url>/2021/08/12/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink时间语义与窗口<a id="more"></a>


</li>
</ul>
<h2 id="Flink时间语义与Watermark"><a href="#Flink时间语义与Watermark" class="headerlink" title="Flink时间语义与Watermark"></a>Flink时间语义与Watermark</h2><p>Event Time：事件创建的时间<br>Ingestion Time：数据进入Flink的时间<br>Processing Time：执行操作算子的本地系统时间，与机器相关</p>
<p>WaterMark是用来处理乱序数据的</p>
<ul>
<li>Watermark是一种衡量Event Time进展的机制们可以设定延迟触发</li>
<li>Watermark是用于处理乱序事件的吗，而正确的处理乱序事件，通常用Watermark机制集合window来实现</li>
<li>数据流重的Watermark用于表示timesamp小于Watermark的数据，都已经到达了，因此，window的执行也是由Watermark触发的</li>
<li>Watermark用来让程序自己平衡延迟和结果正确性</li>
</ul>
<h3 id="Watermark的特点："><a href="#Watermark的特点：" class="headerlink" title="Watermark的特点："></a>Watermark的特点：</h3><ul>
<li>Watermark是一条特殊的数据记录</li>
<li>Watermark必须单调递增，以确保任务的事件事件始终在向前推进，而不是在后退</li>
<li>Watermark与数据的时间戳相关</li>
</ul>
<blockquote>
<p>每条数据都会计算出一个watermark，每个watermark都会和之前的watermark做比较，取更大的一个，确保watermark是向前推进的<br>多个分区的watermark，会取当前window下，所有分区重最小的一个，为了防止数据丢失<br>每个watermark都会和window的结束时间（window.getEnd()）做比较，如果时间大于等于window结束时间，window就会被触发，处理的数据会小于window结束时间的，等于window结束时间的会放到下一个window<br>程序运行以后，会一直获取Watermark（执行getCurrentWatermark()函数），不管有没有数据进来</p>
</blockquote>
<p>具体的可以看之前写的demo<br><a href="https://github.com/gujincheng/FlinkStudy/blob/main/src/main/java/com/hzw/bigdata/flinkstudy/WaterMarkDemo.java">WaterMarkDemo</a></p>
<p>当Flink 用来跟踪事件时间进度的水印已经超过了元素所属窗口的结束时间戳时，<br>即数据延迟的时候，默认情况下，数据会丢失，为了防止这种情况可以使用以下两种方式来避免：</p>
<ul>
<li>可以通过设置allowedLateness来避免<blockquote>
<p>当数据晚于Watermark后，为了防止数据丢失，可以通过设置allowedLateness来避免，<br>Allowed lateness 指定元素在被丢弃之前可以延迟多长时间，其默认值为 0。</p>
</blockquote>
</li>
<li>获取延迟数据作为副输出（把延迟的数据放到另外一个流单独处理）<br>具体可以参考<br><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#allowed-lateness">Flink官网-Allowed Lateness</a></li>
</ul>
<h2 id="Flink窗口"><a href="#Flink窗口" class="headerlink" title="Flink窗口"></a>Flink窗口</h2><p>一般真实的数据流都是无界的，但是window可以把无限的数据流切分，得到有限的数据集进行处理<br>window就是将无限流切割为有限流的一种方式，它会将流数据分发到有限大小的桶重进行分析</p>
<p>窗口化的Flink程序的一般结构如下，第一个代码段中是分组的流，而第二段是非分组的流。正如我们所见，唯一的区别是分组的<code>stream</code>调用<code>keyBy(…)</code>和<code>window(…)</code>，而非分组的<code>stream</code>中<code>window()</code>换成了<code>windowAll(…)</code>，这些也将贯穿都这一页的其他部分中。</p>
<h3 id="Keyed-Windows"><a href="#Keyed-Windows" class="headerlink" title="Keyed Windows"></a>Keyed Windows</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">stream
       <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>               <span class="token operator">&lt;</span><span class="token operator">-</span>  keyed versus non<span class="token operator">-</span>keyed windows
       <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>              <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"assigner"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">trigger</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"trigger"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> <span class="token keyword">default</span> trigger<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">evictor</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"evictor"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no evictor<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">allowedLateness</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"lateness"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> zero<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">sideOutputLateData</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no side output <span class="token keyword">for</span> late data<span class="token punctuation">)</span>
       <span class="token punctuation">.</span>reduce<span class="token operator">/</span>aggregate<span class="token operator">/</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"function"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Non-Keyed-Windows"><a href="#Non-Keyed-Windows" class="headerlink" title="Non-Keyed Windows"></a>Non-Keyed Windows</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">stream
       <span class="token punctuation">.</span><span class="token function">windowAll</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>           <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"assigner"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">trigger</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"trigger"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> <span class="token keyword">default</span> trigger<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">evictor</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"evictor"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no evictor<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">allowedLateness</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"lateness"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> zero<span class="token punctuation">)</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">sideOutputLateData</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span> <span class="token punctuation">(</span><span class="token keyword">else</span> no side output <span class="token keyword">for</span> late data<span class="token punctuation">)</span>
       <span class="token punctuation">.</span>reduce<span class="token operator">/</span>aggregate<span class="token operator">/</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  required<span class="token operator">:</span> <span class="token string">"function"</span>
      <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token function">getSideOutput</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>      <span class="token operator">&lt;</span><span class="token operator">-</span>  optional<span class="token operator">:</span> <span class="token string">"output tag"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>方括号[]内的命令是可选的</p>
<h3 id="WindowAssigner"><a href="#WindowAssigner" class="headerlink" title="WindowAssigner"></a>WindowAssigner</h3><p>WindowAssigner是负责将每一个到来的元素分配给一个或者多个窗口(window),Flink 提供了一些常用的预定义窗口分配器，即:滚动窗口、滑动窗口、会话窗口和全局窗口。<br>你也可以通过继承WindowAssigner类来自定义自己的窗口。所有的内置窗口分配器(除了全局窗口 global window)都是通过时间来分配元素到窗口中的，这个时间要么是处理的时间，要么是事件发生的时间</p>
<h3 id="window分类："><a href="#window分类：" class="headerlink" title="window分类："></a>window分类：</h3><ul>
<li>时间窗口（Time Window）<br>  ** 滚动时间窗口<br>  ** 滑动时间窗口<br>  ** 会话窗口</li>
<li>计数窗口（Count Window）<br>  ** 滚动计数窗口<br>  ** 滑动计数窗口<br>窗口是滚动还是滑动，是根据<code>WindowAssigner</code>来区分的<h4 id="滚动窗口（Tumbling-Windows）"><a href="#滚动窗口（Tumbling-Windows）" class="headerlink" title="滚动窗口（Tumbling Windows）"></a>滚动窗口（Tumbling Windows）</h4></li>
<li>将数据依据固定的窗口长度对数据进行切分</li>
<li>时间对其，窗口长度固定，没有重叠         <blockquote>
<p>TumblingEventTimeWindows,这个WindowAssigner必须要结合watermark使用，否则，window不会触发<br>TumblingProcessingTimeWindows，这个WindowAssigner不需要watermark</p>
</blockquote>
<h4 id="滑动窗口（Sliding-Windows）"><a href="#滑动窗口（Sliding-Windows）" class="headerlink" title="滑动窗口（Sliding Windows）"></a>滑动窗口（Sliding Windows）</h4></li>
<li>滑动窗口是固定窗口的更广义的一种形式，滑动窗口由固定的窗口长度和滑动间隔组成</li>
<li>窗口长度固定，可以有重叠</li>
</ul>
<h4 id="会话窗口（Session-Windows）"><a href="#会话窗口（Session-Windows）" class="headerlink" title="会话窗口（Session Windows）"></a>会话窗口（Session Windows）</h4><ul>
<li>由一系列事件组合一个指定时间长度的timeout间隙组成，也就是一段时间没有接收到新数据就会生成新的窗口</li>
<li>特点：时间无对齐</li>
</ul>
<h3 id="window的生命周期"><a href="#window的生命周期" class="headerlink" title="window的生命周期"></a>window的生命周期</h3><p>当第一个应该属于该窗口的元素到达时，就会创建一个窗口，当时间（事件或处理时间）超过其结束时间戳加上用户指定的时间时，该窗口将被完全删除，<br>Flink 确保了只清除基于时间的window，其他类型的window不清除</p>
<p>此外，每个窗口都有一个触发器（请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#triggers">触发器</a>）和一个函数（ProcessWindowFunction、ReduceFunction 或 AggregateFunction）（请参阅<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#window-functions">窗口函数</a>）。<br>该函数将包含要应用于窗口内容的计算，而触发器指定窗口被认为准备好应用该函数的条件。触发策略可能类似于“当窗口中的元素数量超过 4 时”，或“当水印通过窗口末尾时”。<br>触发器还可以决定在创建和删除窗口之间的任何时间清除窗口的内容。在这种情况下，清除仅指窗口中的元素，而不是窗口元数据。这意味着新数据仍然可以添加到该窗口。<br>除了上述之外，您还可以指定一个 Evictor（参见 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#evictors">Evictors</a>），它能够在触发器触发之后和之前从窗口中删除元素</p>
<h3 id="Window-Functions"><a href="#Window-Functions" class="headerlink" title="Window Functions"></a>Window Functions</h3><p>在定义了窗口分配器之后，我们需要指定我们想要在这些窗口中的每一个上执行的计算。这是窗口函数的职责，<br>它用于在系统确定窗口已准备好处理时处理每个（可能是键控的）窗口的元素。窗口函数可以是<code>ReduceFunction</code>、<code>AggregateFunction</code>或<code>ProcessWindowFunction</code>之一。<br>前两个可以更有效地执行（参见<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/#useful-state-size-considerations">状态大小</a>部分），因为 Flink 可以在每个窗口的元素到达时增量聚合它们。<br><code>ProcessWindowFunction</code>获取包含在窗口中的所有元素的<code>Iterable</code>以及有关元素所属窗口的附加元信息。<br>带有<code>ProcessWindowFunction</code>的窗口转换不能像其他情况一样有效地执行，因为 Flink 在调用函数之前必须在内部缓冲窗口的所有元素。<br>这可以通过将 <code>ProcessWindowFunction</code> 与 <code>ReduceFunction</code> 或 <code>AggregateFunction</code> 结合来获得窗口元素的增量聚合和 <code>ProcessWindowFunction</code> 接收的附加窗口元数据来缓解。</p>
<h4 id="ReduceFunction"><a href="#ReduceFunction" class="headerlink" title="ReduceFunction"></a>ReduceFunction</h4><p>ReduceFunction 指定如何组合来自输入的两个元素以生成相同类型的输出元素。 Flink 使用 ReduceFunction 来增量聚合窗口的元素。<br>ReduceFunction 有多种实现方式<br>第一种是直接窗口内聚合，不能对窗口外的数据做聚合，这个是最基本的reduce<br>第二种，先执行窗口内的聚合，然后，可以执行窗口外的，代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> <span class="token function">reduce</span><span class="token punctuation">(</span>
            <span class="token class-name">ReduceFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> reduceFunction<span class="token punctuation">,</span> <span class="token class-name">ProcessWindowFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">,</span> <span class="token class-name">R</span><span class="token punctuation">,</span> <span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">W</span><span class="token punctuation">></span></span> function<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">TypeInformation</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">R</span><span class="token punctuation">></span></span> resultType <span class="token operator">=</span>
                <span class="token function">getProcessWindowFunctionReturnType</span><span class="token punctuation">(</span>function<span class="token punctuation">,</span> input<span class="token punctuation">.</span><span class="token function">getType</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">return</span> <span class="token function">reduce</span><span class="token punctuation">(</span>reduceFunction<span class="token punctuation">,</span> function<span class="token punctuation">,</span> resultType<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ReduceFunction 处理玩的结果，会当成输入写入到ProcessWindowFunction<br>这种适合处理，先用reduce预聚合，然后再通过ProcessWindowFunction整体聚合<br>AggregateFunction同样有这种功能，可能传入ProcessWindowFunction</p>
<h4 id="AggregateFunction"><a href="#AggregateFunction" class="headerlink" title="AggregateFunction"></a>AggregateFunction</h4><p>AggregateFunction 是 ReduceFunction 的通用版本，它具有三种类型：输入类型 (IN)、累加器类型 (ACC) 和输出类型 (OUT)。<br>输入类型是输入流中元素的类型，AggregateFunction 有一种方法可以将一个输入元素添加到累加器中。<br>该接口还具有用于创建初始累加器、将两个累加器合并为一个累加器以及从累加器中提取输出（OUT 类型）的方法。 我们将在下面的示例中看到它是如何工作的。<br>与 ReduceFunction 相同，Flink 将在窗口的输入元素到达时增量地聚合它们。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">/**
 * The accumulator is used to keep a running sum and a count. The &#123;@code getResult&#125; method
 * computes the average.
 */</span>
<span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">AverageAggregate</span>
    <span class="token keyword">implements</span> <span class="token class-name">AggregateFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Double</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>
  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> <span class="token function">createAccumulator</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> accumulator<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>accumulator<span class="token punctuation">.</span>f0 <span class="token operator">+</span> value<span class="token punctuation">.</span>f1<span class="token punctuation">,</span> accumulator<span class="token punctuation">.</span>f1 <span class="token operator">+</span> <span class="token number">1L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Double</span> <span class="token function">getResult</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> accumulator<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span> accumulator<span class="token punctuation">.</span>f0<span class="token punctuation">)</span> <span class="token operator">/</span> accumulator<span class="token punctuation">.</span>f1<span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> <span class="token function">merge</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> a<span class="token punctuation">,</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Long</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> b<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>f0 <span class="token operator">+</span> b<span class="token punctuation">.</span>f0<span class="token punctuation">,</span> a<span class="token punctuation">.</span>f1 <span class="token operator">+</span> b<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

input
    <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>key selector<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>window assigner<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">AverageAggregate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>上面的示例计算窗口中元素的第二个字段的平均值。</p>
<h4 id="ProcessWindowFunction"><a href="#ProcessWindowFunction" class="headerlink" title="ProcessWindowFunction"></a>ProcessWindowFunction</h4><p>ProcessWindowFunction 获得一个包含窗口所有元素的 Iterable 和一个可以访问时间和状态信息的 Context 对象，这使其能够提供比其他窗口函数更大的灵活性。<br>这是以性能和资源消耗为代价的，因为元素不能增量聚合，而是需要在内部缓冲，直到窗口被认为准备好进行处理。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

input
  <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>t <span class="token operator">-></span> t<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingEventTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">minutes</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token function">process</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyProcessWindowFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">/* ... */</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyProcessWindowFunction</span> 
    <span class="token keyword">extends</span> <span class="token class-name">ProcessWindowFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">TimeWindow</span><span class="token punctuation">></span></span> <span class="token punctuation">&#123;</span>

  <span class="token annotation punctuation">@Override</span>
  <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span><span class="token class-name">String</span> key<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">long</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span></span> in<span class="token operator">:</span> input<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      count<span class="token operator">++</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token string">"Window: "</span> <span class="token operator">+</span> context<span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"count: "</span> <span class="token operator">+</span> count<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>该示例显示了一个 ProcessWindowFunction，它对窗口中的元素进行计数。此外，窗口函数将有关窗口的信息添加到输出中。</p>
<blockquote>
<p>请注意，将 ProcessWindowFunction 用于简单的聚合（例如 count）是非常低效的<br>增量窗口聚合使用 AggregateFunction 或者 ReduceFunction同样可以达到相同的想过，并且，效率很高</p>
</blockquote>
<h4 id="WindowFunction-Legacy-：apply"><a href="#WindowFunction-Legacy-：apply" class="headerlink" title="WindowFunction (Legacy)：apply"></a>WindowFunction (Legacy)：apply</h4><p>在某些可以使用 ProcessWindowFunction 的地方，您也可以使用 WindowFunction。这是 ProcessWindowFunction 的旧版本，提供较少的上下文信息并且没有一些高级功能，例如每个窗口的键控状态。<br>此接口将在某些时候被弃用。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span> input <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>

input
    <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>key selector<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token generics"><span class="token punctuation">&lt;</span>window assigner<span class="token punctuation">></span></span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MyWindowFunction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="在-ProcessWindowFunction-中使用每个窗口状态"><a href="#在-ProcessWindowFunction-中使用每个窗口状态" class="headerlink" title="在 ProcessWindowFunction 中使用每个窗口状态"></a>在 ProcessWindowFunction 中使用每个窗口状态</h4><p>除了访问键控状态之外，ProcessWindowFunction 还可以使用键控状态，该键控状态的范围限定为函数当前正在处理的窗口。 在这种情况下，了解每个窗口状态所指的窗口是什么很重要。 涉及不同的“窗口”：</p>
<blockquote>
<p>这地方没看懂</p>
</blockquote>
<p>flink window相关内容，具体可以参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/windows/">Flink Window</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop集群扩容</title>
    <url>/2022/03/08/Hadoop%E9%9B%86%E7%BE%A4%E6%89%A9%E5%AE%B9/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hadoop集群扩容</li>
</ul>
<a id="more"></a>

<h2 id="Hadoop集群扩容"><a href="#Hadoop集群扩容" class="headerlink" title="Hadoop集群扩容"></a>Hadoop集群扩容</h2>]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Java杂记</title>
    <url>/2021/08/18/Java%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Java范型</li>
</ul>
<a id="more"></a>

<h2 id="Java范型"><a href="#Java范型" class="headerlink" title="Java范型"></a>Java范型</h2><h3 id="什么是范型？"><a href="#什么是范型？" class="headerlink" title="什么是范型？"></a>什么是范型？</h3><p>泛型（generic）是指参数化类型的能力。可以定义带泛型类型的类或方法，随后编译器会用具体的类型来代替它。</p>
<h3 id="为什么要用范型？"><a href="#为什么要用范型？" class="headerlink" title="为什么要用范型？"></a>为什么要用范型？</h3><p>Java语言引入泛型的好处是安全简单。泛型的好处是在编译的时候检查类型安全，并且所有的强制转换都是自动和隐式的，提高代码的重用率。</p>
<ul>
<li>类型安全。 泛型的主要目标是提高 Java 程序的类型安全。通过知道使用泛型定义的变量的类型限制，编译器可以在一个高得多的程度上验证类型假设。没有泛型，这些假设就只存在于程序员的头脑中（或者如果幸运的话，还存在于代码注释中）。</li>
<li>消除强制类型转换。泛型的一个附带好处是，消除源代码中的许多强制类型转换。这使得代码更加可读，并且减少了出错机会。</li>
<li>潜在的性能收益。 泛型为较大的优化带来可能。在泛型的初始实现中，编译器将强制类型转换（没有泛型的话，程序员会指定这些强制类型转换）插入生成的字节码中。但是更多类型信息可用于编译器这一事实，为未来版本的 JVM 的优化带来可能。由于泛型的实现方式，支持泛型（几乎）不需要 JVM 或类文件更改。所有工作都在编译器中完成，编译器生成类似于没有泛型（和强制类型转换）时所写的代码，只是更能确保类型安全而已。</li>
</ul>
<p>注意：<br>Point<T>,这个T表示派生自Object类的任何类，但是使用哪个字母是没有特定意义的！只是为了提高可读性！！！！</p>
<p>遇到一个静态方法，使用如下范型：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">static</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token class-name">WatermarkStrategy</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">T</span><span class="token punctuation">></span></span> <span class="token function">forBoundedOutOfOrderness</span><span class="token punctuation">(</span><span class="token class-name">Duration</span> maxOutOfOrderness<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>ctx<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token keyword">new</span> <span class="token class-name">BoundedOutOfOrdernessWatermarks</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>maxOutOfOrderness<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这个方法的返回值是<code>WatermarkStrategy&lt;T&gt;</code>,前面那个T，不知道是什么意思，在用的时候，使用如下方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">stream<span class="token punctuation">.</span><span class="token function">assignTimestampsAndWatermarks</span><span class="token punctuation">(</span><span class="token class-name">WatermarkStrategy</span>
                <span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token function">forBoundedOutOfOrderness</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withIdleness</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">withTimestampAssigner</span><span class="token punctuation">(</span><span class="token punctuation">(</span>event<span class="token punctuation">,</span>timestamp<span class="token punctuation">)</span> <span class="token operator">-></span> event<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>x <span class="token operator">-></span> x<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingEventTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">apply</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">WindowFunctionTest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><code>WatermarkStrategy.&lt;Tuple2&lt;String, Long&gt;&gt;</code>：因为这个方法是静态方法，所以可以直接类名.方法，后面的<code>.&lt;Tuple2&lt;String, Long&gt;&gt;</code>就是方法里前面那个<T></p>
<h2 id="Java的多态"><a href="#Java的多态" class="headerlink" title="Java的多态"></a>Java的多态</h2><p>多态是指，针对某个类型的方法调用，其真正执行的方法取决于运行时期实际类型的方法<br>多态体现为父类引用变量可以指向子类对象。<br>前提条件：必须有子父类关系。</p>
<blockquote>
<p>注意：在使用多态后的父类引用变量调用方法时，会调用子类重写后的方法。</p>
</blockquote>
<ul>
<li><p>多态的定义与使用格式<br>  定义格式：父类类型 变量名=new 子类类型();</p>
</li>
<li><p>多态是同一个行为具有多个不同表现形式或形态的能力。多态就是同一个接口，使用不同的实例而执行不同操作。</p>
</li>
<li><p>多态成员变量：编译运行看左边</p>
</li>
<li><p>多态成员方法：编译看左边，运行看右边</p>
<h3 id="多态的转型"><a href="#多态的转型" class="headerlink" title="多态的转型"></a>多态的转型</h3><p>多态的转型分为向上转型和向下转型两种<br>向上转型：多态本身就是向上转型过的过程<br>使用格式：父类类型 变量名=new 子类类型();<br>适用场景：当不需要面对子类类型时，通过提高扩展性，或者使用父类的功能就能完成相应的操作。  </p>
</li>
</ul>
<p>向下转型：一个已经向上转型的子类对象可以使用强制类型转换的格式，将父类引用类型转为子类引用各类型<br>使用格式：子类类型 变量名=（子类类型） 父类类型的变量；<br>适用场景：当要使用子类特有功能时。  </p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Main</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 给一个有普通收入、工资收入和享受国务院特殊津贴的小伙伴算税:</span>
        <span class="token class-name">Income</span><span class="token punctuation">[</span><span class="token punctuation">]</span> incomes <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Income</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">new</span> <span class="token class-name">Income</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token keyword">new</span> <span class="token class-name">Salary</span><span class="token punctuation">(</span><span class="token number">7500</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token keyword">new</span> <span class="token class-name">StateCouncilSpecialAllowance</span><span class="token punctuation">(</span><span class="token number">15000</span><span class="token punctuation">)</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token function">totalTax</span><span class="token punctuation">(</span>incomes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">double</span> <span class="token function">totalTax</span><span class="token punctuation">(</span><span class="token class-name">Income</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> incomes<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">double</span> total <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Income</span> income<span class="token operator">:</span> incomes<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            total <span class="token operator">=</span> total <span class="token operator">+</span> income<span class="token punctuation">.</span><span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token keyword">return</span> total<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> <span class="token class-name">Income</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">protected</span> <span class="token keyword">double</span> income<span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token class-name">Income</span><span class="token punctuation">(</span><span class="token keyword">double</span> income<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">this</span><span class="token punctuation">.</span>income <span class="token operator">=</span> income<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> income <span class="token operator">*</span> <span class="token number">0.1</span><span class="token punctuation">;</span> <span class="token comment">// 税率10%</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> <span class="token class-name">Salary</span> <span class="token keyword">extends</span> <span class="token class-name">Income</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token class-name">Salary</span><span class="token punctuation">(</span><span class="token keyword">double</span> income<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>income<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>income <span class="token operator">&lt;=</span> <span class="token number">5000</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>income <span class="token operator">-</span> <span class="token number">5000</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.2</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span class="token keyword">class</span> <span class="token class-name">StateCouncilSpecialAllowance</span> <span class="token keyword">extends</span> <span class="token class-name">Income</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token class-name">StateCouncilSpecialAllowance</span><span class="token punctuation">(</span><span class="token keyword">double</span> income<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>income<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">double</span> <span class="token function">getTax</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>样例2：     </p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Test</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">testDuo</span><span class="token punctuation">(</span><span class="token class-name">Test1</span> t<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"aa"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">Test2</span> t1 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Test2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        t1<span class="token punctuation">.</span><span class="token function">test</span><span class="token punctuation">(</span><span class="token string">"bb"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">testDuo</span><span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
    <span class="token keyword">public</span> <span class="token keyword">interface</span> <span class="token class-name">Test1</span><span class="token punctuation">&#123;</span>

    <span class="token punctuation">&#125;</span>
   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Test2</span> <span class="token keyword">implements</span> <span class="token class-name">Test1</span><span class="token punctuation">&#123;</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token class-name">String</span> str<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这样做的好处是：</p>
<ol>
<li>消除类型之间的耦合关系</li>
<li>可替换性</li>
<li>可扩充性</li>
<li>接口性</li>
<li>灵活性</li>
<li>简化性</li>
</ol>
<h2 id="抽象类与接口"><a href="#抽象类与接口" class="headerlink" title="抽象类与接口"></a>抽象类与接口</h2><h3 id="抽象类"><a href="#抽象类" class="headerlink" title="抽象类"></a>抽象类</h3><p>在Java中被abstract关键字修饰的类称为抽象类，被abstract关键字修饰的方法称为抽象方法，抽象方法只有方法的声明，没有方法体。抽象类的特点：</p>
<ol>
<li>抽象类不能被实例化只能被继承；<br> 1.1 抽象类不能被实例化，所以抽象类必须被继承，才能被使用<br> 1.2 抽象类可以和类一样，实现接口，但抽象类<font color=#FF0000 >不需要实现接口下的所有方法</font><br> 1.3 抽象类被子类继承以后，就会强迫子类充血抽象类中定义的抽象方法，除非子类也是抽象类</li>
<li>包含抽象方法的一定是抽象类，但是抽象类不一定含有抽象方法</li>
<li>抽象类中的抽象方法的修饰符只能是public或者protected，默认为default</li>
<li>抽象类可以包含属性、方法、构造方法，但是构造方法不能用于实例化，并且子类实例化以后，<font color=#FF0000 >抽象类的构造方法一定会被调用</font></li>
</ol>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>Java中接口用interface关键字修饰，特点为:</p>
<ol>
<li>接口可以包含变量、方法；变量被隐式的指定为 public stastic final，方法被隐式指定为public abstract</li>
<li>接口支持多继承，即一个接口可以extends多个接口，间接的解决了java中类的单继承问题</li>
<li>一个类可以实现多个接口</li>
<li>JDK1.8中对接口增加了新的特性：<br> 4.1 默认方法（default method）：JDK 1.8允许给接口添加非抽象的方法实现，但必须使用default关键字修饰；定义了default的方法可以不被实现子类所实现，但只能被实现子类的对象调用；如果子类实现了多个接口，并且这些接口包含一样的默认方法，则子类必须重写默认方法；<br> 4.2 静态方法（static method）：JDK 1.8中允许使用static关键字修饰一个方法，<font color=#FF0000 >并可以提供实现</font>，称为接口静态方法。接口静态方法只能通过接口调用（接口名.静态方法名）。</li>
</ol>
<blockquote>
<p>总结：继承是一个 “是不是”的关系，而 接口 实现则是 “有没有”的关系。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系，比如狗是否能钻火圈，能则可以实现这个接口，不能就不实现这个接口。</p>
</blockquote>
<h2 id="Java常用的设计模式"><a href="#Java常用的设计模式" class="headerlink" title="Java常用的设计模式"></a>Java常用的设计模式</h2><h3 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h3><p><strong>解决了什么痛点或有什么好处?</strong><br>保证在Java应用程序中，一个类Class只有一个实例存在。 使用单例模式的好处还在于可以节省内存，因为它限制了实例的个数，有利于Java垃圾回收</p>
<p><strong>什么情况下使用单例模式?</strong><br>第一、控制资源的使用，通过线程同步来控制资源的并发访问；<br>第二、控制实例产生的数量，达到节约资源的目的。<br>第三、作为通信媒介使用，也就是数据共享，它可以在不建立直接关联的条件下，让多个不相关的两个线程或者进程之间实现通信。<br>比如，数据库连接池的设计一般采用单例模式，数据库连接是一种数据库资源  </p>
<h3 id="策略模式"><a href="#策略模式" class="headerlink" title="策略模式"></a>策略模式</h3><p><strong>解决了什么痛点或有什么好处?</strong></p>
<p><strong>什么情况下使用策略模式?</strong></p>
<h3 id="工厂模式"><a href="#工厂模式" class="headerlink" title="工厂模式"></a>工厂模式</h3><p>mysql的jdbc<br><strong>解决了什么痛点或有什么好处?</strong></p>
<blockquote>
<p>好处<br>将创建实例的工作与使用实例的工作分开，使用者不必关心类对象如何创建，明确了职责。<br>把初始化实例时的工作放到工厂里进行，使代码更容易维护。 更符合面向对象的原则，面向接口编程，而不是面向实现编程。</p>
</blockquote>
<blockquote>
<p>缺点：<br>由于工厂类集中了所有产品创建逻辑，一旦不能正常工作，整个系统都要受到影响。<br>要新增产品类的时候，就要修改工厂类的代码，违反了开放封闭原则(对扩展的开放，对修改的关闭)。<br>简单工厂模式由于使用了静态工厂方法，静态方法不能被继承和重写，会造成工厂角色无法形成基于继承的等级结构。</p>
</blockquote>
<p><strong>什么情况下使用工厂模式?</strong> </p>
<h3 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h3><p>kafka的发布订阅，其实就类似于这种观察者模式<br><strong>解决了什么痛点或有什么好处?</strong></p>
<p><strong>什么情况下使用观察者模式?</strong> </p>
<h2 id="JVM知识点总结"><a href="#JVM知识点总结" class="headerlink" title="JVM知识点总结"></a>JVM知识点总结</h2><p>栈解决程序的运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储的问题，即数据怎么放、放在哪儿。<br>堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用。<br>一个对象的大小是不可估计的，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4btye的引用（堆栈分离的好处：））</p>
<h3 id="JVM调优"><a href="#JVM调优" class="headerlink" title="JVM调优"></a>JVM调优</h3>]]></content>
      <categories>
        <category>大数据</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Iceberg学习笔记</title>
    <url>/2021/08/27/Iceberg%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Iceberg简介</li>
<li>Iceberg架构</li>
<li>Iceberg简单使用案例</li>
<li>Iceberg压力测试<a id="more"></a>

</li>
</ul>
<h2 id="Iceberg简介："><a href="#Iceberg简介：" class="headerlink" title="Iceberg简介："></a>Iceberg简介：</h2><p>pache Iceberg 是一种用于大型分析数据集的开放表格式。 Iceberg 使用类似于 SQL 表的高性能表格式向包括 Spark、Trino、PrestoDB、Flink 和 Hive 在内的计算引擎添加表。<br>从这个定义上来看，Iceberg是一个用于海量数据分析场景下的开源的表格式（其实笔者更愿意用Table Format），也就是说Iceberg本质上是一个表格式。</p>
<h3 id="那什么是表格式？表格式和我们熟悉的文件格式（File-Format）是一回事吗？"><a href="#那什么是表格式？表格式和我们熟悉的文件格式（File-Format）是一回事吗？" class="headerlink" title="那什么是表格式？表格式和我们熟悉的文件格式（File Format）是一回事吗？"></a>那什么是表格式？表格式和我们熟悉的文件格式（File Format）是一回事吗？</h3><p>表和表格式是两个概念。表是一个具象的概念，应用层面的概念，我们天天说的表是简单的行和列的组合。而表格式是数据库系统实现层面一个抽象的概念，它定义了一个表中包含哪些字段，表下面文件的组织形式、表索引信息、统计信息以及上层查询引擎读取、写入表中文件的接口<br>可以参考<a href="https://blog.csdn.net/qq_31866793/article/details/115505649">Apache Iceberg 数据湖从入门到放弃(1) —— 初步入门三部曲</a></p>
<p>我们可以简单理解为他是基于计算层（flink、spark）和存储层（orc、parqurt）的一个中间层，我们可以把它定义成一种“数据组织格式”，Iceberg将其称之为“表格式”也是表达类似的含义。<br>他与底层的存储格式（比如ORC、Parquet之类的列式存储格式）最大的区别是，它并不定义数据存储方式，而是定义了数据、元数据的组织方式，向上提供统一的“表”的语义。<br>它构建在数据存储格式之上，其底层的数据存储仍然使用Parquet、ORC等进行存储。在hive建立一个iceberg格式的表。用flink或者spark写入iceberg，然后再通过其他方式来读取这个表，<br>比如spark、flink、presto等。</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul>
<li>增量读取处理能力：Iceberg支持通过流式方式读取增量数据，支持Structed Streaming以及Flink table Source；</li>
<li>支持事务（ACID），上游数据写入即可见，不影响当前数据处理任务，简化ETL；提供upsert和merge into能力，可以极大地缩小数据入库延迟；</li>
<li>可扩展的元数据，快照隔离以及对于文件列表的所有修改都是原子操作；</li>
<li>同时支持流批处理、支持多种存储格式和灵活的文件组织：提供了基于流式的增量计算模型和基于批处理的全量表计算模型。批处理和流任务可以使用相同的存储模型，数据不再孤立；Iceberg支持隐藏分区和分区进化，方便业务进行数据分区策略更新。支持Parquet、Avro以及ORC等存储格式。</li>
<li>支持多种计算引擎，优秀的内核抽象使之不绑定特定的计算引擎，目前Iceberg支持的计算引擎有Spark、Flink、Presto以及Hive。</li>
</ul>
<p>与其他数据湖产品对比：<br><img src="/uploads/20210520/Iceberg%E4%B8%8E%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E7%B3%8A%E7%BB%84%E4%BB%B6%E5%AF%B9%E6%AF%94.png" alt="Iceberg与其他数据糊组件对比"></p>
<h2 id="Iceberg架构"><a href="#Iceberg架构" class="headerlink" title="Iceberg架构"></a>Iceberg架构</h2><p>Iceberg只是一个table format，不存在架构方面</p>
<h3 id="Iceberg写数据流程"><a href="#Iceberg写数据流程" class="headerlink" title="Iceberg写数据流程"></a>Iceberg写数据流程</h3><p>Iceberg写入流程及文件结构：Iceberg在数据写入的时候，<br>① 先把数据写入到data file文件中；<br>② 当一组data file文件写完之后，会根据这个data file文件中column的一些统计信息（如:每个column的min/max值），生成一个对应的manifest文件；<br>③ 然后Iceberg把一次写入后涉及到的manifest文件组成一个 manifest list， manifest list文件中也会存入一些相关manifest的统计信息（如：分区信息，manifest有效性）等；<br>④ 然后按照整个manifest list 生成一个对应的snapshot文件；<br>⑤ 生成完snapshot文件之后，Iceberg会把当前snapshot的ID及存储路径等信息写入到metadata文件中；<br>⑥ 当一切准备完毕之后，会以原子操作的方式commit这个metadata文件，这样一次iceberg的数据写入就完成了。随着每次的写入iceberg就生成了如下图这样的一个文件组织模式。<br><img src="/uploads/20210520/iceberg-metadata.png" alt="Icreberg文件组织模式"></p>
<h3 id="Iceberg读数据流程"><a href="#Iceberg读数据流程" class="headerlink" title="Iceberg读数据流程"></a>Iceberg读数据流程</h3><p>Iceberg的分区查找优化：<br>Iceberg数据表每一次的修改后的状态都会生成一个snapshot（s0,s1）文件，snapshot文件中包含了一个manifest文件的list，<br>list中存储了当前的snapshot状态是由哪些manifest文件组成的。每一个manifest的文件中会指向到真实数据的存储文件 data file（一般是parquet格式）。<br>在这种结构中，每一个快照读取所需要的数据文件都已经清晰的定义在了manifest list 和 manifest的文件中，<br>并且manifest文件中还存储了相关的partition信息，那么在读取数据的时候如果需要删选partition，<br>通过manifest的中存储的信息以K&amp;V映射方式在O(1)复杂度的计算中就能定位到需要读取的partition目录。<br>当前常用的数据读取引擎，例如hive需要遍历整个数据目录下的文件索引来寻找必要的partition，是一个O(n)的复杂度查找过程。<br>在大数据常见的海量分区下，采用partition映射的模式来选取目录的优化效果是非常明显的，<br>可以在Ryan Blue的讲座中看到在NetFlix的应用场景中2600个分区只需要10S就列出了，<br>而使用hive大概10分钟还没有完成 。</p>
<p>Iceberg谓词下推的三层过滤：<br>① 分区过滤：Iceberg支持查询中的谓词下推，前面已经说了Iceberg是支持隐式分区的，就是说在读取数据的时候不需要在SQL中指定分区。<br> Iceberg会接收上层计算引擎下推过来的谓词表达式，根据谓词表达式中column分区列的信息进行分区转换的计算。<br> 例如 一个Iceberg表有一列 time ，用户设定了在 time 列上按照小时分区，当查询条件为   time &gt;= 2020-01-01 10：00 AND &lt; 2020-01-01 13:00 的时候Iceberg会根据下推过来的谓词表达式和Schema中定义的分区转换表达式进行计算。<br> 直接算出数据分区是在 10点11点12点三个分区中，然后依据manifest中的分区字段直接定位到分区目录。<br>② 文件过滤：Iceberg会把谓词继续下推到更细的筛选粒度，根据谓词的表达式和manifest中column的min/max值Iceberg可以有效的过滤查询数据所覆盖的具体data file，<br>对扫描集做进一步的筛选，如果筛选column是有序的那么下推效果将更加明显。<br>③ RowGroup过滤：经过分区过滤和文件过滤之后Iceberg还会继续把谓词表达式下推到data file文件内部的RowGroup级别，<br>根据parquet文件的metadata信息对RowGroup做进一步的筛选。经过以上三层的筛选，Iceberg最终把数据的扫描集缩小到必须读取的RowGroup级别，<br>然后把需要读取的RowGroup数据读入到内存之中。<br>（同样在Ryan Blue的讲座中我们可以看到，通过层层筛选(命中 min/max)之后，iceberg使得数据计算任务从61小时降低到了22分钟）。</p>
<p>Iceberg的向量化读取和数据的zero copy：在低版本的spark中，由于spark DataSourceV2的API不支持批量读取，<br>因此Iceberg通过for循环把筛选后的数据一行一行的返回给spark去处理这个过程中既需要数据不断的在内存中互相拷贝，<br>也无法发挥列式数据在现代CPU架构中的向量化处理能力。为了进一步提升读取速度，Iceberg在spark2.4.4版本之后，<br>利用spark BatchColumn的读取特性引入了向量化读取的能力。<br> ① 经过谓词下推后，Iceberg把需要的RowGroup数据读入到了内存中。RowGroup是列式组织的，具有可向量化处理的优势；<br> ② Iceberg会根据SQL语句的project来删减需要读取的 column trunk；<br> ③ 然后Iceberg借助Arrow插件作为共享内存，以page + Batch size 为单位一次性的把一个批次大小的数据存入到共享内存中；<br> ④ 当数据存储完之后把共享内存地址返回给spark，spark拿到共享内存地址之后，可以不再进行数据拷贝直接通过偏移量来访问Arrow获取数据。</p>
<p>可以参考<a href="https://www.codercto.com/a/106417.html">Apache Iceberg 对推荐应用架构的优化及读写流程解析</a></p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ul>
<li>Iceberg数据更新的时候貌似不是实时更新的，而是准实时更新的，而且，每次更新，都会生成文件，这就导致，如果频繁更新，那么HDFS上的小文件可能会比较多，这里可以测试一下</li>
<li><h2 id="Iceberg简单使用案例"><a href="#Iceberg简单使用案例" class="headerlink" title="Iceberg简单使用案例"></a>Iceberg简单使用案例</h2></li>
</ul>
<h2 id="Iceberg压力测试"><a href="#Iceberg压力测试" class="headerlink" title="Iceberg压力测试"></a>Iceberg压力测试</h2>]]></content>
      <categories>
        <category>大数据</category>
        <category>Iceberg</category>
      </categories>
      <tags>
        <tag>Iceberg</tag>
      </tags>
  </entry>
  <entry>
    <title>Java面试题</title>
    <url>/2021/11/18/Java%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Java面试题总结</li>
</ul>
<a id="more"></a>


<h2 id="Java基础面试题"><a href="#Java基础面试题" class="headerlink" title="Java基础面试题"></a>Java基础面试题</h2><p><strong><font size = 5>1. 抽象类和接口的区别？</font></strong><br><strong>相同点:</strong>  </p>
<ol>
<li>都位于继承的顶端,用于被其他类实现或继承;  </li>
<li>都不能直接实例化对象;  </li>
<li>都可以包含抽象方法,其子类都必须覆写这些抽象方法;  </li>
</ol>
<p><strong>区别:</strong>  </p>
<ol>
<li>抽象类为部分方法提供实现,避免子类重复实现这些方法,提高代码重用性;接口只能包含抽象方法,java1.8以后也有default修饰的方法，还有stastic的方法可以有方法体;  </li>
<li>一个类只能继承一个直接父类(可能是抽象类),却可以实现多个接口;(接口弥补了Java的单继承)  </li>
<li>抽象类是这个事物中应该具备的内容, 继承体系是一种 is..a关系  </li>
<li>接口是这个事物中的额外内容,继承体系是一种 like..a关系  </li>
</ol>
<h2 id="常见JVM面试题及答案整理"><a href="#常见JVM面试题及答案整理" class="headerlink" title="常见JVM面试题及答案整理"></a>常见JVM面试题及答案整理</h2><p><strong><font size = 5>1. 什么情况下会发生栈内存溢出？</font></strong><br>栈是线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口等信息。局部变量表又包含基本数据类型，对象引用类型<br>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常，方法递归调用产生这种结果。<br>如果Java虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是无法申请到足够的内存去完成扩展，或者在新建立线程的时候没有足够的内存去创建对应的虚拟机栈，那么Java虚拟机将抛出一个OutOfMemory 异常。(线程启动过多)<br>参数 -Xss 去调整JVM栈的大小</p>
<p>可以参考<a href="https://blog.csdn.net/qq_41701956/article/details/100074023">常见JVM面试题及答案整理</a></p>
<p><strong><font size = 5>2. 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。</font></strong><br>1）几种垃圾收集器：</p>
<ul>
<li>Serial收集器： 单线程的收集器，收集垃圾时，必须stop the world，使用复制算法。</li>
<li>ParNew收集器： Serial收集器的多线程版本，也需要stop the world，复制算法。</li>
<li>Parallel Scavenge收集器： 新生代收集器，复制算法的收集器，并发的多线程收集器，目标是达到一个可控的吞吐量。如果虚拟机总共运行100分钟，其中垃圾花掉1分钟，吞吐量就是99%。</li>
<li>Serial Old收集器： 是Serial收集器的老年代版本，单线程收集器，使用标记整理算法。</li>
<li>Parallel Old收集器： 是Parallel Scavenge收集器的老年代版本，使用多线程，标记-整理算法。</li>
<li>CMS(Concurrent Mark Sweep) 收集器： 是一种以获得最短回收停顿时间为目标的收集器，标记清除算法，运作过程：初始标记，并发标记，重新标记，并发清除，收集结束会产生大量空间碎片。</li>
<li>G1收集器： 标记整理算法实现，运作流程主要包括以下：初始标记，并发标记，最终标记，筛选标记。不会产生空间碎片，可以精确地控制停顿。<br>2）CMS收集器和G1收集器的区别：</li>
<li>CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用；</li>
<li>G1收集器收集范围是老年代和新生代，不需要结合其他收集器使用；</li>
<li>CMS收集器以最小的停顿时间为目标的收集器；</li>
<li>G1收集器可预测垃圾回收的停顿时间</li>
<li>CMS收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片</li>
<li>G1收集器使用的是“标记-整理”算法，进行了空间整合，降低了内存空间碎片。 </li>
</ul>
]]></content>
      <categories>
        <category>面试题</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac使用笔记（一）</title>
    <url>/2021/05/20/Mac%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>安装并配置<code>oh my zsh</code></li>
<li>安装并配置java</li>
<li>mac环境下Sublime使用技巧</li>
<li>Mac常用快捷键</li>
</ul>
<a id="more"></a>

<p>最近新买了MacBook，但是刚从Windows切换到Mac OS系统感觉很不适应，记录一下适应的过程</p>
<h2 id="Mac下必备软件"><a href="#Mac下必备软件" class="headerlink" title="Mac下必备软件"></a>Mac下必备软件</h2><ul>
<li>the unarchiver: 无感解压</li>
<li>有道云笔记</li>
<li>IDEA</li>
<li>大数据相关软件</li>
<li>Iterm2  &amp;&amp; oh my zsh</li>
<li>sublime</li>
<li>百度云网盘</li>
<li>Snipaste：截图神器</li>
</ul>
<h2 id="安装并配置oh-my-zsh"><a href="#安装并配置oh-my-zsh" class="headerlink" title="安装并配置oh my zsh"></a>安装并配置<code>oh my zsh</code></h2><p>Mac自带的终端界面体验实在不敢恭维。这里记录一下安装<code>oh my zsh</code>的过程</p>
<ul>
<li>首先确保当前shell是zsh，如果不是，使用<code>chsh -s /bin/zsh</code></li>
<li>用自己的git fork一下<code>ohmyzsh/ohmyzsh</code>,然后从自己的git仓库clone下来，这样快一点<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">## clone程序
git clone git@github.com:gujincheng&#x2F;ohmyzsh.git ~&#x2F;.oh-my-zsh
## 编辑.zshrc
cp ~&#x2F;.oh-my-zsh&#x2F;templates ~&#x2F;.zshrc
## 修改主题为arrow
ZSH_THEME&#x3D;&quot;arrow&quot;
## 安装常用插件
plugins&#x3D;(git zsh-autosuggestions zsh-syntax-highlighting)
## 安装插件的时候，可以把插件fork到自己的git上，然后从自己的git上clone到~&#x2F;.oh-my-zsh&#x2F;custom&#x2F;plugins
&#96;&#96;&#96;  
* .zshrc完整配置：
&#96;&#96;&#96;shell 
# If you come from bash you might have to change your $PATH.
# export PATH&#x3D;$HOME&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;bin:$PATH

# Path to your oh-my-zsh installation.
export ZSH&#x3D;$HOME&#x2F;.oh-my-zsh

# Set name of the theme to load --- if set to &quot;random&quot;, it will
# load a random theme each time oh-my-zsh is loaded, in which case,
# to know which specific one was loaded, run: echo $RANDOM_THEME
# See https:&#x2F;&#x2F;github.com&#x2F;ohmyzsh&#x2F;ohmyzsh&#x2F;wiki&#x2F;Themes
#ZSH_THEME&#x3D;&quot;robbyrussell&quot;
#ZSH_THEME&#x3D;&quot;essembeh&quot;
ZSH_THEME&#x3D;&quot;arrow&quot;
# Set list of themes to pick from when loading at random
# Setting this variable when ZSH_THEME&#x3D;random will cause zsh to load
# a theme from this variable instead of looking in $ZSH&#x2F;themes&#x2F;
# If set to an empty array, this variable will have no effect.
#ZSH_THEME_RANDOM_CANDIDATES&#x3D;( &quot;robbyrussell&quot; &quot;agnoster&quot; )

# Uncomment the following line to use case-sensitive completion.
# CASE_SENSITIVE&#x3D;&quot;true&quot;

# Uncomment the following line to use hyphen-insensitive completion.
# Case-sensitive completion must be off. _ and - will be interchangeable.
# HYPHEN_INSENSITIVE&#x3D;&quot;true&quot;

# Uncomment the following line to disable bi-weekly auto-update checks.
# DISABLE_AUTO_UPDATE&#x3D;&quot;true&quot;

# Uncomment the following line to automatically update without prompting.
# DISABLE_UPDATE_PROMPT&#x3D;&quot;true&quot;

# Uncomment the following line to change how often to auto-update (in days).
# export UPDATE_ZSH_DAYS&#x3D;13

# Uncomment the following line if pasting URLs and other text is messed up.
# DISABLE_MAGIC_FUNCTIONS&#x3D;&quot;true&quot;

# Uncomment the following line to disable colors in ls.
# DISABLE_LS_COLORS&#x3D;&quot;true&quot;

# Uncomment the following line to disable auto-setting terminal title.
# DISABLE_AUTO_TITLE&#x3D;&quot;true&quot;

# Uncomment the following line to enable command auto-correction.
# ENABLE_CORRECTION&#x3D;&quot;true&quot;

# Uncomment the following line to display red dots whilst waiting for completion.
# Caution: this setting can cause issues with multiline prompts (zsh 5.7.1 and newer seem to work)
# See https:&#x2F;&#x2F;github.com&#x2F;ohmyzsh&#x2F;ohmyzsh&#x2F;issues&#x2F;5765
# COMPLETION_WAITING_DOTS&#x3D;&quot;true&quot;

# Uncomment the following line if you want to disable marking untracked files
# under VCS as dirty. This makes repository status check for large repositories
# much, much faster.
# DISABLE_UNTRACKED_FILES_DIRTY&#x3D;&quot;true&quot;

# Uncomment the following line if you want to change the command execution time
# stamp shown in the history command output.
# You can set one of the optional three formats:
# &quot;mm&#x2F;dd&#x2F;yyyy&quot;|&quot;dd.mm.yyyy&quot;|&quot;yyyy-mm-dd&quot;
# or set a custom format using the strftime function format specifications,
# see &#39;man strftime&#39; for details.
# HIST_STAMPS&#x3D;&quot;mm&#x2F;dd&#x2F;yyyy&quot;

# Would you like to use another custom folder than $ZSH&#x2F;custom?
# ZSH_CUSTOM&#x3D;&#x2F;path&#x2F;to&#x2F;new-custom-folder

# Which plugins would you like to load?
# Standard plugins can be found in $ZSH&#x2F;plugins&#x2F;
# Custom plugins may be added to $ZSH_CUSTOM&#x2F;plugins&#x2F;
# Example format: plugins&#x3D;(rails git textmate ruby lighthouse)
# Add wisely, as too many plugins slow down shell startup.
plugins&#x3D;(git zsh-autosuggestions zsh-syntax-highlighting)

source $ZSH&#x2F;oh-my-zsh.sh

# User configuration

# export MANPATH&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;man:$MANPATH&quot;
#JAVA_HOME&#x3D;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_291.jdk&#x2F;Contents&#x2F;Home
JAVA_HOME&#x3D;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_291.jdk&#x2F;Contents&#x2F;Home
MAVEN_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;apache-maven-3.8.1
CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar

NODE_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;node-v14.16.1
SCALA_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;scala-2.12.13
HADOOP_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;hadoop-3.2.2
HIVE_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;hive-3.1.2
SPARK_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;spark-3.1.1
HBASE_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;hbase-2.3.5
FLINK_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;flink-1.12.2
ZK_HOME&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.6.3

export JAVA_HOME&#x3D;$JAVA_HOME
PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH:$MAVEN_HOME&#x2F;bin:$PATH:$NODE_HOME&#x2F;bin:$PATH
PATH&#x3D;$SCALA_HOME&#x2F;bin:$PATH:$HADOOP_HOME&#x2F;bin:$PATH:$SPARK_HOME&#x2F;bin:$PATH
PATH&#x3D;$HIVE_HOME&#x2F;bin:$HBASE_HOME&#x2F;bin:$PATH:$FLINK_HOME&#x2F;bin:$PATH:$ZK_HOME&#x2F;bin:$PATH
PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin


export PATH
export LANG&#x3D;zh_CN.UTF-8
alias subl&#x3D;&quot;&#x2F;Applications&#x2F;Sublime\ Text.app&#x2F;Contents&#x2F;SharedSupport&#x2F;bin&#x2F;subl&quot;
alias emacs&#x3D;&quot;&#x2F;Applications&#x2F;Emacs.app&#x2F;Contents&#x2F;MacOS&#x2F;Emacs&quot;
# You may need to manually set your language environment
# export LANG&#x3D;en_US.UTF-8

# Preferred editor for local and remote sessions
# if [[ -n $SSH_CONNECTION ]]; then
#   export EDITOR&#x3D;&#39;vim&#39;
# else
#   export EDITOR&#x3D;&#39;mvim&#39;
# fi

# Compilation flags
# export ARCHFLAGS&#x3D;&quot;-arch x86_64&quot;

# Set personal aliases, overriding those provided by oh-my-zsh libs,
# plugins, and themes. Aliases can be placed here, though oh-my-zsh
# users are encouraged to define aliases within the ZSH_CUSTOM folder.
# For a full list of active aliases, run &#96;alias&#96;.
#
# Example aliases
# alias zshconfig&#x3D;&quot;mate ~&#x2F;.zshrc&quot;
# alias ohmyzsh&#x3D;&quot;mate ~&#x2F;.oh-my-zsh&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
Iterm2快捷键：</li>
<li>Command + N ： 新建tab页</li>
<li>Command + Enter ： 全屏/退出全屏</li>
</ul>
<h2 id="Mac使用ssh-agent登陆远程服务器"><a href="#Mac使用ssh-agent登陆远程服务器" class="headerlink" title="Mac使用ssh-agent登陆远程服务器"></a>Mac使用ssh-agent登陆远程服务器</h2><p>该功能类似SecureCRT里的<code>Tools-Manage Agent Keys</code></p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">eval &#96;ssh-agent&#96;
## id_rsa_work为之前保存的私钥文件
ssh-add ~&#x2F;.ssh&#x2F;id_rsa_work<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>但是，这种方式有一个缺点，每次打开终端都要执行一次，这里把它加载到环境变量里<br>在.zshrc里添加一下内容：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">eval &#96;ssh-agent&#96; &gt; &#x2F;dev&#x2F;null
ssh-add ~&#x2F;.ssh&#x2F;id_rsa_work &gt; &#x2F;dev&#x2F;null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="安装并配置java"><a href="#安装并配置java" class="headerlink" title="安装并配置java"></a>安装并配置java</h2><p>mac下安装java很简单，但是配置java的环境变量，被恶心到了，找不到java的安装路径</p>
<ul>
<li>首先到官网上下载java安装包，注意，下载那个大的，也就是200多M的文件，下载小的，不包含jdk</li>
<li>查找JDK安装目录<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">## 执行如下命令
&#x2F;usr&#x2F;libexec&#x2F;java_home -V
## 该命令会把机器上所有的java版本都列出来，因为我之前先安装了一个不包含jdk的java，就导致我这里有两个java
## 但是很明显，我需要的jdk是下面的那个
JAVA_HOME&#x3D;&#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk1.8.0_291.jdk&#x2F;Contents&#x2F;Home

## 自己跟着网上安装了一次jdk11，但是找不到tools.jar和dt.jar,在idea中调试代码的时候，一直报错，最终放弃了
## 之后有空再试试<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<img src="/uploads/20210520/jdk%E7%89%88%E6%9C%AC%E4%BF%A1%E6%81%AF.png" alt="jdk版本信息"><br>有2个java是因为一开始装的java不是jdk，是jre，而且两个的版本不一样。</li>
</ul>
<h2 id="mac环境下Sublime使用技巧"><a href="#mac环境下Sublime使用技巧" class="headerlink" title="mac环境下Sublime使用技巧"></a>mac环境下Sublime使用技巧</h2><ul>
<li>命令行使用Sublime打开文件<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">alias subl&#x3D;&quot;&#x2F;Applications&#x2F;Sublime\ Text.app&#x2F;Contents&#x2F;SharedSupport&#x2F;bin&#x2F;subl&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>Sublime列式编辑<br>按住鼠标中键，或者按住<code>command</code>使用鼠标选择文本</li>
<li>Sublime查找与替换快捷键  <ul>
<li>查找：<code>command + F</code></li>
<li>替换：<code>command +shift + F</code>,需要注意是否忽略大小写，是否正则匹配</li>
</ul>
</li>
<li>Sublime呼出命令行<ul>
<li>安装Terminus插件</li>
<li>配置快捷键<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"alt+shift+t"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"toggle_terminus_panel"</span> <span class="token punctuation">&#125;</span>
<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li>Sublime使用home/end快捷键到行首行尾<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"ctrl+shift+t"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"toggle_terminus_panel"</span> <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"move_to"</span><span class="token punctuation">,</span> <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span><span class="token property">"to"</span><span class="token operator">:</span> <span class="token string">"bol"</span><span class="token punctuation">,</span> <span class="token property">"extend"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#123;</span> <span class="token property">"keys"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"move_to"</span><span class="token punctuation">,</span> <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span><span class="token property">"to"</span><span class="token operator">:</span> <span class="token string">"eol"</span><span class="token punctuation">,</span> <span class="token property">"extend"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">&#125;</span> <span class="token punctuation">&#125;</span>
<span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>Sublime配置文件：<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
	<span class="token property">"theme"</span><span class="token operator">:</span> <span class="token string">"Default.sublime-theme"</span><span class="token punctuation">,</span>
	<span class="token property">"translate_tabs_to_spaces"</span><span class="token operator">:</span>  <span class="token boolean">true</span><span class="token punctuation">,</span>
	<span class="token property">"color_scheme"</span><span class="token operator">:</span> <span class="token string">"Packages/Color Scheme - Default/Monokai.tmTheme"</span><span class="token punctuation">,</span>
	<span class="token property">"font_face"</span><span class="token operator">:</span> <span class="token string">"Courier New"</span><span class="token punctuation">,</span>
	<span class="token property">"font_size"</span><span class="token operator">:</span> <span class="token number">18</span><span class="token punctuation">,</span>
	<span class="token property">"ignored_packages"</span><span class="token operator">:</span>
	<span class="token punctuation">[</span>
		<span class="token string">"Vintage"</span><span class="token punctuation">,</span>
	<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="mac-安装homebrew"><a href="#mac-安装homebrew" class="headerlink" title="mac 安装homebrew"></a>mac 安装homebrew</h2><pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">&#x2F;bin&#x2F;zsh -c &quot;$(curl -fsSL https:&#x2F;&#x2F;gitee.com&#x2F;cunkai&#x2F;HomebrewCN&#x2F;raw&#x2F;master&#x2F;Homebrew.sh)&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Mac安装mysql"><a href="#Mac安装mysql" class="headerlink" title="Mac安装mysql"></a>Mac安装mysql</h2>具体参考<br><a href="https://zhuanlan.zhihu.com/p/257006114">mac 安装mysql详细教程</a></li>
</ul>
<h2 id="Mac常用快捷键"><a href="#Mac常用快捷键" class="headerlink" title="Mac常用快捷键"></a>Mac常用快捷键</h2><p>Mac系统快捷键设置：<br>系统偏好设置 -&gt; 键盘 -&gt; 快捷键<br><code>command + 左右方向键</code>： 到句首/尾（下一个/上一个标点符号）<br><code>option + 左右方向键</code>：跳到行首/行尾<br><code>ctrl + 左右方向键</code>：切换后台进程（窗口），是直接上一个/下一个窗口<br><code>ctrl + 上下方向键</code>:  呼出所有后台进程（窗口）<br><code>shift + 中/英</code>：切换大小写<br><code>command + tab</code>:切换后台进程，按住command会有所有后台，然后按tab可以切换（只是图标）<br><code>command + 上下方向键</code>：进入上层文件夹（在访达里使用）<br><code>ctrl + command + Q</code>: 锁屏<br><code>command + 空格</code>：聚焦搜索<br><code>option + command + 空格</code>：在访达里搜索<br><code>option + command + D</code>:显示/隐藏程序坞<br><code>shift + command + 2</code>:截图到剪切板<br><code>option + command + T</code>:自动生成try catch<br><code>command + 7</code>: 打开/关闭structure<br><code>ctrl + option + o</code>: 自动删除java不用了的package</p>
<h2 id="开启-HIDPI，让-2K-显示器更舒适"><a href="#开启-HIDPI，让-2K-显示器更舒适" class="headerlink" title="开启 HIDPI，让 2K 显示器更舒适"></a>开启 HIDPI，让 2K 显示器更舒适</h2><p>mac自带的屏幕太小了，自己买的外接显示器是2k的，mac不会自动启动hidpi，所以字特别小，不好看。这里强行让mac知道可以启用hidpi<br>具体可以参考:<br><a href="https://sspai.com/post/57549">为 macOS 10.15 开启 HiDPI，让 2K 显示器更舒适</a></p>
<h2 id="Mac安装Hadoop、hive遇到的问题"><a href="#Mac安装Hadoop、hive遇到的问题" class="headerlink" title="Mac安装Hadoop、hive遇到的问题"></a>Mac安装Hadoop、hive遇到的问题</h2><p>具体的配置，会放到github上，之后再换电脑，直接从git上clone即可</p>
<ul>
<li><p>运行start-all.sh,报异常<code>golden-02: ssh: connect to host golden-02 port 22: Connection refused</code></p>
<blockquote>
<p>原因: mac原本没有打开远程访问的权限，即ssh到本机不通。<br>解决方法：系统偏好设置-&gt;共享-&gt;远程登录</p>
</blockquote>
</li>
<li><p><code>golden-02: gujincheng@golden-02: Permission denied (publickey,password,keyboard-interactive).</code></p>
<blockquote>
<p>原因：没有配置ssh免密钥<br>解决方法：cd ~/.ssh &amp;&amp; cat id_rsa.pub &gt;&gt; authorized_keys</p>
</blockquote>
</li>
<li><p>在HDFS管理页面，查看/tmp目录出现没有权限访问</p>
<blockquote>
<p>原因：core-site.xml的默认配置<code>hadoop.http.staticuser.user=dr.who</code><br>解决方法：在core-site.xml添加如下内容：</p>
</blockquote>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>gujincheng<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>不需要重新初始化namenode（<code>hdfs namenode -format</code>）</p>
</li>
<li><p>hive报错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>原因：安装包是直接复制过来的，mysql虽然重新安装了，但是hive的元数据没有重新初始化<br>解决方法：<code>schematool -dbType mysql -initSchema</code></p>
</blockquote>
</li>
</ul>
<h2 id="Mac终端设置ls颜色"><a href="#Mac终端设置ls颜色" class="headerlink" title="Mac终端设置ls颜色"></a>Mac终端设置ls颜色</h2><p>这种方式设置的颜色，会随着终端的颜色变化而变化，很实用。<br>具体步骤如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell"># 1.下载安装 coreutils
brew install coreutils
# 2.创建颜色配置文件
gdircolors --print-database &gt; ~&#x2F;.dir_colors<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>编辑.zshrc</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">if brew list | grep coreutils &gt; &#x2F;dev&#x2F;null ; then
    PATH&#x3D;&quot;$(brew --prefix coreutils)&#x2F;libexec&#x2F;gnubin:$PATH&quot; 
    alias ls&#x3D;&#39;ls -F --show-control-chars --color&#x3D;auto&#39; 
    eval &#96;gdircolors -b $HOME&#x2F;.dir_colors&#96; 
fi

## 可以省略if条件，直接执行条件语句的内容
PATH&#x3D;&quot;$(brew --prefix coreutils)&#x2F;libexec&#x2F;gnubin:$PATH&quot; 
alias ls&#x3D;&#39;ls -F --show-control-chars --color&#x3D;auto&#39; 
eval &#96;gdircolors -b $HOME&#x2F;.dir_colors&#96; 
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>最后<code>source .zshrc</code></p>
<h2 id="Mac下使用netcat发送消息"><a href="#Mac下使用netcat发送消息" class="headerlink" title="Mac下使用netcat发送消息"></a>Mac下使用netcat发送消息</h2><p>直接使用nc命令，不知道为啥不行。<br>需要使用brew安装一下<code>brew install netcat</code><br><code>netcat -l -p 9999</code>:发送消息<br><code>netcat golden-02 9999</code>:接受消息<br>9999是端口号，默认是localhost</p>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>Sublime</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB杂记（一）</title>
    <url>/2021/01/18/MongoDB%E6%9D%82%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h2 id="collection表名包含特殊字符"><a href="#collection表名包含特殊字符" class="headerlink" title="collection表名包含特殊字符"></a>collection表名包含特殊字符</h2><p>   当collection表名包含特殊字符时，mongo sehll在find()等操作时会报错，这时候，可以使用getCollection函数，把表明以字符串的形式传进函数内<br>例如：  </p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">db.getCollection(&#39;all-aa-bb_cc_dd_20200129&#39;).find()<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
]]></content>
      <categories>
        <category>大数据</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka学习笔记（一）</title>
    <url>/2021/01/21/Kafka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Kafka简介（后补）</li>
<li>Kafka可以干什么？（后补）</li>
<li>Kafka安装与启动</li>
<li>Kafka常用操作<a id="more"></a>
<h2 id="Kafka简介"><a href="#Kafka简介" class="headerlink" title="Kafka简介"></a>Kafka简介</h2></li>
</ul>
<h2 id="Kafka可以干什么？"><a href="#Kafka可以干什么？" class="headerlink" title="Kafka可以干什么？"></a>Kafka可以干什么？</h2><h2 id="Kafka安装与启动"><a href="#Kafka安装与启动" class="headerlink" title="Kafka安装与启动"></a>Kafka安装与启动</h2><h3 id="Kafka安装"><a href="#Kafka安装" class="headerlink" title="Kafka安装"></a>Kafka安装</h3><p>Kafka需要用到java，安装前需要安装java，这里省略<br>Kafka可以使用内置的zookeeper，也可以使用单独的zookeeper，一般生产环境都是使用单独的zookeeper集群<br>zookeeper安装可以参考<a href="https://gujincheng.github.io/2021/01/21/Zookeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/">Zookeeper学习笔记（一）</a><br>官网下载Kafka安装包，并解压</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar zxvf kafka-2.11.0.tar.gz -C .
cd kafka-2.11.0&#x2F;config
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>修改server.properties</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">host.name&#x3D;golden-02
# 指定kafka日志文件的存储目录
log.dirs&#x3D;&#x2F;opt&#x2F;modules&#x2F;kafka-2.11.0&#x2F;kafka-logs
# 指定zookeeper的连接地址，多个地址用逗号分隔
zookeeper.connect&#x3D;golden-02:2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里设置了kafka-logs，手动生成了这个文件夹</p>
<p>最后，设置Kakfa的环境变量</p>
<h3 id="Kafka启动等操作"><a href="#Kafka启动等操作" class="headerlink" title="Kafka启动等操作"></a>Kafka启动等操作</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 启动
cd &#x2F;opt&#x2F;modules&#x2F;kafka-2.11.0&#x2F; &amp;&amp; bin&#x2F;kafka-server-start.sh config&#x2F;server.properties &amp;
# 关闭
cd &#x2F;opt&#x2F;modules&#x2F;kafka-2.11.0&#x2F; &amp;&amp; bin&#x2F;kafka-server-stop.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Kafka操作样例"><a href="#Kafka操作样例" class="headerlink" title="Kafka操作样例"></a>Kafka操作样例</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 查看所有topic
bin&#x2F;kafka-topics.sh --zookeeper golden-02:2181 --list
## 创建topic
bin&#x2F;kafka-topics.sh --zookeeper golden-02:2181 --create --replication-factor 3 --partitions 1 --topic first
## 删除topic
bin&#x2F;kafka-topics.sh --zookeeper golden-02:2181 --delete --topic first
## 发送消息
 bin&#x2F;kafka-console-producer.sh --broker-list golden-02:9092 --topic first
## 消费消息
bin&#x2F;kafka-console-consumer.sh  --bootstrap-server golden-02:9092  --from-beginning --topic first
## 查看某个Topic的详情
bin&#x2F;kafka-topics.sh --zookeeper golden-02:2181  --describe --topic first
## 查看某个group_id的消费情况，offset
bin&#x2F;kafka-consumer-groups.sh --bootstrap-server golden-02:9092 --describe --group fink-test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>选项说明：  </p>
<ul>
<li>–topic 定义topic名</li>
<li>–replication-factor 定义副本数</li>
<li>–partitions 定义分区数</li>
</ul>
<p>删除topic时删除不掉，日志提醒：<br><code>This will have no impact if delete.topic.enable is not set to true</code><br><img src="/uploads/20210121/kafka-delete-error.png" alt="kafka-delete-error"><br>到kafka的server.properties里设置<code>delete.topic.enable=true</code></p>
<h2 id="Kafka常见问题"><a href="#Kafka常见问题" class="headerlink" title="Kafka常见问题"></a>Kafka常见问题</h2><ul>
<li>auto.offset.reset设置无效<blockquote>
<p>原因:<code>auto.offset.reset</code>只会在Kafka中没有初始偏移量，或者服务器上不再存在当前偏移量的时候才会生效。<br>换句话说，如果当前<code>group_id</code>已经消费过这个<code>topic</code>（可以查到offset），这个参数就没用了，要再想从头开始消费，就得换个group_id了<br>官网说明：<br><img src="/uploads/20210125/Kafka%E5%AE%98%E7%BD%91%E8%A7%A3%E9%87%8Aauto.offset.reset.png" alt="Kafka官网解释auto.offset.reset"></p>
</blockquote>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis杂记（一）</title>
    <url>/2021/01/18/Redis%E6%9D%82%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>什么是Redis</li>
<li>Redis有哪些优缺点</li>
<li>为什么要用 Redis 而不用 map/guava 做缓存?</li>
<li>Redis为什么这么快</li>
<li>Redis的应用场景</li>
<li>Redis持久化</li>
<li>Redis踩的坑</li>
</ul>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="什么是Redis"><a href="#什么是Redis" class="headerlink" title="什么是Redis"></a>什么是Redis</h3><p>Redis(Remote Dictionary Server) 是一个使用 C 语言编写的，开源的（BSD许可）高性能非关系型（NoSQL）的键值对数据库。<br>Redis 可以存储键和五种不同类型的值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，满足大部分的使用要求<br><img src="/uploads/20211109/Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png" alt="Redis数据类型"></p>
<p>以上可以参考<a href="https://www.cnblogs.com/javazhiyin/p/13839357.html">Redis 常见面试题</a></p>
<h2 id="Redis踩的坑"><a href="#Redis踩的坑" class="headerlink" title="Redis踩的坑"></a>Redis踩的坑</h2><p>最近在测试任务的时候，把reids的key和value写反了，导致生产环境的reids凭空多了200多万脏数据，在网上查了一个批量删除的命令，直接在生产环境执行了，导致redis宕机、OOM了</p>
<p>所以，以后再操作生产环境数据库，特别是删除、大规模数据遍历、消耗性能比较大的情况下，在网上查的命令最好还是在测试环境测试一下再用，多么痛的领悟</p>
<p>这里记录一下两个命令：</p>
<h3 id="错误的命令"><a href="#错误的命令" class="headerlink" title="错误的命令"></a>错误的命令</h3><p>在数据量较大的情况下，千万别用类似keys *的操作，keys会把reids里所有的key一口气都遍历一遍，消耗性能奇高。。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;pws&#125;&#39; keys &#39;0^!*&#39; |xargs redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;psw&#125;&#39; DEL<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="正确的命令："><a href="#正确的命令：" class="headerlink" title="正确的命令："></a>正确的命令：</h3><p>在生产环境下，尽量使用scan</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;psw&#125;&#39; --scan --pattern &quot;0^!*&quot; | xargs -L 1000 redis-cli -h $&#123;ip&#125; -p 6379 -n 4 -a &#39;$&#123;psw&#125;&#39; del<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>具体可以参考：<a href="https://zhuanlan.zhihu.com/p/102092251">Redis 千万不要乱用KEYS命令，不然会挨打的</a>  </p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala杂记（一）</title>
    <url>/2021/01/18/Scala%E6%9D%82%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>使用Scala解析Json</li>
</ul>
<a id="more"></a>
<h3 id="解析json"><a href="#解析json" class="headerlink" title="解析json"></a>解析json</h3><p>个人认为，解析json用的最多的就是fastjson了<br>使用前需要在pom文件中引用：</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.alibaba<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>fastjson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.47<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>代码案例：</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> jsonStr <span class="token operator">=</span>
  <span class="token triple-quoted-string string">"""
    |[
    |        &#123;
    |            "type_name" : "aa",
    |            "score" : 0.9995,
    |            "classcode" : "a1:0.2136;a2:0.2136;a3:0.2136;a4:0.1582;a5:0.1578;a6:0.0429;a7:0.0004"
    |        &#125;,
    |        &#123;
    |            "type_name" : "bb",
    |            "score" : 0.0005,
    |            "classcode" : "b1:0.5000;b2:0.5000"
    |        &#125;
    |    ]
    |"""</span><span class="token punctuation">.</span>stripMargin
<span class="token keyword">val</span> typeTageArr <span class="token operator">=</span> mutable<span class="token punctuation">.</span>ArrayBuffer<span class="token punctuation">[</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token string">""</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>jsonStr<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token string">"[]"</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>jsonStr<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
  <span class="token keyword">val</span> jsonArr <span class="token operator">=</span> JSON<span class="token punctuation">.</span>parseArray<span class="token punctuation">(</span>jsonStr<span class="token punctuation">)</span>
  <span class="token keyword">val</span> houses <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0</span> until jsonArr<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>jsonArr<span class="token punctuation">.</span>getJSONObject<span class="token punctuation">)</span><span class="token punctuation">.</span>toArray
  <span class="token keyword">for</span><span class="token punctuation">(</span>jsMap <span class="token keyword">&lt;-</span> houses<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
    <span class="token keyword">val</span> typeName <span class="token operator">=</span> jsMap<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"type_name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString
    <span class="token keyword">val</span> classCode <span class="token operator">=</span> jsMap<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"classcode"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">";"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=></span> x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">":"</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
    typeTageArr <span class="token operator">+=</span> Map<span class="token punctuation">(</span><span class="token string">"type"</span> <span class="token operator">-></span> typeName<span class="token punctuation">,</span><span class="token string">"classTags"</span> <span class="token operator">-></span> classCode<span class="token punctuation">)</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="array转json"><a href="#array转json" class="headerlink" title="array转json"></a>array转json</h3><p>一开始使用JSON.toJSONString(typeTageArr)这种方式，但是报如下错</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">error: ambiguous reference to overloaded definition,
both method toJSONString in object JSON of type (x$1: Any, x$2: com.alibaba.fastjson.serializer.SerializerFeature*)String
and  method toJSONString in object JSON of type (x$1: Any)String<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>从报错的信息当中我们得知是scala对对重载定义的模糊引用造成，从fastjson的源码中可以看到，有两个toJSONString的方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token class-name">Object</span> object<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> emptyFilters<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">String</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token class-name">Object</span> object<span class="token punctuation">,</span> <span class="token class-name">SerializerFeature</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> features<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">return</span> <span class="token function">toJSONString</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> DEFAULT_GENERATE_FEATURE<span class="token punctuation">,</span> features<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在第二个方法中SerializerFeature… features 是一个可变长参数，带有变长参数的方法重载使得scala在调用方法时感到“模糊”，就无法匹配参数的类型</p>
<p>所以在array或者map转json对象的时候，使用json4s比较好<br>使用案例：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>json4s<span class="token punctuation">.</span></span><span class="token class-name">JsonDSL</span><span class="token punctuation">.</span>_
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>json4s<span class="token punctuation">.</span>jackson<span class="token punctuation">.</span></span><span class="token class-name">JsonMethods</span><span class="token punctuation">.</span>_
<span class="token function">compact</span><span class="token punctuation">(</span><span class="token function">render</span><span class="token punctuation">(</span>typeTageArr<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>使用起来很方便</p>
<h2 id="Scala中调用方法和函数"><a href="#Scala中调用方法和函数" class="headerlink" title="Scala中调用方法和函数"></a>Scala中调用方法和函数</h2><p>Scala中的+ - * / %等操作符的作用与Java一样，位操作符 &amp; | ^ &gt;&gt; &lt;&lt;也一样。只是有一点特别的：这些操作符实际上是方法。例如：<br><code>a + b</code>是<code>a.+(b)</code>的简写<br><code>a 方法 b</code>可以写成 <code>a.方法(b)</code></p>
<h2 id="Scala-方法和函数的区别"><a href="#Scala-方法和函数的区别" class="headerlink" title="Scala 方法和函数的区别"></a>Scala 方法和函数的区别</h2><p>可以参考<a href="https://www.huaweicloud.com/articles/da048fd844830f817cc39b6cf484cc16.html">Scala 方法与函数</a><br>Scala 方法与函数,二者在语义上的区别很小,Scala 方法是类的一部分，而函数是一个对象可以赋值给一个变量。换句话来说在类中定义的函数即是方法。<br>Scala 中使用<code>val</code>语句可以定义函数，<code>def</code>语句定义方法。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Scala面试题</title>
    <url>/2021/12/06/Scala%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Scala面试题总结</li>
</ul>
<a id="more"></a>


<p><strong><font size = 5>1. 方法和函数的区别？</font></strong><br>Scala 方法与函数,二者在语义上的区别很小,Scala 方法是类的一部分，而函数是一个对象可以赋值给一个变量。换句话来说在类中定义的函数即是方法。<br>Scala 中使用<code>val</code>语句可以定义函数，<code>def</code>语句定义方法。</p>
<p><strong><font size = 5>2. Scala类型系统中Nil, Null, None, Nothing四个类型的区别？？</font></strong><br>Null是一个trait（特质），是所以引用类型AnyRef的一个子类型，null是Null唯一的实例。<br>Nothing也是一个trait（特质），是所有类型Any（包括值类型和引用类型）的子类型，它不在有子类型，它也没有实例，实际上为了一个方法抛出异常，通常会设置一个默认返回类型。<br>Nil代表一个List空类型，等同List[Nothing]<br>None是Option monad的空标识（深入了解请参考问题Q11）</p>
<p><strong><font size = 5>3. 什么是高阶函数？</font></strong><br>高阶函数指能接受或者返回其他函数的函数，scala中的filter map flatMap函数都能接受其他函数作为参数。</p>
<p><strong><font size = 5>4. 什么是隐式转换？</font></strong><br>通过隐式转换，程序员可以在编写Scala程序时故意漏掉一些信息，让编译器去尝试在编译期间自动推导出这些信息来，这种特性可以极大的减少代码量，忽略那些冗长，过于细节的代码<br>隐式转换必须满足无歧义规则，在声明隐式参数的类型是最好使用特别的或自定义的数据类型，不要使用Int,String这些常用类型，避免碰巧匹配<br>调用方法：</p>
<ol>
<li>将方法或变量标记为implicit</li>
<li>将方法的参数列表标记为implicit</li>
<li>将类标记为implicit</li>
</ol>
<p>Scala支持3种形式的隐式转换：<br>隐式值：用于给方法提供参数<br>隐式视图：用于类型间转换或使针对某类型的方法能调用成功<br>隐式类：使用implicit声明类</p>
<p><strong><font size = 5>5. scala的模式匹配？</font></strong><br>有点类似于Java语言的 switch，但其实还是有很大的不同的</p>
<ul>
<li>java 的 switch 仅仅会做一些基本类型的匹配，然后执行一些动作，并且是没有返回值的。</li>
<li>scala 的模式匹配除了可以匹配数值，同时它还能匹配类型，同时它还是有返回值的</li>
</ul>
]]></content>
      <categories>
        <category>面试题</category>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>Selenium与PhantomJS踩过的坑</title>
    <url>/2021/01/16/Selenium%E4%B8%8EPhantomJS%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Selenium与PhantomJS踩过的坑<a id="more"></a>
<h2 id="Selenium与PhantomJS踩过的坑"><a href="#Selenium与PhantomJS踩过的坑" class="headerlink" title="Selenium与PhantomJS踩过的坑"></a>Selenium与PhantomJS踩过的坑</h2><h3 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h3>Selenium是一个Web的自动化测试工具，最初是为网站自动化测试而开发的，类型像我们玩游戏用的按键精灵，可以按指定的命令自动化操作，不同是Selenium可以直接运行在浏览器上，它支持所有主流的浏览器(包括PhantomJS这些无界面的浏览器)。</li>
</ul>
<p>Selenium可以根据我们的指令，让浏览器自动加载页面，获取需要的页面，甚至页面截屏，或者判断网站上某些动作是否发生。</p>
<p>Selenium自己不带浏览器，不支持浏览器的功能，它需要与第三方浏览器结合在一起才能使用。但是我们有时候需要让它内嵌在代码中运行，所有我们需要用一个叫PhantomJS的工具代替真实的浏览器。</p>
<h4 id="Selenium的安装"><a href="#Selenium的安装" class="headerlink" title="Selenium的安装"></a>Selenium的安装</h4><p>直接通过pip安装即可，这里没什么坑</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip install selenium<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="PhantomJS"><a href="#PhantomJS" class="headerlink" title="PhantomJS"></a>PhantomJS</h3><p>PhantomJS是一个基于Webkit的”无界面”(headless)浏览器，它会把网站加载到内存并执行页面上的JavaScript，因为不会展示图形界面，所以运行起来比完整的浏览器更高效。</p>
<p>如果我们把Selenium和PhantomJS结合在一起，就可以运行一个非常强大的网络爬虫了，这个爬虫可以处理JavaScript、Cookie、headers，以及任何我们真实用户需要做的事情。</p>
<h4 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h4><ul>
<li>PhantomJS只能从它的网站(<a href="http://phantomjs.org/download.html)%E4%B8%8B%E8%BD%BD%E3%80%82">http://phantomjs.org/download.html)下载。</a></li>
<li>因为PhantomJS是一个功能完善(虽然无界面)的浏览器而非一个Python库，所以它不需要像Python的其它库一样安装，但我们可以通过Selenium调用PhantomJS来直接使用</li>
<li>PhantomsJS官方才考文档：<a href="http://phantomjs.org/documention">http://phantomjs.org/documention</a></li>
<li>这里不能通过pip、apt-get，yum等方式安装，一开始在自己虚拟机通过apt-get安装，但是一直报错。后来又全卸载，重新通过官网下载手动安装才行。</li>
<li>在自己的远程服务器中运行代码，报错：<pre class="line-numbers language-python" data-language="python"><code class="language-python">TypeError<span class="token punctuation">:</span> urlopen<span class="token punctuation">(</span><span class="token punctuation">)</span> got multiple values <span class="token keyword">for</span> keyword argument <span class="token string">'body'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
原因是服务器的urllib3版本太低，卸载以后重装就好了<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo apt-get remove python-urllib3
sudo pip install -U urllib3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
下面是代码：<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#-*-  coding:utf-8 -*-</span>
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>keys <span class="token keyword">import</span> Keys
<span class="token keyword">import</span> time
driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>PhantomJS<span class="token punctuation">(</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"www.wangzhi.com"</span><span class="token punctuation">)</span>  <span class="token comment">#穿入你的网址</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"email"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"aaa@qq.com"</span><span class="token punctuation">)</span> <span class="token comment">#按F12，查看网页源代码中登录界面的name传参是什么</span>
<span class="token comment"># 我的网页：&lt;input id="loginEmail" class='login_input' type="text" name="email" placeholder="请输入您的邮箱"></span>
<span class="token comment"># 所以 find_element_by_name("email")里面穿的是email，pwd一样，find_element_by_id也一样</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"pwd"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'111111'</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"loginButton"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>save_screenshot<span class="token punctuation">(</span><span class="token string">'broad.png'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

</li>
</ul>
<h3 id="服务器没有中文字体"><a href="#服务器没有中文字体" class="headerlink" title="服务器没有中文字体"></a>服务器没有中文字体</h3><p>所有都准备好了，原本以为万事大吉，但是发现截图的内容，不能显示中文。<br>在网上查了原因是系统没有装中文字体。<br>安装字体可以参考<a href="https://www.jianshu.com/p/e7f12b8c8602">https://www.jianshu.com/p/e7f12b8c8602</a></p>
<h3 id="中文字体解决以后，又出现了截图页面不完整"><a href="#中文字体解决以后，又出现了截图页面不完整" class="headerlink" title="中文字体解决以后，又出现了截图页面不完整"></a>中文字体解决以后，又出现了截图页面不完整</h3><p>最后在网上查了原因 ，是因为分辨率的原因<br>在代码上添加</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">driver<span class="token punctuation">.</span>set_window_size<span class="token punctuation">(</span><span class="token number">1366</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>完整代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#-*-  coding:utf-8 -*-</span>
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>common<span class="token punctuation">.</span>keys <span class="token keyword">import</span> Keys
<span class="token keyword">import</span> time
driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>PhantomJS<span class="token punctuation">(</span>service_args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'--ignore-ssl-errors=true'</span><span class="token punctuation">,</span> <span class="token string">'--ssl-protocol=any'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"yourwebsite"</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>set_window_size<span class="token punctuation">(</span><span class="token number">1366</span><span class="token punctuation">,</span> <span class="token number">768</span><span class="token punctuation">)</span> <span class="token comment">#这里必须加在get网页的后面，加在它之前没用</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"email"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">"你的用户名"</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_name<span class="token punctuation">(</span><span class="token string">"pwd"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'你的密码'</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>find_element_by_id<span class="token punctuation">(</span><span class="token string">"loginButton"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>save_screenshot<span class="token punctuation">(</span><span class="token string">'/data/jenkins/broadcastPicture/broad.png'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>因为截图涉及公司数据，就不粘贴到这里了。</p>
<p>实践过程中，通过参考 <a href="https://www.cnblogs.com/miqi1992/p/8093958.html">Python爬虫(二十一)_Selenium与PhantomJS</a>实现了自动截图，<br>参考<a href="https://www.cnblogs.com/miqi1992/p/8120185.html">Python爬虫(二十二)_selenium案例：模拟登陆豆瓣</a>实现了自动登录  </p>
]]></content>
      <categories>
        <category>爬虫</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Selenium</tag>
        <tag>PhantomJS</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark面试题</title>
    <url>/2021/11/18/Spark%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Spark面试题总结</li>
</ul>
<a id="more"></a>


<p><strong><font size = 5>1. 对于 Spark 中的数据倾斜问题你有什么好的方案?</font></strong><br>数据倾斜是因为数据中的key分布的不均匀导致的。</p>
<ol>
<li>可以把小表广播出去或者使用<code>map join</code></li>
<li>采样倾斜key并分拆join操作，对倾斜key做添加随机数处理。</li>
<li>如果其中一个表存在多个key倾斜，把主表的所有key都添加1-n随机数，把从表每条数据都复制n次，并添加1-n的随机数，然后再join</li>
<li>自定义Partitioner：原始的spark使用的是hashPartition，可以自定义一个paritioner，把key拆分到多个task里去</li>
<li>提高shuffle操作的并行度，使用reduceByKey(1000)，sparkSQL里设置<code>spark.sql.shuffle.partitions=1000</code></li>
</ol>
<p><strong><font size = 5>2. 描述一下RDD,DataFrame,DataSet,DataStream的区别和联系？</font></strong><br>RDD：弹性分布式数据集，RDD是SparkCore的基本数据结构<br>DataFrame: 从源码上看，DataFrame其实就是指定row的DataSet，<code>type DataFrame = Dataset[Row]</code><br>DataSet：Dataset是一个由特定领域的对象组成强类型集合，可以使用函数（DSL）或关系运算（SQL）进行并行的转换操作。 每个Dataset 还有一个称为“DataFrame”的无类型（untypedrel）视图，它是[[Row]]的数据集。<br>Dataset和DataFrame的区别与联系：<br>1、Dataset是强类型，会在编译的时候进行类型检测；而DataFrame是弱类型的，在执行的时候进行类型检测；<br>2、序列化方式不通，Dataset是通过Encoder进行序列化，支持动态的生成代码，直接在bytes的层面进行排序，过滤等的操作；而DataFrame是采用可选的java的标准序列化或是kyro进行序列化<br>3、DataFrame和Dataset实质上都是一个逻辑计划，并且是懒加载的，都包含着scahema信息，只有到数据要读取的时候，才会将逻辑计划进行分析和优化，并最终转化为RDD<br>4、二者由于api是统一的，所以都可以采用DSL和SQL方式进行开发，都可以通过sparksession对象进行创建或者是通过transform转化操作得到<br>Dataset和RDD的区别与联系：<br>首先，Dataset的底层不是RDD，但是它可以和RDD互相转化，DS的一些算子例如filter等都是自己实现的，并没有调用RDD的算子<br>DStream：离散化流（DStream），SparkStreaming中的基本抽象，DSream 代表了一系列连续的RDD，DStream中每个RDD包含特定时间间隔的数据，一个DStream 对应了时间维度上的多个RDD。</p>
<p><strong><font size = 5>3. 简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数? </font></strong><br>窄依赖：每一个父RDD的partition最多被子RDD的一个partition使用<br>宽依赖：多个子RDD的partition会依赖同一个父RDD的partition<br>spark根据RDD的依赖关系划分stage，遇到一个宽依赖，就划分一个stage<br>stage中task数目由stage末端的RDD分区个数来决定</p>
<p><strong><font size = 5>4. 列举Spark常用的transformation和action算子，有哪些算子会导致Shuffle?</font></strong><br>transformation算子：map、flatMap、reduceByKey、groupByKey、filter等<br>action算子：take、ccollect、count、reduce等<br>reduceByKey、groupByKey等会产生Shuffle<br>注意：<br>reduceByKey和groupByKey只是会产生shuffle，但是不是action算子</p>
<p><strong><font size = 5>5. 简述下Spark中的缓存(cache和persist)与checkpoint机制，并指出两者的区别和联系</font></strong><br>cache缓存到内存中<br>persist可以缓存到磁盘和内存里<br>checkpoint只能缓存到hdfs上（磁盘上）<br>Persist 和 Cache，不会丢掉RDD间的依赖链/依赖关系，CheckPoint会斩断依赖链</p>
<p><strong><font size = 5>6. Spark开发调优总结</font></strong></p>
<ol>
<li>避免创建重复的RDD</li>
<li>尽可能复用同一个RDD</li>
<li>对多次使用的RDD进行持久化</li>
<li>尽量避免使用shuffle类算子</li>
<li>使用map-side预聚合的shuffle操作</li>
<li>使用高性能的算子<br> 6.1 使用reduceByKey/aggregateByKey替代groupByKey<br> 6.2 使用mapPartitions替代普通map<br> 6.3 使用foreachPartitions替代foreach<br> 6.4 使用filter之后进行coalesce操作<br> 6.4 使用repartitionAndSortWithinPartitions替代repartition与sort类操作  </li>
<li>广播大变量，减少大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC(垃圾回收)</li>
<li>使用Kryo优化序列化性能</li>
<li>优化数据结构</li>
</ol>
<p><strong><font size = 5>7. Spark为什么快，Spark SQL 一定比 Hive 快吗</font></strong><br>1、Spark 计算比 MapReduce 快的根本原因在于 DAG 计算模型，消除了冗余的 HDFS 读写，Spark不需要将计算的中间结果写入磁盘<br>    如果计算不涉及与其他节点进行数据交换，Spark 可以在内存中一次性完成这些操作，也就是中间结果无须落盘，减少了磁盘 IO 的操作<br>2、Spark 是基于内存的计算并不是spark快的根本原因<br>3、MapReduce每启动一个Task便会启动一次JVM，基于进程的操作。而Spark每次MapReduce操作是基于线程的，只在启动Executor时启动一次JVM，内存的Task操作是在线程复用的<br>总结：Spark比Mapreduce运行更快，主要得益于其对mapreduce操作的优化以及对JVM使用的优化<br>Spark SQL 不一定比Hive快，例如没有shuffle的或者只有一次shuffle的，有可能hive的速度不会低于spark-sql</p>
<p><strong><font size = 5>8. Spark Streaming小文件问题</font></strong><br>1、增加 batch 大小<br>2、在输出到hdfs的时候，Coalesce一下<br>3、单独起一个定时任务来合并小文件</p>
<p><strong><font size = 5>9. Checkpoint和持久化有什么区别？</font></strong><br>1、持久化只是将数据保存在BlockManager中，而RDD的lineage是不变的，但是checkpoint执行完后，RDD已经没有之前所谓的依赖RDD了，而只有一个强行为其设置的checkpointRDD，RDD的lineage（血缘关系，依赖关系）改变了<br>2、持久化的数据丢失可能性更大，磁盘、内存都可能会存在数据丢失的情况。但是checkpoint的数据通常是存储在如HDFS等容错、高可用的文件系统，数据丢失可能性较小。<br>注：默认情况下，如果某个RDD没有持久化，但是设置了checkpoint，会存在问题，本来这个job都执行结束了，但是由于中间RDD没有持久化，checkpoint job想要将RDD的数据写入外部文件系统的话，需要全部重新计算一次，<br>再将计算出来的RDD数据checkpoint到外部文件系统。所以，建议对checkpoint()的RDD使用persist(StorageLevel.DISK_ONLY)，该RDD计算之后，就直接持久化到磁盘上。后面进行checkpoint操作时就可以直接从磁盘上读取RDD的数据，并checkpoint到外部文件系统。</p>
<p><strong><font size = 5>10. SparkStreaming读取Kafka数据的两种方式，有什么区别？</font></strong><br>SparkStreaming读取Kafka数据有两种方式，分别为基于Receiver方式和基于Direct(No Receiver)方式<br>1、基于Receiver方式：<br>    1.1 需要使用单独的Receiver线程来异步获取Kafka数据。<br>    1.2 Receiver底层实现中使用了Kafka高级消费者API,因此,不需要自己管理Offset,只需指定Zookeeper和消费者组GroupID,系统便会自行管理。<br>    1.3 执行过程: Spark Streaming启动时，会在Executor中同时启动Receiver异步线程用于从Kafka持续获取数据，获取的数据先存储在Receiver中(存储方式由StorageLevel决定)，后续，当Batch Job触发后，这些数据会被转移到剩下的Executor中被处理。处理完毕后，Receiver会自动更新Zookeeper中的Offset。<br>    1.4 默认情况下,程序失败或Executor宕掉后可能会丢失数据，为避免数据丢失，可启用预写日志(Write Ahead Log,WAL)。将Receiver收到的数据再备份一份到更可靠的系统如HDFS分布式文件中，以冗余的数据来换取数据不丢失。<br>    1.5 生产下，为保证数据完全不丢失，一般需要启用WAL。启用WAL，在数据量较大，网络不好情况下，会严重降低性能<br>2、基于Direct(No Receiver)方式<br>    2.1 不需要使用单独的Receiver线程从Kafka获取数据。<br>    2.2 使用Kafka简单消费者API,不需要ZooKeeper参与，直接从Kafka Broker获取数据。<br>    2.3 执行过程:Spark Streaming Batch Job触发时，Driver端确定要读取的Topic-Partition的OffsetRange，然后由Executor并行从Kafka各Partition读取数据并计算。<br>    2.4 为保证整个应用EOS， Offset管理一般需要借助外部存储实现。如Mysql、HBase等。<br>    2.5 由于不需要WAL，且Spark Streaming会创建和Kafka Topic Partition一样多的RDD Partition,且一一对应，这样,就可以并行读取，大大提高了性能。<br>    2.6 Spark Streaming应用启动后，自己通过内部currentOffsets变量跟踪Offset，避免了基于Receiver的方式中Spark Streaming和Zookeeper中的Offset不一致问题。</p>
<p><strong><font size = 5>11. 如何使用Spark实现TopN的获取（描述思路或使用伪代码）？</font></strong><br>最简单的就是，直接reduceByKey计算key的个数，然后按照value排序<br>但是，这样会有一个问题，就是当数据量很大的时候，有可能会导致OOM，或者数据倾斜<br>可以使用map算子，把每个key添加一个随机数，然后再reduceByKey,最后再把key拆出来，再做一次reduceByKey</p>
<p><strong><font size = 5>12. Spark在什么情况下会OOM</font></strong></p>
<ol>
<li>map过程产生大量对象导致内存溢出</li>
<li>数据不平衡导致内存溢出</li>
<li>coalesce调用导致内存溢出</li>
<li>shuffle后内存溢出</li>
<li>广播了大变量</li>
</ol>
<p>指定spark的垃圾回收算法G1GC：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">-conf spark.driver.extraJavaOptions&#x3D;&quot;-XX:+UseG1GC -Dlog4j.configuration&#x3D;log4j.properties&quot; \
--conf spark.executor.extraJavaOptions&#x3D;&quot;-XX:+UseG1GC -Dlog4j.configuration&#x3D;log4j.properties&quot; \<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<p><strong><font size = 5>13. RDD的弹性表现在哪几点？</font></strong></p>
<ol>
<li>自动的进行内存和磁盘的存储切换</li>
<li>基于Linage的高效容错</li>
<li>task如果失败会自动进行特定次数的重试</li>
<li>stage如果失败会自动进行特定次数的重试，而且只会计算失败的分片</li>
<li>checkpoint和persist，数据计算之后持久化缓存</li>
<li>数据调度弹性，DAG TASK调度和资源无关</li>
<li>数据分片的高度弹性</li>
</ol>
<p><strong><font size = 5>14. RDD通过Linage（记录数据更新）的方式为何很高效？</font></strong></p>
<p><strong><font size = 5>14. Spark与MapReduce以及Tez的区别？</font></strong></p>
<ul>
<li>spark与tez都是以dag方式处理数据</li>
<li>MR相比tez和spark，每次计算结果都会落盘，增加了磁盘IO</li>
</ul>
<p>tez和spark的区别：</p>
<ul>
<li>spark更像是一个通用的计算引擎，提供内存计算，实时流处理，机器学习等多种计算方式，适合迭代计算</li>
<li>tez作为一个框架工具，特定为hive和pig提供批量计算</li>
<li>spark属于内存计算，支持多种运行模式，可以跑在standalone，yarn上；而tez只能跑在yarn上；虽然spark与yarn兼容，但是spark不适合和其他yarn应用跑在一起</li>
<li>tez能够及时的释放资源，重用container，节省调度时间，对内存的资源要求率不高； 而spark如果存在迭代计算时，container一直占用资源；</li>
</ul>
<p>可以参考<a href="https://zhuanlan.zhihu.com/p/49169166">Spark面试题(一)</a></p>
]]></content>
      <categories>
        <category>面试题</category>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper学习笔记（一）</title>
    <url>/2021/01/21/Zookeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Zookeeper简介</li>
<li>Zookeeper可以干什么？</li>
<li>Zookeeper安装与启动</li>
<li>Zookeeper常用操作<a id="more"></a>
<h2 id="Zookeeper简介"><a href="#Zookeeper简介" class="headerlink" title="Zookeeper简介"></a>Zookeeper简介</h2></li>
</ul>
<h2 id="Zookeeper可以干什么？"><a href="#Zookeeper可以干什么？" class="headerlink" title="Zookeeper可以干什么？"></a>Zookeeper可以干什么？</h2><h2 id="Zookeeper安装与启动"><a href="#Zookeeper安装与启动" class="headerlink" title="Zookeeper安装与启动"></a>Zookeeper安装与启动</h2><h3 id="Zookeeper安装"><a href="#Zookeeper安装" class="headerlink" title="Zookeeper安装"></a>Zookeeper安装</h3><p>Zookeeper需要用到java，安装前需要安装java，这里省略<br>官网下载Zookeeper安装包，并解压</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">tar zxvf zookeeper-3.4.6.tar.gz -C .
cd zookeeper-3.4.6&#x2F;conf
cp zoo_sample.cfg zoo.cfg <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>修改zoo.cfg</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># The number of milliseconds of each tick
tickTime&#x3D;2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit&#x3D;10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit&#x3D;5
# the directory where the snapshot is stored.
# do not use &#x2F;tmp for storage, &#x2F;tmp here is just 
# example sakes.
dataDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F;zkData
dataLogDir&#x3D;&#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F;zkDataLog
# the port at which the clients will connect
clientPort&#x3D;2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里设置了dataDir和dataLogDir，手动生成了这两个文件，不知道会不会自动生成<br>最后，设置Zookeeper的环境变量</p>
<h3 id="Zookeeper启动等操作"><a href="#Zookeeper启动等操作" class="headerlink" title="Zookeeper启动等操作"></a>Zookeeper启动等操作</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 启动
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh start
# 关闭
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh stop
# 查看ZK服务状态
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh status
#  重启ZK服务
cd &#x2F;opt&#x2F;modules&#x2F;zookeeper-3.4.6&#x2F; &amp;&amp; bin&#x2F;zkServer.sh restart<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Zookeeper操作样例"><a href="#Zookeeper操作样例" class="headerlink" title="Zookeeper操作样例"></a>Zookeeper操作样例</h2>]]></content>
      <categories>
        <category>大数据</category>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>azkban从编译开始安装</title>
    <url>/2021/01/16/azkban%E4%BB%8E%E7%BC%96%E8%AF%91%E5%BC%80%E5%A7%8B%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>如何下载Azkaban稳定版代码</li>
<li>如何构建Azkaban源码</li>
<li>如何配置Azkaban</li>
<li>启动Azkaban注意点<a id="more"></a>
<h2 id="从git上下载最新的azkban稳定版代码"><a href="#从git上下载最新的azkban稳定版代码" class="headerlink" title="从git上下载最新的azkban稳定版代码"></a>从git上下载最新的azkban稳定版代码</h2>git clone <a href="https://github.com/azkaban/azkaban.git">https://github.com/azkaban/azkaban.git</a> -b 3.74.3<br>这里还有个问题，如何把这个代码放到自己的git上，我放到公司的gitlab上之后，编译的名字就变了，很奇怪。</li>
</ul>
<h2 id="构建Azkaban"><a href="#构建Azkaban" class="headerlink" title="构建Azkaban"></a>构建Azkaban</h2><p>./gradlew clean<br>./gradlew build -x test<br>-x是指不做单元测试，不加这个会特别慢<br>这里我构建了很多次，用公司配制好的服务器构建，文件名老是不对<br>名字老是azkaban-web-server-0.1.0-SNAPSHOT.tar.gz和azkaban-exec-server-0.1.0-SNAPSHOT.tar.gz</p>
<p>后来还是直接clone官网上的代码来构建</p>
<h2 id="配置mysql"><a href="#配置mysql" class="headerlink" title="配置mysql"></a>配置mysql</h2><p>需要用mysql的root用户创建一个azkban数据库，我这里创建的数据库名为azkban3<br>然后 从编译文件夹里：<br>在azkaban/azkaban-db/build/sql下找到create-all-sql-3.74.3.sql<br>然后再mysql命令行：<br>create database azkaban3；<br>use azkaban3<br>source /home/data-platform/create-all-sql-3.74.3.sql<br>这样就把azkaban的所有表都创建完了</p>
<p>创建用户名为azkban的用户，用户名为azkban@123<br>CREATE USER ‘azkaban’@’%’ IDENTIFIED BY ‘azkaban@123’; #创建用户<br>grant all on azkaban3.* to azkaban@’%’ identified by ‘azkaban@123’; #授权azkaban3给azkaban<br>flush privileges  #s刷新</p>
<p>##启动azkban-exec-server<br>cd /opt/azkaban/azkaban-exec-server-3.74.3 &amp;&amp; ./bin/start-exec.sh</p>
<p>这里有个问题：<br>直接启动exec-server后启动web-server，webserver会找不到活跃的excutor<br>报错信息为:</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2019&#x2F;07&#x2F;04 14:32:08.532 +0800 INFO [ExecutorManager] [Azkaban] Initializing executors from database.
2019&#x2F;07&#x2F;04 14:32:08.535 +0800 ERROR [ExecutorManager] [Azkaban] No active executors found
2019&#x2F;07&#x2F;04 14:32:08.536 +0800 ERROR [StdOutErrRedirect] [Azkaban] Exception in thread &quot;main&quot;
2019&#x2F;07&#x2F;04 14:32:08.536 +0800 ERROR [StdOutErrRedirect] [Azkaban] azkaban.executor.ExecutorManagerException: No active executors found
2019&#x2F;07&#x2F;04 14:32:08.536 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ActiveExecutors.setupExecutors(ActiveExecutors.java:52)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ExecutorManager.setupExecutors(ExecutorManager.java:197)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ExecutorManager.initialize(ExecutorManager.java:131)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.executor.ExecutorManager.start(ExecutorManager.java:145)
2019&#x2F;07&#x2F;04 14:32:08.537 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.webapp.AzkabanWebServer.launch(AzkabanWebServer.java:231)
2019&#x2F;07&#x2F;04 14:32:08.538 +0800 ERROR [StdOutErrRedirect] [Azkaban]       at azkaban.webapp.AzkabanWebServer.main(AzkabanWebServer.java:224)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>解决办法：<br>手动激活exec-server<br>curl http://${executorHost}:${executorPort}/executor?action=activate<br>executorHost：就是安装服务器的IP<br>executorPort：就是启动azkban-exec-server后，产生的executor.port里的端口号</p>
<h2 id="启动azkaban-web-server"><a href="#启动azkaban-web-server" class="headerlink" title="启动azkaban-web-server"></a>启动azkaban-web-server</h2><p>cd /opt/azkaban/azkaban-web-server-3.74.3 &amp;&amp; ./bin/start-web.sh</p>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>启动server必须要到azkaban-web-server-3.74.3这个目录，因为默认启动找的配置文件为 conf/azkaban.properties</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Azkaban</category>
      </categories>
      <tags>
        <tag>Azkaban</tag>
      </tags>
  </entry>
  <entry>
    <title>emacs手动安装、解决不能使用中文输入法</title>
    <url>/2021/01/16/emacs%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E3%80%81%E8%A7%A3%E5%86%B3%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5%E6%B3%95/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>emacs下载杆状</li>
<li>解决不能使用中文输入法</li>
</ul>
<a id="more"></a>
<h2 id="emacs的安装"><a href="#emacs的安装" class="headerlink" title="emacs的安装"></a>emacs的安装</h2><h3 id="emacs的下载，解压"><a href="#emacs的下载，解压" class="headerlink" title="emacs的下载，解压"></a>emacs的下载，解压</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wget http:&#x2F;&#x2F;mirrors.ustc.edu.cn&#x2F;gnu&#x2F;emacs&#x2F;emacs-25.3.tar.gz
tar -zxf emacs-25.3.tar.gz -C &#x2F;opt&#x2F;modules
cd &#x2F;opt&#x2F;modules&#x2F;emacs-25.3&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local --with-x-toolkit&#x3D;gtk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这里会报错。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">You seem to be running X, but no X development libraries
were found.  You should install the relevant development files for X
and for the toolkit you want, such as Gtk+, Lesstif or Motif.  Also make
sure you have development files for image handling, i.e.
tiff, gif, jpeg, png and xpm.
If you are sure you want Emacs compiled without X window support, pass
  --without-x
to configure.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>需要下载相关依赖</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo apt-get install libxpm-dev
sudo apt-get install libjpeg62-dev
sudo apt-get install libgif-dev
sudo apt-get install libtiff5-dev
sudo apt-get install libncurses5-dev
sudo apt-get install libgtk2.0-dev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>重新编译后正常</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">make
sudo make install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>到此，emac的安装已经结束</p>
<h3 id="安装spacemacs"><a href="#安装spacemacs" class="headerlink" title="安装spacemacs"></a>安装spacemacs</h3><p>spacemacs可以在emacs里使用vim的命令，让emacs更人性化一点。</p>
<p>安装很简单，就是clone项目到~/.emacs.d目录去</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;syl20bnr&#x2F;spacemacs ~&#x2F;.emacs.d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>安装完spacemacs，第一次启动emacs会加载很多包，没关系，等一会就好了</p>
<h3 id="解决emacs不能使用中文输入法"><a href="#解决emacs不能使用中文输入法" class="headerlink" title="解决emacs不能使用中文输入法"></a>解决emacs不能使用中文输入法</h3><p>我的环境是ubuntu16.04，系统语言是English，但是在vim里，gedit都可以输入中文。只有emacs不行，在网上查了原因，是emacs自带的一个bug，因为比较久远，不会再修复了<br>这里在修复之前，已经安装了搜狗输入法</p>
<p>这里的处理办法是：<br>    在 .bashrc文件下添加：<br>    export LC_CTYPE=zh_CN.UTF-8<br>这样不会修改整个系统的环境，但是只针对自己这个用户来书，够用了。但是报了没有zh_CN.UTF-8这个文件</p>
<p>原因是系统中还没有中文语言包<br>这里安装一下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo apt-get install  -y language-pack-zh-hans
sudo apt-get install -y language-pack-zh-hant
cd &#x2F;usr&#x2F;share&#x2F;locales    
sudo .&#x2F;install-language-pack zh_CN   ##开始安装zh_CN中文字符集<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/20210116/emacs-install-error.png" alt="emacs-install-error"><br>这里的报错不用管<br>然后重启电脑就好了。</p>
<h3 id="Emacs-Org-mode"><a href="#Emacs-Org-mode" class="headerlink" title="Emacs Org-mode"></a>Emacs Org-mode</h3><p>使用emacs生成 表格是真的方便</p>
<h4 id="生成表格"><a href="#生成表格" class="headerlink" title="生成表格"></a>生成表格</h4><p><code>C-c |</code>    :生成表格，在buffer区域会提示输入N*M,代表N列M行的表格（注意，这里的<code>*</code>其实输入的是<code>x</code>）<br>使用<code>TAB</code>格式化表格</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>emacs</tag>
      </tags>
  </entry>
  <entry>
    <title>flink-cdc实时采集数据库入Kafka</title>
    <url>/2022/03/11/flink-cdc%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5Kafka/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink-CDC实时采集Mysql入Kafka</li>
<li>Flink-CDC实时采集Sqlserver入Kafka</li>
</ul>
<a id="more"></a>


<h2 id="Flink-CDC实时采集Mysql入Kafka"><a href="#Flink-CDC实时采集Mysql入Kafka" class="headerlink" title="Flink-CDC实时采集Mysql入Kafka"></a>Flink-CDC实时采集Mysql入Kafka</h2><p>环境信息：<br>flink-1.13.6<br>mysql-5.7.26<br>kafka_2.11-2.1.0-cdh6.2.0</p>
<h3 id="Mysql开启binlog"><a href="#Mysql开启binlog" class="headerlink" title="Mysql开启binlog"></a>Mysql开启binlog</h3><p>检查binlog开启状态：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 如果log_bin显示为ON，则代表已开启。</span>
<span class="token keyword">show</span> variables <span class="token operator">like</span> <span class="token string">'log_%'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>首先找到<code>my.cnf</code>:</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">[root@ddp5 tmp]# mysql --help | grep &#39;Default options&#39; -A 1
Default options are read from the following files in the given order:
&#x2F;etc&#x2F;my.cnf &#x2F;etc&#x2F;mysql&#x2F;my.cnf &#x2F;usr&#x2F;etc&#x2F;my.cnf ~&#x2F;.my.cnf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>可以看到mysql优先加载/etc/my.cnf中的配置。<br>所以需要在/etc/my.cnf中mysqld节添加开启binlog的配置：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#设置日志路径，注意路经需要mysql用户有权限写
## &#x2F;data&#x2F;mysql&#x2F;logs&#x2F;是binlog存储路径，mysql-bin是文件名
## 在该文件夹下会生成 mysql-bin.000001、 mysql-bin.index文件
log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;logs&#x2F;mysql-bin
#选择row模式
binlog_format&#x3D;ROW
##配置serverid
server_id&#x3D;1
#设置binlog清理时间
expire_logs_days &#x3D; 7
##binlog每个日志文件大小
max_binlog_size &#x3D; 100m
##binlog缓存大小
binlog_cache_size &#x3D; 4m
##最大binlog缓存大小
max_binlog_cache_size &#x3D; 512m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>修改完配置后，重启mysql。执行SHOW VARIABLES LIKE ‘log_bin’; Value 值为 ON即可</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">service mysqld restart<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="binlog的三种模式比较"><a href="#binlog的三种模式比较" class="headerlink" title="binlog的三种模式比较"></a>binlog的三种模式比较</h3><p>binlog的格式也有三种：<code>STATEMENT</code>、<code>ROW</code>、<code>MIXED</code>。<br><strong>STATMENT模式：</strong> 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。<br><strong>优点：</strong> 不需要记录每一条SQL语句与每行的数据变化，这样子binlog的日志也会比较少，减少了磁盘IO，提高性能。<br><strong>缺点：</strong> 在某些情况下会导致master-slave中的数据不一致 。</p>
<p><strong>ROW基于行的复制(row-based replication, RBR)格式：</strong> 不记录每一条SQL语句的上下文信息，仅需记录哪条数据被修改了，修改成了什么样子了。<br><strong>优点：</strong> 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。<br><strong>缺点：</strong> 会产生大量的日志，尤其是alter table的时候会让日志暴涨。<br>MIXED混合模式复制(mixed-based replication, MBR)：以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。<br>具体参考<a href="https://www.jianshu.com/p/8e7e288c41b1">MySQL如何开启binlog？binlog三种模式的分析</a><br>我们实时采集mysql数据，需要开启<code>ROW</code>模式</p>
<h3 id="flinkSQL读取mysqlBinlog并写入kafka"><a href="#flinkSQL读取mysqlBinlog并写入kafka" class="headerlink" title="flinkSQL读取mysqlBinlog并写入kafka"></a>flinkSQL读取mysqlBinlog并写入kafka</h3>]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink-CDC</category>
      </categories>
      <tags>
        <tag>Flink-CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>hdfs块文件丢失</title>
    <url>/2022/03/08/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hdfs块文件丢失</li>
</ul>
<a id="more"></a>

<h2 id="hdfs块文件丢失"><a href="#hdfs块文件丢失" class="headerlink" title="hdfs块文件丢失"></a>hdfs块文件丢失</h2><p>最近公司集群扩容，运维那边不知道怎么操作的，导致hdfs的block块文件丢失了。</p>
<p>个人猜测，公司的五台节点，都新挂载了一个新盘，datanode上配置了新盘，重启之后，hadoop集群肯定是要负载均衡一下的，迁移一些文件到新盘<br>这时候namenode会可能会进入安全模式，CM上很多组件都会报红，这时候我们的运维强制退出了安全模式，重启了hadoop集群，但是只是猜测，具体原因找不到了</p>
<p>先说问题描述：<br>启动hive的时候，报如下报错日志：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory &#x2F;tmp&#x2F;hive&#x2F;root&#x2F;eceb6690-1510-4703-8a4b-60ea03c3fcec. Name node is in safe mode.
The reported blocks 10427 needs additional 4373 blocks to reach the threshold 0.9990 of total blocks 14815.
The number of live datanodes 3 has reached the minimum number 1. Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:ddp2
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1448)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1435)
        ... 12 more<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>很明显，报错就是丢失了4373个block，导致namenode进入安全模式</p>
<h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>出现前面提到的问题主要原因是客户端写入的数据没有及时保存到磁盘中，从而导致数据丢失；又因为数据块丢失达到一定的比率，导致hdfs启动进入安全模式。</p>
<p>为了弄清楚导致安全模式的原因，下面主要对hdfs安全模式和如何退出安全模式进行分析。</p>
<h3 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h3><p>当 hdfs的NameNode节点启动时，会进入安全模式阶段。安全模式主要是为了系统启动的时候检查各个DataNode上数据块的有效性，同时根据策略必要的复制或者删除部分数据块。</p>
<p>在此阶段，NameNode加载fsimage（Filesystem image：文件meta信息的持久化的检查点）文件到内存中，然后在editlog中执行相应的操作。加载fsimage文件包含文件metadata信息，但是不包含文件块位置的信息。</p>
<p>DataNode启动的时候扫描本地磁盘，保存的block信息，然后将这些信息汇报给NameNode,让 NameNode得到块的位置信息，并对每个文件对应的数据块副本进行统计。</p>
<p>如果hdfs数据量很大时，进入至退出安全模式时间较长。</p>
<h3 id="安全模式退出条件"><a href="#安全模式退出条件" class="headerlink" title="安全模式退出条件"></a>安全模式退出条件</h3><p>当最小副本条件满足时，即一定比例（dfs.safemode.threshold.pct缺省值0.999f）的数据块都达到最小副本数，系统就会退出安全模式。当最小副本条件未达到要求时，就会对副本数不足的数据块安排DataNode进行复制，直至达到最小副本数。如果datanode丢失的block达到一定的比例（1-dfs.safemode.threshold.pct），则系统会一直处于安全模式状态即只读状态。而在安全模式下，系统会处于只读状态，NameNode不会处理任何块的复制和删除命令。</p>
<p>dfs.safemode.threshold.pct（缺省值0.999f）表示HDFS启动的时候，如果DataNode上报的block个数达到了元 数据 记录的block个数的0.999倍才可以离开安全模式，否则一直是这种只读模式。如果设为1则HDFS永远是处于SafeMode。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>比较粗暴的方式，删除损坏掉的block</p>
<ol>
<li>执行命令退出安全模式：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop dfsadmin -safemode leave<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>执行健康检查，删除损坏掉的block。<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs fsck  &#x2F;  -delete<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里的路径虽然写的是<code>/</code>，但是不是删除所有文件，是删除根目录以下的所有的损坏的块文件</li>
</ol>
<p>生产环境一般考虑先恢复： 找到数据块的位置和丢失的数据信息</p>
<ol>
<li>查看/所有分区信息：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs hdfs fsck &#x2F; -files -blocks -locations<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>恢复数据文件，前提是，datanode里的block文件还存在，如果不存在了，虽然信息提示SUCCESS，但是其实还是没有恢复成功<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hdfs debug recoverLease -path $&#123;path&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
我这里使用恢复命令没有效果，直接到datanode的文件存储目录查看了以下，报找不到的block都找不到<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd &#x2F;data&#x2F;dfs&#x2F;dn&#x2F;current ## 通过查看hdfs-site.xml查看datanode的文件实际存储位置
find . -name &quot;blk_1073743358_2534*&quot;   ## 查看当前目录及以下，文件名包含blk_1073743358_2534的文件。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


</li>
</ol>
<p>通过查看hdfs-site.xmhjl找到datanode的日志文件路径：/var/log/hadoop-hdfs<br>查看datanode日志文件：<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D1.png" alt="hdfs块文件丢失恢复1"><br>通过日志可以看出，之前的恢复命令有的成功，有的失败，这里分别找了成功和失败的block查看了一下，发现成功日志的block块是恢复成功了，但是失败的确实没有成功</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">## 以下文件是成功的block块的文件，查看block块所属哪个文件路径，可以通过hdfs hdfs fsck &#x2F; -files -blocks -locations命令查看
[root@ddp3 tmp]# hadoop fs -ls &#x2F;tmp&#x2F;logs&#x2F;digiwin&#x2F;logs&#x2F;application_1645166873581_4910&#x2F;ddp4_8041
-rw-r-----   3 digiwin hadoop      70423 2022-03-01 11:13 &#x2F;tmp&#x2F;logs&#x2F;digiwin&#x2F;logs&#x2F;application_1645166873581_4910&#x2F;ddp4_8041<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>查看datanode3的log，找其中一块block查看具体的生成时间，已经从哪台节点复制过来的<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D2.png" alt="hdfs块文件丢失恢复2"><br>可以看出，blk_1073741854是2022-03-07 13:27:37从192.168.5.25复制过来的。<br>查看datanode3的blk_1073741854生成时间：<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D3.png" alt="hdfs块文件丢失恢复3"><br>查看datanode5的blk_1073741854生成时间：<br><img src="/uploads/202203/hdfs%E5%9D%97%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1%E6%81%A2%E5%A4%8D4.png" alt="hdfs块文件丢失恢复4"><br>可以很明显的看出，blk_1073741854在dn5上是2022-03-04的时候生成的，但是dn3是2022-03-07新复制的<br>所以，数据恢复操作，要有一个前提，丢失的块不能没有副本，需要从其他副本节点复制过来</p>
<p>这里也可以参考一下<a href="https://www.cnblogs.com/prayer21/p/4819789.html">HDFS中datanode节点block损坏后的自动恢复过程</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>maven编译Hudi与Flink源码</title>
    <url>/2022/03/10/maven%E7%BC%96%E8%AF%91Hudi%E4%B8%8EFlink%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>maven编译Hudi与Flink源码</li>
</ul>
<a id="more"></a>


<h2 id="maven编译hudi源码"><a href="#maven编译hudi源码" class="headerlink" title="maven编译hudi源码"></a>maven编译hudi源码</h2><p>到github上下载hudi源码，本文选择0.10.1版本</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;hudi.git -b release-0.10.1 <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h3><p>Flink-1.13.6<br>Scala-2.11<br>CDH-6.2.0<br>Hadoop-3.0.0<br>Hive-2.1.1<br>Hudi-0.10(release-0.10.1 )<br>maven-3.6.3<br>jdk-1.8</p>
<h3 id="配置maven并编译源代码"><a href="#配置maven并编译源代码" class="headerlink" title="配置maven并编译源代码"></a>配置maven并编译源代码</h3><p>为了加快下载速度，修改maven的settings.xml，添加aliyun远程仓库</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirror</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>alimaven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirrorOf</span><span class="token punctuation">></span></span>central,!cloudera<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirrorOf</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>aliyun maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>https://maven.aliyun.com/nexus/content/groups/public/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirror</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>注意：</strong> 这里是https，原本从自己电脑上复制下来是http，然后一直报如下错误：<br><img src="/uploads/202203/maven%E7%BC%96%E8%AF%91hudi%E6%8A%A5%E9%94%99%E6%97%A5%E5%BF%971.png" alt="maven编译hudi报错日志1"><br>编译时报错，显示连接中央仓库501<br>经过百度得知，原来中央仓库不再支持http访问，需要将路径更改为https</p>
<p>进入hudi源代码目录，并执行一下语句：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mvn clean install -DskipTests -Dmaven.test.skip&#x3D;true -Dscala-2.11 -Dhadoop.version&#x3D;3.0.0-cdh6.2.0 -Pflink-bundle-shade-hive2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>开始的时候没有指定跳过检查，导致一直报错，编译的时候，一定要跳过检查</p>
<ul>
<li>-DskipTests</li>
<li>-Dmaven.test.skip=true</li>
</ul>
<p>因为跳过了检查，hudi包里有两个测试模块，里面引用了hudi-common里的test的java类，需要从编译列表里去除，后期可以调查一下不跳过检查，怎么编译源码</p>
<p>跳过检查后，编译成功：<br><img src="/uploads/202203/Hudi%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E6%88%90%E5%8A%9F.png" alt="Hudi源码编译成功"></p>
<h3 id="编译结果说明"><a href="#编译结果说明" class="headerlink" title="编译结果说明"></a>编译结果说明</h3><p>packaging/hudi-flink-bundle/target下的hudi-flink-bundle jar 是 flink 用来写入和读取数据</p>
<h3 id="补充maven相关知识"><a href="#补充maven相关知识" class="headerlink" title="补充maven相关知识"></a>补充maven相关知识</h3><h4 id="Maven如何配置多个远程仓库"><a href="#Maven如何配置多个远程仓库" class="headerlink" title="Maven如何配置多个远程仓库"></a>Maven如何配置多个远程仓库</h4><p>常用配置：我们常用的配置是在maven的配置文件的 mirrors 标签中去配置远程仓库，但是 mirrors 标签中配置多个远程仓库的时候，只有第一个会生效，只有第一个仓库无法访问的时候才会使用第二个仓库，如果第一个仓库能访问，但是没有你所需要的依赖，那它是不会去第二个仓库中下载依赖的。所以如果在这里配置远程仓库的话，因为不同项目用到的依赖不一样，不是每个仓库中都有，这时候就需要你手动切换远程仓库。</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirror</span><span class="token punctuation">></span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>alimaven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mirrorOf</span><span class="token punctuation">></span></span>central,!cloudera<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirrorOf</span><span class="token punctuation">></span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>aliyun maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>http://maven.aliyun.com/nexus/content/groups/public/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mirror</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>多个远程仓库配置：在Maven的配置文件中的 profiles 标签下面配置多个远程仓库，这样配置之后，如果第一个仓库中如果没有你需要的依赖，或者第一个仓库无法访问，那么会自动的去第二个仓库中下载你需要的依赖，就不需要手动切换远程仓库了。</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>profiles</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>profile</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>myProfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repositories</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repository</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>myRepository<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>Repository for me<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>http://172.172.177.240:8081/nexus/content/groups/public<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repository</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>repository</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>deploymentRepo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>deploymentRepo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
                 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">></span></span>https://repo.digiwincloud.com.cn/maven/repository/releases/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">></span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repository</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>repositories</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>profile</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>profiles</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>activeProfiles</span><span class="token punctuation">></span></span>
     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>activeProfile</span><span class="token punctuation">></span></span>myProfile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>activeProfile</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>activeProfiles</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>注意：</strong></p>
<ul>
<li>在 profiles 标签中配置过远程仓库之后，mirrors 标签中就不需要再配置了，原先配置过也可以删掉或者注释掉。</li>
<li>settings.xml配置文件中最好不要写中文注释，一定要记得将中文注释删掉。</li>
</ul>
<h2 id="maven编译Flink源码"><a href="#maven编译Flink源码" class="headerlink" title="maven编译Flink源码"></a>maven编译Flink源码</h2><p>环境还是上面的环境，这里选用flink-1.13.6进行编译</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">wget https:&#x2F;&#x2F;dlcdn.apache.org&#x2F;flink&#x2F;flink-1.13.6&#x2F;flink-1.13.6-src.tgz --no-check-certificate
tar zxvf flink-1.13.6-src.tgz -C .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>以前需要先编译flink-shaded-hadoop这个包，将hadoop和hive指定你对应生产的版本编译出flink-shaded-hadoop-2-uber_xxx包，然后将这个包放在lib的目录下，flink启动任务的时候去lib加载。<br>自从1.11.0版本以后，Flink官方为了让Flink变得Hadoop Free，现在能支持hadoop2和hadoop3，同时可以指定不同的Hadoop环境<br>为了达到这一目标，通过设置export HADOOP_CLASSPATH=<code>hadoop classpath</code>即可，不用编译flink-shaded包。<br><strong>重点：</strong> 编译好的Flink的jar里面是没有包含Hadoop和Hive的代码。当Flink任务启动的时候，JM和TM都是通过HADOOP_CLASSPATH环境变量获取Hadoop的相关变量。</p>
<p>因为之前都已经配置过maven环境了，所以编译起来还是很方便的，直接运行编译代码：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">mvn clean install -DskipTests -Dfast -Drat.skip&#x3D;true -Dhaoop.version&#x3D;3.0.0-cdh6.2.0 -Pvendor-repos -Dinclude-hadoop -Dscala-2.11 -T10C

# -Dfast  #在flink根目录下pom.xml文件中fast配置项目中含快速设置,其中包含了多项构建时的跳过参数. #例如apache的文件头(rat)合法校验，代码风格检查，javadoc生成的跳过等，详细可阅读pom.xml
# install maven的安装命令
# -T10C #支持多处理器或者处理器核数参数,加快构建速度,推荐Maven3.3及以上
# -Pinclude-hadoop  将hadoop的 jar包，打入到lib&#x2F;中
# -Pvendor-repos   # 如果需要指定hadoop的发行商，如CDH，需要使用-Pvendor-repos
# -Dscala-2.11     # 指定scala的版本为2.11
# -Dhadoop.version&#x3D;3.0.0-cdh6.2.0  指定 hadoop 的版本，这里的版本与CDH集群版本的Hadoop一致就行<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Hudi</tag>
      </tags>
  </entry>
  <entry>
    <title>org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient报错，问题排查</title>
    <url>/2021/01/16/org-apache-hadoop-hive-ql-metadata-SessionHiveMetaStoreClient%E6%8A%A5%E9%94%99%EF%BC%8C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient报错，问题排查<a id="more"></a>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2>最近在整合pyspark与hive，新安装spark-2.3.3以客户端的方式访问hive数据，运行方式使用spark on yarn，但是在配置spark读取hive数据的时候，这里直接把hive下的hive-site.xml复制到spark目录下，启动了一次spark，上面的问题就出现了。</li>
</ul>
<h2 id="网上的说法："><a href="#网上的说法：" class="headerlink" title="网上的说法："></a>网上的说法：</h2><p>hive元数据问题，需要重新初始化hive的元数据<br>但是这个方法肯定不适合我，因为仓库里的表不能受影响，上千张表呢，如果初始化了，所有表都要重新创建。</p>
<h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><ul>
<li><p>首先查看服务器上/tmp/${user}/hive.log文件，这个是公司服务器当时配置的详细的hive执行日志。<br>在日志中，有一段报错：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">2019-07-06T10:01:53,737 ERROR [370c0a81-c922-4c61-8315-264c39b372c3 main] metastore.RetryingHMSHandler: MetaException(message:Hive Schema version 3.1.0 does not match metastore&#39;s schema version 1.2.0 Metastore is not upgraded or corrupt)
        at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:9063)
        at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:9027)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里的意思是，hive的版本是3.1.0，但是元数据中的版本信息是1.2.0，因此报错。</p>
</li>
<li><p>到hive的元数据库里查了下version表里的数据，确实版本是1.2.0</p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>这里猜测，spark在读取hive元数据的时候，因为spark是直接从官网上下载的，可能官网上的spark是用hive1.2.0版本编译的，所以，它默认使用的1.2.0，导致在启动的时候，修改了hive的元数据<br>但是具体的原因还不知道<br>下面会拿官网上的spark源码手动编译测试一下</p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2></li>
</ul>
<ol>
<li>直接修改version表的数据<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> version<span class="token punctuation">;</span>
<span class="token keyword">update</span> VERSION <span class="token keyword">set</span> SCHEMA_VERSION<span class="token operator">=</span><span class="token string">'2.1.1'</span> <span class="token keyword">where</span>  VER_ID<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
2、在hvie-site.xml中关闭版本验证<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<img src="/uploads/20210116/ive-metadata.png" alt="hive-metadata"></li>
</ol>
<h2 id="深入研究"><a href="#深入研究" class="headerlink" title="深入研究"></a>深入研究</h2><p>   在spark官网上查看了相关的资料，发现，在官网上下载的spark安装包，默认编译的hive版本是1.2.1的，所以每次启动spark的时候，会检查hive的版本。如果采用hive的默认配置，如果不一样，<br>就会修改version<br>    <img src="/uploads/20210116/hive-version-official-website.png" alt="hive-version-official-website"><br>一开始尝试着下载spark源码重新编译spark安装包，编译执行hive的版本为3.1.1，但是，发现每次指定hive的版本，maven下载依赖的时候，都会报错。<br>报错信息如下：</p>
<p>后来想了个折中的办法，spark还是使用原始版本，但是修改一下hive-site.xml文件。<br>    注意：这里修改的是spark的conf下的hive-site.xml，原始的hive里的不需要修改</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>
    Enforce metastore schema version consistency.
    True: Verify that version information stored in metastore matches with one from Hive jars.  Also disable automatic
          schema migration attempt. Users are required to manually migrate schema after Hive upgrade which ensures
          proper metastore schema migration. (Default)
    False: Warn if the version information stored in metastore doesn't match with one from in Hive jars.
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification.record.version<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>
    When true the current MS version is recorded in the VERSION table. If this is disabled and verification is
     enabled the MS will be unusable.
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这两个配置的具体含义：</p>
<ul>
<li><code>hive.metastore.schema.verification</code> 如果设置为true，那么每次启动hive或者spark的时候，都会检查hive的版本。如果为false，则会告警  </li>
<li><code>hive.metastore.schema.verification.record.version</code> 如果设置为true，每次启动spark的时候，如果检查了hive的版本和spark编译的版本不一致，那么就会修改hive的元数据</li>
</ul>
<p>这里的修改需要设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hive.metastore.schema.verification&#x3D;false   
hive.metastore.schema.verification.record.version&#x3D;false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>以下有3个反例：</p>
<ul>
<li>如过这两个都为true，那么spark会修改hive元数据</li>
<li>如果<code>hive.metastore.schema.verification=true</code>，<br>并且<code>hive.metastore.schema.verification.record.version=false</code>，这时候启动spark就会报错：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: MetaException(message:Hive Schema version 1.2.0 does not match metastore&#39;s schema version 3.1.0 Metastore is not upgraded or corrupt)
	at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:6679)
	at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:6645)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>如果设置<code>hive.metastore.schema.verification=false</code><br>且<code>hive.metastore.schema.verification.record.version=true</code>，spark还是会修改hive的元数据</li>
</ul>
<p><img src="/uploads/20210116/hive-metastore-schema-verification.png" alt="hive-metastore-schema-verification"><br><img src="/uploads/20210116/hive-metastore-latest-effect.png" alt="hive-metastore-latest-effect"></p>
<p>所以，只要设置<code>hive.metastore.schema.verification.record.version=false</code>就可以了，但是为了保险起见，我两个都设置成false了</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>linux杂记（一）</title>
    <url>/2021/01/16/linux%E6%9D%82%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>shell常用语法</li>
<li>shell实用命令<a id="more"></a>
<h2 id="IF-条件判断"><a href="#IF-条件判断" class="headerlink" title="IF 条件判断"></a>IF 条件判断</h2><h3 id="判断-boot-分区可用容量小于-20MB-时报警，否则显示-OK"><a href="#判断-boot-分区可用容量小于-20MB-时报警，否则显示-OK" class="headerlink" title="判断 boot 分区可用容量小于 20MB 时报警，否则显示 OK"></a>判断 boot 分区可用容量小于 20MB 时报警，否则显示 OK</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">df | grep &quot;boot&quot; | awk &#39; &#123;if ($4&lt;20000)  print &quot;Alart&quot; ; else print &quot;OK&quot;&#125;&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="While-循环"><a href="#While-循环" class="headerlink" title="While 循环"></a>While 循环</h2><h3 id="指定范围内执行动作"><a href="#指定范围内执行动作" class="headerlink" title="指定范围内执行动作"></a>指定范围内执行动作</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 语法一
awk &#39;i&#x3D;1 &#123;&#125; BEGIN &#123;while (i&lt;3) &#123;++i;print i&#125;&#125;&#39; test.txt 
# 语法二
awk &#39;BEGIN &#123;do &#123;++i;print i&#125; while (i&lt;3)&#125;&#39; test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="For-循环"><a href="#For-循环" class="headerlink" title="For 循环"></a>For 循环</h2><h3 id="for-变量；条件；计数器"><a href="#for-变量；条件；计数器" class="headerlink" title="for (变量；条件；计数器)"></a>for (变量；条件；计数器)</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">awk &#39;BEGIN &#123;for (i&#x3D;1;i&lt;3;i++) print i&#125;&#39; test.txt
awk &#39;BEGIN &#123;for (i&#x3D;3;i&gt;1;i--) print i&#125;&#39; test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
上述 While 和 For 循环语句使用的 awk 均使用 BEGIN 模式，即在未读取文档内容前就会将 BEGIN 代码执行完毕，所以输入文档可以是任意文档。<br>具体参考：<br><a href="https://blog.csdn.net/sunny_future/article/details/80287236">https://blog.csdn.net/sunny_future/article/details/80287236</a></li>
</ul>
<h2 id="查询文件下所有文件是否包含某个字符串"><a href="#查询文件下所有文件是否包含某个字符串" class="headerlink" title="查询文件下所有文件是否包含某个字符串"></a>查询文件下所有文件是否包含某个字符串</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">find .| xargs grep -ri &quot;class&quot; <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="目录下的所有文件中查找字符串-并且只打印出含有该字符串的文件名"><a href="#目录下的所有文件中查找字符串-并且只打印出含有该字符串的文件名" class="headerlink" title="目录下的所有文件中查找字符串,并且只打印出含有该字符串的文件名"></a>目录下的所有文件中查找字符串,并且只打印出含有该字符串的文件名</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">find .| xargs grep -ri &quot;class&quot; -l <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="遍历指定文件夹下所有文件"><a href="#遍历指定文件夹下所有文件" class="headerlink" title="遍历指定文件夹下所有文件"></a>遍历指定文件夹下所有文件</h2><h3 id="采用递归的方式"><a href="#采用递归的方式" class="headerlink" title="采用递归的方式"></a>采用递归的方式</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">function scandir() &#123;
    local cur_dir parent_dir workdir
    workdir&#x3D;$1
    cd $&#123;workdir&#125;
    if [ $&#123;workdir&#125; &#x3D; &quot;&#x2F;&quot; ]
    then
        cur_dir&#x3D;&quot;&quot;
    else
        cur_dir&#x3D;$(pwd)
    fi

    for dirlist in $(ls $&#123;cur_dir&#125;)
    do
        if test -d $&#123;dirlist&#125;;then
            cd $&#123;dirlist&#125;
            scandir $&#123;cur_dir&#125;&#x2F;$&#123;dirlist&#125;
            cd ..
        else
            echo $&#123;cur_dir&#125;&#x2F;$&#123;dirlist&#125;
        fi
    done                       
&#125;

if test -d $1                  
then
    scandir $1                 
elif test -f $1                
then
    echo &quot;you input a file but not a directory,pls reinput and try again&quot;
    exit 1
else
    echo &quot;the Directory isn&#39;t exist which you input,pls input a new one!!&quot;
    exit 1
fi
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="利用命令行："><a href="#利用命令行：" class="headerlink" title="利用命令行："></a>利用命令行：</h3><p>获取bigdata下所有的以.sh结尾的文件</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">find &#x2F;home&#x2F;bigdata -name &quot;*.sh&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>参考：<br>    <a href="https://blog.csdn.net/u010801696/article/details/78913494">https://blog.csdn.net/u010801696/article/details/78913494</a></p>
<h2 id="ftp在centos下如何登陆"><a href="#ftp在centos下如何登陆" class="headerlink" title="ftp在centos下如何登陆"></a>ftp在centos下如何登陆</h2><h3 id="ftp的登陆方式"><a href="#ftp的登陆方式" class="headerlink" title="ftp的登陆方式"></a>ftp的登陆方式</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ftp
open ip port
## 输入完host以后，会弹出让输入用户名和密码，之后就登陆进去了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="sftp的登陆方式"><a href="#sftp的登陆方式" class="headerlink" title="sftp的登陆方式"></a>sftp的登陆方式</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sftp -P port user@ip
## 回车后提示输入密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="lftp（不需要手动输入用户名密码，常用于自动化脚本中）"><a href="#lftp（不需要手动输入用户名密码，常用于自动化脚本中）" class="headerlink" title="lftp（不需要手动输入用户名密码，常用于自动化脚本中）"></a>lftp（不需要手动输入用户名密码，常用于自动化脚本中）</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">lftp -u user,psw sftp:&#x2F;&#x2F;ip:host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="ftp使用模糊查询下载所有匹配的文件"><a href="#ftp使用模糊查询下载所有匹配的文件" class="headerlink" title="ftp使用模糊查询下载所有匹配的文件"></a>ftp使用模糊查询下载所有匹配的文件</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">open 192.168.1.1 10021
prompt   ##取消ftp的交互式，否则每次下载下一个文件都要回车一下，仅对当前窗口有效，ftp退出后，下次进入需要重新prompt
mget 2020-05-12*   #下载正则匹配上的所有文件
get aaa.dat    # 下载指定文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="ubuntu下替换apt-get的源"><a href="#ubuntu下替换apt-get的源" class="headerlink" title="ubuntu下替换apt-get的源"></a>ubuntu下替换apt-get的源</h3><p>参考<a href="https://www.cnblogs.com/gabin/p/6519352.html">https://www.cnblogs.com/gabin/p/6519352.html</a></p>
<h3 id="解决出现-unable-to-resolve-host-问题"><a href="#解决出现-unable-to-resolve-host-问题" class="headerlink" title="解决出现 unable to resolve host 问题"></a>解决出现 unable to resolve host 问题</h3><p>ubuntu在sudo的时候，总是出现unable to resolve host，解决步骤：</p>
<ul>
<li>修改 /etc/hosts里的127.0.0.1 localhost 后面加上主机名称（127.0.0.1 localhost aaa）</li>
<li>修改/etc/hostname，这里的名称和上面的主机名称保持一致(aaa)</li>
</ul>
<h3 id="ssh免秘钥"><a href="#ssh免秘钥" class="headerlink" title="ssh免秘钥"></a>ssh免秘钥</h3><p>用过好几次免秘钥，但是每次都会忘了应该把copy谁的公钥到另外用户的.ssh文件夹<br>这里专门记录一次</p>
<blockquote>
<p>A要使用ssh免密登录到B用户下（可以使远程服务器），就把A的用户下的.ssh文件的id_rsa.pub 内容 cat到远程服务器B 的.ssh的authorized_keys 文件里</p>
</blockquote>
<blockquote>
<p>说明白点就是，A用户如果想免秘钥登录B用户，那么就需要把公钥先让B用户知道。这样就是自己人了。</p>
</blockquote>
<p>还有一个注意点：<br>如果希望ssh公钥生效需满足至少下面两个条件：</p>
<ul>
<li>.ssh目录的权限必须是700 </li>
<li>.ssh/authorized_keys文件权限必须是600</li>
</ul>
<p>具体可以参考<br><a href="https://www.jb51.net/article/94599.htm">https://www.jb51.net/article/94599.htm</a></p>
<h3 id="awk实现sql中group-by，count的功能"><a href="#awk实现sql中group-by，count的功能" class="headerlink" title="awk实现sql中group by，count的功能"></a>awk实现sql中group by，count的功能</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">awk -F &quot; &quot; &#39;&#123; w[$2]+&#x3D;1&#125; END&#123; for (a in w)  print a, w[a]&#125;&#39; detail.csv  &gt; aaa.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>可以参考<br><a href="https://www.cnblogs.com/ginvip/p/6352157.html">https://www.cnblogs.com/ginvip/p/6352157.html</a><br><a href="http://www.blogjava.net/henry14/archive/2012/01/15/368560.html">http://www.blogjava.net/henry14/archive/2012/01/15/368560.html</a></p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>python实现scp功能</title>
    <url>/2021/01/16/python%E5%AE%9E%E7%8E%B0scp%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p>最近公司有一个需求，需要把服务器A上的任务放到服务器B上，因为B上有HTTP，并且可以被外网访问，但是直接通过shell的scp，每次都需要输入密码。这里用python简单实现一下</p>
<p>直接上代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> paramiko
<span class="token keyword">import</span> sys

<span class="token keyword">def</span> <span class="token function">deleteRemoteFile</span><span class="token punctuation">(</span>dt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ssh <span class="token operator">=</span> paramiko<span class="token punctuation">.</span>SSHClient<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssh<span class="token punctuation">.</span>set_missing_host_key_policy<span class="token punctuation">(</span>paramiko<span class="token punctuation">.</span>AutoAddPolicy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#第一次登录的认证信息</span>
    ssh<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>hostname<span class="token operator">=</span><span class="token string">'192.168.72.208'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">,</span> username<span class="token operator">=</span><span class="token string">'gold'</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'gold!23'</span><span class="token punctuation">)</span> <span class="token comment"># 连接服务器</span>
    stdin<span class="token punctuation">,</span> stdout<span class="token punctuation">,</span> stderr <span class="token operator">=</span> ssh<span class="token punctuation">.</span>exec_command<span class="token punctuation">(</span><span class="token string">'rm /home/gold/data//*'</span><span class="token punctuation">)</span> <span class="token comment"># 执行命令</span>
    ssh<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">uploadFile2Remote</span><span class="token punctuation">(</span>dt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    transport <span class="token operator">=</span> paramiko<span class="token punctuation">.</span>Transport<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'192.168.72.208'</span><span class="token punctuation">,</span> <span class="token number">65522</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    transport<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>username<span class="token operator">=</span><span class="token string">'gold'</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'gold!23'</span><span class="token punctuation">)</span>
    sftp <span class="token operator">=</span> paramiko<span class="token punctuation">.</span>SFTPClient<span class="token punctuation">.</span>from_transport<span class="token punctuation">(</span>transport<span class="token punctuation">)</span>
    sftp<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">'/home/gold/data/broad.png'</span><span class="token punctuation">,</span> <span class="token string">'/home/gold/data/broad_%s.png'</span> <span class="token operator">%</span> dt<span class="token punctuation">)</span>
    transport<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    unix_ts <span class="token operator">=</span> sys<span class="token punctuation">.</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    deleteRemoteFile<span class="token punctuation">(</span>unix_ts<span class="token punctuation">)</span>
    uploadFile2Remote<span class="token punctuation">(</span>unix_ts<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h2><ul>
<li>这里有一个坑，就是sftp在put的时候，需要把在208服务器上的文件名写出来，代码执行的逻辑想当于先touch 一个文件，然后往这个文件里写数据，如果不加文件名，直接到文件夹，就会报错</li>
</ul>
<p>具体的可以参考：<br><a href="https://www.cnblogs.com/fang123456/p/7235688.html">python实现ssh及sftp功能</a></p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title>python杂记（一）</title>
    <url>/2021/01/18/python%E6%9D%82%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h2 id="使用-args简化输入代码"><a href="#使用-args简化输入代码" class="headerlink" title="使用**args简化输入代码"></a>使用**args简化输入代码</h2><p>test(<strong>kwargs)</strong> 的作用则是把字典 kwargs 变成关键字参数传递。比如，如果 kwargs 等于 {‘a’:1,’b’:2,’c’:3} ，那这个代码就等价于 test(a=1,b=2,c=3) 。</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>python调用jenkinsAPI构建jenkins，并传递参数</title>
    <url>/2021/01/16/python%E8%B0%83%E7%94%A8jenkinsAPI%E6%9E%84%E5%BB%BAjenkins%EF%BC%8C%E5%B9%B6%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>安装jenkins</li>
<li>通过pythonAPI实现参数化jenkins构建</li>
</ul>
<a id="more"></a>
<h2 id="安装jenkins"><a href="#安装jenkins" class="headerlink" title="安装jenkins"></a>安装jenkins</h2><p>安装jenkins很简单，可以用多种方式安装，这里知道的有：</p>
<ul>
<li>在官网下载rpm包，手动安装，最费事</li>
<li>centos系统通过yum安装，ubuntu通过apt-get安装(不推荐，因为很多东西都使用了默认的)</li>
<li>直接下载官网上的war包：wget <a href="http://ftp-chi.osuosl.org/pub/jenkins/war-stable/2.164.2/jenkins.war">http://ftp-chi.osuosl.org/pub/jenkins/war-stable/2.164.2/jenkins.war</a></li>
</ul>
<p>我这里直接用的下载war包</p>
<h2 id="遇到的坑"><a href="#遇到的坑" class="headerlink" title="遇到的坑"></a>遇到的坑</h2><p>在安装之前，公司的服务器上已经有一个版本的jekins在运行了，所有参数都已经被设置过了，所以，重新安装的版本，虽然文件夹，用户都和以前的版本不一样，但是每次jenkins页面都是直接跳转上个版本的，并不会进入首次激活jenkins的界面</p>
<p>原因是：公司的服务器上配置了JENKINS_HOME，但是jenkins在启动的时候，会首先获取JENKINS_HOME,并读取文件夹内的配置信息。</p>
<p>解决办法：这里取了个巧，在每次启动jenkins的时候，手动指定JENKINS_HOME=/data/jenkins2,这样就不会读取上个版本的信息了</p>
<h2 id="通过pythonAPI实现参数化jenkins构建"><a href="#通过pythonAPI实现参数化jenkins构建" class="headerlink" title="通过pythonAPI实现参数化jenkins构建"></a>通过pythonAPI实现参数化jenkins构建</h2><p>这里要实现的场景是，通过前端的页面，选择相应的下拉框，传递参数到后台jenkins，然后jenkins获取相应的参数，计算以这些参数为条件的数据。</p>
<h2 id="创建jenkins项目"><a href="#创建jenkins项目" class="headerlink" title="创建jenkins项目"></a>创建jenkins项目</h2><p>这里创建的项目需要添加param</p>
<p><img src="/uploads/20210116/jenkins-param.png" alt="hive-import-data"></p>
<p>需要几个参数，就添加几个参数</p>
<h3 id="安装python-jenkins"><a href="#安装python-jenkins" class="headerlink" title="安装python-jenkins"></a>安装python-jenkins</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo pip install python-jenkins<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>直接上代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> jenkins
server <span class="token operator">=</span> jenkins<span class="token punctuation">.</span>Jenkins<span class="token punctuation">(</span><span class="token string">'http://192.168.59.149:28080'</span><span class="token punctuation">,</span> username<span class="token operator">=</span><span class="token string">'jenkins'</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'jenkins@!23'</span><span class="token punctuation">)</span>
server<span class="token punctuation">.</span>build_job<span class="token punctuation">(</span><span class="token string">'jxInstantQuery'</span><span class="token punctuation">)</span>
server<span class="token punctuation">.</span>build_job<span class="token punctuation">(</span><span class="token string">'jxInstantQuery2'</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">'param1'</span><span class="token punctuation">:</span> <span class="token string">'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'</span><span class="token punctuation">,</span> <span class="token string">'param2'</span><span class="token punctuation">:</span> <span class="token string">'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>里面的执行shell：<br><img src="/uploads/20210116/jenkins-build.png" alt="hive-import-data"></p>
<p>最终的效果：<br><img src="/uploads/20210116/jenkins-console.png" alt="hive-import-data"></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>spark on yarn遇到的问题（一）</title>
    <url>/2021/01/18/spark%20on%20yarn%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态</li>
<li>spark on yarn任务提交缓慢解决</li>
</ul>
<a id="more"></a>
<h1 id="以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态"><a href="#以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态" class="headerlink" title="以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态"></a>以yarn-client方式提交spark任务，任务一直卡在ACCEPTED状态</h1><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>   spark是以客户端的方式安装的，并没有启动spark的mesos集群，这时候的spark就相当与hive客户端。<br>   以local模型和yarn-cluster方式提交任务，都能正确额执行，但是一yarn-client方式就卡在ACCEPTED</p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>在网上查了资料，都说是资源不够用，需要调整<code>yarn.scheduler.capacity.maximum-am-resource-percent</code>从0.1改成0.5，<br>但是我测试数据才几k，集群内存128G，所以我直接排除了这个原因。后来想到，只有<code>yarn-client</code>方式失败，那问题应该出来driver端。<br>就查看了一下服务器的/etc/hosts，发现diver上有集群其他节点的IP等信息，但是其他节点没有driver配置信息，导致<code>driver</code>能访问到集群，<br>但是集群其他节点访问不了driver，所以<code>local</code>模式可以执行<br><code>yarn-cluster</code>上可以执行，是因为客户端只要把任务提交到yarn上，客户端就没有用了。<br>但是<code>yarn-client</code>方式，客户端是充当了<code>driver</code>，<code>driver</code>需要一直和集群有通信，所以接收不到<code>resouceManager</code>的反馈。任务就一直卡住了</p>
<h2 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h2><p>   有两个方法：<br>   1、在命令后面加上一个–conf spark.driver.host=$your_ip_address，后面直接填客户端机器的IP地址就行<br> <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark-submit \ 
        --master yarn \
        --deploy-mode client \
        --num-executors 2 \
        --executor-memory 1G \
        --executor-cores 1 \
        --conf spark.driver.host&#x3D;192.168.72.129\
         dmp_broadcast_data_day.py
 &#96;&#96;&#96;   
   2、在集群其他节点上都把driver服务器的IP加上去。

# spark on yarn任务提交缓慢解决
## 问题背景
   在使用pyspark提交任务导yarn上的时候，每次提交任务，都要等待好长时间，但是在之前公司中，提交任务导yarn上很快的，所以就调查了一下
   在提交任务的时候，有一个WARN的日志：
&#96;&#96;&#96;shell
    WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>   在网上查了一下，每一次我们运行的时候，如果没有指定 <code>spark.yarn.archive or spark.yarn.jars</code>，Spark将在安装路径下的Jar目录，将其所有的Jar包打包然后将其上传到分布式缓存<br>   官网的原话：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">To make Spark runtime jars accessible from YARN side, you can specify spark.yarn.archive or spark.yarn.jars. For details please refer to Spark Properties. If neither spark.yarn.archive nor spark.yarn.jars is specified, Spark will create a zip file with all jars under $SPARK_HOME&#x2F;jars and upload it to the distributed cache.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="调优方法"><a href="#调优方法" class="headerlink" title="调优方法"></a>调优方法</h2><ul>
<li>首先将Spark安装路径下的所有jar包上传到HDFS上</li>
<li>在spark的conf目录下的spark-defaults.conf添加<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark.yarn.archive               hdfs:&#x2F;&#x2F;ycluster-3&#x2F;data&#x2F;hadoop&#x2F;spark-jars&#x2F;*jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="有个bug"><a href="#有个bug" class="headerlink" title="有个bug"></a>有个bug</h3>我记得我当时按照这个步骤修改完，提交任务导yarn上之后，会报以下错误<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ERROR SparkContext: Error initializing SparkContext.
org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.
    at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:85)
    at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:62)
    at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:156)
    at org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:509)
    at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2313)
    at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:868)
    at org.apache.spark.sql.SparkSession$Builder$$anonfun$6.apply(SparkSession.scala:860)
    at scala.Option.getOrElse(Option.scala:121)
    at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:860)
    at org.apache.spark.repl.Main$.createSparkSession(Main.scala:95)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
这里以前忘记怎么修复的了，现在果然又遇到了，查了很多资料，总结出两点：</li>
<li>spark-env.sh文件中的HADOOP_CONF_DIR配置错误</li>
<li>yarn的虚拟内存超限，contrainer被干杀死</li>
</ul>
<p>这里查了一下，我的是spark-end.sh配置没问题，问题出现在第二点<br>我的<code>yarn-site.xml</code>的<code>yarn.nodemanager.vmem-pmem-ratio=2.1</code>，虚拟内存最大是2.1，查看yarn上的日志，发现实际内存是2.2，所以，这里把它设置成了3.1</p>
<pre class="line-numbers language-none"><code class="language-none">&lt;!--2个配置只用配置一个即可解决问题，当然都配置也没问题--&gt;
&lt;!--虚拟内存设置是否生效,若实际虚拟内存大于设置值 &quot;--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;&#x2F;name&gt;
    &lt;value&gt;false&lt;&#x2F;value&gt;
    &lt;description&gt;Whether virtual memory limits will be enforced for containers&lt;&#x2F;description&gt;
&lt;&#x2F;property&gt;
&lt;!--配置虚拟内存&#x2F;物理内存的值，默认为2.1,物理内存默认应该是1g，所以虚拟内存是2.1g--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;&#x2F;name&gt;
    &lt;value&gt;3.1&lt;&#x2F;value&gt;
    &lt;description&gt;Ratio between virtual memory to physical memory when setting memory limits for containers&lt;&#x2F;description&gt;
&lt;&#x2F;property&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title>spark性能优化之序列化</title>
    <url>/2021/01/15/spark%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96/</url>
    <content><![CDATA[<h3 id="序列化是干什么的？"><a href="#序列化是干什么的？" class="headerlink" title="序列化是干什么的？"></a>序列化是干什么的？</h3><p>序列化简单来说就保存对象在内存中的状态也可以说是实例化变量。这是Java提供的用来保存 Object state，一种保存对象状态的机制。只有实现了serializable接口的类的对象才能被实例化<br>Java中，一切都是对象，在分布式环境中经常需要将Object从这一端网络或设备传递到另一端。这就需要有一种可以在两端传输数据的协议。Java序列化机制就是为了解决这个问题而产生。</p>
<h3 id="什么情况下会用到序列化？"><a href="#什么情况下会用到序列化？" class="headerlink" title="什么情况下会用到序列化？"></a>什么情况下会用到序列化？</h3><ul>
<li>当你想把内存中的对象写入到硬盘时</li>
<li>当你想用套接字在网络上传输对象时</li>
<li>当你想通过RMI调用对象时(RMI总结来说就是远程调用对象，在一个jvm上调用另一个jvm的对象)</li>
</ul>
<h3 id="Spark为什么需要序列化？"><a href="#Spark为什么需要序列化？" class="headerlink" title="Spark为什么需要序列化？"></a>Spark为什么需要序列化？</h3><p>Spark是分布式执行引擎，其核心抽象是弹性分布式数据集RDD，其代表了分布在不同节点的数据。Spark的计算是在executor上分布式执行的，所以对象在执行中需要通过网络传输，或者持久化到本地磁盘的时候必须要经过序列化。</p>
<h3 id="Spark支持的序列化"><a href="#Spark支持的序列化" class="headerlink" title="Spark支持的序列化"></a>Spark支持的序列化</h3><p>spark默认使用的是java序列化，java序列化的好处是非常灵活，开发起来很简单，缺点是速度较慢，在某些情况下序列化的结果也比较大<br>Spark也能使用Kryo（版本2）序列化对象。Kryo不但速度极快，而且产生的结果更为紧凑（通常能提高10倍）。Kryo的缺点是不支持所有类型，为了更好的性能，你需要提前注册程序中所使用的类（class）。</p>
<h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Test"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>set<span class="token punctuation">(</span><span class="token string">"spark.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.spark.serializer.KryoSerializer"</span><span class="token punctuation">)</span>   <span class="token comment">//声明序列化器为KryoSerializer</span>
      <span class="token punctuation">.</span>registerKryoClasses<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>MyClass1<span class="token punctuation">]</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span>MyClass2<span class="token punctuation">]</span><span class="token punctuation">,</span>classOf<span class="token punctuation">[</span>MyClass3<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">//注册要序列化的自定义类型</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>参考：<a href="https://tech.meituan.com/2016/04/29/spark-tuning-basic.html">https://tech.meituan.com/2016/04/29/spark-tuning-basic.html</a><br>原则八</p>
<h3 id="spark性能调优"><a href="#spark性能调优" class="headerlink" title="spark性能调优"></a>spark性能调优</h3><p>有篇文章写得很好，可以参考下<br><a href="https://www.cnblogs.com/stillcoolme/p/10576563.html">https://www.cnblogs.com/stillcoolme/p/10576563.html</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>spark-sql使用笔记</title>
    <url>/2021/01/18/spark-sql%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>spark-sql如何使用hive的udf</li>
<li>spark-sql解决小文件问题</li>
<li>spark-sql cli 输出日志级别为warn</li>
<li>sparksql读取hive数据报错<a id="more"></a>
<h2 id="如何使用hive的udf"><a href="#如何使用hive的udf" class="headerlink" title="如何使用hive的udf"></a>如何使用hive的udf</h2></li>
<li>可以使用<code>spark-sql --jars /opt/hive/udf.jar</code>,指定udf的路径 </li>
<li>还可以在<code>spark-default.conf</code>里指定<code>spark.jars    /opt/hive/udf.jar</code></li>
</ul>
<h2 id="Truncated-the-string-representation-of-a-plan-since-it-was-too-large"><a href="#Truncated-the-string-representation-of-a-plan-since-it-was-too-large" class="headerlink" title="Truncated the string representation of a plan since it was too large"></a>Truncated the string representation of a plan since it was too large</h2><p>在<code>spark-default.conf</code>里设置</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark.sql.debug.maxToStringFields   2000
spark.debug.maxToStringFields   2000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决："><a href="#使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决：" class="headerlink" title="使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决："></a>使用sparksql默认情况下会生成很多小文件，设置如下参数可以解决：</h2><ul>
<li>通过设置spark参数，<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">set spark.sql.adaptive.enabled&#x3D;true;
set set spark.sql.adaptive.shuffle.targetPostShuffleInputSize &#x3D; 134217728;
# 在sql中添加：distribute by cast(rand() * 5 as int)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
具体可以参考：<a href="https://www.jianshu.com/p/ddd2382a738a">如何避免Spark SQL做数据导入时产生大量小文件</a><br>这个方式不太靠谱，一开始设置的时候，没什么问题，但是后面不知道集群配置更改了什么，导致这个设置失效了。</li>
<li>通过REPARTITION或者COALESCE，将Hive风格的Coalesce and Repartition Hint 应用到Spark SQL</li>
</ul>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">INSERT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">SELECT</span> <span class="token comment">/*+ COALESCE(numPartitions) */</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">INSERT</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">SELECT</span> <span class="token comment">/*+ REPARTITION(numPartitions) */</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>例如：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>adaptive<span class="token punctuation">.</span>enabled<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>adaptive<span class="token punctuation">.</span>shuffle<span class="token punctuation">.</span>targetPostShuffleInputSize <span class="token operator">=</span> <span class="token number">134217728</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> app<span class="token punctuation">.</span>app_prom_realtime_marketing_use_coupon_effect_da <span class="token keyword">partition</span><span class="token punctuation">(</span>dt <span class="token operator">=</span> <span class="token string">'$&#123;dt&#125;'</span><span class="token punctuation">)</span>
<span class="token keyword">select</span> <span class="token comment">/*+ COALESCE(1) */</span>
       from_unixtime<span class="token punctuation">(</span>unix_timestamp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'yyyy-MM-dd HH:mm:ss'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> etl_date<span class="token punctuation">,</span>
       business_id                                                                                        <span class="token punctuation">,</span><span class="token comment">--商家ID</span>
       business_name                                                                                       <span class="token comment">--商家名称</span>
<span class="token keyword">from</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>app_prom_realtime_marketing_use_coupon_effect_da_20210311_01<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意：单纯使用<code>/*+ COALESCE(1) */</code>，文件数不是1，但也不会有200个空文件了，通过设置两个<code>set</code>，保证文件数可以为1<br>这种方式对spark的版本有要求，最好在2.4.x以上<br>还可以设置一下<code>set spark.sql.hive.mergeFiles=true;</code></p>
<h2 id="spark-sql-cli-输出日志级别为warn"><a href="#spark-sql-cli-输出日志级别为warn" class="headerlink" title="spark-sql cli 输出日志级别为warn"></a>spark-sql cli 输出日志级别为warn</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spark-sql --name &#39;gjc_spark_cli&#39; \
          --conf &quot;spark.driver.extraJavaOptions&#x3D;-Dlog4j.configuration&#x3D;file:configure&#x2F;log4j.properties&quot; \  ## 用自己的log4j替代客户端的。公司客户端的是info级别，垃圾信息太多
          --conf spark.ui.showConsoleProgress&#x3D;true \      ## 这个参数可以看到执行进度条
          --master yarn \
          --num-executors 20 \
          --executor-memory 6G \
          --driver-cores 4 \
          --driver-memory 6G<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="sparksql读取hive数据报错"><a href="#sparksql读取hive数据报错" class="headerlink" title="sparksql读取hive数据报错"></a>sparksql读取hive数据报错</h2><ul>
<li>问题：  <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 0
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1016)
	... 65 more
Caused by: java.lang.IndexOutOfBoundsException: Index: 0
	at java.util.Collections$EmptyList.get(Collections.java:4454)
	at org.apache.hadoop.hive.ql.io.orc.OrcProto$Type.getSubtypes(OrcProto.java:12240)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.getColumnIndicesFromNames(ReaderImpl.java:651)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.getRawDataSizeOfColumns(ReaderImpl.java:634)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.populateAndCacheStripeDetails(OrcInputFormat.java:927)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:836)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat$SplitGenerator.call(OrcInputFormat.java:702)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
java.lang.RuntimeException: serious problem
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.generateSplitsInfo(OrcInputFormat.java:1021)
	at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getSplits(OrcInputFormat.java:1048)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:46)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>原因：<br> sparksql生成的hive表有空文件，但是sparksql读取空文件的时候，因为表示orc格式的，导致sparksql解析orc文件出错。但是用hive却可以正常读取。</li>
</ul>
<h2 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h2><p>设置<code>set spark.sql.hive.convertMetastoreOrc=true</code><br>单纯的设置以上参数还是会报错：  </p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">java.lang.IndexOutOfBoundsException
	at java.nio.Buffer.checkIndex(Buffer.java:540)
	at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:139)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.extractMetaInfoFromFooter(ReaderImpl.java:374)
	at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&lt;init&gt;(ReaderImpl.java:316)
	at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:187)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$getFileReader$2.apply(OrcFileOperator.scala:75)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$getFileReader$2.apply(OrcFileOperator.scala:73)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.TraversableOnce$class.collectFirst(TraversableOnce.scala:145)
	at scala.collection.AbstractIterator.collectFirst(Iterator.scala:1336)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$.getFileReader(OrcFileOperator.scala:86)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$readSchema$1.apply(OrcFileOperator.scala:95)
	at org.apache.spark.sql.hive.orc.OrcFileOperator$$anonfun$readSchema$1.apply(OrcFileOperator.scala:95)
	at scala.collection.immutable.Stream.flatMap(Stream.scala:489)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>需要再设置<code>set spark.sql.orc.impl=native</code><br>参考<a href="https://issues.apache.org/jira/browse/SPARK-19809">SPARK-19809</a> </p>
<h2 id="两个大表关联，报OOM"><a href="#两个大表关联，报OOM" class="headerlink" title="两个大表关联，报OOM"></a>两个大表关联，报OOM</h2><p>主表数据量6000多万，从表1亿，关联后出现OOM的情况</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">Container killed by YARN for exceeding memory limits. 6.3 GB of 6 GB physical memory used. 
Consider boosting spark.yarn.executor.memoryOverhead.

FetchFailed(null, shuffleId&#x3D;4, mapId&#x3D;-1, reduceId&#x3D;121, message&#x3D;
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 4
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:867)
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:863)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>分析了一下原因，在计算主表和从表的时候，都是使用spark-sql的默认并行度，<br>所以最终都是输出200个文件，最后关联完成还是写出200个文件</p>
<p>这里设置spark-sql的默认并行度为1000，这样主表和从表的数据文件都会变成1000，每次关联的数据量就会小很多<br><code>set spark.sql.shuffle.partitions = 1000;</code><br>问题解决</p>
<h2 id="spark-sql读取hive-orc表报数组越界"><a href="#spark-sql读取hive-orc表报数组越界" class="headerlink" title="spark-sql读取hive orc表报数组越界"></a>spark-sql读取hive orc表报数组越界</h2><p>最近公司上云，spark版本切换到3.0.0，很多数据上传到腾讯云上的环境后，spark-sql报数组越界，具体报错信息如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: java.lang.ArrayIndexOutOfBoundsException: 11
	at org.apache.orc.mapred.OrcStruct.getFieldValue(OrcStruct.java:49)
	at org.apache.spark.sql.execution.datasources.orc.OrcDeserializer.deserialize(OrcDeserializer.scala:60)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>具体问题：使用spark-sql读取hive表，<code>select *</code>可以读取，但是<code>select</code>字段名，就会报数组越界<br>在网上查了很多办法，最终查到原因应该是spark-sql和hive引擎解析orc的方式不一样。</p>
<p>可以通过设置<code>set spark.sql.orc.impl = hive;</code>来解决<br>参考了<a href="https://support.huaweicloud.com/cmpntguide-mrs/mrs_01_1964.html">配置矢量化读取ORC数据</a><br><a href="http://support-it.huawei.com/docs/zh-cn/fusioninsight-all/maintenance-guide/zh-cn_topic_0261891154.html">spark查询ORC表失败，在hive可以正常查询</a></p>
<h2 id="Cannot-overwrite-a-path-that-is-also-being-read-from"><a href="#Cannot-overwrite-a-path-that-is-also-being-read-from" class="headerlink" title="Cannot overwrite a path that is also being read from."></a>Cannot overwrite a path that is also being read from.</h2><p>1.设置 spark.sql.hive.convertMetastoreParquet=false或者spark.sql.hive.convertMetastoreOrc=false</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>sqoop从mysql导数据到hive报错</title>
    <url>/2021/01/18/sqoop%E4%BB%8Emysql%E5%AF%BC%E6%95%B0%E6%8D%AE%E5%88%B0hive%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>   使用sqoop从mysql导数据到hive，从本地服务器是可以访问mysql的（本地服务器是hadoop集群的一个datanode），但是sqoop导数据的时候依然连接不上mysql<br>报错如下：<br><img src="/uploads/20210118/sqoop-import-error.png" alt="sqoop-import-error"><br>从报错可以看出，是数据库连接失败，很常见的问题，但是从本地是可以直连mysql的。</p>
<p>因为sqoop导数据的时候，默认会启动4个map task，这4个map task会随机启动在不动的datanode上，所以在想，是不是因为其他节点没有权限访问mysql导致。<br>但是需要先搞清楚，sqoop在抽取数据的时候，是不是会把4个map task随机启动在不动的datanode上</p>
<p>在官网上有如下内容：<br><img src="/uploads/20210118/sqoop-official-website.png" alt="sqoop-official-website"><br>虽然讲的不是我们要找到，但是可以判断出，sqoop导数据就是会把maptask随机启动在不通的datanode上。<br>因此，sqoop在导数据到mysql的时候，要确认，hadoop集群的每个节点都要有mysql的读权限</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Sqoop</category>
      </categories>
      <tags>
        <tag>Sqoop</tag>
      </tags>
  </entry>
  <entry>
    <title>基于githup搭建个人博客网站</title>
    <url>/2021/01/14/%E5%9F%BA%E4%BA%8Egithup%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>利用Github Pages搭建自己的个人网站</li>
<li>Next主题设置<a id="more"></a>

</li>
</ul>
<h2 id="利用Github-Pages搭建自己的个人网站"><a href="#利用Github-Pages搭建自己的个人网站" class="headerlink" title="利用Github Pages搭建自己的个人网站"></a>利用Github Pages搭建自己的个人网站</h2><p>Github Pages建立网站有多种方式</p>
<ul>
<li>创建个人或者组织网站（我们就是要建立这种）<ul>
<li>这种需要注意，项目名一定要是username<organization>.github.io，否则的话，创建的就是为每个project创建的网站了</li>
</ul>
</li>
<li>为每个project建立网站</li>
</ul>
<p>单纯的使用Githup Pages搭建自己的个人网站还是很简单的，有如下的步骤</p>
<ul>
<li>申请githup账号</li>
<li>创建Repositories<ul>
<li>项目名必须得是username.githup.io，如果不是,最终生成的个人网址就是<a href="https://username.github.io/project/">https://username.github.io/project/</a></li>
</ul>
</li>
<li>在Repositories中生成一个html文件，里面随便写点啥</li>
<li>点击Settings -&gt; GitHub Pages -&gt; 选择分支以及文件夹，上面出现绿色的’Your site is published at’就成功了</li>
</ul>
<h2 id="基于-hexo-github-的个人博客搭建"><a href="#基于-hexo-github-的个人博客搭建" class="headerlink" title="基于 hexo + github 的个人博客搭建"></a>基于 hexo + github 的个人博客搭建</h2><h3 id="nodejs安装"><a href="#nodejs安装" class="headerlink" title="nodejs安装"></a>nodejs安装</h3><p>到官网下载nodejs安装包</p>
<pre class="line-numbers language-none"><code class="language-none">xz -d xxx.tar.xz 
tar xvf xxx.tar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>配置环境变量<br>最后检验是否安装成功 </p>
<pre class="line-numbers language-none"><code class="language-none">node -v
npm -v<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="hexo安装"><a href="#hexo安装" class="headerlink" title="hexo安装"></a>hexo安装</h3><ul>
<li>首先更新apt-get的源,这里为了提高速度，把源改成了aliyun，具体可以看<a href="https://www.cnblogs.com/gabin/p/6519352.html">https://www.cnblogs.com/gabin/p/6519352.html</a><pre class="line-numbers language-none"><code class="language-none">sudo apt-get update
sudo apt-get upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>安装hexo<pre class="line-numbers language-none"><code class="language-none">npm install -g hexo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里如果安装的特别慢，可以设置一下npm的源<pre class="line-numbers language-none"><code class="language-none">npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

</li>
</ul>
<h3 id="hexo-初始化"><a href="#hexo-初始化" class="headerlink" title="hexo 初始化"></a>hexo 初始化</h3><p>在本地创建一个文件夹，也就是之后存放代码的地方，例如blog</p>
<pre class="line-numbers language-none"><code class="language-none">cd blog &amp;&amp; hexo init<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/20210114/hexo-init.png" alt="hexo-init"><br>hexo会自动下载一些文件到这个目录，这个过程需要联网</p>
<pre class="line-numbers language-none"><code class="language-none">hexo g # 生成html
hexo s # 启动服务<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：<br>hexo s是开启本地预览服务，打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 即可看到内容</p>
<h3 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h3><p>这里选择的主题是next，首先下载这个主题<br>hexo版本5.0以上，可以直接使用</p>
<pre class="line-numbers language-none"><code class="language-none">npm install hexo-theme-next@latest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>启用hexo 5.0，需要nodejs版本在10.13.0以上，可以配置package.json来修改hexo的版本</p>
<pre class="line-numbers language-none"><code class="language-none"># 指定版本为^5.0.0
&quot;dependencies&quot;: &#123;
    &quot;hexo&quot;: &quot;^5.0.0&quot;,
    &quot;hexo-generator-archive&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-generator-category&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-generator-index&quot;: &quot;^2.0.0&quot;,
    &quot;hexo-generator-tag&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-renderer-ejs&quot;: &quot;^1.0.0&quot;,
    &quot;hexo-renderer-marked&quot;: &quot;^3.0.0&quot;,
    &quot;hexo-renderer-stylus&quot;: &quot;^2.0.0&quot;,
    &quot;hexo-server&quot;: &quot;^2.0.0&quot;,
    &quot;hexo-theme-landscape&quot;: &quot;^0.0.3&quot;,
    &quot;hexo-theme-next&quot;: &quot;^8.1.0&quot;
  &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下载完成后，修改_config.yml中的theme: landscape改为theme: next</p>
<p>发布到githup上</p>
<pre class="line-numbers language-none"><code class="language-none">hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="上传到github"><a href="#上传到github" class="headerlink" title="上传到github"></a>上传到github</h3><pre class="line-numbers language-none"><code class="language-none">deploy:
  type: git
  repository: git@github.com:xxxn&#x2F;xxx.github.io.git
  branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>此时直接执行hexo d的话一般会报如下错误：</p>
<pre class="line-numbers language-none"><code class="language-none">Deployer not found: github 或者 Deployer not found: git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>原因是还需要安装一个插件：</p>
<pre class="line-numbers language-none"><code class="language-none">npm install hexo-deployer-git --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h2 id="Next主题配置"><a href="#Next主题配置" class="headerlink" title="Next主题配置"></a>Next主题配置</h2><h3 id="菜单设置"><a href="#菜单设置" class="headerlink" title="菜单设置"></a>菜单设置</h3><blockquote>
<blockquote>
<p>菜单包括：首页、归档、分类、标签、关于等等  </p>
</blockquote>
</blockquote>
<p>我们刚开始默认的菜单只有首页和归档两个，不能够满足我们的要求，所以需要添加菜单，打开 主题配置文件 找到Menu Settings</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">menu:
  home: &#x2F; || fa fa-home
  #about: &#x2F;about&#x2F; || fa fa-user
  tags: &#x2F;tags&#x2F; || fa fa-tags
  categories: &#x2F;categories&#x2F; || fa fa-th
  archives: &#x2F;archives&#x2F; || fa fa-archive<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Next主题样式设置"><a href="#Next主题样式设置" class="headerlink" title="Next主题样式设置"></a>Next主题样式设置</h3><p>Next有4种风格供我们选择，打开 主题配置文件 找到Scheme Settings</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># ---------------------------------------------------------------
# Scheme Settings
# ---------------------------------------------------------------

# Schemes
#scheme: Muse
scheme: Mist
#scheme: Pisces
#scheme: Gemini<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="侧栏设置"><a href="#侧栏设置" class="headerlink" title="侧栏设置"></a>侧栏设置</h3><blockquote>
<blockquote>
<p>侧栏设置包括：侧栏位置、侧栏显示与否、文章间距、返回顶部按钮等等</p>
</blockquote>
</blockquote>
<p>打开 主题配置文件 找到sidebar字段</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">sidebar:
  # Sidebar Position.
  position: right
  #position: right

  # Manual define the sidebar width. If commented, will be default for:
  # Muse | Mist: 320
  # Pisces | Gemini: 240
  #width: 300

  # Sidebar Display (only for Muse | Mist), available values:
  #  - post    expand on posts automatically. Default.
  #  - always  expand for all pages automatically.
  #  - hide    expand only when click on the sidebar toggle icon.
  #  - remove  totally remove sidebar including sidebar toggle.
  display: always

  # Sidebar padding in pixels.
  padding: 18
  # Sidebar offset from top menubar in pixels (only for Pisces | Gemini).
  offset: 12
  # Enable sidebar on narrow view (only for Muse | Mist).
  onmobile: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="头像设置"><a href="#头像设置" class="headerlink" title="头像设置"></a>头像设置</h3><p>打开 主题配置文件 找到Sidebar Avatar字段</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Sidebar Avatar
avatar:
  # Replace the default image and set the url here.
  url: &#x2F;uploads&#x2F;avatar.jpg
  # If true, the avatar will be dispalyed in circle.
  rounded: false
  # If true, the avatar will be rotated with the cursor.
  rotated: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加分类-标签模块"><a href="#添加分类-标签模块" class="headerlink" title="添加分类/标签模块"></a>添加分类/标签模块</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hexo new page categories # 分类
hexo new page tags # 标签<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="设置网站缩略图标"><a href="#设置网站缩略图标" class="headerlink" title="设置网站缩略图标"></a>设置网站缩略图标</h3><p>把图片放在themes/next/source/images里，然后打开 主题配置文件 找到favicon，将small、medium、apple_touch_icon三个字段的值都设置成/images/图片名.jpg就可以了，其他字段都注释掉</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">favicon:
  small: &#x2F;images&#x2F;favicon-16x16.png
  medium: &#x2F;images&#x2F;favicon-32x32.png
  apple_touch_icon: &#x2F;images&#x2F;apple-touch-icon.png
  safari_pinned_tab: &#x2F;images&#x2F;logo.svg
  #android_manifest: &#x2F;images&#x2F;manifest.json
  #ms_browserconfig: &#x2F;images&#x2F;browserconfig.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="设置页面宽度"><a href="#设置页面宽度" class="headerlink" title="设置页面宽度"></a>设置页面宽度</h3><p>自我感觉next主题的正文页面太窄了，这里把正文宽度调大，看得舒服点</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">cd hexo-theme-next&#x2F;source&#x2F;css&#x2F;_variables&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>编辑base.styl<br>修改变量值</p>
<pre class="line-numbers language-stylus" data-language="stylus"><code class="language-stylus"><span class="token comment">// Layout sizes</span>
<span class="token comment">// --------------------------------------------------</span>
<span class="token variable-declaration"><span class="token variable">$content-desktop</span>                <span class="token operator">=</span> <span class="token number">700</span><span class="token unit">px</span><span class="token punctuation">;</span></span>
<span class="token variable-declaration"><span class="token variable">$content-desktop-large</span>          <span class="token operator">=</span> <span class="token number">800</span><span class="token unit">px</span><span class="token punctuation">;</span></span>
<span class="token variable-declaration"><span class="token variable">$content-desktop-largest</span>        <span class="token operator">=</span> <span class="token number">950</span><span class="token unit">px</span><span class="token punctuation">;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="修改页面字体大小"><a href="#修改页面字体大小" class="headerlink" title="修改页面字体大小"></a>修改页面字体大小</h3><p>下载的最新版本的next主题的字体不知为啥很大，看的很不舒服。这里修改一下<br>修改hexo-theme-next/source/css/_variables/base.styl</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">&#x2F;&#x2F;以前的
&#x2F;&#x2F;$font-size-base           &#x3D; (hexo-config(&#39;font.enable&#39;) and hexo-config(&#39;font.global.size&#39;) is a &#39;unit&#39;) ? unit(hexo-config(&#39;font.global.size&#39;), em) : 1em;
&#x2F;&#x2F;修改成固定值
$font-size-base           &#x3D; 14px;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加站点访问计数"><a href="#添加站点访问计数" class="headerlink" title="添加站点访问计数"></a>添加站点访问计数</h3><pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Baidu Analytics
baidu_analytics: 730b9e375674d8f70a08061cd491e24c


# Show number of visitors of each article.
# You can visit https:&#x2F;&#x2F;leancloud.cn to get AppID and AppKey.
# AppID and AppKey are recommended to be the same as valine&#39;s for counter compatibility.
# Do not enable both &#96;valine.visitor&#96; and &#96;leancloud_visitors&#96;.
leancloud_visitors:
  enable: true
  app_id: xxxxxxxxxxxxxx
  app_key: xxx
  # Required for apps from CN region
  server_url: # &lt;your server url&gt;
  # Dependencies: https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-leancloud-counter-security
  # If you don&#39;t care about security in leancloud counter and just want to use it directly
  # (without hexo-leancloud-counter-security plugin), set &#96;security&#96; to &#96;false&#96;.
  security: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里可以到度娘上查，很多教程</p>
<h3 id="代码块风格"><a href="#代码块风格" class="headerlink" title="代码块风格"></a>代码块风格</h3><p>next主题下的_config.yml</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">codeblock:
  # Code Highlight theme
  # Available values: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic
  # See: https:&#x2F;&#x2F;github.com&#x2F;chriskempson&#x2F;tomorrow-theme
  highlight_theme: normal
  # Add copy button on codeblock
  copy_button:
    enable: true
    # Show text copy result.
    show_result: true
    # Available values: default | flat | mac
    style: default<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>hexo下的_config.yml</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">highlight:
  enable: true
  line_number: true
  auto_detect: false
  tab_replace: &#39;&#39;
  wrap: true
  hljs: false
prismjs:
  enable: true
  preprocess: true
  line_number: true
  tab_replace: &#39;&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加评论插件"><a href="#添加评论插件" class="headerlink" title="添加评论插件"></a>添加评论插件</h3><p>next主题本身就支持众多评论插件，这里综合各种插件的优劣，最终选择了valine<br>修改config.yml之前，先在本地环境安装一下valine</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># Install valine
npm install valine --save<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>因为next本身已经支持，这里只需要在_config.yml里配置下即可</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Valine
# For more information: https:&#x2F;&#x2F;valine.js.org, https:&#x2F;&#x2F;github.com&#x2F;xCss&#x2F;Valine
valine:
  enable: true
  appid: SkWNsftcFwwI7sR8WGnbm8G0-gzGzoHsz
  appkey: wHfJCMCqkaxidT5nJyOygkO7
  notify: false # Mail notifier
  verify: false # Verification code
  placeholder: Just go go # Comment box placeholder
  avatar: wavatar # Gravatar style
  guest_info: nick,mail,link # Custom comment header
  pageSize: 10 # Pagination size
  language: # Language, available values: en, zh-cn
  visitor: true # Article reading statistic
  comment_count: true # If false, comment count will only be displayed in post page, not in home page
  recordIP: false # Whether to record the commenter IP
  serverURLs: # When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)
  #post_meta_order: 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="添加本地搜索功能"><a href="#添加本地搜索功能" class="headerlink" title="添加本地搜索功能"></a>添加本地搜索功能</h3><p>安装搜索插件  </p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">npm install hexo-generator-searchdb --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>配置next主题_config_yml</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># Local Search
# Dependencies: https:&#x2F;&#x2F;github.com&#x2F;theme-next&#x2F;hexo-generator-searchdb
local_search:
  enable: true
  # If auto, trigger search by changing input.
  # If manual, trigger search by pressing enter key or search button.
  trigger: auto
  # Show top n results per article, show all results by setting to -1
  top_n_per_article: 1
  # Unescape html strings to the readable one.
  unescape: false
  # Preload the search data when the page loads.
  preload: false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>修改hexo项目的_config.yml，添加如下内容：</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml"># search
search:
  path: search.xml
  field: post
  format: html
  limit: 10000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果不添加，那么在<code>hexo s</code>可以搜索，但是deploy后，正式的网页上点击不了搜索</p>
<h3 id="首页添加阅读全文"><a href="#首页添加阅读全文" class="headerlink" title="首页添加阅读全文"></a>首页添加阅读全文</h3><p>当前首页会把正文都显示出来，所以显得首页很长，不美观。<br>在next主题_config.yml配置</p>
<pre class="line-numbers language-yml" data-language="yml"><code class="language-yml">excerpt_description: true<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>还需要手动在每篇正文添加<code>&lt;!-- more --&gt;</code>，并写一下文档摘要</p>
<h3 id="配置百度站点收录管理"><a href="#配置百度站点收录管理" class="headerlink" title="配置百度站点收录管理"></a>配置百度站点收录管理</h3><ol>
<li><p>安装插件：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">npm install hexo-baidu-url-submit --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在根目录 _config.yml 文件里加入以下代码：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">baidu_url_submit:
  count: 100                                # 提交最新的多少个链接
  host: https:&#x2F;&#x2F;gujincheng.github.io&#x2F;       # 在百度站长平台中添加的域名
  token: aaaaa                              # 秘钥
  path: baidu_urls.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>token可以在<br><a href="https://ziyuan.baidu.com/linksubmit/index?site=https://gujincheng.github.io/">https://ziyuan.baidu.com/linksubmit/index?site=https://gujincheng.github.io/</a><br>普通收录里看到</p>
</li>
<li><p>在_config.yml 加入新的deployer<br>需要修改之前的配置方式，以前没有<code>-</code>，现在需要多加一个type，所以需要加<code>-</code>,注意repository和branch要和type对其</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">deploy:
  - type: git
    repository: git@github.com:gujincheng&#x2F;gujincheng.github.com.git
    branch: main
  - type: baidu_url_submitter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>这样操作以后，以后每次的<code>hexo d</code>就会直接提交到百度收录,并会返回一下参数</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">&#123;&quot;remain&quot;:2985,&quot;success&quot;:40&#125;           #表示成功40条<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ol>
]]></content>
      <categories>
        <category>工具箱</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>实时采集架构设计</title>
    <url>/2022/03/07/%E5%AE%9E%E6%97%B6%E9%87%87%E9%9B%86%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>大数据</category>
        <category>实时架构</category>
      </categories>
      <tags>
        <tag>实时架构</tag>
      </tags>
  </entry>
  <entry>
    <title>vim使用手册（一）</title>
    <url>/2021/01/16/vim%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>vim使用手册<a id="more"></a>
个人感觉，vim用熟了，比任何编辑器都好用，VIM的许多特性节省了时间和击键次数，并可以完成一些其他编辑器无法完成的功能，这里在网上找了几个经典案例，记录一下。</li>
</ul>
<p>与大部分其它编辑器不同，进入 Vim 后，缺省状态下键入的字符并不会插入到所编辑的文件之中。Vim 的模式（mode，可以简单地理解为“状态”）概念非常重要。需要知道，Vim 有以下几个模式：</p>
<ul>
<li>正常（normal）模式，缺省的编辑模式；下面如果不加特殊说明，提到的命令都直接在正常模式下输入；任何其它模式中都可以通过键盘上的 Esc 键回到正常模式。</li>
<li>命令（command）模式，用于执行较长、较复杂的命令；在正常模式下输入“:”（一般命令）、“/”（正向搜索）或“?”（反向搜索）即可进入该模式；命令模式下的命令要输入回车键（Enter）才算完成。</li>
<li>插入（insert）模式，输入文本时使用；在正常模式下键入“i”（insert）或“a”（append）即可进入插入模式（也有另外一些命令，如“c”，也可以进入插入模式，但这些命令有其它的作用）。</li>
<li>可视（visual）模式，用于选定文本块；可以在正常模式下输入“v”（小写）来按字符选定，输入“V”（大写）来按行选定，或输入“Ctrl-V”来按方块选定。</li>
</ul>
<p>一般的发布版中还常常带有一个简单的 30 分钟的 Vim 教程，新手在操作系统的命令行上输入<code>vimtutor</code>命令即可开始学习。除上面的简单说明外，本文并不介绍最基本的 Vim 命令，Vim 的新手应该先通过教程熟悉一下 Vim，再继续往下阅读。</p>
<h2 id="常用的指令序列"><a href="#常用的指令序列" class="headerlink" title="常用的指令序列"></a>常用的指令序列</h2><ul>
<li><p>左右交换光标处两字符的位置：xp<br>命令拆分：</p>
<ul>
<li>x剪切当前字符</li>
<li>p粘贴剪切的字符到光标后面</li>
</ul>
</li>
<li><p>上下交换光标处两行的位置： ddp<br>命令拆分：</p>
<ul>
<li>dd 剪切当前行</li>
<li>p 粘贴剪切的内容到光标的下一行</li>
</ul>
</li>
<li><p>行转列：</p>
<ul>
<li><p>第一种, 多行合并成一行,即:<br>AAAAA<br>BBBBB<br>CCCCC<br>合并为:<br>AAAAA BBBBB CCCCC<br>方法1: normal状态下 3J 其中的3是范围,可以是书签或者搜索位置等方式实现,J为合并<br>注: 如果改为3gJ的话,则合并时各行没有空白AAAAABBBBBCCCCC, 下面方法类似,不再重复这两种合并方式的区别.</p>
<p>方法2: 命令状态下 :1,3 join   或 :1,3 j    （注意j前面是空格）</p>
<p>方法3: 传统一点的,替换换行符的方式,为避免最后一行也被换掉,范围缩小了,命令状态下  :1,2s/\n/ /</p>
</li>
<li><p>第二种,隔行合并,即:</p>
<p>AAAAA<br>BBBBB<br>CCCCC<br>DDDDD</p>
<p>合并为:</p>
<p>AAAAA BBBBB<br>CCCCC DDDDD</p>
<p>方法1: 借用一下宏录制功能, normal状态下 qaJjq 实现录制, 然后在合适的区域重复执行n遍,这里2遍即可,normal状态下2@a</p>
<p>方法2: 命令状态下 :1,4g/^/ join  增加了g过滤后,合并变成了隔行处理</p>
</li>
</ul>
</li>
<li><p>在每行行首添加相同的内容<br>  :%s/^/要添加的内容</p>
</li>
<li><p>在每行行尾添加相同的内容<br>  :%s/$/要添加的内容</p>
</li>
<li><p>利用正则表达式删除代码段每行的行号<br>  :%s/^\s*[0-9]<em>\s</em>//gc</p>
</li>
<li><p>删除某一行之前的所有内容</p>
<ul>
<li>先找到这一行，复制这一行的内容，然后全文查找这一行的内容，这时候这一行是高亮的<br><img src="/uploads/20210116/vim-select.png" alt="vim-select"></li>
<li>然后gg回到第一行</li>
<li>dn<br><img src="/uploads/20210116/vim-dn.png" alt="vim-dn"></li>
</ul>
</li>
</ul>
<h2 id="在vim里使用类似Emacs里的orgmode"><a href="#在vim里使用类似Emacs里的orgmode" class="headerlink" title="在vim里使用类似Emacs里的orgmode"></a>在vim里使用类似Emacs里的orgmode</h2><ul>
<li>在.vimrc里添加配置：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Plugin &#39;jceb&#x2F;vim-orgmode&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>在vim命令行模式运行：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">:PluginInstall<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
之后就能直接用vim编辑.org文件，目前vim-orgmode有如下功能：<br>当前 vim orgmode不支持所有orgmode功能，但它非常有用。 已经支持的功能的简短列表：</li>
<li>语法高亮显示</li>
<li>标题的循环可见性( 折叠)</li>
<li>在标题之间导航</li>
<li>编辑文档的结构： 添加，移动，提升，表示标题和更多</li>
<li>vim orgmode和外部( 文件，网页，等等 ) 中的超链接</li>
<li>待办事项列表管理</li>
<li>标题标记</li>
<li>列表中的字母符号和项目符号符号和复选框支持</li>
<li>基本日期处理</li>
<li>导出到其他格式( 通过 Emacs’org模式</li>
</ul>
<h2 id="vim设置leader键"><a href="#vim设置leader键" class="headerlink" title="vim设置leader键"></a>vim设置leader键</h2><p>leader 键简单的说就是一个前缀键，可以自由设定<br>例如，绑定leader键为‘，’</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">&quot; 设置 leader 键，例子为,键，也可以设置为其他的 默认为&quot;&#x2F;&quot;
let mapleader&#x3D;&quot;,&quot;
 
&quot; 设置快捷键，关闭一个窗口
map &lt;leader&gt;wq :wq&lt;CR&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个例子中，在 vim 的<code>normal-mode</code>下，按空格键+w+q 就可以保存文件退出窗口<br>在这个leader的前提下，就不会有键冲突的的情况了</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库-数据质量</title>
    <url>/2021/08/03/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93-%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>数据质量基本概念</li>
<li>影响因素</li>
<li>评估维度</li>
<li>实施流程<a id="more"></a>

</li>
</ul>
<h2 id="数据质量基本概念"><a href="#数据质量基本概念" class="headerlink" title="数据质量基本概念"></a>数据质量基本概念</h2><ul>
<li>数据质量管理（Data Quality Management），是指对数据从计划、获取、存储、共享、维护、应用、消亡生命周期的每个阶段里可能引发的各类数据质量问题，进行识别、度量、监控、预警等一系列管理活动，并通过改善和提高组织的管理水平使得数据质量获得进一步提高</li>
<li>数据质量管理不是一时的数据治理手段，而是循环的管理过程。其终极目标是通过可靠的数据，提升数据在使用中的价值，并最终为企业赢得经济效益</li>
</ul>
<h2 id="影响因素"><a href="#影响因素" class="headerlink" title="影响因素"></a>影响因素</h2><p>数据问题的来源可能产生于从数据源头到数据存储介质的各个环节。在数据采集阶段，数据的真实性、准确性、完整性、时效性都会影响数据质量。除此之外，数据的加工、存储过程都有可能涉及对原始数据的修改，从而引发数据的质量问题。所以，技术、流程、管理等多方面的因素都有可能会影响到数据质量。</p>
<h2 id="评估维度"><a href="#评估维度" class="headerlink" title="评估维度"></a>评估维度</h2><ul>
<li>完整性<br>数据完整性问题包含数据条目不完整，数据属性不完整等</li>
<li>一致性<br>多源数据的数据模型不一致，如命名不一致，数据编码不一致，含义不一致，生命周期不一致等</li>
<li>准确性<br>准确性也叫可靠性，不可靠的数据可能会导致严重的问题，会造成有缺陷的方法和糟糕的决策</li>
<li>唯一性<br>用于识别和度量重复数据，冗余数据，重复数据是导致业务无法协同，流程无法追溯的重要因素，也是数据治理需要解 决的最基本的数据问题</li>
<li>关联性<br>数据关联性问题是指存在数据关联的数据关系缺失或错误，例如：函数关系、相关系数、主外键关系、索引关系等。存在数据关联性问题，会直接影响数据分析的结果，进而影响管理决策。</li>
<li>真实性<br>数据必须真实准确的反映客观的实体存在或真实的业务，真实可靠的原始统计数据是企业统计工作的灵魂</li>
<li>及时性<br>数据的及时性(In-time)是指能否在需要的时候获到数据，数据的及时性与企业的数据处理速度及效率有直接的关系，是影响业务处理和管理效率的关键指标。</li>
<li>逻辑检查<br>不同表字段之间可能会有逻辑关联，需要稽核</li>
<li>离群值检查<br>部分数据可能会偏离其他数据，比如同一个商品金额大家都是100元，而有一条数据是1W</li>
<li>自定义规则<br>由需求方自定义相关规则</li>
<li>波动稽核<br>与上周环比稽核波动情况 </li>
<li>强弱规则<br>每个规则的权重应该是不一样的，需要配置优先级，这对后续的告警方式是有帮助的</li>
</ul>
]]></content>
      <categories>
        <category>数据仓库</category>
        <category>数据质量</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库面试题</title>
    <url>/2021/11/18/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>数据仓库面试题总结</li>
</ul>
<a id="more"></a>

<p><strong><font size = 5>1. 全量表(df),增量表(di),追加表(da)，拉链表(dz)的区别及使用场景？</font></strong></p>
<p><strong><font size = 5>2. 星型模型和雪花模型？</font></strong></p>
<p><strong><font size = 5>3. 缓慢变化维如何处理，几种方式？</font></strong></p>
<ol>
<li>直接覆盖历史数据</li>
<li>采用拉链表，把记录的过程都记录下来</li>
<li>增加预留资源，每次变化，把新变化的数据放到备用字段</li>
<li>字段透传，把变化的纬度透传到上层的事实表，这样就不用关联了</li>
</ol>
<p><strong><font size = 5>4. 说说你从0-1搭建数仓都做了什么？你觉得最有挑战的是什么？</font></strong></p>
<p><strong><font size = 5>5. 流批一体有什么好处？为什么要搞流批一体？</font></strong><br>传统数仓Lambda架构，数据分析需求基于流、批两套计算引擎产出，这种分离的架构不仅会带来两套开发成本，也导致数据逻辑和口径难以对齐<br><a href="https://baijiahao.baidu.com/s?id=1685957539299113384&wfr=spider&for=pc">为什么阿里云要做流批一体？</a><br>流批一体首先是架构上的流批一体，不仅仅是计算引擎流批一体，存储引擎也需要流批一体，计算引擎可以使用flink，存储引擎，现在常用的可以使用Hudi，Iceberg</p>
<p><strong><font size = 5>6. left semi join和left jion区别？</font></strong></p>
<ul>
<li><code>left semi join</code>左半连接,是 in(keySet) 的关系，遇到右表重复记录，左表会跳过；<br>当右表不存在的时候，左表数据不会显示; 相当于SQL的in语句，注意，结果中是没有B表的字段的<br>LEFT SEMI JOIN 是 IN/EXISTS 子查询的一种更高效的实现。</li>
<li><code>left join</code>:当右表不存在的时候，则会显示NULL</li>
</ul>
<p>数仓面试题可以参考<br><a href="https://blog.csdn.net/qq_28680977/article/details/108460523">2020大厂面试题-数仓篇</a></p>
<p>参考<br><a href="https://mp.weixin.qq.com/s/0mgy07WAMBYNBP6er8_hDA">(终极版)2021大数据面试真题(务必进来看一下)</a></p>
]]></content>
      <categories>
        <category>面试题</category>
        <category>大数据</category>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>日常工具软件问题</title>
    <url>/2021/01/22/%E6%97%A5%E5%B8%B8%E5%B7%A5%E5%85%B7%E8%BD%AF%E4%BB%B6%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>VMWare常见问题</li>
<li>IDEA常见问题<a id="more"></a>
<h2 id="VMWare常见问题"><a href="#VMWare常见问题" class="headerlink" title="VMWare常见问题"></a>VMWare常见问题</h2><h3 id="VMWare开启虚拟机黑屏"><a href="#VMWare开启虚拟机黑屏" class="headerlink" title="VMWare开启虚拟机黑屏"></a>VMWare开启虚拟机黑屏</h3>解决办法：</li>
<li>在windows下搜索cmd，并以管理员身份打开，输入：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">netsh winsock reset<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>重启电脑</li>
</ul>
<h2 id="IDEA常见问题"><a href="#IDEA常见问题" class="headerlink" title="IDEA常见问题"></a>IDEA常见问题</h2><h3 id="maven编译报错-source-1-5-中不支持-lambda-表达式"><a href="#maven编译报错-source-1-5-中不支持-lambda-表达式" class="headerlink" title="maven编译报错 -source 1.5 中不支持 lambda 表达式"></a>maven编译报错 -source 1.5 中不支持 lambda 表达式</h3><p><img src="/uploads/20210124/IDEA%E4%B8%AD%E7%BC%96%E8%AF%91Maven%E9%A1%B9%E7%9B%AE%E6%8A%A5%E9%94%99.png" alt="IDEA中编译Maven项目报错"><br>解决办法：<br>在pom文件中添加:</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.7.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>encoding</span><span class="token punctuation">></span></span>UTF-8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>encoding</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Maven编译时报：编码GBK的不可映射字符"><a href="#Maven编译时报：编码GBK的不可映射字符" class="headerlink" title="Maven编译时报：编码GBK的不可映射字符"></a>Maven编译时报：编码GBK的不可映射字符</h3><p>解决办法：<br><img src="/uploads/20210124/%E7%BC%96%E7%A0%81GBK%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6_1.png" alt="编码GBK的不可映射字符_1"><br><img src="/uploads/20210124/%E7%BC%96%E7%A0%81GBK%E7%9A%84%E4%B8%8D%E5%8F%AF%E6%98%A0%E5%B0%84%E5%AD%97%E7%AC%A6_2.png" alt="编码GBK的不可映射字符_2"></p>
<h3 id="IDEA常用快捷键（windows）"><a href="#IDEA常用快捷键（windows）" class="headerlink" title="IDEA常用快捷键（windows）"></a>IDEA常用快捷键（windows）</h3><ul>
<li><code>Alt + 1</code> 项目视图，可以自动关闭左边侧边栏</li>
<li><code>Crl + E</code> 最近文件列表</li>
<li>快速按两下<code>Shift</code>，全局文件搜索</li>
<li><code>Crl + Shift + N</code> 跳转到某个文件，可以直接搜索</li>
<li><code>Alt+Insert</code> 可以生成构造器/Getter/Setter等</li>
<li><code>Ctrl + W</code> 按一个word来进行选择操作，在IDEA里的这个快捷键功能是先选择光标所在字符处的单词，然后是选择源代码的扩展区域</li>
<li><code>shift + F6</code>修改文件名</li>
</ul>
<h2 id="IDEA常用快捷键（mac）"><a href="#IDEA常用快捷键（mac）" class="headerlink" title="IDEA常用快捷键（mac）"></a>IDEA常用快捷键（mac）</h2><ul>
<li>当前行注释： ctrl+/</li>
<li>撤销行注释： ctrl+/</li>
<li>块状注释： ctrl+shift+/</li>
<li>撤销块注释： ctrl+shift+/</li>
<li>实现/重写方法：command + N</li>
<li>全局查找： shift + command + f</li>
<li>全局替换： shift + command + r</li>
<li>当前文件查找： command + f</li>
<li>当前文件替换： command + r</li>
<li>最近查看过的文件： command + e</li>
<li>打开类结构： command + 7</li>
<li>前往父类/父类方法： command + u</li>
<li>呼出文件列表： command + 上方向键</li>
</ul>
<p>当用IDEA写java的时候，写匿名函数的时候，如果不知道new什么，可以在方法()里使用<code>option + /</code>会自动提示创建什么对象<br><img src="/uploads/20210520/IDEA%E7%BC%96%E5%86%99JAVA.png" alt="IDEA编写JAVA"><br>鼠标悬浮在提醒的对象名上，会提醒这个对象是什么类的，直接new就可以</p>
<h2 id="IDEA常用插件"><a href="#IDEA常用插件" class="headerlink" title="IDEA常用插件"></a>IDEA常用插件</h2><ul>
<li>leetcode editor  刷算法</li>
<li>codota ai aotocomplete for java   自动补全java，从githup上找相似的</li>
<li>easy code  自动写java实体类</li>
<li>translation  在线翻译，看源码可以使用</li>
<li>key promoter  提醒快捷键的，用的功能会自动提示</li>
<li>maven helper  解决maven依赖冲突</li>
<li>alibaba java coding   代码规范</li>
<li>codeglance  类似sublime的代码缩影。可以替代下拉框</li>
<li>GsonFormat   自动根据json创建实体类</li>
<li>ignore    git过滤</li>
<li>rainbow brackets  括号变成彩虹颜色</li>
<li>acejump  类似vim快速定位</li>
</ul>
<p>在IDEA写java的时候，如果不知道是什么类型，可以使用<code>option + shift + enter</code>来自动补全<br>例如：<br><code>map = mapState.iterator().next();</code><br>把鼠标悬浮在map变量上，然后可以点击<code>create local variable &#39;map&#39;</code>,或者<code>option + shift + enter</code>来自动补全</p>
<p><code>option + shift + enter</code>： 鼠标悬浮在倒入的无用的包上（import变灰色的），使用这个快捷键，可以自动清除无用的包</p>
<blockquote>
<p>在写java或者scala的时候，直接写=号右边的内容，然后加一个.var,然后enter，就可以自动补全左边的定义变量的操作<br>在编辑java的时候，在调用类和正在编辑的类中来回切换： option + command + 方向键</p>
</blockquote>
<h2 id="github网页可以访问，但是ping不通"><a href="#github网页可以访问，但是ping不通" class="headerlink" title="github网页可以访问，但是ping不通"></a>github网页可以访问，但是ping不通</h2><p>最近从github上拉取代码，总是报超时，ping github.com后连不通<br>一开始以为是国外ip访问不了，翻墙试了一下，还是不行<br>最后解决方法，修改hosts文件<br>原因是直接ping github.com返回的服务器ip ping不通，但是github本身是有很多ip的，我们挑一个可以ping的通的ip</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">140.82.113.4 github.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>问题解决</p>
]]></content>
      <categories>
        <category>工具箱</category>
      </categories>
      <tags>
        <tag>VMWare</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>获取yarn上application资源占用情况</title>
    <url>/2021/12/09/%E8%8E%B7%E5%8F%96yarn%E4%B8%8Aapplication%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>根据yarn的applicationid获取应用实时资源消耗的方法</li>
<li>写python脚本调取yarn api获取实时资源消耗情况</li>
</ul>
<a id="more"></a>


<h2 id="根据yarn的applicationid获取应用实时资源消耗的方法"><a href="#根据yarn的applicationid获取应用实时资源消耗的方法" class="headerlink" title="根据yarn的applicationid获取应用实时资源消耗的方法"></a>根据yarn的applicationid获取应用实时资源消耗的方法</h2><p>这种方法是根据hadoop的配置文件，使用YarnClient来获取applicationId的资源占用情况</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">YarnListener</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">Logger</span> logger <span class="token operator">=</span> <span class="token class-name">LoggerFactory</span><span class="token punctuation">.</span><span class="token function">getLogger</span><span class="token punctuation">(</span><span class="token class-name">YarnListener</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">URL</span> resource <span class="token operator">=</span> <span class="token class-name">HDFSUtil</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getClassLoader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getResource</span><span class="token punctuation">(</span><span class="token string">"config/hadoop-conf"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> resourceDir <span class="token operator">=</span> resource<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token class-name">Constants</span><span class="token punctuation">.</span>SEPARATOR<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">YarnConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resourceDir<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token string">"hdfs-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resourceDir<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token string">"core-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">addResource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>resourceDir<span class="token punctuation">.</span><span class="token function">concat</span><span class="token punctuation">(</span><span class="token string">"yarn-site.xml"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">YarnClient</span> yarnClient <span class="token operator">=</span> <span class="token class-name">YarnClient</span><span class="token punctuation">.</span><span class="token function">createYarnClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        yarnClient<span class="token punctuation">.</span><span class="token function">init</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        yarnClient<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
        <span class="token class-name">ApplicationId</span> applicationId <span class="token operator">=</span> <span class="token class-name">ApplicationId</span><span class="token punctuation">.</span><span class="token function">newInstance</span><span class="token punctuation">(</span><span class="token number">1577686647484L</span><span class="token punctuation">,</span><span class="token number">0001</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
            <span class="token class-name">ApplicationReport</span> report <span class="token operator">=</span> yarnClient<span class="token punctuation">.</span><span class="token function">getApplicationReport</span><span class="token punctuation">(</span>applicationId<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getStartTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getApplicationResourceUsageReport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getUsedResources</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getVirtualCores</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getApplicationResourceUsageReport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getUsedResources</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getMemorySize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getStartTime</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>report<span class="token punctuation">.</span><span class="token function">getApplicationResourceUsageReport</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">YarnException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        yarnClient<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果如下：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json">num_used_containers<span class="token operator">:</span> <span class="token number">-1</span>
num_reserved_containers<span class="token operator">:</span> <span class="token number">-1</span>
used_resources <span class="token punctuation">&#123;</span>
  memory<span class="token operator">:</span> <span class="token number">-1</span>
  virtual_cores<span class="token operator">:</span> <span class="token number">-1</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">"Mi"</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"vcores"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">""</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
reserved_resources <span class="token punctuation">&#123;</span>
  memory<span class="token operator">:</span> <span class="token number">-1</span>
  virtual_cores<span class="token operator">:</span> <span class="token number">-1</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">"Mi"</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"vcores"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">""</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
needed_resources <span class="token punctuation">&#123;</span>
  memory<span class="token operator">:</span> <span class="token number">-1</span>
  virtual_cores<span class="token operator">:</span> <span class="token number">-1</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">"Mi"</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
  resource_value_map <span class="token punctuation">&#123;</span>
    key<span class="token operator">:</span> <span class="token string">"vcores"</span>
    value<span class="token operator">:</span> <span class="token number">-1</span>
    units<span class="token operator">:</span> <span class="token string">""</span>
    type<span class="token operator">:</span> COUNTABLE
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
memory_seconds<span class="token operator">:</span> <span class="token number">5549488</span>
vcore_seconds<span class="token operator">:</span> <span class="token number">5378</span>
preempted_memory_seconds<span class="token operator">:</span> <span class="token number">5549488</span>
preempted_vcore_seconds<span class="token operator">:</span> <span class="token number">5378</span>
application_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
  value<span class="token operator">:</span> <span class="token number">5549488</span>
<span class="token punctuation">&#125;</span>
application_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"vcores"</span>
  value<span class="token operator">:</span> <span class="token number">5378</span>
<span class="token punctuation">&#125;</span>
application_preempted_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"memory-mb"</span>
  value<span class="token operator">:</span> <span class="token number">5549488</span>
<span class="token punctuation">&#125;</span>
application_preempted_resource_usage_map <span class="token punctuation">&#123;</span>
  key<span class="token operator">:</span> <span class="token string">"vcores"</span>
  value<span class="token operator">:</span> <span class="token number">5378</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>这种方法，感觉可以和hive的hook结合起来使用，在hivesql执行过程中，就把资源使用情况保存下来<br>这里的资源占用都是实时的占用，可以取一个平均资源占用来当作这个任务的资源占用情况</p>
<p>具体可以参考<a href="https://blog.csdn.net/trnanan/article/details/104986262">根据yarn的applicationid获取应用实时资源消耗的方法</a></p>
<h2 id="写python脚本调取yarn-api获取实时资源消耗情况"><a href="#写python脚本调取yarn-api获取实时资源消耗情况" class="headerlink" title="写python脚本调取yarn api获取实时资源消耗情况"></a>写python脚本调取yarn api获取实时资源消耗情况</h2><p>这种方式，就是用爬虫yarn的监控页面，取页面上的内容，其实不是很好，因为namenode在ha之后会切换，但是很方便</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> json
<span class="token keyword">import</span> time
<span class="token keyword">import</span> pymysql
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup
<span class="token keyword">import</span> os<span class="token punctuation">,</span>threading<span class="token punctuation">,</span>time

url_full<span class="token operator">=</span><span class="token string">"http://ip:port/cluster"</span>

conn <span class="token operator">=</span> pymysql<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'114.67.103.201'</span><span class="token punctuation">,</span>user <span class="token operator">=</span> <span class="token string">"root"</span><span class="token punctuation">,</span>passwd <span class="token operator">=</span> <span class="token string">"admin@123456"</span><span class="token punctuation">,</span>db <span class="token operator">=</span> <span class="token string">"myuse"</span><span class="token punctuation">)</span>
cur<span class="token operator">=</span>conn<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#获取游标</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">"GET"</span><span class="token punctuation">,</span> url_full<span class="token punctuation">,</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>url_full<span class="token punctuation">)</span>
soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span> <span class="token comment">#也可用lxml</span>
<span class="token comment">#已提交的任务</span>
apps_submit <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(1)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_submit<span class="token punctuation">)</span>
<span class="token comment">#等待中的任务</span>
apps_pending <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(2)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_pending<span class="token punctuation">)</span>
<span class="token comment">#运行中的任务</span>
apps_running <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(3)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_running<span class="token punctuation">)</span>
<span class="token comment">#已完成的任务</span>
apps_completed <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(4)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>apps_completed<span class="token punctuation">)</span>
<span class="token comment">#运行的contaniner</span>
container_running <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(5)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>container_running<span class="token punctuation">)</span>
<span class="token comment">#一用的内存</span>
memory_used <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(6)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>memory_used<span class="token punctuation">)</span>
<span class="token comment">#总内存</span>
memory_total <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(7)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>memory_total<span class="token punctuation">)</span>
<span class="token comment">#已用的core</span>
core_used <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(9)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>core_used<span class="token punctuation">)</span>
<span class="token comment">#总的core</span>
core_total <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#metricsoverview > tbody > tr > td:nth-of-type(10)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>core_total<span class="token punctuation">)</span>
<span class="token comment">#yarn总的节点数</span>
node_total <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#nodemetricsoverview > tbody > tr > td:nth-of-type(1) > a'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>node_total<span class="token punctuation">)</span>
<span class="token comment">#yran的调度类型</span>
yarn_scheduler_type <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#schedulermetricsoverview > tbody > tr > td:nth-of-type(1)'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>yarn_scheduler_type<span class="token punctuation">)</span>

sql<span class="token operator">=</span><span class="token string">"insert into yarn_monitor(apps_submit,apps_pending,apps_running,memory_used,memory_total,core_used,node_total,yarn_scheduler_type)"</span> \
                <span class="token string">" values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)"</span>
cur<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>sql<span class="token punctuation">,</span><span class="token punctuation">(</span>apps_submit<span class="token punctuation">,</span>apps_pending<span class="token punctuation">,</span>apps_running<span class="token punctuation">,</span>memory_used<span class="token punctuation">,</span>memory_total<span class="token punctuation">,</span>core_used<span class="token punctuation">,</span>node_total<span class="token punctuation">,</span>yarn_scheduler_type<span class="token punctuation">)</span><span class="token punctuation">)</span>
conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
cur<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


]]></content>
      <categories>
        <category>大数据</category>
        <category>监控</category>
      </categories>
      <tags>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title>采集写入hudi设计文档</title>
    <url>/2022/02/28/%E9%87%87%E9%9B%86%E5%86%99%E5%85%A5hudi%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>采集写入hudi设计文档</li>
</ul>
<a id="more"></a>


<h1 id="采集hudi表结构设计"><a href="#采集hudi表结构设计" class="headerlink" title="采集hudi表结构设计"></a>采集hudi表结构设计</h1><h2 id="采集hudi表目录"><a href="#采集hudi表目录" class="headerlink" title="采集hudi表目录:"></a>采集hudi表目录:</h2><ul>
<li><p>hudi表目录：/apps/hudi/warehouse/fdm/tableName</p>
</li>
<li><p>hudi删除表目录：/apps/hudi/warehouse/fdm/tableName_del</p>
</li>
</ul>
<h2 id="采集hudi表外表hive表"><a href="#采集hudi表外表hive表" class="headerlink" title="采集hudi表外表hive表"></a>采集hudi表外表hive表</h2><ul>
<li>读优化视图表：tableName_ro</li>
<li>快照视图：tableName_rt</li>
</ul>
<h2 id="按月分区表"><a href="#按月分区表" class="headerlink" title="按月分区表"></a>按月分区表</h2><p>/basePath/tableName/2021-07/</p>
<p>/basePath/tableName/2021-08/</p>
<p>/basePath/tableName/…/</p>
<p>/basePath/tableName/2021-09/</p>
<p>概述：根据创建日期所在月分区，按月分区表适合大部分业务场景，业务每天数据量不是很大，或者数据变更不是很频繁，按月分区表以dam结尾。<br>优点：减少Hdfs小文件数量，hudi表使用MOR格式。<br>缺点：数据倾斜导致一个分区数据很大，分区内更新效率低</p>
<h2 id="按日分区表"><a href="#按日分区表" class="headerlink" title="按日分区表"></a>按日分区表</h2><p>/basePath/tableName/2021-08-16/<br>/basePath/tableName/2021-08-17/<br>/basePath/tableName/…/<br>/basePath/tableName/2021-09-14/</p>
<p>概述：根据创建日期分区，按日分区表适合业务每天数据量很大，或者数据变更频繁，适用于读少写多大表场景，按日分区表以dad结尾。<br>优点：优化写入效率，hudi表使用MOR格式。<br>缺点：分区越来越多，hive查询效率低，数据倾斜导致一个分区数据量很少，带来小文件问题</p>
<h1 id="采集表元数据管理"><a href="#采集表元数据管理" class="headerlink" title="采集表元数据管理"></a>采集表元数据管理</h1><h2 id="元数据管理流程"><a href="#元数据管理流程" class="headerlink" title="元数据管理流程"></a>元数据管理流程</h2><p><img src="/uploads/202203/%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png" alt="元数据管理流程"></p>
<h2 id="hudi-schema限制"><a href="#hudi-schema限制" class="headerlink" title="hudi schema限制"></a>hudi schema限制</h2><ul>
<li>hudi支持类型有null、boolean、int、long、float、double、bytes、string、array、map、enum</li>
<li>不能删除字段，不能修改字段名</li>
<li>添加字段需要有默认值</li>
<li>字段类型修改只允许如下变化：int修改成long，int、long修改成float，int、long、float修改成double，bytes修改成string，string修改成bbytes</li>
</ul>
<h2 id="mysql-hudi字段类型映射"><a href="#mysql-hudi字段类型映射" class="headerlink" title="mysql hudi字段类型映射"></a>mysql hudi字段类型映射</h2><table>
<thead>
<tr>
<th>序号</th>
<th>mysql</th>
<th>hudi</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>VARCHAR</td>
<td>string</td>
</tr>
<tr>
<td>2</td>
<td>DATE</td>
<td>string</td>
</tr>
<tr>
<td>3</td>
<td>CHAR</td>
<td>string</td>
</tr>
<tr>
<td>4</td>
<td>TINYINT</td>
<td>int</td>
</tr>
<tr>
<td>5</td>
<td>SMALLINT</td>
<td>int</td>
</tr>
<tr>
<td>6</td>
<td>DATETIME</td>
<td>long（string）hudi不支持时间类型，可以存储时间戳</td>
</tr>
<tr>
<td>7</td>
<td>TEXT</td>
<td>string</td>
</tr>
<tr>
<td>8</td>
<td>TIMESTAMP</td>
<td>long（string）hudi不支持时间类型，可以存储时间戳</td>
</tr>
<tr>
<td>9</td>
<td>INT</td>
<td>int</td>
</tr>
<tr>
<td>10</td>
<td>BIT</td>
<td>int</td>
</tr>
<tr>
<td>11</td>
<td>VARBINARY</td>
<td>string</td>
</tr>
<tr>
<td>12</td>
<td>LONGTEXT</td>
<td>string</td>
</tr>
<tr>
<td>13</td>
<td>DECIMAL</td>
<td>string</td>
</tr>
<tr>
<td>15</td>
<td>DOUBLE</td>
<td>double</td>
</tr>
<tr>
<td>16</td>
<td>BIGINT</td>
<td>long</td>
</tr>
<tr>
<td>17</td>
<td>BLOB</td>
<td>string</td>
</tr>
<tr>
<td>18</td>
<td>TINYINT UNSIGNED</td>
<td>int</td>
</tr>
<tr>
<td>19</td>
<td>SMALLINT UNSIGNED</td>
<td>int</td>
</tr>
<tr>
<td>20</td>
<td>INT UNSIGNED</td>
<td>long</td>
</tr>
<tr>
<td>21</td>
<td>BIGINT UNSIGNED</td>
<td>long</td>
</tr>
<tr>
<td>22</td>
<td>FLOAT UNSIGNED</td>
<td>float</td>
</tr>
<tr>
<td>23</td>
<td>DOUBLE UNSIGNED</td>
<td>double</td>
</tr>
<tr>
<td>24</td>
<td>FLOAT</td>
<td>float</td>
</tr>
<tr>
<td>25</td>
<td>MEDIUMINT UNSIGNED</td>
<td>int</td>
</tr>
</tbody></table>
<ol>
<li><h1 id="采集初始化到hudi"><a href="#采集初始化到hudi" class="headerlink" title="采集初始化到hudi"></a>采集初始化到hudi</h1></li>
</ol>
<p>采集初始化根据数据创建日期采集到数据日期所在月份的分区，示意图如3-1：<br><img src="/uploads/202203/%E5%88%9D%E5%A7%8B%E5%8C%96hudi%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F.png" alt="初始化hudi分区格式"></p>
<p>采集初始化由采集模块发起，请求调度，调度触发脚本机执行初始化任务，脚本机启动使用spark任务采集关系数据库数据，spark任务使用Datax采集MySQL、MongoDB，使用Hudi-spark-client模块将数据写入Hudi，示意图如3-2<br>这里依然生成了调度任务，只是在初始化的时候用了一次，可以简化成采集直接和脚本机接入，由采集直接触发脚本机执行任务，但是这个改动量比较大。<br><img src="/uploads/202203/%E5%88%9D%E5%A7%8B%E5%8C%96%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B.png" alt="初始化采集流程"></p>
<h1 id="采集实时写入hudi"><a href="#采集实时写入hudi" class="headerlink" title="采集实时写入hudi"></a>采集实时写入hudi</h1><ul>
<li>插入数据记录，直接插入到hudi原表</li>
<li>更新数据记录，直接更新hudi原表记录</li>
<li>删除数据记录，直接删除hudi原表记录，同时插入hudi删除表</li>
<li>以分钟频率拉取kafka记录摄入hudi，减少元数据提交次数</li>
</ul>
<p><img src="/uploads/202203/%E5%88%86%E9%92%9F%E9%A2%91%E7%8E%87.png" alt="分钟频率"></p>
<p>采集实时写入hudi由采集模块发起，在启动实时写入任务的时候将采集任务分配到固定的Flink节点，通过ESF和Flink节点通信，在Flink节点启动线程执行实时写入hudi任务，任务以每分钟频率拉取，使用Hudi-flink-client模块将数据写入Hudi，示意图如4-2<br><img src="/uploads/202203/%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B.png" alt="采集流程"></p>
<h1 id="异步合并parquet任务"><a href="#异步合并parquet任务" class="headerlink" title="异步合并parquet任务"></a>异步合并parquet任务</h1><p>对于Merge-On-Read表，数据使用列式Parquet文件和行式Avro文件存储，更新被记录到增量文件，然后进行同步/异步compaction生成新版本的列式文件。Merge-On-Read表可减少数据写入延迟，因而进行不阻塞摄入的异步Compaction很有意义，流程如下图5-1<br>创建一个调度任务，调度任务每个小时触发一次合并任务<br><img src="/uploads/202203/%E5%BC%82%E6%AD%A5%E5%90%88%E5%B9%B6parquet.png" alt="异步合并parquet"></p>
<ol>
<li><h1 id="监控报警"><a href="#监控报警" class="headerlink" title="监控报警"></a>监控报警</h1></li>
</ol>
<ul>
<li>Flink节点心跳检查</li>
<li>实时摄入任务每分钟（单次）写入耗时、写入insert条数、写入update条数、写入delete条数、写入数据条数、写入数据量，上报统一监控</li>
<li>异步合并parquet任务合并log文件数、合并耗时，上报统一监控</li>
<li>实时写入失败情况下报警</li>
</ul>
<h1 id="管理界"><a href="#管理界" class="headerlink" title="管理界"></a>管理界</h1><p><img src="/uploads/202203/%E7%AE%A1%E7%90%86%E7%95%8C%E9%9D%A2.png" alt="管理界面"></p>
<ul>
<li>存储目标添加hudi存储方式</li>
<li>提供按月分区、按日分区，根据近半年每日新增数据分析初始值，可修改</li>
<li>采集频率默认1m，提供30s、2m可选项</li>
<li>分区时间字段，例如创建时间</li>
</ul>
<h1 id="FDM表（hudi）后续使用特点"><a href="#FDM表（hudi）后续使用特点" class="headerlink" title="FDM表（hudi）后续使用特点"></a>FDM表（hudi）后续使用特点</h1><ol>
<li>实时采集默认都走hudi，全量表，拉链表功能保留，有需要可以用，不建议用</li>
<li>任务使用建议走spark引擎</li>
</ol>
<h1 id="问题列表"><a href="#问题列表" class="headerlink" title="问题列表"></a>问题列表</h1><ol>
<li>无创建时间表分区问题</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>采集</category>
      </categories>
      <tags>
        <tag>hudi</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题总结（一）</title>
    <url>/2021/06/30/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>spark面试题</li>
<li>hbase面试题</li>
<li>kafka面试题</li>
<li>flume面试题</li>
<li>hive面试题</li>
<li>kudu面试题</li>
<li>presto面试题</li>
<li>flink面试题</li>
<li>redis面试题</li>
<li>mongodb面试题</li>
<li>es面试题</li>
<li>数据仓库面试题</li>
<li>java面试题</li>
<li>scala面试题</li>
<li>sqoop与datax面试题<a id="more"></a>

</li>
</ul>
<h2 id="Spark面试题总结"><a href="#Spark面试题总结" class="headerlink" title="Spark面试题总结"></a>Spark面试题总结</h2><h2 id="Kafka面试题总结"><a href="#Kafka面试题总结" class="headerlink" title="Kafka面试题总结"></a>Kafka面试题总结</h2><ul>
<li><strong>Kafka 分布式的情况下，如何保证消息的顺序?</strong><pre class="line-numbers language-none"><code class="language-none">Kakfa不保证数据的整体有序，但是可以设置分区内消息有序，可以设置相同的key到同一个partition，这样就可以保证同一个key的消息，肯定是有序的<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


</li>
</ul>
<h2 id="数据仓库面试题总结"><a href="#数据仓库面试题总结" class="headerlink" title="数据仓库面试题总结"></a>数据仓库面试题总结</h2><h2 id="Hbase面试题"><a href="#Hbase面试题" class="headerlink" title="Hbase面试题"></a>Hbase面试题</h2><ul>
<li><strong>Hbase是写快还是读快？为什么？</strong><pre class="line-numbers language-none"><code class="language-none">Hbase是写快读慢。
Hbase写入速度比读取速度要快，根本原因LSM存储引擎
LSM核心思想的核心就是放弃部分读能力，换取写入的最大化能力
LSM核心思路就是假定内存足够大，因此不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在内存中，等到积累到最后多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾
将对数据的修改增量保持在内存中，达到指定的大小限制后将这些修改操作批量写入磁盘，不过读取的时候稍微麻烦，需要合并磁盘中历史数据和内存中最近修改操作，所以写入性能大大提升，读取时可能需要先看是否命中内存，否则需要访问较多的磁盘文件
LSM树原理把一棵大树拆分成N棵小树，它首先写入内存中，随着小树越来越大，内存中的小树会flush到磁盘中，磁盘中的树定期可以做merge操作，合并成一棵大树，以优化读性能<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>







</li>
</ul>
<h2 id="Sqoop与DataX面试题"><a href="#Sqoop与DataX面试题" class="headerlink" title="Sqoop与DataX面试题"></a>Sqoop与DataX面试题</h2><ul>
<li><strong>Sqoop与DataX优缺点比较？</strong>  <table>
<thead>
<tr>
<th align="center">功能</th>
<th align="center">DataX</th>
<th align="center">Sqoop</th>
</tr>
</thead>
<tbody><tr>
<td align="center">运行模型</td>
<td align="center">单进程多线程</td>
<td align="center">MapReduce</td>
</tr>
<tr>
<td align="center">Mysql读写</td>
<td align="center">单机压力大；读写粒度容易控制</td>
<td align="center">mr模式重，写出错处理麻烦</td>
</tr>
<tr>
<td align="center">hive读写</td>
<td align="center">单机压力大</td>
<td align="center">很好</td>
</tr>
<tr>
<td align="center">分布式</td>
<td align="center">不支持，可以通过调度系统规避</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center">流控</td>
<td align="center">有流控功能</td>
<td align="center">需要定制</td>
</tr>
<tr>
<td align="center">DataX是单机的，不是分布式的，但是可以通过在多台脚本机上启动任务来规避。但是DataX比较灵活，Sqoop重一点。</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">DataX虽然是单机的，但是，它的客户端是与namenode通信，走的是hdfs写数据流程，写数据的过程是并行执行的</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
</li>
</ul>
<p>Canel 是实时的，可以采集mysql的Binlog数据</p>
<h2 id="Redis面试题"><a href="#Redis面试题" class="headerlink" title="Redis面试题"></a>Redis面试题</h2><ul>
<li><strong>Redis有哪些优缺点</strong></li>
<li>*优点**</li>
<li>读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。</li>
<li>支持数据持久化，支持AOF和RDB两种持久化方式。</li>
<li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。</li>
<li>数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。</li>
<li>支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><p>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。</p>
</li>
<li><p>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。</p>
</li>
<li><p>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。</p>
</li>
<li><p>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。</p>
</li>
<li><p><strong>为什么要用 Redis 而不用 map/guava 做缓存?</strong><br>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。<br>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。</p>
</li>
</ul>
<ul>
<li><strong>Redis 的持久化机制是什么？各自的优缺点？</strong><br>Redis 提供两种持久化机制 <code>RDB（默认）</code> 和 <code>AOF 机制</code><br>RDB：是Redis DataBase缩写快照<blockquote>
<p>RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。</p>
</blockquote>
</li>
</ul>
<p>优点：<br>1、只有一个文件 dump.rdb，方便持久化。<br>2、容灾性好，一个文件可以保存到安全的磁盘。<br>3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能<br>4.相对于数据集大时，比 AOF 的启动效率更高。</p>
<p>缺点：<br>1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候)</p>
<blockquote>
<p>AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。<br>当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p>
</blockquote>
<p>优点：<br>1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。<br>2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。<br>3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）)</p>
<p>缺点：<br>1、AOF 文件比 RDB 文件大，且恢复速度慢。<br>2、数据集大的时候，比 rdb 启动效率低。</p>
<blockquote>
<p><code>RDB（默认）</code> 和 <code>AOF 机制</code>优缺点是什么？ </p>
</blockquote>
<p>AOF文件比RDB更新频率高，优先使用AOF还原数据。<br>AOF比RDB更安全也更大<br>RDB性能比AOF好<br>如果两个都配了优先加载AOF</p>
<ul>
<li><strong>Redis的过期键的删除策略</strong><blockquote>
<p>MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据</p>
</blockquote>
</li>
</ul>
<p>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p>
<ul>
<li>全局的键空间选择性移除<br>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<br>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的）<br>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li>
<li>设置过期时间的键空间选择性移除<br>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。<br>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。<br>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li>
</ul>
<h2 id="flink面试题"><a href="#flink面试题" class="headerlink" title="flink面试题"></a>flink面试题</h2><p>移步<a href="https://gujincheng.github.io/">Flink面试题总结</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>DataX学习笔记</title>
    <url>/2021/12/27/DataX%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>DataX学习笔记</li>
</ul>
<a id="more"></a>

<h2 id="DataX概览"><a href="#DataX概览" class="headerlink" title="DataX概览"></a>DataX概览</h2><h3 id="DataX-3-0概览"><a href="#DataX-3-0概览" class="headerlink" title="DataX 3.0概览"></a>DataX 3.0概览</h3><p> DataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p>
<h3 id="DataX-的设计理念"><a href="#DataX-的设计理念" class="headerlink" title="DataX 的设计理念"></a>DataX 的设计理念</h3><p>为了解决异构数据源同步问题，DataX 将复杂的网状的同步链路变成了星型数据链路，DataX 作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到 DataX，便能跟已有的数据源做到无缝数据同步。<br><img src="/uploads/20211228/DataX%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF.png" alt="DataX数据链路"></p>
<h3 id="框架设计"><a href="#框架设计" class="headerlink" title="框架设计"></a>框架设计</h3><p><img src="/uploads/20211228/DataX%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1.png" alt="DataX框架设计"></p>
<ul>
<li>Reader：数据采集模块，负责采集数据源的数据，将数据发给Framework。</li>
<li>Wiriter: 数据写入模块，负责不断向Framwork取数据，并将数据写入到目的端。</li>
<li>Framework:用于连接read和writer,作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等你核心技术问题。<h3 id="运行原理"><a href="#运行原理" class="headerlink" title="运行原理"></a>运行原理</h3><img src="/uploads/20211228/DataX%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86.png" alt="DataX运行原理"></li>
<li>*核心模块介绍：**</li>
</ul>
<ol>
<li>DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。</li>
<li>DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。</li>
<li>切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。</li>
<li>每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—&gt;Channel—&gt;Writer的线程来完成任务同步工作。</li>
<li>DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0</li>
</ol>
<p><strong>DataX调度流程：</strong><br>举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。 DataX的调度决策思路是：</p>
<ol>
<li>DataXJob根据分库分表切分成了100个Task。</li>
<li>根据20个并发，DataX计算共需要分配4个TaskGroup。</li>
<li>4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。</li>
</ol>
<ul>
<li>Job：单个作业的管理节点，负责数据清理、子任务划分、TaskGroup监控管理。</li>
<li>Task：由Job切分而来，是DataX作业的最小单元，每个Task负责一部分数据的同步工作。</li>
<li>Schedule：将Task组成TaskGroup，单个TaskGroup的并发数量为5。</li>
<li>TaskGroup：负责启动Task。</li>
</ul>
<h3 id="DataX3-0插件体系"><a href="#DataX3-0插件体系" class="headerlink" title="DataX3.0插件体系"></a>DataX3.0插件体系</h3><p>经过几年积累，DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入。DataX目前支持数据如下：<br>| 类型               | 数据源                          | Reader(读) | Writer(写) | 文档                                                         |<br>| —————— | ——————————- | ———- | ———- | ———————————————————— |<br>| RDBMS 关系型数据库 | MySQL                           | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.md">写</a> |<br>|                    | Oracle                          | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/oraclereader/doc/oraclereader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/oraclewriter/doc/oraclewriter.md">写</a> |<br>|                    | OceanBase                       | √          | √          | <a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase">读</a> 、<a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/use-datax-to-full-migration-data-to-oceanbase">写</a> |<br>|                    | SQLServer                       | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/sqlserverreader/doc/sqlserverreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/sqlserverwriter/doc/sqlserverwriter.md">写</a> |<br>|                    | PostgreSQL                      | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/postgresqlreader/doc/postgresqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/postgresqlwriter/doc/postgresqlwriter.md">写</a> |<br>|                    | DRDS                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/drdsreader/doc/drdsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/drdswriter/doc/drdswriter.md">写</a> |<br>|                    | 通用RDBMS(支持所有关系型数据库) | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/rdbmsreader/doc/rdbmsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/rdbmswriter/doc/rdbmswriter.md">写</a> |<br>| 阿里云数仓数据存储 | ODPS                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/odpsreader/doc/odpsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/odpswriter/doc/odpswriter.md">写</a> |<br>|                    | ADS                             |            | √          | <a href="https://github.com/alibaba/DataX/blob/master/adswriter/doc/adswriter.md">写</a> |<br>|                    | OSS                             | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/ossreader/doc/ossreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/osswriter/doc/osswriter.md">写</a> |<br>|                    | OCS                             |            | √          | <a href="https://github.com/alibaba/DataX/blob/master/ocswriter/doc/ocswriter.md">写</a> |<br>| NoSQL数据存储      | OTS                             | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/otsreader/doc/otsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/otswriter/doc/otswriter.md">写</a> |<br>|                    | Hbase0.94                       | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase094xreader/doc/hbase094xreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase094xwriter/doc/hbase094xwriter.md">写</a> |<br>|                    | Hbase1.1                        | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase11xreader/doc/hbase11xreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xwriter/doc/hbase11xwriter.md">写</a> |<br>|                    | Phoenix4.x                      | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase11xsqlreader/doc/hbase11xsqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase11xsqlwriter/doc/hbase11xsqlwriter.md">写</a> |<br>|                    | Phoenix5.x                      | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hbase20xsqlreader/doc/hbase20xsqlreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hbase20xsqlwriter/doc/hbase20xsqlwriter.md">写</a> |<br>|                    | MongoDB                         | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/mongodbreader/doc/mongodbreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/mongodbwriter/doc/mongodbwriter.md">写</a> |<br>|                    | Hive                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md">写</a> |<br>|                    | Cassandra                       | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/cassandrareader/doc/cassandrareader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/cassandrawriter/doc/cassandrawriter.md">写</a> |<br>| 无结构化数据存储   | TxtFile                         | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/txtfilereader/doc/txtfilereader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/txtfilewriter/doc/txtfilewriter.md">写</a> |<br>|                    | FTP                             | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/ftpreader/doc/ftpreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/ftpwriter/doc/ftpwriter.md">写</a> |<br>|                    | HDFS                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/hdfsreader/doc/hdfsreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/hdfswriter/doc/hdfswriter.md">写</a> |<br>|                    | Elasticsearch                   |            | √          | <a href="https://github.com/alibaba/DataX/blob/master/elasticsearchwriter/doc/elasticsearchwriter.md">写</a> |<br>| 时间序列数据库     | OpenTSDB                        | √          |            | <a href="https://github.com/alibaba/DataX/blob/master/opentsdbreader/doc/opentsdbreader.md">读</a> |<br>|                    | TSDB                            | √          | √          | <a href="https://github.com/alibaba/DataX/blob/master/tsdbreader/doc/tsdbreader.md">读</a> 、<a href="https://github.com/alibaba/DataX/blob/master/tsdbwriter/doc/tsdbhttpwriter.md">写</a> |</p>
<p>DataX Framework提供了简单的接口与插件交互，提供简单的插件接入机制，只需要任意加上一种插件，就能无缝对接其他数据源。</p>
<h2 id="DataX使用案例"><a href="#DataX使用案例" class="headerlink" title="DataX使用案例"></a>DataX使用案例</h2><p>DataX通过插件机制，动态的在运行时载入reader和writer进行数据同步的执行。<br>所以在使用DataX的时候，需要指定reader和writer，确定是数据是从哪里来到哪里去<br>例如，现在需要采集mysql数据到hive。那么reader其实就是mysql，writer就是hdfs</p>
<ol>
<li>进入到<code>datax/plugin/reader</code>查看reader下插件目录，从中发现有mysqlreader</li>
<li>再进入<code>datax/plugin/writer</code>查看writer下插件目录，从中发现有hdfswriter</li>
<li>查看官方给的调用模版,执行<code>bin/datax.py -r mysqlreader -w hdfswriter</code>,得到如下json：<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
    <span class="token property">"job"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
        <span class="token property">"content"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
            <span class="token punctuation">&#123;</span>
                <span class="token property">"reader"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"mysqlreader"</span><span class="token punctuation">,</span>
                    <span class="token property">"parameter"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                        <span class="token property">"column"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token property">"connection"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
                            <span class="token punctuation">&#123;</span>
                                <span class="token property">"jdbcUrl"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                <span class="token property">"table"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                            <span class="token punctuation">&#125;</span>
                        <span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token property">"password"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"username"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"where"</span><span class="token operator">:</span> <span class="token string">""</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
                <span class="token property">"writer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"hdfswriter"</span><span class="token punctuation">,</span>
                    <span class="token property">"parameter"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                        <span class="token property">"column"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token property">"compress"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"defaultFS"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"fieldDelimiter"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"fileName"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"fileType"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"path"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
                        <span class="token property">"writeMode"</span><span class="token operator">:</span> <span class="token string">""</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token property">"setting"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"speed"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
                <span class="token property">"channel"</span><span class="token operator">:</span> <span class="token string">""</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<p><strong>注意：</strong> 这里的模版只会给必写的选项，非必写的，就不会在这个模版里。例如<code>hadoopConfig</code><br>如果要看全部的选项，可以在源码里找到相对应的插件目录，里面有相应的md文件，例如hdfswriter的文档在<br><code>DataX/hdfswriter/doc/hdfswriter.md</code></p>
<ol start="4">
<li>编写自己的mysql2hive.json文件，并执行<code>bin/datax.py job/mysql2hive.json</code>即可</li>
</ol>
<p>完整的mysql2hive.json案例：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
	<span class="token property">"job"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
		<span class="token property">"content"</span><span class="token operator">:</span><span class="token punctuation">[</span>
			<span class="token punctuation">&#123;</span>
				<span class="token property">"reader"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
					<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"mysqlreader"</span><span class="token punctuation">,</span>
					<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
						<span class="token property">"column"</span><span class="token operator">:</span><span class="token punctuation">[</span>
							<span class="token string">"`id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`activity_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`start_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`end_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`status`"</span><span class="token punctuation">,</span>
							<span class="token string">"`status_desc`"</span><span class="token punctuation">,</span>
							<span class="token string">"`charge_type`"</span><span class="token punctuation">,</span>
							<span class="token string">"`daily_budgets`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bid`"</span><span class="token punctuation">,</span>
							<span class="token string">"`kb_cost_task_id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`account_type`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bp_id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bp_type`"</span><span class="token punctuation">,</span>
							<span class="token string">"`bp_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`shop_id`"</span><span class="token punctuation">,</span>
							<span class="token string">"`shop_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`create_user`"</span><span class="token punctuation">,</span>
							<span class="token string">"`create_user_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`create_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`update_user`"</span><span class="token punctuation">,</span>
							<span class="token string">"`update_time`"</span><span class="token punctuation">,</span>
							<span class="token string">"`yn`"</span><span class="token punctuation">,</span>
							<span class="token string">"`update_user_name`"</span><span class="token punctuation">,</span>
							<span class="token string">"`sales_order_no`"</span>
						<span class="token punctuation">]</span><span class="token punctuation">,</span>
						<span class="token property">"connection"</span><span class="token operator">:</span><span class="token punctuation">[</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"customParam"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
								<span class="token property">"jdbcUrl"</span><span class="token operator">:</span><span class="token punctuation">[</span>
									<span class="token string">"jdbc:mysql://xxxx:3306/ad_star_store?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true"</span>
								<span class="token punctuation">]</span><span class="token punctuation">,</span>
								<span class="token property">"querySql"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
								<span class="token property">"table"</span><span class="token operator">:</span><span class="token punctuation">[</span>
									<span class="token string">"hbp_ad_activity"</span>
								<span class="token punctuation">]</span>
							<span class="token punctuation">&#125;</span>
						<span class="token punctuation">]</span><span class="token punctuation">,</span>
						<span class="token property">"mandatoryEncoding"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
						<span class="token property">"monthTableMode"</span><span class="token operator">:</span><span class="token string">""</span><span class="token punctuation">,</span>
						<span class="token property">"password"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"splitPk"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
						<span class="token property">"tableOrView"</span><span class="token operator">:</span><span class="token string">"1"</span><span class="token punctuation">,</span>
						<span class="token property">"username"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"version"</span><span class="token operator">:</span><span class="token string">"2"</span><span class="token punctuation">,</span>
						<span class="token property">"where"</span><span class="token operator">:</span><span class="token null keyword">null</span>
					<span class="token punctuation">&#125;</span>
				<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
				<span class="token property">"transformer"</span><span class="token operator">:</span><span class="token punctuation">[</span>
					<span class="token punctuation">&#123;</span>
						<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"proxy_transformer"</span><span class="token punctuation">,</span>
						<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
							<span class="token property">"code"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"columnIndex"</span><span class="token operator">:</span><span class="token number">-1</span><span class="token punctuation">,</span>
							<span class="token property">"extraPackage"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"paras"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"1"</span><span class="token punctuation">,</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span><span class="token string">"id"</span><span class="token punctuation">,</span><span class="token string">"activity_name"</span><span class="token punctuation">,</span><span class="token string">"start_time"</span><span class="token punctuation">,</span><span class="token string">"end_time"</span><span class="token punctuation">,</span><span class="token string">"status"</span><span class="token punctuation">,</span><span class="token string">"status_desc"</span><span class="token punctuation">,</span><span class="token string">"charge_type"</span><span class="token punctuation">,</span><span class="token string">"daily_budgets"</span><span class="token punctuation">,</span><span class="token string">"bid"</span><span class="token punctuation">,</span><span class="token string">"kb_cost_task_id"</span><span class="token punctuation">,</span><span class="token string">"account_type"</span><span class="token punctuation">,</span><span class="token string">"bp_id"</span><span class="token punctuation">,</span><span class="token string">"bp_type"</span><span class="token punctuation">,</span><span class="token string">"bp_name"</span><span class="token punctuation">,</span><span class="token string">"shop_id"</span><span class="token punctuation">,</span><span class="token string">"shop_name"</span><span class="token punctuation">,</span><span class="token string">"create_user"</span><span class="token punctuation">,</span><span class="token string">"create_user_name"</span><span class="token punctuation">,</span><span class="token string">"create_time"</span><span class="token punctuation">,</span><span class="token string">"update_user"</span><span class="token punctuation">,</span><span class="token string">"update_time"</span><span class="token punctuation">,</span><span class="token string">"yn"</span><span class="token punctuation">,</span><span class="token string">"update_user_name"</span><span class="token punctuation">,</span><span class="token string">"sales_order_no"</span><span class="token punctuation">]</span>
						<span class="token punctuation">&#125;</span>
					<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
					<span class="token punctuation">&#123;</span>
						<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"proxy_transformer"</span><span class="token punctuation">,</span>
						<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
							<span class="token property">"code"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"columnIndex"</span><span class="token operator">:</span><span class="token number">-1</span><span class="token punctuation">,</span>
							<span class="token property">"extraPackage"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
							<span class="token property">"paras"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"2"</span><span class="token punctuation">,</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span><span class="token string">"id"</span><span class="token punctuation">,</span><span class="token string">"activity_name"</span><span class="token punctuation">,</span><span class="token string">"start_time"</span><span class="token punctuation">,</span><span class="token string">"end_time"</span><span class="token punctuation">,</span><span class="token string">"status"</span><span class="token punctuation">,</span><span class="token string">"status_desc"</span><span class="token punctuation">,</span><span class="token string">"charge_type"</span><span class="token punctuation">,</span><span class="token string">"daily_budgets"</span><span class="token punctuation">,</span><span class="token string">"bid"</span><span class="token punctuation">,</span><span class="token string">"kb_cost_task_id"</span><span class="token punctuation">,</span><span class="token string">"account_type"</span><span class="token punctuation">,</span><span class="token string">"bp_id"</span><span class="token punctuation">,</span><span class="token string">"bp_type"</span><span class="token punctuation">,</span><span class="token string">"bp_name"</span><span class="token punctuation">,</span><span class="token string">"shop_id"</span><span class="token punctuation">,</span><span class="token string">"shop_name"</span><span class="token punctuation">,</span><span class="token string">"create_user"</span><span class="token punctuation">,</span><span class="token string">"create_user_name"</span><span class="token punctuation">,</span><span class="token string">"create_time"</span><span class="token punctuation">,</span><span class="token string">"update_user"</span><span class="token punctuation">,</span><span class="token string">"update_time"</span><span class="token punctuation">,</span><span class="token string">"yn"</span><span class="token punctuation">,</span><span class="token string">"update_user_name"</span><span class="token punctuation">,</span><span class="token string">"sales_order_no"</span><span class="token punctuation">]</span>
						<span class="token punctuation">&#125;</span>
					<span class="token punctuation">&#125;</span>
				<span class="token punctuation">]</span><span class="token punctuation">,</span>
				<span class="token property">"writer"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
					<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"hdfswriter"</span><span class="token punctuation">,</span>
					<span class="token property">"parameter"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
						<span class="token property">"column"</span><span class="token operator">:</span><span class="token punctuation">[</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"activity_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"start_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"end_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"status"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"status_desc"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"charge_type"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"daily_budgets"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bid"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"kb_cost_task_id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"BIGINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"account_type"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bp_id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bp_type"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TINYINT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"bp_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"shop_id"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"shop_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"create_user"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"create_user_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"create_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"update_user"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"update_time"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"TIMESTAMP"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"yn"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"INT"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"update_user_name"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
							<span class="token punctuation">&#123;</span>
								<span class="token property">"name"</span><span class="token operator">:</span><span class="token string">"sales_order_no"</span><span class="token punctuation">,</span>
								<span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"STRING"</span>
							<span class="token punctuation">&#125;</span>
						<span class="token punctuation">]</span><span class="token punctuation">,</span>
						<span class="token property">"compress"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
						<span class="token property">"defaultFS"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"fieldDelimiter"</span><span class="token operator">:</span><span class="token string">"\t"</span><span class="token punctuation">,</span>
						<span class="token property">"fileName"</span><span class="token operator">:</span><span class="token string">"hbp_ad_activity"</span><span class="token punctuation">,</span>
						<span class="token property">"fileType"</span><span class="token operator">:</span><span class="token string">"text"</span><span class="token punctuation">,</span>
						<span class="token property">"hadoopConfig"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>  
							<span class="token property">"fs.defaultFS"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.ha.namenodes.HZWONE"</span><span class="token operator">:</span><span class="token string">"nn1,nn2"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.nameservices"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.namenode.rpc-address.HZWONE.nn2"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx:xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.namenode.rpc-address.HZWONE.nn1"</span><span class="token operator">:</span><span class="token string">"hdfs://xxxx:xxxx"</span><span class="token punctuation">,</span>
							<span class="token property">"dfs.client.failover.proxy.provider.HZWONE"</span><span class="token operator">:</span><span class="token string">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>
						<span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
						<span class="token property">"path"</span><span class="token operator">:</span><span class="token string">"xxxx"</span><span class="token punctuation">,</span>
						<span class="token property">"writeMode"</span><span class="token operator">:</span><span class="token string">"append"</span>
					<span class="token punctuation">&#125;</span>
				<span class="token punctuation">&#125;</span>
			<span class="token punctuation">&#125;</span>
		<span class="token punctuation">]</span><span class="token punctuation">,</span>
		<span class="token property">"setting"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
			<span class="token property">"errorLimit"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
			<span class="token property">"speed"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
				<span class="token property">"batchSize"</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>
				<span class="token property">"channel"</span><span class="token operator">:</span><span class="token number">8</span><span class="token punctuation">,</span>
				<span class="token property">"record"</span><span class="token operator">:</span><span class="token number">0</span>
			<span class="token punctuation">&#125;</span>
		<span class="token punctuation">&#125;</span>
	<span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>hadoopConfig是为了datax往hdfs写数据如何配置高可用</p>
<h2 id="DataX定制化插件开发与使用"><a href="#DataX定制化插件开发与使用" class="headerlink" title="DataX定制化插件开发与使用"></a>DataX定制化插件开发与使用</h2><h3 id="DataX为什么要使用插件机制？"><a href="#DataX为什么要使用插件机制？" class="headerlink" title="DataX为什么要使用插件机制？"></a>DataX为什么要使用插件机制？</h3><p>从设计之初，DataX就把异构数据源同步作为自身的使命，为了应对不同数据源的差异、同时提供一致的同步原语和扩展能力，DataX自然而然地采用了<code>框架 + 插件</code>的模式：</p>
<ul>
<li>插件只需关心数据的读取或者写入本身。</li>
<li>而同步的共性问题，比如：类型转换、性能、统计，则交由框架来处理。<br>作为插件开发人员，则需要关注两个问题：</li>
</ul>
<p>数据源1. 本身的读写数据正确性。<br>如何与2. 框架沟通、合理正确地使用框架。</p>
<h3 id="插件视角看框架"><a href="#插件视角看框架" class="headerlink" title="插件视角看框架"></a>插件视角看框架</h3><h4 id="逻辑执行模型"><a href="#逻辑执行模型" class="headerlink" title="逻辑执行模型"></a>逻辑执行模型</h4><p>插件开发者不用关心太多，基本只需要关注特定系统读和写，以及自己的代码在逻辑上是怎样被执行的，哪一个方法是在什么时候被调用的。在此之前，需要明确以下概念：</p>
<ul>
<li>Job: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。</li>
<li>Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。</li>
<li>TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup</li>
<li>JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker</li>
<li>TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。<br>简而言之， Job拆分成Task，在分别在框架提供的容器中执行，插件只需要实现Job和Task两部分逻辑。</li>
</ul>
<h4 id="物理执行模型"><a href="#物理执行模型" class="headerlink" title="物理执行模型"></a>物理执行模型</h4><p>框架为插件提供物理上的执行能力（线程）。DataX框架有三种运行模式：</p>
<ul>
<li>Standalone: 单进程运行，没有外部依赖。</li>
<li>Local: 单进程运行，统计信息、错误信息汇报到集中存储。</li>
<li>Distrubuted: 分布式多进程运行，依赖DataX Service服务。<br>当然，上述三种模式对插件的编写而言没有什么区别，你只需要避开一些小错误，插件就能够在单机/分布式之间无缝切换了。 当JobContainer和TaskGroupContainer运行在同一个进程内时，就是单机模式（Standalone和Local）；当它们分布在不同的进程中执行时，就是分布式（Distributed）模式。</li>
</ul>
<h4 id="编程接口"><a href="#编程接口" class="headerlink" title="编程接口"></a>编程接口</h4><p>那么，Job和Task的逻辑应是怎么对应到具体的代码中的？</p>
<p>首先，插件的入口类必须扩展Reader或Writer抽象类，并且实现分别实现Job和Task两个内部抽象类，Job和Task的实现必须是 内部类 的形式，原因见 加载原理 一节。<br>具体参考<a href="https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md">DataX插件开发宝典</a></p>
<h4 id="插件定义"><a href="#插件定义" class="headerlink" title="插件定义"></a>插件定义</h4><p>代码写好了，有没有想过框架是怎么找到插件的入口类的？框架是如何加载插件的呢？</p>
<p>在每个插件的项目中，都有一个plugin.json文件，这个文件定义了插件的相关信息，包括入口类。例如：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"mysqlwriter"</span><span class="token punctuation">,</span>
    <span class="token property">"class"</span><span class="token operator">:</span> <span class="token string">"com.alibaba.datax.plugin.writer.mysqlwriter.MysqlWriter"</span><span class="token punctuation">,</span>
    <span class="token property">"description"</span><span class="token operator">:</span> <span class="token string">"Use Jdbc connect to database, execute insert sql."</span><span class="token punctuation">,</span>
    <span class="token property">"developer"</span><span class="token operator">:</span> <span class="token string">"alibaba"</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>name: 插件名称，大小写敏感。框架根据用户在配置文件中指定的名称来搜寻插件。 十分重要 。</li>
<li>class: 入口类的全限定名称，框架通过反射插件入口类的实例。十分重要 。</li>
<li>description: 描述信息。</li>
<li>developer: 开发人员。<h4 id="打包发布"><a href="#打包发布" class="headerlink" title="打包发布"></a>打包发布</h4>DataX使用assembly打包，assembly的使用方法请咨询谷哥或者度娘。打包命令如下：<br><code>mvn clean package -DskipTests assembly:assembly</code><br>DataX插件需要遵循统一的目录结构：<pre class="line-numbers language-text" data-language="text"><code class="language-text">$&#123;DATAX_HOME&#125;
|-- bin       
|   &#96;-- datax.py
|-- conf
|   |-- core.json
|   &#96;-- logback.xml
|-- lib
|   &#96;-- datax-core-dependencies.jar
&#96;-- plugin
    |-- reader
    |   &#96;-- mysqlreader
    |       |-- libs
    |       |   &#96;-- mysql-reader-plugin-dependencies.jar
    |       |-- mysqlreader-0.0.1-SNAPSHOT.jar
    |       &#96;-- plugin.json
    &#96;-- writer
        |-- mysqlwriter
        |   |-- libs
        |   |   &#96;-- mysql-writer-plugin-dependencies.jar
        |   |-- mysqlwriter-0.0.1-SNAPSHOT.jar
        |   &#96;-- plugin.json
        |-- oceanbasewriter
        &#96;-- odpswriter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>${DATAX_HOME}/bin: 可执行程序目录。</li>
<li>${DATAX_HOME}/conf: 框架配置目录。</li>
<li>${DATAX_HOME}/lib: 框架依赖库目录。</li>
<li>${DATAX_HOME}/plugin: 插件目录。</li>
</ul>
<p>插件目录分为reader和writer子目录，读写插件分别存放。插件目录规范如下：</p>
<ul>
<li>${PLUGIN_HOME}/libs: 插件的依赖库。</li>
<li>${PLUGIN_HOME}/plugin-name-version.jar: 插件本身的jar。</li>
<li>${PLUGIN_HOME}/plugin.json: 插件描述文件。<br>尽管框架加载插件时，会把${PLUGIN_HOME}下所有的jar放到classpath，但还是推荐依赖库的jar和插件本身的jar分开存放。</li>
</ul>
<p><strong>注意</strong>： 插件的目录名字必须和plugin.json中定义的插件名称一致。</p>
<h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>DataX使用json作为配置文件的格式。<br>具体参考<a href="https://github.com/alibaba/DataX/blob/master/dataxPluginDev.md">DataX插件开发宝典</a></p>
<h3 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h3><p>hdfswriter写到hdfs只会产生一个文件，是因为并发为1嘛？<br>这里需要确认一下</p>
<p>公司写hudi的时候，仅在实时用的是spark，在离线初始化的时候使用了datax，这里没有用spark重写datax的writer，用spark写不了data的writer</p>
<h3 id="抽取本地mysql报如下错误"><a href="#抽取本地mysql报如下错误" class="headerlink" title="抽取本地mysql报如下错误"></a>抽取本地mysql报如下错误</h3><ul>
<li><p>报mysql链接不上，报错日志如下：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">ERROR RetryUtil - Exception when calling callable, 异常Msg:DataX无法连接对应的数据库，可能原因是：
1) 配置的ip&#x2F;port&#x2F;database&#x2F;jdbc错误，无法连接。
2) 配置的username&#x2F;password错误，鉴权失败。请和DBA确认该数据库的连接信息是否正确。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>*解决办法：**<br>datax里面的mysql驱动更换成合适的8.x的版本就好了:</p>
</li>
<li><p>报值非法</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">com.alibaba.datax.common.exception.DataXException: Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 任务读取配置文件出错. 配置文件路径[job.setting.speed.channel] 值非法, 期望是整数类型: For input string: &quot;&quot;. 请检查您的配置并作出修改.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>*解决办法：**<br>channel一开始写成了 “”,改成int就可以了</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"setting"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
			<span class="token property">"errorLimit"</span><span class="token operator">:</span><span class="token null keyword">null</span><span class="token punctuation">,</span>
			<span class="token property">"speed"</span><span class="token operator">:</span><span class="token punctuation">&#123;</span>
				<span class="token property">"batchSize"</span><span class="token operator">:</span><span class="token number">0</span><span class="token punctuation">,</span>  ## 批提交
				<span class="token property">"channel"</span><span class="token operator">:</span><span class="token number">8</span><span class="token punctuation">,</span> ##并发量
				<span class="token property">"record"</span><span class="token operator">:</span><span class="token number">0</span>  # 对数据条数做限制
			<span class="token punctuation">&#125;</span>
		<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
        <category>DataX</category>
      </categories>
      <tags>
        <tag>DataX</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（三）</title>
    <url>/2021/02/07/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink状态管理</li>
<li>Flink Checkpoint机制</li>
<li>Flink精准一次探究</li>
</ul>
<a id="more"></a>
<h2 id="Flink状态管理"><a href="#Flink状态管理" class="headerlink" title="Flink状态管理"></a>Flink状态管理</h2><p>看到一篇文章，讲述的Flink的状态管理特别详细，忍不住想记录一下，哈哈<br>具体可以参考：<br><a href="https://blog.csdn.net/qq_42596142/article/details/104097745?ops_request_misc=&request_id=&biz_id=102&utm_source=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1">Flink状态管理：Keyed State和Operator List State深度解析</a></p>
<h3 id="为什么要管理状态"><a href="#为什么要管理状态" class="headerlink" title="为什么要管理状态"></a>为什么要管理状态</h3><p>有状态的计算是流处理框架要实现的重要功能，因为稍复杂的流处理场景都需要记录状态，然后在新流入数据的基础上不断更新状态。下面的几个场景都需要使用流处理的状态功能：</p>
<ul>
<li>数据流中的数据有重复，我们想对重复数据去重，需要记录哪些数据已经流入过应用，当新数据流入时，根据已流入过的数据来判断去重。</li>
<li>检查输入流是否符合某个特定的模式，需要将之前流入的元素以状态的形式缓存下来。比如，判断一个温度传感器数据流中的温度是否在持续上升。</li>
<li>对一个时间窗口内的数据进行聚合分析，分析一个小时内某项指标的75分位或99分位的数值。</li>
<li>在线机器学习场景下，需要根据新流入数据不断更新机器学习的模型参数。</li>
</ul>
<p>我们知道，Flink的一个算子有多个子任务，每个子任务分布在不同实例上，我们可以把状态理解为某个算子子任务在其当前实例上的一个变量，变量记录了数据流的历史信息。当新数据流入时，我们可以结合历史信息来进行计算。实际上，Flink的状态是由算子的子任务来创建和管理的。一个状态更新和获取的流程如下图所示，一个算子子任务接收输入流，获取对应的状态，根据新的计算结果更新状态。一个简单的例子是对一个时间窗口内输入流的某个整数字段求和，那么当算子子任务接收到新元素时，会获取已经存储在状态中的数值，然后将当前输入加到状态上，并将状态数据更新。</p>
<p><img src="/uploads/20210208/Flink%E4%BB%BB%E5%8A%A1.png" alt="Flink任务"></p>
<p>获取和更新状态的逻辑其实并不复杂，但流处理框架还需要解决以下几类问题：</p>
<ul>
<li>数据的产出要保证实时性，延迟不能太高。</li>
<li>需要保证数据不丢不重，恰好计算一次，尤其是当状态数据非常大或者应用出现故障需要恢复时，要保证状态的计算不出任何错误。</li>
<li>一般流处理任务都是7*24小时运行的，程序的可靠性非常高。<br>基于上述要求，我们不能将状态直接交由内存管理，因为内存的容量是有限制的，当状态数据稍微大一些时，就会出现内存不够的问题。假如我们使用一个持久化的备份系统，不断将内存中的状态备份起来，当流处理作业出现故障时，需要考虑如何从备份中恢复。而且，大数据应用一般是横向分布在多个节点上，流处理框架需要保证横向的伸缩扩展性。可见，状态的管理并不那么容易。</li>
</ul>
<p>作为一个计算框架，Flink提供了有状态的计算，封装了一些底层的实现，比如状态的高效存储、Checkpoint和Savepoint持久化备份机制、计算资源扩缩容等问题。因为Flink接管了这些问题，开发者只需调用Flink API，这样可以更加专注于业务逻辑。</p>
<h3 id="Flink的几种状态类型"><a href="#Flink的几种状态类型" class="headerlink" title="Flink的几种状态类型"></a>Flink的几种状态类型</h3><h4 id="Managed-State和Raw-State"><a href="#Managed-State和Raw-State" class="headerlink" title="Managed State和Raw State"></a>Managed State和Raw State</h4><p>Flink有两种基本类型的状态：托管状态（Managed State）和原生状态（Raw State）。从名称中也能读出两者的区别：Managed State是由Flink管理的，Flink帮忙存储、恢复和优化，Raw State是开发者自己管理的，需要自己序列化。</p>
<table>
<thead>
<tr>
<th></th>
<th>Managed State</th>
<th>Raw State</th>
</tr>
</thead>
<tbody><tr>
<td>状态管理方式</td>
<td>Flink Runtime托管，自动存储、自动恢复、自动伸缩</td>
<td>用户自己管理</td>
</tr>
<tr>
<td>状态数据结构</td>
<td>Flink提供的常用数据结构，如ListState、MapState等</td>
<td>字节数组：byte[]</td>
</tr>
<tr>
<td>使用场景</td>
<td>绝大多数Flink算子</td>
<td>用户自定义算子</td>
</tr>
</tbody></table>
<p>两者的具体区别有：</p>
<ul>
<li>从状态管理的方式上来说，Managed State由Flink Runtime托管，状态是自动存储、自动恢复的，Flink在存储管理和持久化上做了一些优化。当我们横向伸缩，或者说我们修改Flink应用的并行度时，状态也能自动重新分布到多个并行实例上。Raw State是用户自定义的状态。</li>
<li>从状态的数据结构上来说，Managed State支持了一系列常见的数据结构，如ValueState、ListState、MapState等。Raw State只支持字节，任何上层数据结构需要序列化为字节数组。使用时，需要用户自己序列化，以非常底层的字节数组形式存储，Flink并不知道存储的是什么样的数据结构。</li>
<li>从具体使用场景来说，绝大多数的算子都可以通过继承Rich函数类或其他提供好的接口类，在里面使用Managed State。Raw State是在已有算子和Managed State不够用时，用户自定义算子时使用。</li>
</ul>
<p>下文将重点介绍Managed State。</p>
<h4 id="Keyed-State和Operator-State"><a href="#Keyed-State和Operator-State" class="headerlink" title="Keyed State和Operator State"></a>Keyed State和Operator State</h4><p>对Managed State继续细分，它又有两种类型：Keyed State和Operator State。这里先简单对比两种状态，后续还将展示具体的使用方法。</p>
<p>Keyed State是KeyedStream上的状态。假如输入流按照id为Key进行了keyBy分组，形成一个KeyedStream，数据流中所有id为1的数据共享一个状态，可以访问和更新这个状态，以此类推，每个Key对应一个自己的状态。下图展示了Keyed State，因为一个算子子任务可以处理一到多个Key，算子子任务1处理了两种Key，两种Key分别对应自己的状态。<br><img src="/uploads/20210208/Flink%E7%8A%B6%E6%80%81%E8%AE%A1%E7%AE%97KeyedState.png" alt="Flink状态计算KeyedState"><br>Operator State可以用在所有算子上，每个算子子任务或者说每个算子实例共享一个状态，流入这个算子子任务的数据可以访问和更新这个状态。下图展示了Operator State，算子子任务1上的所有数据可以共享第一个Operator State，以此类推，每个算子子任务上的数据共享自己的状态。<br><img src="/uploads/20210208/Flink%E7%8A%B6%E6%80%81%E8%AE%A1%E7%AE%97OperatorState.png" alt="Flink状态计算OperatorState"><br>无论是Keyed State还是Operator State，Flink的状态都是基于本地的，即每个算子子任务维护着这个算子子任务对应的状态存储，算子子任务之间的状态不能相互访问。</p>
<p>在之前各算子的介绍中曾提到，为了自定义Flink的算子，我们可以重写Rich Function接口类，比如RichFlatMapFunction。使用Keyed State时，我们也可以通过重写Rich Function接口类，在里面创建和访问状态。对于Operator State，我们还需进一步实现CheckpointedFunction接口。</p>
<table>
<thead>
<tr>
<th></th>
<th>Keyed State</th>
<th>Operator State</th>
</tr>
</thead>
<tbody><tr>
<td>适用算子类型</td>
<td>只适用于KeyedStream上的算子</td>
<td>可以用于所有算子</td>
</tr>
<tr>
<td>状态分配</td>
<td>每个Key对应一个状态</td>
<td>一个算子子任务对应一个状态</td>
</tr>
<tr>
<td>创建和访问方式</td>
<td>重写Rich Function，通过里面的RuntimeContext访问</td>
<td>实现CheckpointedFunction等接口</td>
</tr>
<tr>
<td>横向扩展</td>
<td>状态随着Key自动在多个算子子任务上迁移</td>
<td>有多种状态重新分配的方式</td>
</tr>
<tr>
<td>支持的数据结构</td>
<td>ValueState、ListState、MapState等</td>
<td>ListState、BroadcastState等</td>
</tr>
</tbody></table>
<p>上表总结了Keyed State和Operator State的区别。</p>
<h4 id="横向扩展问题"><a href="#横向扩展问题" class="headerlink" title="横向扩展问题"></a>横向扩展问题</h4><p>状态的横向扩展问题主要是指修改Flink应用的并行度，确切的说，每个算子的并行实例数或算子子任务数发生了变化，应用需要关停或启动一些算子子任务，某份在原来某个算子子任务上的状态数据需要平滑更新到新的算子子任务上。其实，Flink的Checkpoint就是一个非常好的在各算子间迁移状态数据的机制。算子的本地状态将数据生成快照（snapshot），保存到分布式存储（如HDFS）上。横向伸缩后，算子子任务个数变化，子任务重启，相应的状态从分布式存储上重建（restore）。<br><img src="/uploads/20210208/%E6%A8%AA%E5%90%91%E6%89%A9%E5%B1%95.png" alt="横向扩展"><br>对于Keyed State和Operator State这两种状态，他们的横向伸缩机制不太相同。由于每个Keyed State总是与某个Key相对应，当横向伸缩时，Key总会被自动分配到某个算子子任务上，因此Keyed State会自动在多个并行子任务之间迁移。对于一个非KeyedStream，流入算子子任务的数据可能会随着并行度的改变而改变。如上图所示，假如一个应用的并行度原来为2，那么数据会被分成两份并行地流入两个算子子任务，每个算子子任务有一份自己的状态，当并行度改为3时，数据流被拆成3支，或者并行度改为1，数据流合并为1支，此时状态的存储也相应发生了变化。对于横向伸缩问题，Operator State有两种状态分配方式：一种是均匀分配，另一种是将所有状态合并，再分发给每个实例上。</p>
<h4 id="Keyed-State的使用方法"><a href="#Keyed-State的使用方法" class="headerlink" title="Keyed State的使用方法"></a>Keyed State的使用方法</h4><p>对于Keyed State，Flink提供了几种现成的数据结构供我们使用，包括ValueState、ListState等，他们的继承关系如下图所示。首先，State主要有三种实现，分别为ValueState、MapState和AppendingState，AppendingState又可以细分为ListState、ReducingState和AggregatingState。<br><img src="/uploads/20210208/%E7%BB%A7%E6%89%BF%E5%85%B3%E7%B3%BB.png" alt="继承关系"></p>
<p>这几个状态的具体区别在于：</p>
<ul>
<li>ValueState[T]是单一变量的状态，T是某种具体的数据类型，比如Double、String，或我们自己定义的复杂数据结构。我们可以使用value()方法获取状态，使用update(value: T)更新状态。</li>
<li>MapState[K, V]存储一个Key-Value map，其功能与Java的Map几乎相同。get(key: K)可以获取某个key下的value，put(key: K, value: V)可以对某个key设置value，contains(key: K)判断某个key是否存在，remove(key: K)删除某个key以及对应的value，entries(): java.lang.Iterable[java.util.Map.Entry[K, V]]返回MapState中所有的元素，iterator(): java.util.Iterator[java.util.Map.Entry[K, V]]返回一个迭代器。需要注意的是，MapState中的key和Keyed State的key不是同一个key。</li>
<li>ListState[T]存储了一个由T类型数据组成的列表。我们可以使用add(value: T)或addAll(values: java.util.List[T])向状态中添加元素，使用get(): java.lang.Iterable[T]获取整个列表，使用update(values: java.util.List[T])来更新列表，新的列表将替换旧的列表。</li>
<li>ReducingState[T]和AggregatingState[IN, OUT]与ListState[T]同属于MergingState[T]。与ListState[T]不同的是，ReducingState[T]只有一个元素，而不是一个列表。它的原理是新元素通过add(value: T)加入后，与已有的状态元素使用ReduceFunction合并为一个元素，并更新到状态里。AggregatingState[IN, OUT]与ReducingState[T]类似，也只有一个元素，只不过AggregatingState[IN, OUT]的输入和输出类型可以不一样。ReducingState[T]和AggregatingState[IN, OUT]与窗口上进行ReduceFunction和AggregateFunction很像，都是将新元素与已有元素做聚合。</li>
</ul>
<p>注意，Flink的核心代码目前使用Java实现的，而Java的很多类型与Scala的类型不太相同，比如List和Map。这里不再详细解释Java和Scala的数据类型的异同，但是开发者在使用Scala调用这些接口，比如状态的接口，需要注意将Java的类型转为Scala的类型。对于List和Map的转换，只需要需要引用import scala.collection.JavaConversions._，并在必要的地方添加后缀asScala或asJava来进行转换。此外，Scala和Java的空对象使用习惯不太相同，Java一般使用null表示空，Scala一般使用None。</p>
<h2 id="Flink-Checkpoint机制"><a href="#Flink-Checkpoint机制" class="headerlink" title="Flink Checkpoint机制"></a>Flink Checkpoint机制</h2><h3 id="如何理解flink中state-状态"><a href="#如何理解flink中state-状态" class="headerlink" title="如何理解flink中state(状态)"></a>如何理解flink中state(状态)</h3><p>state泛指：flink中有状态函数和运算符在各个元素(element)/事件(event)的处理过程中存储的数据（注意：状态数据可以修改和查询，可以自己维护，根据自己的业务场景，保存历史数据或者中间结果到状态(state)中）；<br>使用状态计算的例子：</p>
<ul>
<li>当应用程序搜索某些事件模式时，状态将存储到目前为止遇到的事件序列。</li>
<li>在每分钟/小时/天聚合事件时，状态保存待处理的聚合。</li>
<li>当在数据点流上训练机器学习模型时，状态保持模型参数的当前版本。</li>
<li>当需要管理历史数据时，状态允许有效访问过去发生的事件。</li>
</ul>
<p>无状态计算指的是数据进入Flink后经过算子时只需要对当前数据进行处理就能得到想要的结果；<br>有状态计算就是需要和历史的一些状态或进行相关操作，才能计算出正确的结果；</p>
<h3 id="flink中checkpoint执行流程"><a href="#flink中checkpoint执行流程" class="headerlink" title="flink中checkpoint执行流程"></a>flink中checkpoint执行流程</h3><ul>
<li>checkpoint机制是Flink可靠性的基石，可以保证Flink集群在某个算子因为某些原因(如 异常退出)出现故障时，能够将整个应用流图的状态恢复到故障之前的某一状态，保 证应用流图状态的一致性。Flink的checkpoint机制原理来自“Chandy-Lamport algorithm”算法。 (分布式快照算)</li>
<li>每个需要checkpoint的应用在启动时，Flink的JobManager为其创建一个 CheckpointCoordinator，CheckpointCoordinator全权负责本应用的快照制作。</li>
<li>CheckpointCoordinator周期性的向该流应用的所有source算子发送barrier。</li>
<li>当某个source算子收到一个barrier时，便暂停数据处理过程，然后将自己的当前状 态制作成快照，并保存到指定的持久化存储中，最后向CheckpointCoordinator报告 自己快照制作情况，同时向自身所有下游算子广播该barrier，恢复数据处理</li>
<li>下游算子收到barrier之后，会暂停自己的数据处理过程，然后将自身的相关状态制作成快照，并保存到指定的持久化存储中，最后向CheckpointCoordinator报告自身 快照情况，同时向自身所有下游算子广播该barrier，恢复数据处理。</li>
<li>每个算子按照步骤3不断制作快照并向下游广播，直到最后barrier传递到sink算子，快照制作完成。</li>
<li>当CheckpointCoordinator收到所有算子的报告之后，认为该周期的快照制作成功; 否则，如果在规定的时间内没有收到所有算子的报告，则认为本周期快照制作失败 ;</li>
</ul>
<p>整个过程如下：</p>
<ol>
<li>JobManager端的 CheckPointCoordinator向 所有SourceTask发送CheckPointTrigger，Source Task会在数据流中安插CheckPoint barrier</li>
<li>当task收到所有的barrier后，向自己的下游继续传递barrier，然后自身执行快照，并将自己的状态异步写入到持久化存储中。增量CheckPoint只是把最新的一部分更新写入到 外部存储；为了下游尽快做CheckPoint，所以会先发送barrier到下游，自身再同步进行快照</li>
<li>当task完成备份后，会将备份数据的地址（state handle）通知给JobManager的CheckPointCoordinator；如果CheckPoint的持续时长超过 了CheckPoint设定的超时时间，CheckPointCoordinator 还没有收集完所有的 State Handle，CheckPointCoordinator就会认为本次CheckPoint失败，会把这次CheckPoint产生的所有 状态数据全部删除。</li>
<li>最后 CheckPoint Coordinator 会把整个 StateHandle 封装成 completed CheckPoint Meta，写入到hdfs。</li>
</ol>
<h3 id="什么是barrier对齐？"><a href="#什么是barrier对齐？" class="headerlink" title="什么是barrier对齐？"></a>什么是barrier对齐？</h3><p><img src="/uploads/20211109/barrier%E5%AF%B9%E9%BD%90.png" alt="barrier对齐"></p>
<ul>
<li>一旦Operator从输入流接收到CheckPoint barrier n，它就不能处理来自该流的任何数据记录，直到它从其他所有输入接收到barrier n为止。否则，它会混合属于快照n的记录和属于快照n + 1的记录；</li>
<li>接收到barrier n的流暂时被搁置。从这些流接收的记录不会被处理，而是放入输入缓冲区。</li>
<li>上图中第2个图，虽然数字流对应的barrier已经到达了，但是barrier之后的1、2、3这些数据只能放到buffer中，等待字母流的barrier到达；</li>
<li>一旦最后所有输入流都接收到barrier n，Operator就会把缓冲区中pending 的输出数据发出去，然后把CheckPoint barrier n接着往下游发送</li>
<li>这里还会对自身进行快照；之后，Operator将继续处理来自所有输入流的记录，在处理来自流的记录之前先处理来自输入缓冲区的记录。</li>
</ul>
<h3 id="什么是barrier不对齐？"><a href="#什么是barrier不对齐？" class="headerlink" title="什么是barrier不对齐？"></a>什么是barrier不对齐？</h3><p>checkpoint 是要等到所有的barrier全部都到才算完成</p>
<ul>
<li>上述图2中，当还有其他输入流的barrier还没有到达时，会把已到达的barrier之后的数据1、2、3搁置在缓冲区，等待其他流的barrier到达后才能处理</li>
<li>barrier不对齐就是指当还有其他流的barrier还没到达时，为了不影响性能，也不用理会，直接处理barrier之后的数据。等到所有流的barrier的都到达后，就可以对该Operator做CheckPoint了；</li>
</ul>
<p>为什么要进行barrier对齐？不对齐到底行不行？<br>Exactly Once时必须barrier对齐，如果barrier不对齐就变成了At Least Once；</p>
<h3 id="checkpoint中保存的是什么信息"><a href="#checkpoint中保存的是什么信息" class="headerlink" title="checkpoint中保存的是什么信息"></a>checkpoint中保存的是什么信息</h3><p>快照里面到底保存着什么信息呢？以flink消费kafka数据wordcount为例：<br>我们从Kafka读取到一条条的日志，从日志中解析出app_id，然后将统计的结果放到内存中一个Map集合，app_id做为key，对应的pv做为value，每次只需要将相应app_id 的pv值+1后put到Map中即可；<br>kafka topic：test；<br>flink运算流程如下：<br>kakfa的testtopic的分区 —&gt; Flink的source task —&gt; flink的pv计算task</p>
<h2 id="Flink-Exactly-once语义探究"><a href="#Flink-Exactly-once语义探究" class="headerlink" title="Flink Exactly-once语义探究"></a>Flink Exactly-once语义探究</h2><p>Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义;<br>Flink不是默认就有EOS的，flink 官方推荐所有需要保证EOS的sink 逻辑都继承TwoPhaseCommitSinkFunction抽象类。它具体定义如下四个抽象方法。需要我们去在子类中实现。</p>
<pre><code class="java">protected abstract TXN beginTransaction() throws Exception;
protected abstract void preCommit(TXN transaction) throws Exception;
protected abstract void commit(TXN transaction);
protected abstract void abort(TXN transaction);</code></pre>
<p>beginTransaction(): 开始一个事务，返回事务信息的句柄。<br>preCommit :预提交（即提交请求）阶段的逻辑<br>commit():正式提交阶段的逻辑<br>abort():取消事务</p>
<h3 id="Flink实现端到端的精准一次"><a href="#Flink实现端到端的精准一次" class="headerlink" title="Flink实现端到端的精准一次"></a>Flink实现端到端的精准一次</h3><p>端到端精确一次: flink是通过两步提交的方式实现,内部和外部存储系统间的精确一次语义，即容错发生时每条输入消息依旧只会影响最终结果一次,需满足如下三点:<br>source: 支持数据可重放,即当容错发生后,支持读取上个state标记后的数据,如kafka offset<br>link内部:通设置精确一次的checkpoint保障了内部计算在容错时候的精确一次语义<br>sink:必须支持事物或者幂等操作(继承TwoPhaseCommitSinkFunction抽象类)<br>使用kafka的sink已经自动实现了，但是，自己写的sink，需要自己继承TwoPhaseCommitSinkFunction抽象类</p>
<h3 id="flink的二阶段提交"><a href="#flink的二阶段提交" class="headerlink" title="flink的二阶段提交"></a>flink的二阶段提交</h3><p>两阶段提交（two-phase commit, 2PC）是最基础的分布式一致性协议，应用广泛<br>2PC 在分布式系统中，为了让每个节点能够感知其他所有节点的事务执行情况，需要我们引入一个中心节点的凡是统一所有节点的执行逻辑和进度。这个中心节点叫做协调者（coordinator），而其中向中心节点汇报或者被中心节点调度的其他节点叫做参与者。</p>
<h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><p><strong>请求阶段</strong><br>1、协调者向所有参与者发送准备请求与事务内容，询问是否可以准备事务提交，并等待参与者的响应。<br>2、参与者执行事务中的包含操作，并记录undo日志（用于回滚）和redo日志（用于重放），但是不真正提交。<br>3、参与者向协调者返回事务才做的执行结果，执行陈工返回yes,否则返回no.<br><strong>提交阶段（分成成功和失败两种情况）</strong><br>若所有的参与者都返回yes,说明事务可以提交。<br>1、协调者向所有参与者发送commit请求。<br>2、参与者收到commit 请求后，将事务真正的提交上去，并释放占用的事务资源，并向协调者返回ack。<br>3、协调者收到所有参与者ack消息，事务成功完成。<br><strong>事务回滚</strong><br>若有参与者返回no或者超时未返回，说明事务终端，需要回滚。<br>1、协调者向所有参与者发送rollback请求。<br>2、参与者收到rollback请求后，根据undo日志回滚到事务执行前的状态，释放占用的事务资源，并向协调者返回ack。<br>3、协调者收到所有参与者的ack消息，事务回滚完成。</p>
<h4 id="2PC-的优缺点"><a href="#2PC-的优缺点" class="headerlink" title="2PC 的优缺点"></a>2PC 的优缺点</h4><p><strong>优点</strong><br>2PC的优点在于原理非常简单，容易理解及实现。<br><strong>缺点</strong><br>缺点主要有3个，列举如下：<br>（1）协调者存在单点问题。如果协调者挂了，整个2PC逻辑就彻底不能运行。<br>（2）、执行过程是完全同步的。各参与者在等待其他参与者响应的过程中都处于阻塞状态，大并发下有性能问题。<br>（3）、仍然存在不一致风险。如果由于网络异常等意外导致只有部分参与者收到了commit请求，就会造成部分参与者提交了事务而其他参与者未提交的情况。</p>
<p>具体可以参考<a href="https://www.cnblogs.com/zhipeng-wang/p/14082806.html">flink的二阶段提交</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>FlinkCDC与常用CDC对比</title>
    <url>/2021/12/17/FlinkCDC%E4%B8%8E%E5%B8%B8%E7%94%A8CDC%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>CDC概述</li>
<li>CDC的种类</li>
</ul>
<a id="more"></a>

<h2 id="一、CDC概述"><a href="#一、CDC概述" class="headerlink" title="一、CDC概述"></a>一、CDC概述</h2><p>CDC在广义的概念上，Change Data Capture变更数据获取的技术，我们都可以称为 CDC。<br>CDC技术常用于：</p>
<ul>
<li>数据同步，用于备份，容灾</li>
<li>数据分发，一个数据源分发给多个下游系统</li>
<li>数据采集，面向数据仓库/数据湖的 ETL 数据集成，是非常重要的数据源</li>
</ul>
<h2 id="二、CDC的种类"><a href="#二、CDC的种类" class="headerlink" title="二、CDC的种类"></a>二、CDC的种类</h2><p>目前主流的实现方案可以分为两种：<br>1、基于查询的CDC</p>
<ul>
<li>离线调度查询作业，批处理。把一张表同步到其他系统，每次通过查询去获取查询的结果</li>
<li>无法保障数据一致性，查的过程中有可能数据已经发生了多次变更</li>
<li>不保障实时性，基于离线调度有查询延迟</li>
</ul>
<p>2、基于日志的CDC</p>
<ul>
<li>实时消费日志，流处理，例如MYSQL的BINLOG完整记录库里面的变更，可以把BINLOG当作流的数据源</li>
<li>保障数据一致性，因为BINLOG所有的历史明细都可以获得</li>
<li>提供实时数据，因为提供是流式的消费方式，所以实时性有爆炸</li>
</ul>
<h3 id="常见的开源CDC工具"><a href="#常见的开源CDC工具" class="headerlink" title="常见的开源CDC工具"></a>常见的开源CDC工具</h3><table>
<thead>
<tr>
<th></th>
<th>DataX</th>
<th>Sqoop</th>
<th>Kettle</th>
<th>Canal</th>
<th>Maxwell</th>
<th>Flink CDC</th>
<th>Debezium</th>
</tr>
</thead>
<tbody><tr>
<td>CDC机制</td>
<td>查询</td>
<td>查询</td>
<td>查询</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
<td>日志</td>
</tr>
<tr>
<td>增量同步</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>断点续传</td>
<td>×</td>
<td>×</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>全量同步</td>
<td>√</td>
<td>√</td>
<td>√</td>
<td>×</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>架构</td>
<td>单机</td>
<td>分布式</td>
<td>分布式</td>
<td>单机</td>
<td>单机</td>
<td>分布式</td>
<td>单机</td>
</tr>
</tbody></table>
<p>实际演示Canal、MaxWell、FlinkCDC比对</p>
<h2 id="三、FlinkCDC使用案例"><a href="#三、FlinkCDC使用案例" class="headerlink" title="三、FlinkCDC使用案例"></a>三、FlinkCDC使用案例</h2><h3 id="使用前提"><a href="#使用前提" class="headerlink" title="使用前提"></a>使用前提</h3><p>1、开启binlog，MySQL级别为 ROW<br>2、导入cdc依赖</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!--        Flink CDC--></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.alibaba.ververica<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-mysql-cdc<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="使用DEMO"><a href="#使用DEMO" class="headerlink" title="使用DEMO"></a>使用DEMO</h3><h4 id="1、DataStream-API"><a href="#1、DataStream-API" class="headerlink" title="1、DataStream API"></a>1、DataStream API</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span></span><span class="token class-name">MySqlSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>table<span class="token punctuation">.</span></span><span class="token class-name">StartupOptions</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">DebeziumSourceFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>ververica<span class="token punctuation">.</span>cdc<span class="token punctuation">.</span>debezium<span class="token punctuation">.</span></span><span class="token class-name">StringDebeziumDeserializationSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>



<span class="token comment">/**
 * @author mt
 * @create 2021-10-26 20:13
 */</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkTestCDC</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DebeziumSourceFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> build <span class="token operator">=</span> <span class="token class-name">MySqlSource</span><span class="token punctuation">.</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">hostname</span><span class="token punctuation">(</span><span class="token string">"hadoop102"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">port</span><span class="token punctuation">(</span><span class="token number">3306</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">databaseList</span><span class="token punctuation">(</span><span class="token string">"test"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">tableList</span><span class="token punctuation">(</span><span class="token string">"test.sensor"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">password</span><span class="token punctuation">(</span><span class="token string">"root"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">username</span><span class="token punctuation">(</span><span class="token string">"root"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">deserializer</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">StringDebeziumDeserializationSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">startupOptions</span><span class="token punctuation">(</span><span class="token class-name">StartupOptions</span><span class="token punctuation">.</span><span class="token function">initial</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stringDataStreamSource <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>build<span class="token punctuation">)</span><span class="token punctuation">;</span>
        stringDataStreamSource<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="2、Table-API"><a href="#2、Table-API" class="headerlink" title="2、Table API"></a>2、Table API</h4><pre class="line-numbers language-Java" data-language="Java"><code class="language-Java">import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

import org.apache.flink.table.api.Table;

import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import org.apache.flink.types.Row;


&#x2F;**
 * @author mt
 * @create 2021-09-30 11:07
 *&#x2F;
public class Test &#123;
    public static void main(String[] args) throws Exception &#123;
        StreamExecutionEnvironment env &#x3D; StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(1);
        StreamTableEnvironment tableEnvironment &#x3D; StreamTableEnvironment.create(env);
        tableEnvironment.executeSql(
                &quot;CREATE TABLE sensor_test ( &quot; +
                        &quot; id STRING NOT NULL, &quot; +
                        &quot; ts BIGINT, &quot; +
                        &quot; vc INTEGER &quot; +
                        &quot;) WITH ( &quot; +
                        &quot; &#39;connector&#39; &#x3D; &#39;mysql-cdc&#39;, &quot; +
                        &quot; &#39;hostname&#39; &#x3D; &#39;hadoop102&#39;, &quot; +
                        &quot; &#39;port&#39; &#x3D; &#39;3306&#39;, &quot; +
                        &quot; &#39;username&#39; &#x3D; &#39;root&#39;, &quot; +
                        &quot; &#39;password&#39; &#x3D; &#39;root&#39;, &quot; +
                        &quot; &#39;database-name&#39; &#x3D; &#39;test&#39;, &quot; +
                        &quot; &#39;table-name&#39; &#x3D; &#39;sensor&#39; &quot; +
                        &quot;) &quot;);
        Table table &#x3D; tableEnvironment.sqlQuery(&quot;select * from sensor_test&quot;);
        tableEnvironment.toRetractStream(table, Row.class).print();
        env.execute();
    &#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>目前最新版本Flink CDC支持的连接器<br><img src="/uploads/20220223/FlinkCDC%E6%94%AF%E6%8C%81%E7%9A%84%E6%95%B0%E6%8D%AE%E6%BA%90.png" alt="DataX运行原理"></p>
<h1 id="四、MaxWell配置文件"><a href="#四、MaxWell配置文件" class="headerlink" title="四、MaxWell配置文件"></a>四、MaxWell配置文件</h1><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># tl;dr config
log_level&#x3D;info
producer&#x3D;kafka
kafka.bootstrap.servers&#x3D;hadoop102:9092,hadoop103:9092,hadoop104:9092
kafka_topic&#x3D;ggggg_cccc_aaaa
# mysql login info
host&#x3D;hadoop102
user&#x3D;maxwell
password&#x3D;123456

#同步历史数据时需要配置如下的
client_id&#x3D;maxwell_2
#     *** general ***
# choose where to produce data to. stdout|file|kafka|kinesis|pubsub|sqs|rabbitmq|redis
#producer&#x3D;kafka

# set the log level.  note that you can configure things further in log4j2.xml
#log_level&#x3D;DEBUG # [DEBUG, INFO, WARN, ERROR]

# if set, maxwell will look up the scoped environment variables, strip off the prefix and inject the configs
#env_config_prefix&#x3D;MAXWELL_

#     *** mysql ***
# mysql host to connect to
#host&#x3D;hostname
# mysql port to connect to
#port&#x3D;3306
# mysql user to connect as.  This user must have REPLICATION SLAVE permissions,
# as well as full access to the &#96;maxwell&#96; (or schema_database) database
#user&#x3D;maxwell
# mysql password
#password&#x3D;maxwell



# options to pass into the jdbc connection, given as opt&#x3D;val&amp;opt2&#x3D;val2
#jdbc_options&#x3D;opt1&#x3D;100&amp;opt2&#x3D;hello
# name of the mysql database where maxwell keeps its own state
#schema_database&#x3D;maxwell
# whether to use GTID or not for positioning
#gtid_mode&#x3D;true
# SSL&#x2F;TLS options
# To use VERIFY_CA or VERIFY_IDENTITY, you must set the trust store with Java opts:
#   -Djavax.net.ssl.trustStore&#x3D;&lt;truststore&gt; -Djavax.net.ssl.trustStorePassword&#x3D;&lt;password&gt;
# or import the MySQL cert into the global Java cacerts.
# MODE must be one of DISABLED, PREFERRED, REQUIRED, VERIFY_CA, or VERIFY_IDENTITY
#

# turns on ssl for the maxwell-store connection, other connections inherit this setting unless specified
#ssl&#x3D;DISABLED
# for binlog-connector
#replication_ssl&#x3D;DISABLED
# for the schema-capture connection, if used
#schema_ssl&#x3D;DISABLED


# maxwell can optionally replicate from a different server than where it stores
# schema and binlog position info.  Specify that different server here:

#replication_host&#x3D;other
#replication_user&#x3D;username
#replication_password&#x3D;password
#replication_port&#x3D;3306


# This may be useful when using MaxScale&#39;s binlog mirroring host.
# Specifies that Maxwell should capture schema from a different server than
# it replicates from:
#schema_host&#x3D;other
#schema_user&#x3D;username
#schema_password&#x3D;password
#schema_port&#x3D;3306
#       *** output format ***
# records include binlog position (default false)
#output_binlog_position&#x3D;true
# records include a gtid string (default false)
#output_gtid_position&#x3D;true
# records include fields with null values (default true).  If this is false,
# fields where the value is null will be omitted entirely from output.
#output_nulls&#x3D;true
# records include server_id (default false)
#output_server_id&#x3D;true
# records include thread_id (default false)
#output_thread_id&#x3D;true
# records include schema_id (default false)
#output_schema_id&#x3D;true
# records include row query, binlog option &quot;binlog_rows_query_log_events&quot; must be enabled&quot; (default false)
#output_row_query&#x3D;true
# DML records include list of values that make up a row&#39;s primary key (default false)
#output_primary_keys&#x3D;true
# DML records include list of columns that make up a row&#39;s primary key (default false)
#output_primary_key_columns&#x3D;true
# records include commit and xid (default true)
#output_commit_info&#x3D;true
# This controls whether maxwell will output JSON information containing
# DDL (ALTER&#x2F;CREATE TABLE&#x2F;ETC) infromation. (default: false)
# See also: ddl_kafka_topic
#output_ddl&#x3D;true
#       *** kafka ***
# list of kafka brokers
#kafka.bootstrap.servers&#x3D;hosta:9092,hostb:9092
# kafka topic to write to
# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
# in the latter case &#39;database&#39; and &#39;table&#39; will be replaced with the values for the row being processed
#kafka_topic&#x3D;maxwell
# alternative kafka topic to write DDL (alter&#x2F;create&#x2F;drop) to.  Defaults to kafka_topic
#ddl_kafka_topic&#x3D;maxwell_ddl
# hash function to use.  &quot;default&quot; is just the JVM&#39;s &#39;hashCode&#39; function.
#kafka_partition_hash&#x3D;default # [default, murmur3]


# how maxwell writes its kafka key.
#
# &#39;hash&#39; looks like:
# &#123;&quot;database&quot;:&quot;test&quot;,&quot;table&quot;:&quot;tickets&quot;,&quot;pk.id&quot;:10001&#125;
#
# &#39;array&#39; looks like:
# [&quot;test&quot;,&quot;tickets&quot;,[&#123;&quot;id&quot;:10001&#125;]]
#
# default: &quot;hash&quot;
#kafka_key_format&#x3D;hash # [hash, array]


# extra kafka options.  Anything prefixed &quot;kafka.&quot; will get
# passed directly into the kafka-producer&#39;s config.

# a few defaults.
# These are 0.11-specific. They may or may not work with other versions.
kafka.compression.type&#x3D;snappy
kafka.retries&#x3D;0
kafka.acks&#x3D;1
#kafka.batch.size&#x3D;16384


# kafka+SSL example
# kafka.security.protocol&#x3D;SSL
# kafka.ssl.truststore.location&#x3D;&#x2F;var&#x2F;private&#x2F;ssl&#x2F;kafka.client.truststore.jks
# kafka.ssl.truststore.password&#x3D;test1234
# kafka.ssl.keystore.location&#x3D;&#x2F;var&#x2F;private&#x2F;ssl&#x2F;kafka.client.keystore.jks
# kafka.ssl.keystore.password&#x3D;test1234
# kafka.ssl.key.password&#x3D;test1234#

# controls a heuristic check that maxwell may use to detect messages that
# we never heard back from.  The heuristic check looks for &quot;stuck&quot; messages, and
# will timeout maxwell after this many milliseconds.
#
# See https:&#x2F;&#x2F;github.com&#x2F;zendesk&#x2F;maxwell&#x2F;blob&#x2F;master&#x2F;src&#x2F;main&#x2F;java&#x2F;com&#x2F;zendesk&#x2F;maxwell&#x2F;producer&#x2F;InflightMessageList.java
# if you really want to get into it.
#producer_ack_timeout&#x3D;120000 # default 0


#           *** partitioning ***

# What part of the data do we partition by?
#producer_partition_by&#x3D;database # [database, table, primary_key, transaction_id, column]


# specify what fields to partition by when using producer_partition_by&#x3D;column
# column separated list.
#producer_partition_columns&#x3D;id,foo,bar


# when using producer_partition_by&#x3D;column, partition by this when
# the specified column(s) don&#39;t exist.
#producer_partition_by_fallback&#x3D;database


#            *** kinesis ***

#kinesis_stream&#x3D;maxwell
# AWS places a 256 unicode character limit on the max key length of a record
# http:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;kinesis&#x2F;latest&#x2F;APIReference&#x2F;API_PutRecord.html
#
# Setting this option to true enables hashing the key with the md5 algorithm
# before we send it to kinesis so all the keys work within the key size limit.
# Values: true, false
# Default: false
#kinesis_md5_keys&#x3D;true
#            *** sqs ***
#sqs_queue_uri&#x3D;aws_sqs_queue_uri
# The sqs producer will need aws credentials configured in the default
# root folder and file format. Please check below link on how to do it.
# http:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;sdk-for-java&#x2F;v1&#x2F;developer-guide&#x2F;setup-credentials.html
#            *** pub&#x2F;sub ***
#pubsub_project_id&#x3D;maxwell
#pubsub_topic&#x3D;maxwell
#ddl_pubsub_topic&#x3D;maxwell_ddl

#            *** rabbit-mq ***
#rabbitmq_host&#x3D;rabbitmq_hostname
#rabbitmq_port&#x3D;5672
#rabbitmq_user&#x3D;guest
#rabbitmq_pass&#x3D;guest
#rabbitmq_virtual_host&#x3D;&#x2F;
#rabbitmq_exchange&#x3D;maxwell
#rabbitmq_exchange_type&#x3D;fanout
#rabbitmq_exchange_durable&#x3D;false
#rabbitmq_exchange_autodelete&#x3D;false
#rabbitmq_routing_key_template&#x3D;%db%.%table%
#rabbitmq_message_persistent&#x3D;false
#rabbitmq_declare_exchange&#x3D;true

#           *** redis ***
#redis_host&#x3D;redis_host
#redis_port&#x3D;6379
#redis_auth&#x3D;redis_auth
#redis_database&#x3D;0
# name of pubsub&#x2F;list&#x2F;whatever key to publish to
#redis_key&#x3D;maxwell

# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
#redis_pub_channel&#x3D;maxwell
# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
#redis_list_key&#x3D;maxwell
# this can be static, e.g. &#39;maxwell&#39;, or dynamic, e.g. namespace_%&#123;database&#125;_%&#123;table&#125;
# Valid values for redis_type &#x3D; pubsub|lpush. Defaults to pubsub
#redis_type&#x3D;pubsub

#           *** custom producer ***
# the fully qualified class name for custom ProducerFactory
# see the following link for more details.
# http:&#x2F;&#x2F;maxwells-daemon.io&#x2F;producers&#x2F;#custom-producer
#custom_producer.factory&#x3D;
# custom producer properties can be configured using the custom_producer.* property namespace
#custom_producer.custom_prop&#x3D;foo

#          *** filtering ***
# filter rows out of Maxwell&#39;s output.  Command separated list of filter-rules, evaluated in sequence.
# A filter rule is:
#  &lt;type&gt; &quot;:&quot; &lt;db&gt; &quot;.&quot; &lt;tbl&gt; [ &quot;.&quot; &lt;col&gt; &quot;&#x3D;&quot; &lt;col_val&gt; ]
#  type    ::&#x3D; [ &quot;include&quot; | &quot;exclude&quot; | &quot;blacklist&quot; ]
#  db      ::&#x3D; [ &quot;&#x2F;regexp&#x2F;&quot; | &quot;string&quot; | &quot;&#96;string&#96;&quot; | &quot;*&quot; ]
#  tbl     ::&#x3D; [ &quot;&#x2F;regexp&#x2F;&quot; | &quot;string&quot; | &quot;&#96;string&#96;&quot; | &quot;*&quot; ]
#  col_val ::&#x3D; &quot;column_name&quot;
#  tbl     ::&#x3D; [ &quot;&#x2F;regexp&#x2F;&quot; | &quot;string&quot; | &quot;&#96;string&#96;&quot; | &quot;*&quot; ]
#
# See http:&#x2F;&#x2F;maxwells-daemon.io&#x2F;filtering for more details
#
#filter&#x3D; exclude: *.*, include: foo.*, include: bar.baz, include: foo.bar.col_eg &#x3D; &quot;value_to_match&quot;


# javascript filter
# maxwell can run a bit of javascript for each row if you need very custom filtering&#x2F;data munging.
# See http:&#x2F;&#x2F;maxwells-daemon.io&#x2F;filtering&#x2F;#javascript_filters for more details
#
#javascript&#x3D;&#x2F;path&#x2F;to&#x2F;javascript_filter_file
#       *** encryption ***
# Encryption mode. Possible values are none, data, and all. (default none)
#encrypt&#x3D;none

# Specify the secret key to be used
#secret_key&#x3D;RandomInitVector
#       *** monitoring ***
# Maxwell collects metrics via dropwizard. These can be exposed through the
# base logging mechanism (slf4j), JMX, HTTP or pushed to Datadog.
# Options: [jmx, slf4j, http, datadog]
# Supplying multiple is allowed.
#metrics_type&#x3D;jmx,slf4j
# The prefix maxwell will apply to all metrics
#metrics_prefix&#x3D;MaxwellMetrics # default MaxwellMetrics
# Enable (dropwizard) JVM metrics, default false
#metrics_jvm&#x3D;true
# When metrics_type includes slf4j this is the frequency metrics are emitted to the log, in seconds
#metrics_slf4j_interval&#x3D;60
# When metrics_type includes http or diagnostic is enabled, this is the port the server will bind to.
#http_port&#x3D;8080
# When metrics_type includes http or diagnostic is enabled, this is the http path prefix, default &#x2F;.
#http_path_prefix&#x3D;&#x2F;some&#x2F;path&#x2F;
# ** The following are Datadog specific. **
# When metrics_type includes datadog this is the way metrics will be reported.
# Options: [udp, http]
# Supplying multiple is not allowed.
#metrics_datadog_type&#x3D;udp
# datadog tags that should be supplied
#metrics_datadog_tags&#x3D;tag1:value1,tag2:value2

# The frequency metrics are pushed to datadog, in seconds
#metrics_datadog_interval&#x3D;60
# required if metrics_datadog_type &#x3D; http
#metrics_datadog_apikey&#x3D;API_KEY
# required if metrics_datadog_type &#x3D; udp
#metrics_datadog_host&#x3D;localhost # default localhost
#metrics_datadog_port&#x3D;8125 # default 8125
# Maxwell exposes http diagnostic endpoint to check below in parallel:
# 1. binlog replication lag
# 2. producer (currently kafka) lag
# To enable Maxwell diagnostic
#http_diagnostic&#x3D;true # default false
# Diagnostic check timeout in milliseconds, required if diagnostic &#x3D; true
#http_diagnostic_timeout&#x3D;10000 # default 10000
#    *** misc ***
# maxwell&#39;s bootstrapping functionality has a couple of modes.
#
# In &quot;async&quot; mode, maxwell will output the replication stream while it
# simultaneously outputs the database to the topic.  Note that it won&#39;t
# output replication data for any tables it is currently bootstrapping -- this
# data will be buffered and output after the bootstrap is complete.
#
# In &quot;sync&quot; mode, maxwell stops the replication stream while it
# outputs bootstrap data.
#
# async mode keeps ops live while bootstrapping, but carries the possibility of
# data loss (due to buffering transactions).  sync mode is safer but you
# have to stop replication.
#bootstrapper&#x3D;async [sync, async, none]
# output filename when using the &quot;file&quot; producer
#output_file&#x3D;&#x2F;path&#x2F;to&#x2F;file<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="五、Cancal配置文件"><a href="#五、Cancal配置文件" class="headerlink" title="五、Cancal配置文件"></a>五、Cancal配置文件</h2><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#################################################
## mysql serverId , v1.0.26+ will autoGen
# canal.instance.mysql.slaveId&#x3D;0
# enable gtid use true&#x2F;false
canal.instance.gtidon&#x3D;false
# position info
canal.instance.master.address&#x3D;hadoop102:3306
canal.instance.master.journal.name&#x3D;
canal.instance.master.position&#x3D;
canal.instance.master.timestamp&#x3D;
canal.instance.master.gtid&#x3D;
# rds oss binlog
canal.instance.rds.accesskey&#x3D;
canal.instance.rds.secretkey&#x3D;
canal.instance.rds.instanceId&#x3D;
# table meta tsdb info
canal.instance.tsdb.enable&#x3D;true
#canal.instance.tsdb.url&#x3D;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;canal_tsdb
#canal.instance.tsdb.dbUsername&#x3D;canal
#canal.instance.tsdb.dbPassword&#x3D;canal
#canal.instance.standby.address &#x3D;
#canal.instance.standby.journal.name &#x3D;
#canal.instance.standby.position &#x3D;
#canal.instance.standby.timestamp &#x3D;
#canal.instance.standby.gtid&#x3D;


# username&#x2F;password
canal.instance.dbUsername&#x3D;canal
canal.instance.dbPassword&#x3D;canal
canal.instance.connectionCharset &#x3D; UTF-8
# enable druid Decrypt database password
canal.instance.enableDruid&#x3D;false
#canal.instance.pwdPublicKey&#x3D;MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5&#x2F;zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2&#x2F;JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ&#x3D;&#x3D;


# table regex
canal.instance.filter.regex&#x3D;.*\\..*
# table black regex
canal.instance.filter.black.regex&#x3D;
# table field filter(format: schema1.tableName1:field1&#x2F;field2,schema2.tableName2:field1&#x2F;field2)
#canal.instance.filter.field&#x3D;test1.t_product:id&#x2F;subject&#x2F;keywords,test2.t_company:id&#x2F;name&#x2F;contact&#x2F;ch
# table field black filter(format: schema1.tableName1:field1&#x2F;field2,schema2.tableName2:field1&#x2F;field2)
#canal.instance.filter.black.field&#x3D;test1.t_product:subject&#x2F;product_image,test2.t_company:id&#x2F;name&#x2F;contact&#x2F;ch


# mq config  
canal.mq.topic&#x3D;kkkk_ffff_aaaaa
# dynamic topic route by schema or table regex
#canal.mq.dynamicTopic&#x3D;mytest1.user,mytest2\\..*,.*\\..*
canal.mq.partition&#x3D;0
# hash partition config
#canal.mq.partitionsNum&#x3D;3
#canal.mq.partitionHash&#x3D;test.table:id^name,.*\\..*
#################################################<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      <categories>
        <category>Flink</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink学习笔记（一）</title>
    <url>/2021/01/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink简介</li>
<li>Flink如何提交任务到Yarn</li>
<li>Flink任务案例</li>
</ul>
<a id="more"></a>

<h2 id="Flink简介"><a href="#Flink简介" class="headerlink" title="Flink简介"></a>Flink简介</h2><h3 id="Flink是什么？"><a href="#Flink是什么？" class="headerlink" title="Flink是什么？"></a>Flink是什么？</h3><p>Apache Flink 是一个<code>框架</code>和<code>分布式处理引擎</code>，用于在<code>无边界</code>和<code>有边界</code>数据流上进行<code>有状态</code>的计算。Flink 能在所有常见集群环境中运行，并能以<code>内存速度</code>和<code>任意规模</code>进行计算。  </p>
<blockquote>
<p>Flink是一个流计算驱动的引擎，核心是Streaming。但是，它可以基于Streaming的内核，实现流批一体更全能的架构</p>
</blockquote>
<ul>
<li>无边界数据流<br>有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果的完整性  <blockquote>
<p>纯实时数据，不存在等数据累计一定程度再处理的情况，数据生产后，立刻消费</p>
</blockquote>
</li>
<li>有边界数据流<br>有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理  <blockquote>
<p>批处理数据，需要数累积一定量以后再行处理</p>
</blockquote>
</li>
<li>有状态的计算  </li>
</ul>
<p>Flink有如下优点：</p>
<ul>
<li>真正的流处理</li>
<li>多种窗口</li>
<li>自带状态(state) </li>
<li>精确一次传输语义</li>
<li>时间管理</li>
</ul>
<h3 id="流式计算框架对比"><a href="#流式计算框架对比" class="headerlink" title="流式计算框架对比"></a>流式计算框架对比</h3><ul>
<li>模型：Storm和Flink是真正的一条一条处理数据；Spark Streaming其实是小批处理，一次处理一批数据（小批量）</li>
<li>API：Storm使用基础API进行开发，比如实现一个简单的sum求和操作；而Spark Streaming和Flink中都提供封装后的高阶函数，可以直接拿来使用</li>
<li>保证次数：在数据处理方面，Storm可以实现至少处理一次，但不能保证仅处理一次，这样就会导致数据重复处理问题，所以针对计数类的需求，可能会产生一些误差；Spark Streaming和Flink通过事务可以保证对数据实现仅一次的处理</li>
<li>容错机制：Storm通过ACK机制实现数据的容错机制，而SparkStreaming和Flink可以通过CheckPoint机制实现容错机制</li>
<li>状态管理：Storm中没有实现状态管理，Spark Streaming实现了基于DStream的状态管理，Flink实现了基于操作的状态管理</li>
<li>延时：表示数据处理的延时情况，因此Storm和Flink接收到一条数据就处理一条数据，其数据处理的延时性是很低的；而Spark Streaming是小型批处理，数据处理的延时性相对会偏高</li>
<li>吞吐量：Storm的吞吐量其实也不低，只是相对于其他几个框架而言较低；而Spark Streaming和Flink的吞吐量是比较高的</li>
</ul>
<blockquote>
<p>Strom是第一代实时处理框架，基于流处理，数据吞吐量和延迟上效果不理想，只支持at least once和at most once，不能保证精确一次性，在数据准确性上存在不足<br>Spark Streaming作为第二代实时处理框架，基于mini-batch思想，每次处理一小批数据，一小批数据包含多个事件，以接近事实处理效果，概况性来说是微批次、准实时<br>Spark Streaming说到底，还是微批处理，并不是真正的实时处理，所以它的吞吐量很好，但是实时性没有Flink好，而且Spark官方也说了，最好不要把batch设置的太小<br>第三代实时处理框架，支持有界和无界数据流上做有状态计算，以时间为单位，支持exactly once，数据的准确性得到提高，相比Strom，吞吐量更高，延迟更低，相比SparkStreaming，Flink是真正意义上的实时计算，所需计算资源更少</p>
</blockquote>
<h3 id="工作中如何选择实时计算框架"><a href="#工作中如何选择实时计算框架" class="headerlink" title="工作中如何选择实时计算框架"></a>工作中如何选择实时计算框架</h3><ul>
<li>需要关注流数据是否需要进行状态管理，如果是，那么只能SparkStreaming和Flink中选择一个。</li>
<li>需要考虑项目对At-least-once（至少一次）或者Exactly-once（仅一次）消息投递模式是否有特殊要求，如果必须要保证仅一次，也不能选择Storm。</li>
<li>对于小型独立的项目，并且需要低延迟的场景，建议使用Storm，这样比较简单。</li>
<li>如果你的项目已经使用了Spark，并且秒级别的实时处理可以满足需求的话，建议使用Spark Streaming</li>
<li>要求消息投递语义为Exactly-once；数据量较大，要求高吞吐低延迟；需要进行状态管理或窗口统计，这时建议使用Flink。</li>
</ul>
<h3 id="Flink下载安装"><a href="#Flink下载安装" class="headerlink" title="Flink下载安装"></a>Flink下载安装</h3><p>到官网上下载Flink安装包，并解压<br>这里只是要把Flink当成一个客户端，提交任务到Yarn上，所以不必配置Flink集群，只需要配置一下<code>HADOOP_CLASSPATH</code></p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export HADOOP_CLASSPATH&#x3D;&#96;hadoop classpath&#96;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>最后，配置Flink的环境变量</p>
<h2 id="Flink如何提交任务到Yarn"><a href="#Flink如何提交任务到Yarn" class="headerlink" title="Flink如何提交任务到Yarn"></a>Flink如何提交任务到Yarn</h2><p>在官网点击<code>Documentation</code> -&gt; <code>Latest stable release</code> -&gt; <code>Deploy Flink</code> -&gt; <code> Clusters and Deployments</code> -&gt; <code>YARN</code><br><img src="/uploads/20210122/flink-yarn-deploy.png" alt="flink-yarn-deploy"><br>Flink提交任务到Yarn有3种方式：  </p>
<ul>
<li><p>Application Mode<br>Application Mode将在YARN上启动一个Flink集群，其中Application jar的main()方法将在YARN中的JobManager上执行。<br>应用程序完成后，Flink集群将立即关闭。可以使用<code>yarn application -kill &lt;ApplicationId&gt;</code>或取消Flink作业来手动停止集群</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run-application -t yarn-application .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/20210124/Application-Mode%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%88%B0Yarn.png" alt="Application-Mode提交任务到Yarn"></p>
<blockquote>
<p>这种就是直接把Flink任务注册到Yarn上，就跟Spark、Hive任务提交Yarn任务一样。</p>
</blockquote>
<p> 通过这种方式提交到Yarn上，可以与它交互以执行诸如取消、获取保存点之类的操作</p>
 <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 列举集群上的app
flink list -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY
# 取消正在执行的job
flink cancel -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY &lt;jobId&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 需要注意的是，任务取消后，Flink集群也会停止<br> 为了挖掘Application Mode的潜力，可以考虑使用<code>yarn.provided.lib.dirs</code>配置选项，将应用程序jar上传到集群中所有节点都可以访问的位置，例如HDFS上</p>
 <pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">   flink run-application -t yarn-application \
-Dyarn.provided.lib.dirs&#x3D;&quot;hdfs:&#x2F;&#x2F;myhdfs&#x2F;my-remote-flink-dist-dir&quot; \
hdfs:&#x2F;&#x2F;myhdfs&#x2F;jars&#x2F;my-application.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 由于所需的Flink jar和应用程序jar将由指定的远程位置接收，而不是由客户机发送到集群，因此上面的内容将允许作业提交变得格外轻量级。</p>
<blockquote>
<p>任务启动的时候，客户端不需要再把jar上传到每个jobManager了，跑完了也不会再删除。</p>
</blockquote>
</li>
<li><p>Per-Job Cluster Mode<br>Per-Job Cluster Mode将在Yarn上启动Flink集群，然后在本地运行提供的应用程序jar，最后将JobGraph提交给YARN上的JobManager<br>如果传递–detached参数，客户端将在集群接受提交后停止。<br>提交的任务一旦停止，Flink集群也将停止</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -t yarn-per-job --detached .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>同样，通过这种方式提交的任务，也可以与它交互以执行诸如取消、获取保存点之类的操作</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 列举集群上的app
flink list -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY
# 取消正在执行的job
flink cancel -t yarn-application -Dyarn.application.id&#x3D;application_XXXX_YY &lt;jobId&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>Session Mode</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># 如果成功，在yarn上是可以看到application_id的
yarn-session.sh --detached
# 成功后会打印：
#JobManager Web Interface: http:&#x2F;&#x2F;golden-02:39461
#2021-01-22 17:29:31,594 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                
# [] - The Flink YARN session cluster has been started in detached mode. 
# In order to stop Flink gracefully, use the following command:
#$ echo &quot;stop&quot; | yarn-session.sh -id application_1611306127593_0001
#If this should not be possible, then you can also kill Flink via YARN&#39;s web interface or via:
#$ yarn application -kill application_1611306127593_0001
#Note that killing Flink might not clean up all job artifacts and temporary files.
# 执行一个测试job
flink run .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar
# 杀掉Flink的任务可以使用cancel
flink cancel $&#123;flink_app_id&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/uploads/20210122/flink%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E5%88%B0yarn%E4%B8%8A%E5%88%97%E8%A1%A8.png" alt="flink提交任务到yarn上列表"><br><img src="/uploads/20210122/yarn%E4%B8%8A%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%AF%A6%E6%83%85.png" alt="yarn上的任务详情"><br>可以看到，yarn的任务监控页面只能找到一个application_id，但是Flink的任务列表有2个</p>
<p> <code>Session Mode</code>有两种操作模式：</p>
<ul>
<li><p>attached mode (default):<code>yarn-session.sh</code>将任务提交到Yarn上以后，不会关闭，会继续与集群通信，跟踪集群任务的状态，如果任务失败，会在客户端显示错误，如果客户端被停止，它也会向集群发送关闭任务的信号                         </p>
</li>
<li><p>detached mode (-d or –detached):<code>yarn-session.sh</code>将任务提交到Yarn上以后，会直接返回，要是想停止集群中的任务，就需要调用另外一个客户端，或者使用Yarn的工具(<code>yarn application -kill</code>)<br><code>Session Mode</code>将在<code>/tmp/.YARN properties-&lt;username&gt;</code>中创建一个隐藏的<code>YARN properties</code>文件，提交作业时，命令行界面将提取该文件进行集群发现<br>提交Flink作业时，也可以在命令行界面中手动指定目标session。举个例子：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -t yarn-session -Dyarn.application.id&#x3D;application_XXXX_YY .&#x2F;examples&#x2F;streaming&#x2F;TopSpeedWindowing.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>这里测试了一下，只能是注册session的application_id</p>
</blockquote>
<p>可以使用<code>yarn-session.sh -id application_XXXX_YY</code>重新连接session<br>除了通过配置conf/flink-conf.yaml，还可以在提交session时将使用-Dkey=value参数配置传递给yarn-session.sh客户端。</p>
<blockquote>
<p>Flink提交任务到yarn上，需要提前启动一个application，然后后面的flink任务会共享这个application的资源？  </p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="Flink任务案例"><a href="#Flink任务案例" class="headerlink" title="Flink任务案例"></a>Flink任务案例</h2><p>公司是Flink是以java为开发语言的，这里学习也使用java</p>
<h3 id="配置Flink的Maven开发环境"><a href="#配置Flink的Maven开发环境" class="headerlink" title="配置Flink的Maven开发环境"></a>配置Flink的Maven开发环境</h3><p>到Flink的官网，点击<code>Getting Started</code> -&gt; <code>Application Development</code> -&gt; <code>DataStream API</code> -&gt; <code>Project Configuration</code><br><img src="/uploads/20210122/flink-maven-1.png" alt="flink-maven-1"><br><img src="/uploads/20210122/flink-maven-2.png" alt="flink-maven-2"><br>也可以在Flink的下载页面寻找maven的配置项<br>得到maven配置:</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-streaming-java_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-clients_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flink-connector-kafka_2.11<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="实现简单功能：Flink消费Kafka数据后再写入Kafka"><a href="#实现简单功能：Flink消费Kafka数据后再写入Kafka" class="headerlink" title="实现简单功能：Flink消费Kafka数据后再写入Kafka"></a>实现简单功能：Flink消费Kafka数据后再写入Kafka</h3><p>下面直接上代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStreamSource</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaProducer</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka2Kafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Kafka参数</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">DataStreamSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> kafkaData <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>
                inputTopic<span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                properties<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        kafkaData<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Sink</span>
        <span class="token class-name">Properties</span> prop <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        prop<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        prop<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"zookeeper.connect"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:2181"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        prop<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"flink-write"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        kafkaData<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>
                <span class="token string">"golden-02:9092"</span><span class="token punctuation">,</span>
                <span class="token string">"flink-write"</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">name</span><span class="token punctuation">(</span><span class="token string">"flink-connectors-kafka"</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// execute</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka consumer to kafka "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="IDEA本地调试Flink程序报错"><a href="#IDEA本地调试Flink程序报错" class="headerlink" title="IDEA本地调试Flink程序报错"></a>IDEA本地调试Flink程序报错</h3><p>如果直接在IDEA上执行，会报如下错误：<br><img src="/uploads/20210125/IDEA%E7%9B%B4%E6%8E%A5%E8%BF%90%E8%A1%8CFlink%E4%BB%BB%E5%8A%A1.png" alt="IDEA直接运行Flink任务"><br>本质上，这是因为没有配置java的jre环境，可以使用两种办法解决：</p>
<ul>
<li><p>导入<code>Flink</code> lib文件夹下的jar包<br>导入流程：<br>依次点击 <code>File</code> -&gt; <code>Project Structure</code> -&gt; <code>Module</code> -&gt; <code>Dependencies</code><br><img src="/uploads/20210125/IDEA%E9%85%8D%E7%BD%AEFlink-lib%E6%96%87%E4%BB%B6%E5%A4%B9.png" alt="IDEA配置Flink-lib文件夹"><br>配置完成后，右键<code>run</code>，控制台就能看到程序的运行结果了<br><img src="/uploads/20210125/IDEA%E6%89%A7%E8%A1%8CFlink%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="IDEA执行Flink程序执行结果"></p>
</li>
<li><p>通过配置java的jre环境解决：<br>配置方法：<br><img src="/uploads/20210125/IDEA%E9%85%8D%E7%BD%AEJRE.png" alt="IDEA配置JRE"><br>或者，配置JRE的环境变量</p>
</li>
</ul>
<p>通过命令行提交任务到yarn上执行：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">flink run -t yarn-per-job --class com.hzw.bigdata.flinkstudy.FlinkConsumerKafka2Kafka FlinkStudy-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>给<code>first</code>topic生产点数据：<br><img src="/uploads/20210125/Kafka%E5%8E%9F%E5%A7%8Btopic%E7%94%9F%E4%BA%A7%E6%95%B0%E6%8D%AE.png" alt="Kafka原始topic生产数据"><br>消费flink写入的另一个topic数据<br><img src="/uploads/20210125/%E6%B6%88%E8%B4%B9Flink%E5%86%99%E5%85%A5Kafka%E5%8F%A6%E4%B8%80%E4%B8%AAtopic%E6%95%B0%E6%8D%AE.png" alt="消费Flink写入Kafka另一个topic数据"></p>
<p>虽然利用<code>Per-Job Cluster Mode</code>方式提交到Yarn上执行成功了，但是使用<code>Application Mode</code>方式是报错的<br>报错信息如下：</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Caused by: org.apache.flink.streaming.runtime.tasks.StreamTaskException: Cannot instantiate user function.
	at org.apache.flink.streaming.api.graph.StreamConfig.getStreamOperatorFactory(StreamConfig.java:339) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.streaming.runtime.tasks.OperatorChain.&lt;init&gt;(OperatorChain.java:143) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.beforeInvoke(StreamTask.java:509) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:565) ~[flink-dist_2.12-1.12.1.jar:1.12.1]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:722) ~[FlinkStudy-1.0-SNAPSHOT-jar-with-dependencies.jar:?]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:547) ~[FlinkStudy-1.0-SNAPSHOT-jar-with-dependencies.jar:?]
	at java.lang.Thread.run(Thread.java:748) ~[?:1.8.0_201]
Caused by: java.lang.ClassCastException: cannot assign instance of org.apache.commons.collections.map.LinkedMap to field org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.pendingOffsetsToCommit of type org.apache.commons.collections.map.LinkedMap in instance of org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer
	at java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2287) ~[?:1.8.0_201]
	at java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1417) ~[?:1.8.0_201]
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2293) ~[?:1.8.0_201]
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2211) ~[?:1.8.0_201]
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2069) ~[?:1.8.0_201]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>报错原因：<br><code>LinkedMap cannot be cast to LinkedMap exceptions</code><br><code>LinkedMap class is being loaded from two different packages, and those are being assigned to each other.</code></li>
<li>解决办法：<br>在conf/flink-conf.yaml 添加如下内容<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">classloader.resolve-order: parent-first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

</li>
</ul>
<h3 id="实现简单功能：Flink消费Kafka数据并实现wordCount"><a href="#实现简单功能：Flink消费Kafka数据并实现wordCount" class="headerlink" title="实现简单功能：Flink消费Kafka数据并实现wordCount"></a>实现简单功能：Flink消费Kafka数据并实现wordCount</h3><p>这里遇到了问题</p>
<ul>
<li>直接消费kafka数据，不使用window函数，可以正常wordCount</li>
<li>直接copy网上的代码，使用<code>timeWindow(Time.seconds(5))</code>，kafka数据正常消费，但是没有正常计算并打印</li>
<li><code>window(EventTimeSessionWindows.withGap(Time.seconds(1L)))</code>kafka数据正常消费，但是没有正常计算并打印<br>代码如下：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">Types</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>assigners<span class="token punctuation">.</span></span><span class="token class-name">EventTimeSessionWindows</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>assigners<span class="token punctuation">.</span></span><span class="token class-name">TumblingProcessingTimeWindows</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>windowing<span class="token punctuation">.</span>time<span class="token punctuation">.</span></span><span class="token class-name">Time</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// Kafka参数</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> wordCount <span class="token operator">=</span> stream
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
                    <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> tokens <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\\s"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token comment">// 输出结果 (word, 1)</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> token <span class="token operator">:</span> tokens<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                        <span class="token keyword">if</span> <span class="token punctuation">(</span>token<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>INT<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>key <span class="token operator">-></span> key<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token comment">//.window(EventTimeSessionWindows.withGap(Time.seconds(1L)))  //无数据</span>
                <span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">TumblingProcessingTimeWindows</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">Time</span><span class="token punctuation">.</span><span class="token function">seconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//有数据</span>
                <span class="token comment">//.timeWindow(Time.seconds(5))   //无数据</span>
                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>key <span class="token operator">-></span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>f0 <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> key<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        wordCount<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka streaming word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<img src="/uploads/20210125/Flink%E6%9C%89%E6%B6%88%E8%B4%B9%E6%97%A0%E8%BE%93%E5%87%BA.png" alt="Flink有消费无输出"><br><img src="/uploads/20210125/offset%E6%B6%88%E8%B4%B9%E6%83%85%E5%86%B5.png" alt="offset消费情况"></li>
</ul>
<h3 id="从checkpoint点重新消费kafka数据"><a href="#从checkpoint点重新消费kafka数据" class="headerlink" title="从checkpoint点重新消费kafka数据"></a>从checkpoint点重新消费kafka数据</h3><p>发现通过公司封装的Flink，虽然在配置任务的时候，选择了从某个检查点恢复，但是消费的kafka的offset还是从最新的位置开始，这里自己调研一下：</p>
<h3 id="Flink-kafka-consumer的消费模式设置"><a href="#Flink-kafka-consumer的消费模式设置" class="headerlink" title="Flink kafka consumer的消费模式设置"></a>Flink kafka consumer的消费模式设置</h3><ul>
<li>setStartFromEarliest：从队头开始，最早的记录，内部的Consumer提交到Kafka/zk中的偏移量将被忽略。</li>
<li>setStartFromLatest：从队尾开始，最新的记录，内部的Consumer提交到Kafka/zk中的偏移量将被忽略。</li>
<li>setStartFromGroupOffsets()：默认值，从当前消费组记录的偏移量开始，接着上次的偏移量消费，以Consumer提交到Kafka/zk中的偏移量最为起始位置开始消费，group.id设置在consumer的properties里;如果没找到记录的偏移量，则使用consumer的properties的auto.offset.reset设置的策略。</li>
<li>setStartFromSpecificOffsets(Map&lt;TopicPartition, Long&gt;的参数)：从指定的具体位置开始消费</li>
<li>setStartFromTimestamp(long)：从指定的时间戳开始消费，对于每个分区，时间戳大于或等于指定时间戳的记录将用作起始位置。如果一个分区的最新记录早于时间戳，那么只需要从最新记录中读取该分区。在此模式下，Kafka/zk中提交的偏移量将被忽略。<blockquote>
<p>从队头、指定offset、指定时间戳位置开始消费，会把历史数据当成批数据处理，不会有一条处理一条。</p>
</blockquote>
</li>
</ul>
<p>验证代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hzw<span class="token punctuation">.</span>bigdata<span class="token punctuation">.</span>flinkstudy</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>typeinfo<span class="token punctuation">.</span></span><span class="token class-name">Types</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>


<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkConsumerKafka</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
        <span class="token comment">// 创建Flink执行环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"golden-02:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"fink-test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"auto.offset.reset"</span><span class="token punctuation">,</span><span class="token string">"earliest"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> inputTopic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>
        <span class="token comment">// Source</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span>
                <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>inputTopic<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//这里设置一开始总是失败，原因是token.length() &lt; 6不满足，直接exit了</span>
        <span class="token comment">//但是这里有个问题，数据不应该是来一条消费一条吗？，最开始的几条数据，是满足token.length() &lt; 6的</span>
        <span class="token comment">//看这样的情况是，flatmap执行完以后，才会触发后面的函数</span>
        consumer<span class="token punctuation">.</span><span class="token function">setStartFromEarliest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//consumer.setStartFromTimestamp(1612246518000l);</span>
        <span class="token comment">//consumer.setStartFromLatest();</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>consumer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> wordCount <span class="token operator">=</span> stream
                <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">String</span> line<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Integer</span><span class="token punctuation">></span><span class="token punctuation">></span></span> collector<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
                    <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> tokens <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"/s"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token comment">// 输出结果 (word, 1)</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> token <span class="token operator">:</span> tokens<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                        <span class="token comment">//这里的现象是：一直没有输出结果，突然exit(1)，直接走了else，也就是说，它会把历史数据消费完/消费一个批次，再执行后面的聚合</span>
                        <span class="token comment">//但是，这里不知道是会把历史数据消费完才执行后面的聚合，还是只要消费到一定程度就会执行聚合</span>
                        <span class="token comment">//如果一定要消费所有历史数据才聚合，那么可能以后对历史数据的消费需要慎重，因为一口气读取的历史数据如果太多，绝对会出问题</span>
                        <span class="token keyword">if</span> <span class="token punctuation">(</span>token<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> token<span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">6</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                            collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span><span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>token<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>STRING<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>INT<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">keyBy</span><span class="token punctuation">(</span>key <span class="token operator">-></span> key<span class="token punctuation">.</span>f0<span class="token punctuation">)</span>
                <span class="token comment">//.window(TumblingProcessingTimeWindows.of(Time.seconds(1))) //有数据</span>
                <span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
                <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>key <span class="token operator">-></span> <span class="token punctuation">(</span>key<span class="token punctuation">.</span>f0 <span class="token operator">+</span> <span class="token string">":"</span> <span class="token operator">+</span> key<span class="token punctuation">.</span>f1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        wordCount<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"kafka streaming word count"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>


<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink使用案例（一）</title>
    <url>/2021/03/30/Flink%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>实时订单模型实现</li>
</ul>
<a id="more"></a>
<h2 id="实时订单模型实现"><a href="#实时订单模型实现" class="headerlink" title="实时订单模型实现"></a>实时订单模型实现</h2><p>公司最近要重构订单模型，需求是，把订单模型从离线完全转为实时，但是，需要解决如下几点问题：</p>
<ul>
<li>底层的订单表分为3张表，最终的模型是把3个表关联成一张表</li>
<li>底层三个表的数据不是同时产生的，时间跨度有大有小，导致时间窗口不好控制</li>
<li>订单状态随时间变化，导致数据肯定会跨天，甚至有的订单状态变成完成状态需要30天以上  </li>
<li>某个时间点，可能只会有一个表的数据更新，就会导致在处理这条数据的时候，肯定关联不上另外两个表</li>
</ul>
<p>为了解决如上问题，有如下几个思路解决：</p>
<ul>
<li>使用Flink的状态计算</li>
<li>把订单的3个表先缓存下来，每条数据来之后，先去缓存重获取另外两个表的数据</li>
</ul>
<p>考虑到，订单的生命周期太长，一个订单从产生到结束，时间跨度大部分在2周之内，但是在大促期间，有的甚至能跨好几个月，这时候用状态计算来保留订单的状态就有些不恰当了。<br>所以最终考虑使用Hbase作为缓存组件，先将3个订单表缓存到Hbase中</p>
<h3 id="数据源样例："><a href="#数据源样例：" class="headerlink" title="数据源样例："></a>数据源样例：</h3><p>数据源分为t_bdeal(fbdeal_id),t_deal(fdeal_id),t_trade(ftrade_id)表，其中，t_deal中含有fbdeal_id，t_trade表中含有fbdeal_id和fdeal_id<br>数据关系如下图：<br><img src="/uploads/20210330/%E6%95%B0%E6%8D%AE%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="数据关系图"></p>
<p>所以设置<code>Hbase</code> 3个表的<code>rowkey</code>分别是每个表的主键，并在t_bdeal表中添加${fdeal_id}_${ftrade_id}的集合<br>数据样例如下：<br>bdeal缓存数据样例如下：<br><img src="/uploads/20210330/bdeal%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B.png" alt="bdeal缓存数据样例"><br>deal缓存数据样例如下：<br><img src="/uploads/20210330/deal%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B.png" alt="bdeal缓存数据样例"><br>trade缓存数据样例如下：<br><img src="/uploads/20210330/trade%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B.png" alt="bdeal缓存数据样例"></p>
<h3 id="设计方案流程图如下："><a href="#设计方案流程图如下：" class="headerlink" title="设计方案流程图如下："></a>设计方案流程图如下：</h3><p><img src="/uploads/20210330/%E5%AE%9E%E6%97%B6%E8%AE%A2%E5%8D%95%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88.png" alt="实时订单模型设计方案"></p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>这里只贴关键部分的代码。<br>数据流都在<code>transform</code>中实现，这里只贴<code>transform</code>的代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>executor</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span></span>JSON<span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span></span><span class="token class-name">JSONArray</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span></span><span class="token class-name">JSONObject</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>google<span class="token punctuation">.</span>common<span class="token punctuation">.</span>collect<span class="token punctuation">.</span></span><span class="token class-name">Maps</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>common<span class="token punctuation">.</span>base<span class="token punctuation">.</span></span><span class="token class-name">AbstractStreamExcutor</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>common<span class="token punctuation">.</span>base<span class="token punctuation">.</span></span><span class="token class-name">AbstractStreamSink</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>common<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ResourcesUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>constant<span class="token punctuation">.</span></span><span class="token class-name">UserTagConstant</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>sink<span class="token punctuation">.</span></span><span class="token class-name">OmsOrderBdealSink</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">DateUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>haiziwang<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">HBaseUtil</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FilterFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">FlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">MapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token class-name">RichFlatMapFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple2</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>java<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple3</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">SingleOutputStreamOperator</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Collector</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">StringUtils</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Serializable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>text<span class="token punctuation">.</span></span><span class="token class-name">ParseException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Map</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>regex<span class="token punctuation">.</span></span><span class="token class-name">Pattern</span><span class="token punctuation">;</span>

<span class="token comment">/**
 * Author:   gujc
 * Date:     2021/03/03 15:38
 * Description:
 * rowkey设计：
 * bdeal: Fbdeal_id
 * deal: Fdeal_id
 * trade:Ftrade_id
 * 1、Hbase的bdeal表里存deal_id和trade_id的集合（deal_id_set,trade_id_set）
 * 2、之后trade表和bdeal表数据更新，如果是新增，那么也会更新bdeal表数据
 * 3、可能需要在窗口里对数据根据update_time排序，取最新的数据
 * 4、需要考虑一下，如果两个流数据同时过来，应该先更新哪个的问题
 * 5、如果数据更新方式是delete，需要过滤掉吗？
 *
 *
 * 重要未做：
 *      订单表的预分区，你可以找杜鹏这边了解一下采集系统的做法
 *      需要考虑在查询hbase的同时，另外一个并发在更新同一条记录，这里暂时无解，可能需要用到锁
 *      3个表的每条记录都会更新一次kudu，
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">GdmFactOmsOrdersExecutor</span> <span class="token keyword">extends</span> <span class="token class-name">AbstractStreamExcutor</span> <span class="token keyword">implements</span> <span class="token class-name">Serializable</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">/**
     * OMS订单表
     */</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> T_DEAL <span class="token operator">=</span> <span class="token string">"t_deal"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> T_BDEAL <span class="token operator">=</span> <span class="token string">"t_bdeal"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> T_TRADE <span class="token operator">=</span> <span class="token string">"t_trade"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> BDEAL_MATCHES <span class="token operator">=</span> <span class="token string">"t_bdeal_[0-9]+$"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> DEAL_MATCHES <span class="token operator">=</span> <span class="token string">"t_deal_[0-9]+$"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> TRADE_MATCHES <span class="token operator">=</span> <span class="token string">"t_trade_[0-9]+$"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> HBASE_TABLE_TRADE <span class="token operator">=</span> <span class="token string">"hb_app_onedata_oms_orders_t_trade_da"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> HBASE_TABLE_DEAL <span class="token operator">=</span> <span class="token string">"hb_app_onedata_oms_orders_t_deal_da"</span><span class="token punctuation">;</span>
    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> HBASE_TABLE_BDEAL <span class="token operator">=</span> <span class="token string">"hb_app_onedata_oms_orders_t_bdeal_da"</span><span class="token punctuation">;</span>



    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">AbstractStreamSink</span> <span class="token function">getFlinkSink</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">OmsOrderBdealSink</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> <span class="token function">transform</span><span class="token punctuation">(</span><span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> dataStream<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> singleStream <span class="token operator">=</span> dataStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">String</span> value<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">JSONObject</span> jsonObject <span class="token operator">=</span> JSON<span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> data <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> table <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"table"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> type <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>table<span class="token punctuation">,</span> data<span class="token punctuation">,</span>type<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FilterFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">filter</span><span class="token punctuation">(</span><span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> value<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span> optType <span class="token operator">=</span> value<span class="token punctuation">.</span>f2<span class="token punctuation">.</span><span class="token function">toLowerCase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> value<span class="token punctuation">.</span>f1 <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>value<span class="token punctuation">.</span>f1<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token string">"delete"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>optType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>

                <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">FlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple3</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span><span class="token punctuation">,</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">Tuple3</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> jsonObjects <span class="token operator">=</span> JSON<span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>value<span class="token punctuation">.</span>f1<span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> tableName <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>BDEAL_MATCHES<span class="token punctuation">,</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    tableName <span class="token operator">=</span> <span class="token class-name">UserTagConstant</span><span class="token punctuation">.</span>T_BDEAL<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>DEAL_MATCHES<span class="token punctuation">,</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    tableName <span class="token operator">=</span> <span class="token class-name">UserTagConstant</span><span class="token punctuation">.</span>T_DEAL<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">Pattern</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>TRADE_MATCHES<span class="token punctuation">,</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    tableName <span class="token operator">=</span> <span class="token class-name">UserTagConstant</span><span class="token punctuation">.</span>T_TRADE<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span><span class="token class-name">StringUtils</span><span class="token punctuation">.</span><span class="token function">isNullOrWhitespaceOnly</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">JSONObject</span> jsonObject <span class="token operator">:</span> jsonObjects<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>tableName<span class="token punctuation">.</span><span class="token function">toLowerCase</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>jsonObject<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">RichFlatMapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Tuple2</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">private</span> <span class="token class-name">HBaseUtil</span> hBaseUtil<span class="token punctuation">;</span>
            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token keyword">open</span><span class="token punctuation">(</span><span class="token class-name">Configuration</span> parameters<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token keyword">super</span><span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span>parameters<span class="token punctuation">)</span><span class="token punctuation">;</span>
                hBaseUtil <span class="token operator">=</span> <span class="token class-name">HBaseUtil</span><span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token class-name">ResourcesUtil</span><span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token string">"conf"</span><span class="token punctuation">,</span> <span class="token string">"zookeeper"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>

            <span class="token keyword">private</span> <span class="token class-name">JSONArray</span> <span class="token function">mergeProp</span><span class="token punctuation">(</span><span class="token class-name">JSONArray</span> jsonArray<span class="token punctuation">,</span> <span class="token class-name">String</span> prop<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>jsonArray <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    jsonArray <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JSONArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>jsonArray<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span>prop<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
                    jsonArray<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>prop<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">return</span> jsonArray<span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>


            <span class="token comment">/**
             * 更新Hbase表数据
             * 如果数据已经存在，判断update时间是否在历史数据之后，是则更新
             * 数据需要清洗后才能入Hbase
             * Hbase数据结构：
             * rowkey -> Map&lt;orderData,updateTime>
             * 如果是trade数据，那么还需要再更新一下bdeal数据，为了存储tradeArray
             * @param data
             * @return updateRes,更新true，未更新false
             */</span>
            <span class="token keyword">private</span> <span class="token class-name">Boolean</span> <span class="token function">updateHbase</span><span class="token punctuation">(</span><span class="token class-name">JSONObject</span> data<span class="token punctuation">,</span><span class="token class-name">String</span> tableName<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">ParseException</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span> updateTime <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> cacheTableName <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> rowkey <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">String</span> updateTimeCache <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">;</span>
                <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> cacheMap <span class="token operator">=</span> <span class="token class-name">Maps</span><span class="token punctuation">.</span><span class="token function">newHashMap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span>T_DEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    updateTime <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Flast_update_time"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheTableName <span class="token operator">=</span> HBASE_TABLE_DEAL<span class="token punctuation">;</span>
                    rowkey <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_BDEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    updateTime <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_update_time"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheTableName <span class="token operator">=</span> HBASE_TABLE_BDEAL<span class="token punctuation">;</span>
                    rowkey <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_TRADE<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    updateTime <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_update_time"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheTableName <span class="token operator">=</span> HBASE_TABLE_TRADE<span class="token punctuation">;</span>
                    rowkey <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                    <span class="token comment">//更新fbdeal缓存的tradeArray</span>
                    <span class="token class-name">String</span> bdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token class-name">String</span> dealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> bdealDataMap <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>bdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token class-name">JSONArray</span> tradeArrayTemp <span class="token operator">=</span> <span class="token keyword">null</span> <span class="token operator">==</span> bdealDataMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span> <span class="token operator">?</span>
                            <span class="token keyword">new</span> <span class="token class-name">JSONArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealDataMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                    tradeArrayTemp <span class="token operator">=</span> <span class="token function">mergeProp</span><span class="token punctuation">(</span>tradeArrayTemp<span class="token punctuation">,</span>dealId <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> rowkey<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token keyword">if</span><span class="token punctuation">(</span>bdealDataMap<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token comment">//如果bdeal还没有数据,不加updateTime，为了让bdeal数据来了以后，能够更新数据</span>
                        bdealDataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">,</span>bdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        bdealDataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArrayTemp<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                        <span class="token comment">//如果bdeal已经有数据</span>
                        bdealDataMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArrayTemp<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                    hBaseUtil<span class="token punctuation">.</span><span class="token function">insertOrderData</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span> bdealId<span class="token punctuation">,</span>bdealDataMap<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>

                updateTimeCache <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>cacheTableName<span class="token punctuation">,</span>rowkey<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"updateTime"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token comment">//如果更新时间大于缓存的时间，则更新数据，否则不更新</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token class-name">StringUtils</span><span class="token punctuation">.</span><span class="token function">isNullOrWhitespaceOnly</span><span class="token punctuation">(</span>updateTimeCache<span class="token punctuation">)</span> <span class="token operator">||</span>  <span class="token class-name">DateUtil</span><span class="token punctuation">.</span><span class="token function">dateDiffMilliSecond</span><span class="token punctuation">(</span>updateTimeCache<span class="token punctuation">,</span>updateTime<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        data<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArray<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    cacheMap<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"updateTime"</span><span class="token punctuation">,</span>updateTime<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    hBaseUtil<span class="token punctuation">.</span><span class="token function">insertOrderData</span><span class="token punctuation">(</span>cacheTableName<span class="token punctuation">,</span> rowkey<span class="token punctuation">,</span> cacheMap<span class="token punctuation">)</span><span class="token punctuation">;</span>

                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token class-name">DateUtil</span><span class="token punctuation">.</span><span class="token function">dateDiffMilliSecond</span><span class="token punctuation">(</span>updateTimeCache<span class="token punctuation">,</span>updateTime<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token comment">//如果这个数据已经在hbase里存在了，那么不更新hbase，但是需要处理后面的逻辑</span>
                    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
                    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>


            <span class="token comment">/**
             * 主逻辑：
             * updateHbase返回值，更新了数据则继续，否则结束
             * 按照3个订单表的不同，处理逻辑不同：
             *
             * 1. 交易单执行逻辑（bdeal）
             * 1.1 根据tradeArray获取Hbase中trade的数据
             * 1.2 从trade表中获取Fdeal_id，以此获取Hbase中deal的数据
             * 1.3 拼接结果数据，并返回
             *
             * 2. 商品单数据更新处理逻辑(trade)
             * 2.1. 根据Fdeal_id获取Hbase中deal的数据
             * 2.2. 根据Fbdeal_id获取Hbase中bdeal中的数据,并拼接tradeArray，写入bdeal表
             * 2.3. 拼接结果数据，并返回
             *
             * 3. 包裹单数据更新处理逻辑(deal)
             * 3.1 根据Fbdeal_id获取Hbase中bdeal的数据,
             * 3.2 并根据bdeal表的tradeArray获取trade表数据
             * 3.3 拼接结果数据，并返回
             *
             * 需要解决一个问题:
             * 如果trade数据先进来，只会更新trade缓存。那么等到bdeal数据来之后，因为没有tradeArray，数据就没法处理了
             * 所以，在更新trade缓存的时候，也需要更新bdeal的缓存。
             * @param data
             */</span>
            <span class="token keyword">private</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> <span class="token function">handle</span><span class="token punctuation">(</span><span class="token class-name">JSONObject</span> data<span class="token punctuation">,</span><span class="token class-name">String</span> tableName<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">ParseException</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> resArr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">boolean</span> flag <span class="token operator">=</span> <span class="token function">updateHbase</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>tableName<span class="token punctuation">)</span><span class="token punctuation">;</span>

                <span class="token keyword">if</span><span class="token punctuation">(</span>flag<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">if</span><span class="token punctuation">(</span>T_BDEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> fbdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token comment">//根据Fbdeal_id获取Hbase中bdeal的数据('data',jsonObject)</span>
                        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> bdealCacheData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> bdealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> dealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> tradeOrderCacheData <span class="token operator">=</span>  <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            bdealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"=========== bdeal:bdeal:"</span> <span class="token operator">+</span> fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                        <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token comment">//根据trade_id获取trade和deal表信息</span>
                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                <span class="token class-name">String</span> dealId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> tradeId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> orderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> tradeExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                                <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                    tradeOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>orderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>orderDataStr <span class="token operator">+</span> <span class="token string">"=========== bdeal:trade:"</span> <span class="token operator">+</span> tradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span>

                                <span class="token class-name">String</span> dealOrderStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>dealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token class-name">String</span> dealExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>dealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                                <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                    dealOrderCacheData <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>dealOrderStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>dealOrderStr <span class="token operator">+</span> <span class="token string">"=========== bdeal:deal:"</span> <span class="token operator">+</span> dealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span>


                                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> dealOrderCacheData <span class="token operator">&amp;&amp;</span> <span class="token keyword">null</span> <span class="token operator">!=</span> tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    tradeOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">,</span>tradeExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    dealOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">,</span>dealExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> unionOrders <span class="token operator">=</span> <span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">.</span><span class="token function">mergeResult</span><span class="token punctuation">(</span>bdealOrderCacheData<span class="token punctuation">,</span>dealOrderCacheData<span class="token punctuation">,</span>tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    resArr<span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>unionOrders<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token punctuation">&#125;</span>
                            <span class="token punctuation">&#125;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_DEAL<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> fdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> fbdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token comment">//根据Fdeal_id获取Hbase中bdeal的数据('data',jsonObject)</span>
                        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> bdealCacheData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> bdealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> dealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> tradeOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            bdealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"=========== deal:bdeal:"</span> <span class="token operator">+</span> fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token comment">/**
                         * 这里是可以省略一次查询Hbase的。之后做优化。
                         */</span>
                        <span class="token class-name">String</span> dealOrderStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> dealExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            dealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>dealOrderStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>dealOrderStr <span class="token operator">+</span> <span class="token string">"=========== deal:deal"</span> <span class="token operator">+</span> fdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>
                        dealOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">,</span>dealExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> bdealOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                <span class="token comment">//根据trade_id获取trade和deal表信息</span>
                                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                    <span class="token class-name">String</span> dealId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                    <span class="token class-name">String</span> tradeId <span class="token operator">=</span> tradeArray<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"_"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
                                    <span class="token class-name">String</span> tradeExtData <span class="token operator">=</span> <span class="token string">"&#123;&#125;"</span><span class="token punctuation">;</span>
                                    <span class="token keyword">if</span><span class="token punctuation">(</span>dealId<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                        <span class="token class-name">String</span> orderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        tradeExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>tradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                            tradeOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>orderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>orderDataStr <span class="token operator">+</span> <span class="token string">"=========== deal:trade:"</span> <span class="token operator">+</span> tradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        <span class="token punctuation">&#125;</span>
                                    <span class="token punctuation">&#125;</span>

                                    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                        tradeOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">,</span>tradeExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> unionOrders <span class="token operator">=</span> <span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">.</span><span class="token function">mergeResult</span><span class="token punctuation">(</span>bdealOrderCacheData<span class="token punctuation">,</span>dealOrderCacheData<span class="token punctuation">,</span>tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                        resArr<span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>unionOrders<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                    <span class="token punctuation">&#125;</span>
                                <span class="token punctuation">&#125;</span>
                            <span class="token punctuation">&#125;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>T_TRADE<span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        <span class="token class-name">String</span> fdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> fbdealId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Fbdeal_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> ftradeId <span class="token operator">=</span> data<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"Ftrade_id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                        <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">></span></span> bdealCacheData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span>fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> bdealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span> <span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> dealOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token class-name">JSONObject</span> tradeOrderCacheData <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            bdealOrderCacheData <span class="token operator">=</span>  <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"=========== trade:bdeal:"</span> <span class="token operator">+</span> fbdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>


                        <span class="token class-name">String</span> orderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token class-name">String</span> dealExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_DEAL<span class="token punctuation">,</span>fdealId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                            dealOrderCacheData <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>orderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>orderDataStr <span class="token operator">+</span> <span class="token string">"=========== trade:deal:"</span> <span class="token operator">+</span> fdealId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>


                        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">!=</span> bdealOrderCacheData <span class="token operator">&amp;&amp;</span> <span class="token keyword">null</span> <span class="token operator">!=</span> dealOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                            dealOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Fdeal_ext_data"</span><span class="token punctuation">,</span>dealExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">JSONArray</span> tradeArray <span class="token operator">=</span> <span class="token class-name">JSONArray</span><span class="token punctuation">.</span><span class="token function">parseArray</span><span class="token punctuation">(</span>bdealCacheData<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">null</span> <span class="token operator">==</span> tradeArray<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                tradeArray <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JSONArray</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token punctuation">&#125;</span>
                            tradeArray <span class="token operator">=</span> <span class="token function">mergeProp</span><span class="token punctuation">(</span>tradeArray<span class="token punctuation">,</span>fdealId <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> ftradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            bdealCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"tradeArray"</span><span class="token punctuation">,</span>tradeArray<span class="token punctuation">.</span><span class="token function">toJSONString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//tradeArray</span>
                            hBaseUtil<span class="token punctuation">.</span><span class="token function">insertOrderData</span><span class="token punctuation">(</span>HBASE_TABLE_BDEAL<span class="token punctuation">,</span> fbdealId<span class="token punctuation">,</span> bdealCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token comment">//根据trade_id获取trade和deal表信息</span>
                            <span class="token class-name">String</span> tradeOrderDataStr <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>ftradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token string">"orderData"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token class-name">String</span> tradeExtData <span class="token operator">=</span> hBaseUtil<span class="token punctuation">.</span><span class="token function">getRow</span><span class="token punctuation">(</span>HBASE_TABLE_TRADE<span class="token punctuation">,</span>ftradeId<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrDefault</span><span class="token punctuation">(</span><span class="token string">"ext_data"</span><span class="token punctuation">,</span><span class="token string">"&#123;&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

                            <span class="token keyword">try</span><span class="token punctuation">&#123;</span>
                                tradeOrderCacheData <span class="token operator">=</span> <span class="token class-name">JSONObject</span><span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>tradeOrderDataStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>tradeOrderDataStr <span class="token operator">+</span> <span class="token string">"=========== trade:trade:"</span> <span class="token operator">+</span> ftradeId<span class="token punctuation">)</span><span class="token punctuation">;</span>
                                <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                            <span class="token punctuation">&#125;</span>

                            tradeOrderCacheData<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"Ftrade_ext_data"</span><span class="token punctuation">,</span>tradeExtData<span class="token punctuation">)</span><span class="token punctuation">;</span>

                            <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> unionOrders <span class="token operator">=</span> <span class="token class-name">GdmFactOmsOrdersUtil</span><span class="token punctuation">.</span><span class="token function">mergeResult</span><span class="token punctuation">(</span>bdealOrderCacheData<span class="token punctuation">,</span>dealOrderCacheData<span class="token punctuation">,</span>tradeOrderCacheData<span class="token punctuation">)</span><span class="token punctuation">;</span>
                            resArr<span class="token punctuation">.</span><span class="token function">addAll</span><span class="token punctuation">(</span>unionOrders<span class="token punctuation">)</span><span class="token punctuation">;</span>
                        <span class="token punctuation">&#125;</span>

                        <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                    <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
                <span class="token punctuation">&#125;</span>
                <span class="token keyword">return</span> resArr<span class="token punctuation">;</span>
            <span class="token punctuation">&#125;</span>

            <span class="token annotation punctuation">@Override</span>
            <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">flatMap</span><span class="token punctuation">(</span><span class="token class-name">Tuple2</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> value<span class="token punctuation">,</span> <span class="token class-name">Collector</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Object</span><span class="token punctuation">></span></span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">&#123;</span>
                <span class="token class-name">String</span> tableName <span class="token operator">=</span> value<span class="token punctuation">.</span>f0<span class="token punctuation">;</span>
                <span class="token class-name">JSONObject</span> data <span class="token operator">=</span> value<span class="token punctuation">.</span>f1<span class="token punctuation">;</span>
                <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">JSONObject</span><span class="token punctuation">></span></span> list <span class="token operator">=</span> <span class="token function">handle</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>tableName<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">if</span><span class="token punctuation">(</span>list<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> size<span class="token punctuation">;</span> i <span class="token operator">++</span> <span class="token punctuation">)</span><span class="token punctuation">&#123;</span>
                        out<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>list<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">&#125;</span>
                <span class="token punctuation">&#125;</span>
            <span class="token punctuation">&#125;</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> singleStream<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个方案的好处是，任务挂掉以后，不用担心丢数据。重新消费即可</p>
<p>经过测试，此方案完全可行，但是这个方案有如下几点问题：</p>
<ul>
<li>3个表每条数据更新都会更新一次kudu，造成下游的Kudu压力有些大。</li>
<li>在高并发的情况下，Hbase的压力不知道能否抗住，理论上应该没事，后期观察</li>
</ul>
<p>虽然没有用到Flink的状态计算，但是，还是很想研究一下Flink的状态计算，想测试一个案例：<br>实现如下功能：</p>
<ul>
<li>3个kafka输入源，并且实现这3个数据源关联，模仿3个表join</li>
<li>改变其中一个表的字段值，使用状态计算更新最终的结果</li>
<li>增加大时间跨度大于1天，7天，30天。</li>
</ul>
<p>Flink读取kafka多个topic遇到的问题：<br>如果要读取的Topic列表中，其中一个在Topic中没有数据，而你又基于Event Time提取Timestamp并且设置Watermark，<br>会导致整个Topic列表都没法基于时间窗口触发操作，解决方案：<br>先rebalance，然后再设置水位：</p>
<pre class="line-numbers language-scala" data-language="scala"><code class="language-scala"><span class="token keyword">val</span> monitorSampling <span class="token operator">=</span> env
    <span class="token punctuation">.</span>addSource<span class="token punctuation">(</span>kafkaConsumer<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>rebalance
    <span class="token punctuation">.</span>assignTimestampsAndWatermarks<span class="token punctuation">(</span><span class="token keyword">new</span> MyWatermarkGenerator<span class="token punctuation">[</span>MyRecord<span class="token punctuation">]</span><span class="token punctuation">(</span>Time<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span>config<span class="token punctuation">.</span>latencyDuration<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>


<h2 id="Flink反压"><a href="#Flink反压" class="headerlink" title="Flink反压"></a>Flink反压</h2><p>反压（backpressure）是实时计算应用开发中，特别是流式计算中，十分常见的问题。反压意味着数据管道中某个节点成为瓶颈，处理速率跟不上上游发送数据的速率，而需要对上游进行限速。</p>
<h3 id="反压的影响"><a href="#反压的影响" class="headerlink" title="反压的影响"></a>反压的影响</h3><p>反压并不会直接影响作业的可用性，它表明作业处于亚健康的状态，有潜在的性能瓶颈并可能导致更大的数据处理延迟。通常来说，对于一些对延迟要求不太高或者数据量比较小的应用来说，反压的影响可能并不明显，然而对于规模比较大的 Flink 作业来说反压可能会导致严重的问题。</p>
<p>这是因为 Flink 的 checkpoint 机制，反压还会影响到两项指标: checkpoint 时长和 state 大小。</p>
<ul>
<li>前者是因为 checkpoint barrier 是不会越过普通数据的，数据处理被阻塞也会导致 checkpoint barrier 流经整个数据管道的时长变长，因而 checkpoint 总体时间（End to End Duration）变长。</li>
<li>后者是因为为保证 EOS（Exactly-Once-Semantics，准确一次），对于有两个以上输入管道的 Operator，checkpoint barrier 需要对齐（Alignment），接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到state 里面，导致 checkpoint 变大。</li>
</ul>
<p>这两个影响对于生产环境的作业来说是十分危险的，因为 checkpoint 是保证数据一致性的关键，checkpoint 时间变长有可能导致 checkpoint 超时失败，而 state 大小同样可能拖慢 checkpoint 甚至导致 OOM （使用 Heap-based StateBackend）或者物理内存使用超出容器资源（使用 RocksDBStateBackend）的稳定性问题。</p>
<h3 id="定位反压节点"><a href="#定位反压节点" class="headerlink" title="定位反压节点"></a>定位反压节点</h3><p>要解决反压首先要做的是定位到造成反压的节点，这主要有两种办法:</p>
<ul>
<li>通过 Flink Web UI 自带的反压监控面板；</li>
<li>通过 Flink Task Metrics。<br>前者比较容易上手，适合简单分析，后者则提供了更加丰富的信息，适合用于监控系统。因为反压会向上游传导，这两种方式都要求我们从 Source 节点到 Sink 的逐一排查，直到找到造成反压的根源原因。下面分别介绍这两种办法。</li>
</ul>
<p>反压监控面板</p>
<p>Flink Web UI 的反压监控提供了 SubTask 级别的反压监控，原理是通过周期性对 Task 线程的栈信息采样，得到线程被阻塞在请求 Buffer（意味着被下游队列阻塞）的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1 以下则为 OK，0.1 至 0.5 为 LOW，而超过 0.5 则为 HIGH。</p>
<p>如果处于反压状态，那么有两种可能性：</p>
<ul>
<li>该节点的发送速率跟不上它的产生数据速率。这一般会发生在一条输入多条输出的 Operator（比如 flatmap）。</li>
<li>下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率。<br>如果是第一种状况，那么该节点则为反压的根源节点，它是从 Source Task 到 Sink Task 的第一个出现反压的节点。如果是第二种情况，则需要继续排查下游节点。</li>
</ul>
<p>具体可以参考<a href="https://zhuanlan.zhihu.com/p/92743373">如何分析及处理 Flink 反压？</a><br><a href="https://www.jianshu.com/p/2779e73abcb8">一文搞懂 Flink 网络流控与反压机制</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink面试题总结</title>
    <url>/2021/11/11/Flink%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Flink面试题总结</li>
</ul>
<a id="more"></a>



<p><strong><font size = 5>1. Flink是如何支持批流一体的？</font></strong><br>    Flink的开发者认为批处理是流处理的一种特殊情况。批处理是有限的流处理。Flink 使用一个引擎支持了DataSet API 和 DataStream API<br>    在1.12.x以后，DataSet API会逐渐废弃，DataStream API已经既可以处理流也可以处理批了<br>    具体可以参考<a href="https://www.cnblogs.com/binbingg/p/14330354.html">Apache Flink 1.12.0 正式发布，DataSet API 将被弃用，真正的流批一体</a></p>
<p><strong><font size = 5>2. Flink 相比传统的 Spark Streaming 有什么区别?</font></strong><br>    Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型<br>    1. 架构模型Spark Streaming 在运行时的主要角色包括：Master、Worker、Driver、Executor;<br>       Flink 在运行时主要包含：Jobmanager、Taskmanager和Slot。<br>    2. 任务调度Spark Streaming 连续不断的生成微小的数据批次，构建有向无环图DAG，Spark Streaming 会依次创建 DStreamGraph、JobGenerator、JobScheduler。<br>       Flink 根据用户提交的代码生成 StreamGraph，经过优化生成 JobGraph，然后提交给 JobManager进行处理，JobManager 会根据 JobGraph 生成 ExecutionGraph，ExecutionGraph 是 Flink 调度最核心的数据结构，JobManager 根据 ExecutionGraph 对 Job 进行调度。<br>    3. 时间机制Spark Streaming 支持的时间机制有限，只支持处理时间。<br>       Flink 支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间。同时也支持 watermark 机制来处理滞后数据。<br>    4. 容错机制对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰好一次处理语义。<br>       Flink 则使用两阶段提交协议来解决这个问题</p>
<p><strong><font size = 5>3. Flink集群有哪些角色？各自有什么作用？</font></strong><br>    Flink 程序在运行时主要有 TaskManager，JobManager，Client三种角色。<br>    1. JobManager是一个进程，主要负责申请资源，协调以及控制整个job的执行过程，具体包括，调度任务、处理checkpoint、容错等等，在接收到JobClient提交的执行计划之后，针对收到的执行计划，继续解析，因为JobClient只是形成一个operaor层面的执行计划，所以JobManager继续解析执行计划（根据算子的并发度，划分task），形成一个可以被实际调度的由task组成的拓扑图，如上图被解析之后形成下图的执行计划，最后向集群申请资源，一旦资源就绪，就调度task到TaskManager。<br>    2. TaskManager是一个进程，及一个JVM（Flink用java实现）。主要作用是接收并执行JobManager发送的task，并且与JobManager通信，反馈任务状态信息，比如任务分执行中，执行完等状态，上文提到的checkpoint的部分信息也是TaskManager反馈给JobManager的。如果说JobManager是master的话，那么TaskManager就是worker主要用来执行任务。在TaskManager内可以运行多个task。多个task运行在一个JVM内有几个好处，首先task可以通过多路复用的方式TCP连接，其次task可以共享节点之间的心跳信息，减少了网络传输。<br>    3. Client是Flink程序提交的客户端，当用户提交一个Flink程序时，会首先创建一个Client，该Client首先会对用户提交的Flink程序进行预处理，并提交到Flink集群中处理，所以Client需要从用户提交的Flink程序配置中获取JobManager的地址，并建立到JobManager的连接，将Flink Job提交给JobManager<br>    Spark中每个Stage中的Task会被分配到一个Worker中的 -&gt; Executor容器里面的 -&gt; 一个线程池中被执行，Flink称每个Executor为一个TaskManager，每个TaskManager中会有多个slot作为内存隔离：<br>    Spark：Worker  ——&gt;   Executor  ——&gt;  线程池  ——&gt;  线程<br>    Flink：  Worker  ——&gt;   TaskManager  ——&gt;  Slot  ——&gt;  线程 </p>
<p><strong><font size = 5>4. 说说 Flink 资源管理中 Task Slot 的概念</font></strong><br>    Slot是TaskManager资源粒度的划分，每个Slot都有自己独立的内存。所有Slot平均分配TaskManger的内存，比如TaskManager分配给Solt的内存为8G，两个Slot，每个Slot的内存为4G，四个Slot，每个Slot的内存为2G，值得注意的是，Slot仅划分内存，不涉及cpu的划分。同时Slot是Flink中的任务执行器（类似Storm中Executor），每个Slot可以运行多个task，而且一个task会以单独的线程来运行。Slot主要的好处有以下几点：<br>    可以起到隔离内存的作用，防止多个不同job的task竞争内存。<br>    Slot的个数就代表了一个Flink程序的最高并行度，简化了性能调优的过程<br>    允许多个Task共享Slot，提升了资源利用率，举一个实际的例子，kafka有3个partition，对应flink的source有3个task，而keyBy我们设置的并行度为20，这个时候如果Slot不能共享的话，需要占用23个Slot，如果允许共享的话，那么只需要20个Slot即可（Slot的默认共享规则计算为20个）。</p>
<p><strong><font size = 5>5. 说说你知道的Flink分区策略？</font></strong><br>    1. GlobalPartitioner 数据会被分发到下游算子的第一个实例中进行处理。<br>    2. ShufflePartitioner 数据会被随机分发到下游算子的每一个实例中进行处理。<br>    3. RebalancePartitioner 数据会被循环发送到下游的每一个实例中进行处理。<br>    4. RescalePartitioner 这种分区器会根据上下游算子的并行度，循环的方式输出到下游算子的每个实例。<br>        这里有点难以理解，假设上游并行度为2，编号为A和B。下游并行度为4，编号为1，2，3，4。那么A则把数据循环发送给1和2，B则把数据循环发送给3和4。假设上游并行度为4，编号为A，B，C，D。下游并行度为2，编号为1，2。那么A和B则把数据发送给1，C和D则把数据发送给2。<br>    5. BroadcastPartitioner 广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做Jion的场景。<br>    6. ForwardPartitioner 用于将记录输出到下游本地的算子实例。它要求上下游算子并行度一样。简单的说，ForwardPartitioner用来做数据的控制台打印。<br>    7. KeyGroupStreamPartitioner Hash分区器。会将数据按 Key 的 Hash 值输出到下游算子实例中。<br>    8. CustomPartitionerWrapper 用户自定义分区器。需要用户自己实现Partitioner接口，来定义自己的分区逻辑</p>
<p><strong><font size = 5>6. Flink的并行度了解吗？Flink的并行度设置是怎样的？</font></strong><br>    Flink中的任务被分为多个并行任务来执行，其中每个并行的实例处理一部分数据。这些并行实例的数量被称为并行度。我们在实际生产环境中可以从四个不同层面设置并行度：<br>    操作算子层面(Operator Level)<br>    执行环境层面(Execution Environment Level)<br>    客户端层面(Client Level)<br>    系统层面(System Level)<br>    需要注意的优先级：算子层面&gt;环境层面&gt;客户端层面&gt;系统层面</p>
<p><strong><font size = 5>7. Flink的Slot和parallelism有什么区别？</font></strong><br>    slot是指taskmanager的并发执行能力，假设我们将 taskmanager.numberOfTaskSlots 配置为3 那么每一个 taskmanager 中分配3个 TaskSlot, 3个 taskmanager 一共有9个TaskSlot。<br>    parallelism是指taskmanager实际使用的并发能力。假设我们把 parallelism.default 设置为1，那么9个 TaskSlot 只能用1个，有8个空闲。</p>
<p><strong><font size = 5>8. Flink有没有重启策略？说说有哪几种？</font></strong><br>    Flink 实现了多种重启策略。<br>    固定延迟重启策略（Fixed Delay Restart Strategy）<br>    故障率重启策略（Failure Rate Restart Strategy）<br>    没有重启策略（No Restart Strategy）<br>    Fallback重启策略（Fallback Restart Strategy）</p>
<p><strong><font size = 5>9. 用过Flink中的分布式缓存吗？如何使用？</font></strong><br>    Flink实现的分布式缓存和Hadoop有异曲同工之妙。目的是在本地读取文件，并把他放在 taskmanager 节点中，防止task重复拉取。</p>
<p><strong><font size = 5>10. 说说Flink中的广播变量，使用时需要注意什么？</font></strong><br>    我们知道Flink是并行的，计算过程可能不在一个 Slot 中进行，那么有一种情况即：当我们需要访问同一份数据。那么Flink中的广播变量就是为了解决这种情况。<br>    我们可以把广播变量理解为是一个公共的共享变量，我们可以把一个dataset 数据集广播出去，然后不同的task在节点上都能够获取到，这个数据在每个节点上只会存在一份</p>
<p><strong><font size = 5>11. 说说Flink中的窗口？</font></strong><br>    Flink的窗口可以分为Keyed Windows和Non-Keyed Windows，键控窗口会按照key划分逻辑键控流，拥有键控流将允许窗口计算由多个任务并行执行，非键控流的并行度为1<br>    窗口的生命周期：当应该属于该窗口的第一个元素到达时，就会创建一个窗口，并且当时间（事件或处理时间）超过其结束时间戳加上用户指定的允许延迟时，该窗口将被完全删除<br>    窗口分配器可以分为<br>    tumbling windows：无重叠<br>    sliding windows：有重叠<br>    session windows：当会话窗口在一段时间内没有接收到元素时，即发生不活动间隙时，它会关闭<br>    global windows：全局窗口分配器将具有相同键的所有元素分配给同一个全局窗口。仅在指定自定义触发器时才有用。 否则，不会执行任何计算</p>
<p><strong><font size = 5>12. 说说Flink中的状态存储？</font></strong><br>    Flink在做计算的过程中经常需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和 checkpoint 交互。<br>    Flink提供了三种状态存储方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend</p>
<p><strong><font size = 5>13. Flink 中的时间有哪几类？</font></strong><br>    Flink 中的时间和其他流式计算系统的时间一样分为三类：事件时间，摄入时间，处理时间三种。<br>    如果以 EventTime 为基准来定义时间窗口将形成EventTimeWindow,要求消息本身就应该携带EventTime。<br>    如果以 IngesingtTime 为基准来定义时间窗口将形成 IngestingTimeWindow,以 source 的systemTime为准。<br>    如果以 ProcessingTime 基准来定义时间窗口将形成 ProcessingTimeWindow，以 operator 的systemTime 为准。</p>
<p><strong><font size = 5>14. Flink 中水印是什么概念，起到什么作用？</font></strong><br>    Watermark 是 Apache Flink 为了处理 EventTime 窗口计算提出的一种机制, 本质上是一种时间戳。 一般来讲Watermark经常和Window一起被用来处理乱序事件。</p>
<p><strong><font size = 5>15. Flink是如何做到高效的数据交换的？</font></strong><br>    在一个Flink Job中，数据需要在不同的task中进行交换，整个数据交换是有 TaskManager 负责的，TaskManager 的网络组件首先从缓冲buffer中收集records，然后再发送。<br>    Records 并不是一个一个被发送的，二是积累一个批次再发送，batch 技术可以更加高效的利用网络资源</p>
<p><strong><font size = 5>16. Flink是如何做容错的？</font></strong><br>    Flink 实现容错主要靠强大的CheckPoint机制和State机制。Checkpoint 负责定时制作分布式快照、对程序中的状态进行备份；State 用来存储计算过程中的中间状态。</p>
<p><strong><font size = 5>17. Flink 分布式快照的原理是什么？</font></strong><br>    Flink的分布式快照是根据Chandy-Lamport算法量身定做的。简单来说就是持续创建分布式数据流及其状态的一致快照。<br>    核心思想是在 input source 端插入 barrier，控制 barrier 的同步来实现 snapshot 的备份和 exactly-once 语义。</p>
<p><strong><font size = 5>18. Flink 是如何保证Exactly-once语义的？</font></strong><br>    flink会把kafka的offset作为状态存下来，并会定期的做checkpoint持久化。<br>    Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义。 分为以下几个步骤：<br>    开始事务（beginTransaction）创建一个临时文件夹，来写把数据写入到这个文件夹里面<br>    预提交（preCommit）将内存中缓存的数据写入文件并关闭<br>    正式提交（commit）将之前写完的临时文件放入目标目录下。这代表着最终的数据会有一些延迟<br>    丢弃（abort）丢弃临时文件<br>    若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。</p>
<p><strong><font size = 5>19. 说说 Flink的内存管理是如何做的?</font></strong><br>    Flink 并不是将大量对象存在堆上，而是将对象都序列化到一个预分配的内存块上。此外，Flink大量的使用了堆外内存。如果需要处理的数据超出了内存限制，则会将部分数据存储到硬盘上。<br>    Flink 为了直接操作二进制数据实现了自己的序列化框架。理论上Flink的内存管理分为三部分：<br>    Network Buffers：这个是在TaskManager启动的时候分配的，这是一组用于缓存网络数据的内存，每个块是32K，默认分配2048个，可以通过“taskmanager.network.numberOfBuffers”修改<br>    Memory Manage pool：大量的Memory Segment块，用于运行时的算法（Sort/Join/Shuffle等），这部分启动的时候就会分配。，内存的分配支持预分配和lazy load，默认懒加载的方式。<br>    User Code，这部分是除了Memory Manager之外的内存用于User code和TaskManager本身的数据结构。</p>
<p><strong><font size = 5>20. Flink中的Window出现了数据倾斜，你有什么解决办法？</font></strong><br>    window产生数据倾斜指的是数据在不同的窗口内堆积的数据量相差过多。本质上产生这种情况的原因是数据源头发送的数据量速度不同导致的。出现这种情况一般通过两种方式来解决：<br>    在数据进入窗口前做预聚合<br>    重新设计窗口聚合的key</p>
<p><strong><font size = 5>21. Flink任务延迟高，想解决这个问题，你会如何入手？</font></strong><br>    在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。作业参数调优包括：并行度的设置，State的设置，checkpoint的设置</p>
<p><strong><font size = 5>22. Flink是如何处理反压的？</font></strong><br>    Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞</p>
<p><strong><font size = 5>23. Operator Chains（算子链）这个概念你了解吗？</font></strong><br>    为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。<br>    将operators链接成task是非常有效的优化：<br>    它能减少线程之间的切换，<br>    减少消息的序列化/反序列化，<br>    减少数据在缓冲区的交换，<br>    减少了延迟的同时提高整体的吞吐量。<br>    这就是我们所说的算子链</p>
<p><strong><font size = 5>24. Flink什么情况下才会把Operator chain在一起形成算子链？</font></strong><br>    两个operator chain在一起的的条件：<br>    上下游的并行度一致<br>    下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）<br>    上下游节点都在同一个 slot group 中（下面会解释 slot group）<br>    下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）<br>    上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）<br>    两个节点间数据分区方式是 forward（参考理解数据流的分区）<br>    用户没有禁用 chain</p>
<p><strong><font size = 5>25. Flink Job的提交流程</font></strong><br>    用户提交的Flink Job会被转化成一个DAG任务运行，分别是：StreamGraph、JobGraph、ExecutionGraph，<br>    Flink中JobManager与TaskManager，JobManager与Client的交互是基于Akka工具包的，是通过消息驱动。<br>    整个Flink Job的提交还包含着ActorSystem的创建，JobManager的启动，TaskManager的启动和注册。</p>
<p><strong><font size = 5>26. Flink 计算资源的调度是如何实现的？</font></strong><br>    TaskManager中最细粒度的资源是Task slot，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。<br>    通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。<br>    每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，<br>    可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。 每个slot可以接受单个task，也可以接受多个连续task组成的pipeline</p>
<p><strong><font size = 5>27. 简述Flink的数据抽象及数据交换过程？</font></strong><br>    Flink 为了避免JVM的固有缺陷例如java对象存储密度低，FGC影响吞吐和响应等，实现了自主管理内存。MemorySegment就是Flink的内存抽象。<br>    默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。<br>    在MemorySegment这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是Buffer。<br>    对接从Java对象转为Buffer的中间对象是另一个抽象StreamRecord。</p>
<p><strong><font size = 5>28. Flink 中的分布式快照机制是如何实现的？</font></strong><br>    Flink的容错机制的核心部分是制作分布式数据流和操作算子状态的一致性快照。 这些快照充当一致性checkpoint，系统可以在发生故障时回滚。 Flink用于制作这些快照的机制在“分布式数据流的轻量级异步快照”中进行了描述。<br>    它受到分布式快照的标准Chandy-Lamport算法的启发，专门针对Flink的执行模型而定制。<br>    barriers在数据流源处被注入并行数据流中。快照n的barriers被插入的位置（我们称之为Sn）是快照所包含的数据在数据源中最大位置。<br>    例如，在Apache Kafka中，此位置将是分区中最后一条记录的偏移量。 将该位置Sn报告给checkpoint协调器（Flink的JobManager）。<br>    然后barriers向下游流动。当一个中间操作算子从其所有输入流中收到快照n的barriers时，它会为快照n发出barriers进入其所有输出流中。<br>    一旦sink操作算子（流式DAG的末端）从其所有输入流接收到barriers n，它就向checkpoint协调器确认快照n完成。在所有sink确认快照后，意味快照着已完成。<br>    一旦完成快照n，job将永远不再向数据源请求Sn之前的记录，因为此时这些记录（及其后续记录）将已经通过整个数据流拓扑，也即是已经被处理结束。</p>
<p><strong><font size = 5>28. Flink任务延迟高，想解决这个问题，你会如何入手？</font></strong><br>在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。<br>作业参数调优包括：并行度的设置，State的设置，checkpoint的设置。</p>
<p><strong><font size = 5>29. Flink任务延迟高，想解决这个问题，你会如何入手？</font></strong></p>
]]></content>
      <categories>
        <category>面试题</category>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Hbase学习笔记</title>
    <url>/2022/03/01/Hbase%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>Hbase简介</li>
<li>Hbase安装</li>
<li>HBase命令行操作</li>
<li>Phoenix操作Hbase</li>
</ul>
<a id="more"></a>

<h2 id="Hbase简介"><a href="#Hbase简介" class="headerlink" title="Hbase简介"></a>Hbase简介</h2><p>HBASE是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBASE技术可在廉价PC Server上搭建起大规模结构化存储集群。<br>HBASE的目标是存储并处理大型的数据，更具体来说是仅需使用普通的硬件配置，就能够处理由成千上万的行和列所组成的大型数据。</p>
<p>它介于nosql和RDBMS之间，仅能通过主键(row key)和主键的range来检索数据，仅支持单行事务(可通过hive支持来实现多表join等复杂操作)。主要用来存储非结构化和半结构化的松散数据。</p>
<p>Hbase的表模型与关系型数据库的表模型不同：</p>
<ul>
<li>Hbase的表没有固定的字段定义；</li>
<li>Hbase的表中每行存储的都是一些key-value对</li>
<li>Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族</li>
<li>Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中</li>
<li>Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复</li>
<li>Hbase中的数据，包含行键，包含key，包含value，都是byte[ ]类型，hbase不负责为用户维护数据类型</li>
<li>HBASE对事务的支持很差</li>
</ul>
<p>HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：<br>Hbase的表数据存储在HDFS文件系统中，所以，hbase具备如下特性：</p>
<ul>
<li>海量存储</li>
<li>列式存储</li>
<li>数据存储的安全性可靠性极高！</li>
<li>支持高并发</li>
<li>存储容量可以线性扩展；</li>
</ul>
<h3 id="HBase存储机制"><a href="#HBase存储机制" class="headerlink" title="HBase存储机制"></a>HBase存储机制</h3><p>HBase是一个面向列的数据库，在表中它由行排序。表模式定义只能列族，也就是键值对。一个表有多个列族以及每一个列族可以有任意数量的列。后续列的值连续地存储在磁盘上。表中的每个单元格值都具有时间戳。总之，在一个HBase： - 表是行的集合。 - 行是列族的集合。 - 列族是列的集合。 - 列是键值对的集合。</p>
<p>下面给出的表中是HBase模式的一个例子。<br><img src="/uploads/202203/Hbase%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6.png" alt="Hbase存储机制"></p>
<h3 id="名词概念"><a href="#名词概念" class="headerlink" title="名词概念"></a>名词概念</h3><ul>
<li><p><strong>Rowkey的概念</strong><br>Rowkey的概念和mysql中的主键是完全一样的，Hbase使用Rowkey来唯一的区分某一行的数据。Hbase只支持3种查询方式： - 1、基于Rowkey的单行查询 - 2、基于Rowkey的范围扫描 - 3、全表扫描<br>因此，Rowkey对Hbase的性能影响非常大，Rowkey的设计就显得尤为的重要。设计的时候要兼顾基于Rowkey的单行查询也要键入Rowkey的范围扫描。<br>rowkey 行键可以是任意字符串(最大长度是64KB，实际应用中长度一般为 10-100bytes)，最好是16。在HBase 内部，rowkey 保存为字节数组。HBase会对表中的数据按照 rowkey 排序 (字典顺序)</p>
</li>
<li><p><strong>Column的概念</strong><br>列，可理解成MySQL列。</p>
</li>
<li><p><strong>ColumnFamily的概念</strong><br>Hbase通过列族划分数据的存储，列族下面可以包含任意多的列，实现灵活的数据存取。列族是由一个一个的列组成（任意多）。</p>
</li>
</ul>
<p>Hbase表的创建的时候就必须指定列族。就像关系型数据库创建的时候必须指定具体的列是一样的。</p>
<p>Hbase的列族不是越多越好，官方推荐的是列族最好小于或者等于3。我们使用的场景一般是1个列族。</p>
<ul>
<li><p><strong>TimeStamp的概念</strong><br>TimeStamp对Hbase来说至关重要，因为它是实现Hbase多版本的关键。在Hbase中使用不同的timestame来标识相同rowkey行对应的不通版本的数据。<br>在写入数据的时候，如果用户没有指定相应的timestamp，HBase会自动添加一个timestamp，timestamp和服务器时间保持一致。<br>HBase 中通过rowkey和columns确定的为一个存储单元称为cell。每个cell都保存着同一份数据的多个版本。版本通过时间戳来索引。时间戳的类型是64位整型。时间戳可以由 hbase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。每个cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。<br>为了避免数据存在过多版本造成的的管理(包括存贮和索引)负担，hbase 提供了两种数据版本回收方式： - 保存数据的最后 n 个版本 - 保存最近一段时间内的版本（设置数据的生命周期 TTL）。<br>用户可以针对每个列簇进行设置。</p>
</li>
<li><p><strong>单元格（Cell）</strong><br>由{rowkey, column( = +),version}唯一确定的单元。 Cell 中的数据是没有类型的，全部是字节码形式存贮。</p>
</li>
<li><p><strong>Region</strong><br>Region的概念和关系型数据库的分区或者分片差不多。<br>Hbase会将一个大表的数据基于Rowkey的不同范围分配到不通的Region中，每个Region负责一定范围的数据访问和存储。这样即使是一张巨大的表，由于被切割到不通的region，访问起来的时延也很低。</p>
</li>
</ul>
<h2 id="Hbase安装"><a href="#Hbase安装" class="headerlink" title="Hbase安装"></a>Hbase安装</h2><p>此处略过，具体可以参考[][]</p>
<h2 id="HBase命令行操作"><a href="#HBase命令行操作" class="headerlink" title="HBase命令行操作"></a>HBase命令行操作</h2><table>
<thead>
<tr>
<th>名称</th>
<th>命令表达式</th>
</tr>
</thead>
<tbody><tr>
<td>创建表</td>
<td>create ‘表名’, ‘列族名1’,’列族名2’,’列族名N’</td>
</tr>
<tr>
<td>查看所有表</td>
<td>list</td>
</tr>
<tr>
<td>描述表</td>
<td>describe  ‘表名’</td>
</tr>
<tr>
<td>判断表存在</td>
<td>exists  ‘表名’</td>
</tr>
<tr>
<td>判断是否禁用启用表</td>
<td>is_enabled ‘表名’is_disabled ‘表名’</td>
</tr>
<tr>
<td>添加记录</td>
<td>put  ‘表名’, ‘rowKey’, ‘列族 : 列‘  ,  ‘值’</td>
</tr>
<tr>
<td>查看记录rowkey下的所有数据</td>
<td>get  ‘表名’ , ‘rowKey’</td>
</tr>
<tr>
<td>查看表中的记录总数</td>
<td>count  ‘表名’</td>
</tr>
<tr>
<td>获取某个列族</td>
<td>get ‘表名’,’rowkey’,’列族’</td>
</tr>
<tr>
<td>获取某个列族的某个列</td>
<td>get ‘表名’,’rowkey’,’列族：列’</td>
</tr>
<tr>
<td>删除记录</td>
<td>delete  ‘表名’ ,‘行名’ , ‘列族：列’</td>
</tr>
<tr>
<td>删除整行</td>
<td>deleteall ‘表名’,’rowkey’</td>
</tr>
<tr>
<td>删除一张表</td>
<td>先要屏蔽该表，才能对该表进行删除第一步 disable ‘表名’ ，第二步  drop ‘表名’</td>
</tr>
<tr>
<td>清空表</td>
<td>truncate ‘表名’</td>
</tr>
<tr>
<td>查看所有记录</td>
<td>scan “表名”</td>
</tr>
<tr>
<td>查看某个表某个列中所有数据</td>
<td>scan “表名” , {COLUMNS=&gt;’列族名:列名’}</td>
</tr>
<tr>
<td>更新记录</td>
<td>就是重写一遍，进行覆盖，hbase没有修改，都是追加</td>
</tr>
</tbody></table>
<h2 id="Phoenix操作Hbase"><a href="#Phoenix操作Hbase" class="headerlink" title="Phoenix操作Hbase"></a>Phoenix操作Hbase</h2><h3 id="Phoenix安装与配置"><a href="#Phoenix安装与配置" class="headerlink" title="Phoenix安装与配置"></a>Phoenix安装与配置</h3><p>新公司使用的CM来统一管理大数据集群，为了防止软件版本不统一导致各种问题，这里在CM上安装Phoenix</p>
<p>首先，需要确定CM平台是哪个版本的，在CM的管理页面上可以直接看出，我们的CM的6.2.0版本的<br>那么剩下的，就是要下载一个和6.2.0版本想匹配的phoenix安装包<br>但是，CM从2021.1月份开始收费，通过正常渠道无法下载到这个安装包了。这里是在百度上找了很久才找到<br>具体参考<a href="https://blog.csdn.net/hell_oword/article/details/119327354?spm=1001.2014.3001.5502">CDH 6.2 安装 Phoenix</a></p>
<p>安装包已经搞定，下面开始安装</p>
<ol>
<li><p>首先安装 CSD 文件</p>
<ol>
<li>确定 CSD(Custom Service Descriptor) 文件安装路径，公司的安装路径为/opt/cloudera/csd,这里的地址就是server的地址，即ddp1服务器的地址</li>
<li>将 CSD文件(PHOENIX-1.0.jar) 放到到本地描述符存储库路径，然后重启 Cloudera Manager 服务器</li>
<li>重启 cloudera-scm-server 服务<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">systemctl restart cloudera-scm-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>这里如果cloudera-scm-server 服务不重启，虽然phoenix安装上去了也能正常使用，但是，在主页面添加不了服务，监控不了该组件</p>
</blockquote>
</li>
</ol>
</li>
<li><p>安装Phoenix parcel</p>
<ol>
<li>上传文件到<code>/opt/cloudera/parcel-repo</code>目录下，PHOENIX-5.0.0-cdh6.2.0.p0.1308267-el7.parcel、PHOENIX-5.0.0-cdh6.2.0.p0.1308267-el7.parcel.sha 、 manifest.json</li>
<li>点击检查新 Parcel ，当出现 PHOENIX 后，点击 Distribute</li>
<li>点击激活 PHOENIX，并在弹框中点击 确认</li>
<li>集群 -&gt; 操作 -&gt; 添加服务，出现 PHOENIX 服务 </li>
<li>将 PHOENIX 服务添加到每个 Region Server 中</li>
<li>重启hbase集群，否则phoenix启动会报错</li>
</ol>
</li>
</ol>
<h4 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol>
<li><p>Phoenix安装完成以后，在服务里找不到选项，添加不了服务，原因是CSD文件配置好以后，CM没有重启</p>
</li>
<li><p>添加完成phoenix服务以后，监控不了，CM页面提示如下告警信息<br><img src="/uploads/202203/phoenix%E6%B7%BB%E5%8A%A0%E6%9C%8D%E5%8A%A1%E5%BC%82%E5%B8%B8.png" alt="phoenix添加服务异常"><br>在CM界面点击<code>Cloudera Management Service</code>重启后解决</p>
</li>
<li><p>Phoenix安装完成以后，直接打开phoenix-sqlline，报如下错误</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Error: org.apache.hadoop.hbase.DoNotRetryIOException: Unable to load configured region split policy &#39;org.apache.phoenix.schema.MetaDataSplitPolicy&#39; for table &#39;SYSTEM.CATALOG&#39; Set hbase.table.sanity.checks to false at conf or table descriptor if you want to bypass sanity checks
        at org.apache.hadoop.hbase.master.HMaster.warnOrThrowExceptionForFailure(HMaster.java:2232)
        at org.apache.hadoop.hbase.master.HMaster.sanityCheckTableDescriptor(HMaster.java:2079)
        at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1978)
        at org.apache.hadoop.hbase.master.MasterRpcServices.createTable(MasterRpcServices.java:630)
        at org.apache.hadoop.hbase.shaded.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java)
        at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)
        at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:130)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:324)
        at org.apache.hadoop.hbase.ipc.RpcExecutor$Handler.run(RpcExecutor.java:304) (state&#x3D;08000,code&#x3D;101)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>网上的说法是，需要把phoenix的jar包放到hbase的安装路径之下，但是，那应该是自己解压phoenix安装的问题，使用CM安装，CM会把这些配置都设置好的，只需要重启一下Hbase集群即可</p>
</li>
<li><p>phoenix里查不到hbase的表</p>
<ol>
<li>这里不算是问题，phoenix创建的表hbase能看到，但是，hbase的表想要在phoenix里看到，需要做一次映射</li>
</ol>
</li>
</ol>
<h3 id="phoenix映射HBase"><a href="#phoenix映射HBase" class="headerlink" title="phoenix映射HBase"></a>phoenix映射HBase</h3><p>默认情况下，直接在hbase中创建的表，通过phoenix是查看不到的。<br>如果要在phoenix中操作由hbase创建的表，则需要在phoenix中进行表的映射。<br>映射方式有两种：</p>
<blockquote>
<p>视图映射和表映射</p>
</blockquote>
<p>两种方式的区别：</p>
<ul>
<li>视图只读，不支持新增和修改</li>
<li>如果删除视图，源数据不会发生改变</li>
<li>视图的查询效率较低（原因是：表映射会在表中创建一些空的键值对，这些空键值对的存在可以用来提高查询效率，而视图映射没有）</li>
<li>使用create table创建的关联表，如果对表进行了修改，源数据也会改变，同时如果关联表被删除，源表也会被删除。</li>
</ul>
<p>案例：<br>首先在Hbase中创建一个表，并写入几条数据</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create &#39;phoenix&#39;,&#39;info&#39;
put &#39;phoenix&#39;, &#39;row001&#39;,&#39;info:name&#39;,&#39;phoenix&#39;
put &#39;phoenix&#39;, &#39;row002&#39;,&#39;info:name&#39;,&#39;hbase&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ul>
<li>创建视图：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create view &quot;phoenix&quot;(empid varchar primary key,&quot;info&quot;.&quot;name&quot; varchar);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li>*注意：**</li>
</ul>
<ol>
<li>这里一定要注意的是表名和列族以及列名需要用双引号括起来，因为HBase是区分大小写的，如果不用双引号括起来的话Phoenix在创建表的时候会自动将小写转换为大写字母，这样HBase中会创建另外一张表PHOENIX。  </li>
<li>这里查询表名需要用双引号括起来，强制不转换为大写。</li>
</ol>
<p><img src="/uploads/202203/phoenix%E5%88%9B%E5%BB%BAhbase%E8%A7%86%E5%9B%BE.png" alt="phoenix创建hbase视图"></p>
<blockquote>
<p>视图是只读的，不可以修改hbase表的内容</p>
</blockquote>
<ul>
<li>创建关联表：<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create table &quot;phoenix&quot;(empid varchar primary key,&quot;info&quot;.&quot;name&quot; varchar);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
直接这么创建，从hbase端修改的数据，在phoenix里是查不到的。<br>经过阅读官方文档发现，phoenix 4.10 版本后，对列映射做了优化，采用一套新的机制，不在基于列名方式映射到 hbase。<br>如果只是想查询hbase数据，那么可以使用创建视图的方式，但是如果必须要映射到表，需要禁用列映射规则(会降低查询性能)<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">create table &quot;phoenix&quot;(empid varchar primary key,&quot;info&quot;.&quot;name&quot; varchar) column_encoded_bytes&#x3D;0;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<img src="/uploads/202203/phonix%E5%88%9B%E5%BB%BA%E8%A1%A8%E6%98%A0%E5%B0%84hbase%E8%A1%A8.png" alt="phonix创建表映射hbase表"></li>
</ul>
<p>还有一个问题：<br>通过phoenix创建的表，在phoenix侧修改数据后，hbase里的数据是两条<br><img src="/uploads/202203/phoenix%E6%9B%B4%E6%96%B0hbase%E8%A1%A8%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98.png" alt="phoenix更新hbase表存在的问题"><br>不知道这种数据会不会是脏数据</p>
<h3 id="JDBC链接Phoenix"><a href="#JDBC链接Phoenix" class="headerlink" title="JDBC链接Phoenix"></a>JDBC链接Phoenix</h3><p>添加Maven依赖</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0-HBase-2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.glassfish<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>javax.el<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>java代码：</p>
<blockquote>
<p>因为jdbc调用UDF失败，需要把hbase-site.xml加入到resource文件夹下再打包</p>
</blockquote>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>escloud<span class="token punctuation">.</span>phoenix</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>jdbc<span class="token punctuation">.</span></span><span class="token class-name">PhoenixDriver</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token operator">*</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>

<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">PhoenixTest</span> <span class="token punctuation">&#123;</span>
   <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">String</span> driver <span class="token operator">=</span> <span class="token string">"org.apache.phoenix.jdbc.PhoenixDriver"</span><span class="token punctuation">;</span>
   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">SQLException</span> <span class="token punctuation">&#123;</span>
      <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">Class</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span>driver<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">ClassNotFoundException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>
      <span class="token class-name">Statement</span> stmt <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
      <span class="token class-name">ResultSet</span> rs <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
      <span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

      stmt <span class="token operator">=</span> con<span class="token punctuation">.</span><span class="token function">createStatement</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token class-name">String</span> sql <span class="token operator">=</span> <span class="token string">"select * from \"phoenix\""</span><span class="token punctuation">;</span>
      rs <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>sql<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"rowkey:"</span><span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"ROWKEY"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">",name:"</span><span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>

      <span class="token class-name">String</span> s1 <span class="token operator">=</span> <span class="token string">"select CRC32('aaa') as aaa from \"phoenix\""</span><span class="token punctuation">;</span>
      rs <span class="token operator">=</span> stmt<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token string">"AAA:"</span><span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      <span class="token punctuation">&#125;</span>
      stmt<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      con<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="遇到的问题-1"><a href="#遇到的问题-1" class="headerlink" title="遇到的问题"></a>遇到的问题</h4><ol>
<li>java.lang.ClassNotFoundException: org.apache.phoenix.jdbc.PhoenixDriver</li>
</ol>
<p><strong>问题原因：</strong> maven工程打包不正确，应该把依赖也打到jar包里<br><strong>解决办法：</strong> </p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
                    <span class="token comment">&lt;!-- get all project dependencies --></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>
                        <span class="token comment">&lt;!-- bind to the packaging phase --></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<ol start="2">
<li>报找不到方法，具体报错信息<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: org.apache.hadoop.security.authentication.util.KerberosUtil.hasKerberosKeyTab(Ljavax&#x2F;security&#x2F;auth&#x2F;Subject;)Z
        at org.apache.hadoop.security.UserGroupInformation.&lt;init&gt;(UserGroupInformation.java:715)
        at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:925)
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:873)
        at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:740)
        at org.apache.hadoop.hbase.security.User$SecureHadoopUser.&lt;init&gt;(User.java:266)
        at org.apache.hadoop.hbase.security.User.getCurrent(User.java:164)
        at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo.&lt;init&gt;(PhoenixEmbeddedDriver.java:504)
        at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver$ConnectionInfo.create(PhoenixEmbeddedDriver.java:312)
        at org.apache.phoenix.jdbc.PhoenixDriver.getConnectionQueryServices(PhoenixDriver.java:232)
        at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver.createConnection(PhoenixEmbeddedDriver.java:150)
        at org.apache.phoenix.jdbc.PhoenixDriver.connect(PhoenixDriver.java:221)
        at java.sql.DriverManager.getConnection(DriverManager.java:664)
        at java.sql.DriverManager.getConnection(DriverManager.java:270)
        at com.digiwin.escloud.phoenix.Phoenix.main(Phoenix.java:18)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
解决办法：添加maven依赖<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>开启<code>phoenix.schema.isNamespaceMappingEnabled=true</code>之后，再用jdbc方式连接phoenix报如下错误：<br><img src="/uploads/202203/Hbase%E5%BC%80%E5%90%AFNamespace%E6%98%A0%E5%B0%84%E5%90%8EPhoenixJDBC%E6%8A%A5%E9%94%99.png" alt="Hbase开启Namespace映射后PhoenixJDBC报错"><br>原因：<br>开启这个配置以后，sqlline的方式可以默认映射过去，但是jdbc方式需要再手动指定一下<br>解决办法：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 再代码里加配置条件</span>
<span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"phoenix.schema.isNamespaceMappingEnabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="利用Phoenix创建hbase的二级索引"><a href="#利用Phoenix创建hbase的二级索引" class="headerlink" title="利用Phoenix创建hbase的二级索引"></a>利用Phoenix创建hbase的二级索引</h3>配置:<br>安装完 Phoenix 后，需要做一些必要配置才能使用 Phoenix，CDH HBase 配置界面配置如下两处：</li>
<li>hbase-site.xml 的 HBase 服务高级配置代码段（安全阀）</li>
<li>hbase-site.xml 的 HBase 客户端高级配置代码段（安全阀）<br>添加如下参数配置：<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 二级索引支持 --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.regionserver.wal.codec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
然后，按照提示重启HBase服务并重新部署客户端配置即可。</li>
</ol>
<p>创建二级索引：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">index</span> phoneix_index <span class="token keyword">on</span> <span class="token string">"phoenix"</span> <span class="token punctuation">(</span><span class="token string">"info"</span><span class="token punctuation">.</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>需要注意的是：<br><img src="/uploads/202203/Phoenix%E5%88%9B%E5%BB%BA%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E6%B3%A8%E6%84%8F%E7%82%B9.png" alt="Phoenix创建二级索引注意点"><br>所以如果想用hbase的二级索引，只能从phoenix中插入数据</p>
<h3 id="允许Phoenix创建namespace"><a href="#允许Phoenix创建namespace" class="headerlink" title="允许Phoenix创建namespace"></a>允许Phoenix创建namespace</h3><p>CDH HBase 配置界面配置如下两处：</p>
<ol>
<li>hbase-site.xml 的 HBase 服务高级配置代码段（安全阀）</li>
<li>hbase-site.xml 的 HBase 客户端高级配置代码段（安全阀）<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 命名空间映射开启，Phoenix4.8.0开始支持 --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.schema.isNamespaceMappingEnabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.schema.mapSystemTablesToNamespace<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
注意：<br>开启了命名空间以后，通过jdbc方式连接phoenix，需要在代码里配置一下这个参数：<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">// 再代码里加配置条件</span>
<span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"phoenix.schema.isNamespaceMappingEnabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">Connection</span> con <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span><span class="token string">"jdbc:phoenix:ddp5.hadoop:2181"</span><span class="token punctuation">,</span>properties<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
如果不添加如上配置，会报如下错误：<br><img src="/uploads/202203/Hbase%E5%BC%80%E5%90%AFNamespace%E6%98%A0%E5%B0%84%E5%90%8EPhoenixJDBC%E6%8A%A5%E9%94%99.png" alt="Hbase开启Namespace映射后PhoenixJDBC报错"></li>
</ol>
<h3 id="Phoenix允许自定义UDF"><a href="#Phoenix允许自定义UDF" class="headerlink" title="Phoenix允许自定义UDF"></a>Phoenix允许自定义UDF</h3><p>CDH HBase 配置界面配置如下两处：</p>
<ol>
<li>hbase-site.xml 的 HBase 服务高级配置代码段（安全阀）</li>
<li>hbase-site.xml 的 HBase 客户端高级配置代码段（安全阀）<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token comment">&lt;!-- 启用用户自定义函数（UDF） --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.functions.allowUserDefinedFunctions<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>enable UDF functions<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>

<span class="token comment">&lt;!-- 自定义函数，存储jar的hdfs目录 --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.dynamic.jars.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/hbase/lib/udf<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
下面写一个UDF来实现CRC32加密功能：</li>
</ol>
<ul>
<li><p>添加maven配置</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0-HBase-2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>编写java代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>digiwin<span class="token punctuation">.</span>escloud<span class="token punctuation">.</span>phoenix</span><span class="token punctuation">;</span>


<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">ImmutableBytesWritable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Bytes</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>expression<span class="token punctuation">.</span></span><span class="token class-name">Expression</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>expression<span class="token punctuation">.</span>function<span class="token punctuation">.</span></span><span class="token class-name">ScalarFunction</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>parse<span class="token punctuation">.</span></span><span class="token class-name">FunctionParseNode</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>tuple<span class="token punctuation">.</span></span><span class="token class-name">Tuple</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token class-name">PDataType</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span><span class="token class-name">PVarchar</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">SQLException</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>zip<span class="token punctuation">.</span></span>CRC32<span class="token punctuation">;</span>

<span class="token annotation punctuation">@FunctionParseNode</span><span class="token punctuation">.</span><span class="token class-name">BuiltInFunction</span><span class="token punctuation">(</span>
        name <span class="token operator">=</span> <span class="token class-name">CRC32Function</span><span class="token punctuation">.</span>NAME<span class="token punctuation">,</span>
        args <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token annotation punctuation">@FunctionParseNode</span><span class="token punctuation">.</span><span class="token class-name">Argument</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
<span class="token punctuation">)</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CRC32Function</span> <span class="token keyword">extends</span> <span class="token class-name">ScalarFunction</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">String</span> NAME <span class="token operator">=</span> <span class="token string">"CRC32"</span><span class="token punctuation">;</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> <span class="token class-name">Integer</span> LENGTH <span class="token operator">=</span> <span class="token number">19</span><span class="token punctuation">;</span>


    <span class="token keyword">public</span> <span class="token class-name">CRC32Function</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">SQLException</span> <span class="token punctuation">&#123;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token class-name">CRC32Function</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Expression</span><span class="token punctuation">></span></span> children<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">SQLException</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>children<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">CRC32</span> crc32 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">CRC32</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        crc32<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span><span class="token string">"lake"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>crc32<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">evaluate</span><span class="token punctuation">(</span><span class="token class-name">Tuple</span> tuple<span class="token punctuation">,</span> <span class="token class-name">ImmutableBytesWritable</span> ptr<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">getChildExpression</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">evaluate</span><span class="token punctuation">(</span>tuple<span class="token punctuation">,</span> ptr<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>ptr<span class="token punctuation">.</span><span class="token function">getLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
        <span class="token punctuation">&#125;</span>
        <span class="token class-name">CRC32</span> crc32 <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">CRC32</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        crc32<span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span>ptr<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ptr<span class="token punctuation">.</span><span class="token function">getOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ptr<span class="token punctuation">.</span><span class="token function">getLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        ptr<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token class-name">Bytes</span><span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>crc32<span class="token punctuation">.</span><span class="token function">getValue</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">PDataType</span> <span class="token function">getDataType</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token class-name">PVarchar</span><span class="token punctuation">.</span>INSTANCE<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">Integer</span> <span class="token function">getMaxLength</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> LENGTH<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">isNullable</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> <span class="token function">getChildExpression</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">isNullable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> NAME<span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>

    <span class="token keyword">private</span> <span class="token class-name">Expression</span> <span class="token function">getChildExpression</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">return</span> children<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>上传jar包到hdfs</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hadoop fs -put CalculationRealtime-1.0-SNAPSHOT-jar-with-dependencies.jar &#x2F;hbase&#x2F;lib&#x2F;udf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在sqlline创建udf</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> CRC32<span class="token punctuation">(</span><span class="token keyword">varchar</span><span class="token punctuation">)</span> <span class="token keyword">returns</span> <span class="token keyword">varchar</span> <span class="token keyword">as</span> <span class="token string">'com.digiwin.escloud.phoenix.CRC32Function'</span> <span class="token keyword">using</span> jar <span class="token string">'/hbase/lib/udf/CalculationRealtime-1.0-SNAPSHOT-jar-with-dependencies.jar'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/202203/Phoenix%E5%88%9B%E5%BB%BAUDF%E6%88%90%E5%8A%9F.png" alt="Phoenix创建UDF成功"><br>注意：<br>这里的路径因为公司hadoop集群配置了hdfs的开头，所以不要以hdfs:///开头</p>
</li>
<li><p>使用udf</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> CRC32<span class="token punctuation">(</span><span class="token string">'aaa'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> <span class="token string">"phoenix"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><img src="/uploads/202203/phoenix%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89UDF.png" alt="phoenix使用自定义UDF"></p>
</li>
</ul>
<h3 id="通过JDBC使用自定义UDF"><a href="#通过JDBC使用自定义UDF" class="headerlink" title="通过JDBC使用自定义UDF"></a>通过JDBC使用自定义UDF</h3><p>如果是JDBC中使用到了UDF函数，需要在hbase-site.xml中添加参数</p>
<pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.local.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/tmp/hbase-hbase/local/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>UDF 本地文件系统路径<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里虽然在CM上客户端和服务端都设置了上面的参数，但是，还是报如下错误：<br><img src="/uploads/202203/JDBC%E6%96%B9%E5%BC%8F%E8%B0%83%E7%94%A8PhoenixUDF%E6%8A%A5%E9%94%99.png" alt="JDBC方式调用PhoenixUDF报错"><br>这里不知道为啥，我把配置到hbase-site.xml的参数都通过Properties的方式加到代码里了，但是不生效<br>解决办法：<br>在代码里的resource文件夹添加hbase-site.xml，重新打包，就可以了</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hbase</category>
      </categories>
      <tags>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title>hive杂记（一）</title>
    <url>/2021/01/15/hive%E6%9D%82%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hive中的复杂数据类型数据如何导入(array)</li>
<li>hive中load数据到分区和add partition的区别：</li>
<li>hive引用udf的jar报无效</li>
<li>hive实现job并发执行</li>
<li>验证hive两个join的结果是否相等<a id="more"></a>
<h2 id="hive中的复杂数据类型数据如何导入-array"><a href="#hive中的复杂数据类型数据如何导入-array" class="headerlink" title="hive中的复杂数据类型数据如何导入(array)"></a>hive中的复杂数据类型数据如何导入(array)</h2><h3 id="创建hive表"><a href="#创建hive表" class="headerlink" title="创建hive表"></a>创建hive表</h3><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>dws_search_by_program_set_count_his<span class="token punctuation">(</span>
  program_set_id string<span class="token punctuation">,</span> 
  click_array array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">','</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'#'</span>
<span class="token keyword">lines</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\n'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
其中click_array 为array类型。</li>
</ul>
<blockquote>
<p>注意：</p>
</blockquote>
<ul>
<li>在建表的时候一定要指定row format delimited，我这里指定了列与列质检为逗号，array的元素内容为#</li>
</ul>
<p>数据格式：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">100051130,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051133,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051134,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051136,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051138,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051140,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051157,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051161,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0
100051163,0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0#0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下面来导入数据：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/home/gold/dws_search_by_program_set_count_his.csv'</span> overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>dws_search_by_program_set_count_his<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>效果：<br><img src="/uploads/20210114/hive-import-data.png" alt="hive-import-data"></p>
<h2 id="hive中load数据到分区和add-partition的区别："><a href="#hive中load数据到分区和add-partition的区别：" class="headerlink" title="hive中load数据到分区和add partition的区别："></a>hive中load数据到分区和add partition的区别：</h2><p>load data的方式需要移动文件路径，如果把文件就放在分区位置，这时候如果用load data的方式，就会报错，需要用add partition的方式</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> dws<span class="token punctuation">.</span>dws_device_box_info_his_v2 <span class="token keyword">ADD</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>province_alias<span class="token operator">=</span><span class="token string">'js'</span><span class="token punctuation">,</span>dt<span class="token operator">=</span><span class="token string">'20190701'</span><span class="token punctuation">)</span> 
location <span class="token string">'hdfs://ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>如果用load data的方式：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'hdfs://ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701'</span> 
overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> dws<span class="token punctuation">.</span>dws_device_box_info_his_v2 <span class="token keyword">partition</span><span class="token punctuation">(</span>province_alias<span class="token operator">=</span><span class="token string">'js'</span><span class="token punctuation">,</span>dt<span class="token operator">=</span><span class="token string">'20190701'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">`</span><span class="token punctuation">`</span><span class="token punctuation">`</span><span class="token punctuation">`</span>
就会报错：
<span class="token punctuation">`</span><span class="token punctuation">`</span><span class="token punctuation">`</span>shell
FAILED: Execution Error<span class="token punctuation">,</span> <span class="token keyword">return</span> code <span class="token number">1</span> <span class="token keyword">from</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>MoveTask<span class="token punctuation">.</span> Unable <span class="token keyword">to</span> move source hdfs:<span class="token comment">//ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701 to destination hdfs://ycluster-3/user/hive/warehouse/dws.db/dws_device_box_info_his_v2/province_alias=js/dt=20190701</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看出，报错是不能移动文件位置，因为文件已经在这个路径下了</p>
<p>总结：</p>
<ul>
<li>如果文件已经在分区的位置，这时候，需要用add partition的方式</li>
<li>如果文件不在分区的位置，这时候用load data的方式</li>
</ul>
<p>具体的可以参考<br><a href="https://blog.csdn.net/worldchinalee/article/details/80278111">hive中的复杂类型struct、array、map</a>，这里struct、array、map都有</p>
<h2 id="hive引用udf的jar报无效"><a href="#hive引用udf的jar报无效" class="headerlink" title="hive引用udf的jar报无效"></a>hive引用udf的jar报无效</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>原始的hive jar包在/opt/hive/auxlib/udf.jar，因为要测试代码，就又创建了一个jar包，/opt/hive/auxlib/udf1.jar<br>但是不管怎么创建udf，新的udf的代码都没有被引用</p>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>udf1.jar和udf.jar的java 类的路径和类名都是一样的，虽然在引用udf1.jar的时候，重新add jar了，但是hive不是把原始udf.jar从资源配置里拿去，当创建udf的时候，由于引用的类在原始的udf.jar中也有，所以，hive默认会引用hive在启动的时候加载的udf.jar，而不会使用udf1.jar</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>新旧两个jar包，类名或者路径保持不一致</p>
<h2 id="hive实现job并发执行"><a href="#hive实现job并发执行" class="headerlink" title="hive实现job并发执行"></a>hive实现job并发执行</h2><p>写了个sql，job数有20多个，一直都是上一个job跑完，下一个才开始执行，需要执行40多分钟<br>最近找到个方法，可以设置hive-job并发执行，但是这样会提高资源消耗，如果读取的表都是明细表，谨慎使用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>thread<span class="token punctuation">.</span>number<span class="token operator">=</span>最大并发job数<span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>启动了5个并发，时间被控制在10分钟以内了。</p>
<h2 id="hive-两个join的结果是否相等"><a href="#hive-两个join的结果是否相等" class="headerlink" title="hive 两个join的结果是否相等"></a>hive 两个join的结果是否相等</h2><p>有3个表A(id,name) B(id,name) C(id,name)<br>其中A的name为空，B两个都非空</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">A <span class="token keyword">inner</span> <span class="token keyword">join</span> C <span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> c<span class="token punctuation">.</span>id 
<span class="token keyword">union</span> <span class="token keyword">all</span>
B <span class="token keyword">join</span> C <span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> c<span class="token punctuation">.</span>id <span class="token operator">and</span> b<span class="token punctuation">.</span>name <span class="token operator">=</span> c<span class="token punctuation">.</span>name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>是否等于</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token punctuation">(</span>A <span class="token keyword">union</span> <span class="token keyword">all</span> B<span class="token punctuation">)</span> t1
<span class="token keyword">join</span> C t2
<span class="token keyword">on</span> t1<span class="token punctuation">.</span>id <span class="token operator">=</span> t2<span class="token punctuation">.</span>id
<span class="token keyword">where</span> t1<span class="token punctuation">.</span>name <span class="token operator">is</span> <span class="token boolean">null</span> <span class="token operator">or</span> t1<span class="token punctuation">.</span>name <span class="token operator">=</span> t2<span class="token punctuation">.</span>name<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>验证过程:</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111 <span class="token keyword">values</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222 <span class="token keyword">values</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token string">'c'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">)</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 <span class="token keyword">values</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'c'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">)</span>

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111 
<span class="token keyword">union</span> <span class="token keyword">all</span> 
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222<span class="token punctuation">)</span> t1
<span class="token keyword">inner</span> <span class="token keyword">join</span> 
<span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 t2
<span class="token keyword">on</span> t1<span class="token punctuation">.</span>id <span class="token operator">=</span> t2<span class="token punctuation">.</span>id
<span class="token keyword">where</span> t1<span class="token punctuation">.</span>name <span class="token operator">is</span> <span class="token boolean">null</span> <span class="token operator">or</span> t1<span class="token punctuation">.</span>name <span class="token operator">=</span> t2<span class="token punctuation">.</span>name

<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_111 a <span class="token keyword">inner</span> <span class="token keyword">join</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 b
<span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id
<span class="token keyword">union</span> <span class="token keyword">all</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
<span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_222 a <span class="token keyword">inner</span> <span class="token keyword">join</span> <span class="token keyword">temp</span><span class="token punctuation">.</span>gjc_test_333 c
<span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> c<span class="token punctuation">.</span>id <span class="token operator">and</span> a<span class="token punctuation">.</span>name <span class="token operator">=</span> c<span class="token punctuation">.</span>name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>经过验证，两个结果相同 </p>
<h2 id="基于python编写udf，实现判断字符串是否是标准json"><a href="#基于python编写udf，实现判断字符串是否是标准json" class="headerlink" title="基于python编写udf，实现判断字符串是否是标准json"></a>基于python编写udf，实现判断字符串是否是标准json</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment">## add file /home/19190845/udf.py</span>
<span class="token comment">## select transform(fbdeal_id,orderdata) USING 'python udf.py'  AS (fbdeal_id,orderdata) from app.app_onedata_oms_orders_t_bdeal_da;</span>
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> json

<span class="token keyword">def</span> <span class="token function">is_json</span><span class="token punctuation">(</span>myjson<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        json_object <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>myjson<span class="token punctuation">)</span>
    <span class="token keyword">except</span> ValueError<span class="token punctuation">,</span> e<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">False</span>
    <span class="token keyword">return</span> <span class="token boolean">True</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> sys<span class="token punctuation">.</span>stdin<span class="token punctuation">:</span>
    detail <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>detail<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        deal_id <span class="token operator">=</span> detail<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        orderData <span class="token operator">=</span> detail<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        isJson <span class="token operator">=</span> is_json<span class="token punctuation">(</span>orderData<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> isJson<span class="token punctuation">:</span>
            <span class="token keyword">print</span> <span class="token builtin">str</span><span class="token punctuation">(</span>deal_id<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> orderData
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">add</span> <span class="token keyword">file</span> <span class="token operator">/</span>home<span class="token operator">/</span><span class="token number">19190845</span><span class="token operator">/</span>udf<span class="token punctuation">.</span>py
<span class="token keyword">select</span> transform<span class="token punctuation">(</span>fbdeal_id<span class="token punctuation">,</span>orderdata<span class="token punctuation">)</span> <span class="token keyword">USING</span> <span class="token string">'python udf.py'</span>  <span class="token keyword">AS</span> <span class="token punctuation">(</span>fbdeal_id<span class="token punctuation">,</span>orderdata<span class="token punctuation">)</span> <span class="token keyword">from</span> app<span class="token punctuation">.</span>app_onedata_oms_orders_t_bdeal_da<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>以上语句，支持hive mr、tez引擎，并支持spark-sql命令行</p>
<h2 id="hive列转行"><a href="#hive列转行" class="headerlink" title="hive列转行"></a>hive列转行</h2><p>可以使用map和ateral view explode新造列名，很实用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span>  model_code<span class="token punctuation">,</span>
        fact_rate<span class="token punctuation">,</span>
        item_code<span class="token punctuation">,</span>
        quota_name<span class="token punctuation">,</span>
        refer_enum<span class="token punctuation">,</span>
        busi_cnt
<span class="token keyword">from</span>
<span class="token punctuation">(</span><span class="token keyword">select</span> model_code<span class="token punctuation">,</span>
       <span class="token string">'POP001'</span> <span class="token keyword">AS</span> fact_rate<span class="token punctuation">,</span>
       item_code<span class="token punctuation">,</span>
       <span class="token keyword">case</span> <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00101'</span> <span class="token keyword">then</span> <span class="token string">'商品满意度'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00103'</span> <span class="token keyword">then</span> <span class="token string">'物流配送'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00104'</span> <span class="token keyword">then</span> <span class="token string">'服务满意度'</span>
            <span class="token keyword">else</span> <span class="token string">'unknown'</span>
       <span class="token keyword">end</span> <span class="token keyword">as</span> quota_name<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">2</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">2.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt2<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">3</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">3.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt3<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">4</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">4.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt4<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">5</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">5.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt5<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">6</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">6.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt6<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">7</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">7.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt7<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">8</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">8.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt8<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">9</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt9
<span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_business_growth_comment_item_score_da
<span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;stat_date&#125;'</span>
  <span class="token operator">and</span> item_code <span class="token operator">in</span> <span class="token punctuation">(</span><span class="token string">'POP00101'</span><span class="token punctuation">,</span><span class="token string">'POP00103'</span><span class="token punctuation">,</span><span class="token string">'POP00104'</span><span class="token punctuation">)</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> model_code<span class="token punctuation">,</span>
         item_code<span class="token punctuation">)</span> a
lateral <span class="token keyword">view</span> explode<span class="token punctuation">(</span>map<span class="token punctuation">(</span><span class="token string">'2-2.99'</span><span class="token punctuation">,</span> cnt2<span class="token punctuation">,</span>
                         <span class="token string">'3-3.99'</span><span class="token punctuation">,</span> cnt3<span class="token punctuation">,</span>
                         <span class="token string">'4-4.99'</span><span class="token punctuation">,</span> cnt4<span class="token punctuation">,</span>
                         <span class="token string">'5-5.99'</span><span class="token punctuation">,</span> cnt5<span class="token punctuation">,</span>
                         <span class="token string">'6-6.99'</span><span class="token punctuation">,</span> cnt6<span class="token punctuation">,</span>
                         <span class="token string">'7-7.99'</span><span class="token punctuation">,</span> cnt7<span class="token punctuation">,</span>
                         <span class="token string">'8-8.99'</span><span class="token punctuation">,</span> cnt8<span class="token punctuation">,</span>
                         <span class="token string">'9-10'</span><span class="token punctuation">,</span> cnt9<span class="token punctuation">)</span><span class="token punctuation">)</span> b <span class="token keyword">as</span> refer_enum<span class="token punctuation">,</span> busi_cnt
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>或者使用str_to_map函数,不过感觉还不如直接用map</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span>  model_code<span class="token punctuation">,</span>
        fact_rate<span class="token punctuation">,</span>
        item_code<span class="token punctuation">,</span>
        quota_name<span class="token punctuation">,</span>
        refer_enum<span class="token punctuation">,</span>
        busi_cnt
<span class="token keyword">from</span>
<span class="token punctuation">(</span><span class="token keyword">select</span> model_code<span class="token punctuation">,</span>
       <span class="token string">'POP001'</span> <span class="token keyword">AS</span> fact_rate<span class="token punctuation">,</span>
       item_code<span class="token punctuation">,</span>
       <span class="token keyword">case</span> <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00101'</span> <span class="token keyword">then</span> <span class="token string">'商品满意度'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00103'</span> <span class="token keyword">then</span> <span class="token string">'物流配送'</span>
            <span class="token keyword">when</span> item_code <span class="token operator">=</span> <span class="token string">'POP00104'</span> <span class="token keyword">then</span> <span class="token string">'服务满意度'</span>
            <span class="token keyword">else</span> <span class="token string">'unknown'</span>
       <span class="token keyword">end</span> <span class="token keyword">as</span> quota_name<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">2</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">2.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt2<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">3</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">3.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt3<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">4</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">4.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt4<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">5</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">5.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt5<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">6</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">6.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt6<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">7</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">7.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt7<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">8</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">8.99</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt8<span class="token punctuation">,</span>
       <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token keyword">if</span><span class="token punctuation">(</span>item_value <span class="token operator">>=</span> <span class="token number">9</span> <span class="token operator">and</span> item_value <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">,</span>business_id<span class="token punctuation">,</span><span class="token boolean">null</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> cnt9
<span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_business_growth_comment_item_score_da
<span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;stat_date&#125;'</span>
  <span class="token operator">and</span> item_code <span class="token operator">in</span> <span class="token punctuation">(</span><span class="token string">'POP00101'</span><span class="token punctuation">,</span><span class="token string">'POP00103'</span><span class="token punctuation">,</span><span class="token string">'POP00104'</span><span class="token punctuation">)</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> model_code<span class="token punctuation">,</span>
         item_code<span class="token punctuation">)</span> a
LATERAL <span class="token keyword">VIEW</span>
    EXPLODE<span class="token punctuation">(</span>
            STR_TO_MAP<span class="token punctuation">(</span>
                    CONCAT<span class="token punctuation">(</span>
                        <span class="token string">'2-2.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt2 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;3-3.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt3 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;4-4.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt4 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;5-5.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt5 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;6-6.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt6 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;7-7.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt7 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;8-8.99='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt8 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token string">'&amp;9-10='</span><span class="token punctuation">,</span>CAST <span class="token punctuation">(</span>cnt9 <span class="token keyword">AS</span> STRING<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token punctuation">)</span>
                <span class="token punctuation">,</span><span class="token string">'&amp;'</span><span class="token punctuation">,</span> <span class="token string">'='</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span> lateral_table <span class="token keyword">AS</span> refer_enum<span class="token punctuation">,</span> busi_cnt
<span class="token punctuation">;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="hive数据倾斜"><a href="#hive数据倾斜" class="headerlink" title="hive数据倾斜"></a>hive数据倾斜</h2><p>这里数据倾斜的原因是<code>partner_id = 3</code>的数据好几百万，这里的解决办法是，把<code>partner_id = 3</code>的数据单独处理，添加随机数</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token comment">-- 取下单前的最后的广告，提交订单的session关联到广告</span>
<span class="token keyword">drop</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_3<span class="token punctuation">;</span>
<span class="token keyword">create</span>  <span class="token keyword">table</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_3
stored <span class="token keyword">as</span> orc
<span class="token keyword">as</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> <span class="token punctuation">(</span>
<span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>
       row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> ftrade_id<span class="token punctuation">,</span>partner_id <span class="token keyword">order</span> <span class="token keyword">by</span> front_time <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token keyword">as</span> rank <span class="token comment">-- 最新的广告</span>
<span class="token keyword">from</span> <span class="token punctuation">(</span>
  <span class="token keyword">select</span>
       t1<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>
       <span class="token boolean">null</span> <span class="token keyword">as</span> rand_num<span class="token punctuation">,</span>
       t2<span class="token punctuation">.</span>ad_type<span class="token punctuation">,</span><span class="token comment">-- 广告类型</span>
       t2<span class="token punctuation">.</span>ad_id<span class="token punctuation">,</span><span class="token comment">-- 广告id</span>
       t2<span class="token punctuation">.</span>keyword_id<span class="token punctuation">,</span><span class="token comment">-- 竞价关键词id</span>
       t2<span class="token punctuation">.</span>keyword_contect <span class="token punctuation">,</span><span class="token comment">-- 竞价关键词内容</span>
       t2<span class="token punctuation">.</span>sku_id <span class="token keyword">as</span> search_ad_sku_id  <span class="token punctuation">,</span><span class="token comment">-- 搜索广告商品id</span>
       t2<span class="token punctuation">.</span>is_premium                  <span class="token punctuation">,</span><span class="token comment">-- 是否溢价</span>
       front_time
  <span class="token keyword">from</span> <span class="token punctuation">(</span>
  <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_1
  <span class="token keyword">where</span> partner_id <span class="token operator">&lt;></span> <span class="token number">3</span><span class="token punctuation">)</span>  t1
  <span class="token keyword">left</span> <span class="token keyword">join</span> <span class="token punctuation">(</span>
      <span class="token keyword">select</span> ad_type<span class="token punctuation">,</span>                      <span class="token comment">-- 广告类型</span>
             ad_id<span class="token punctuation">,</span>                        <span class="token comment">-- 广告id</span>
             keyword_id<span class="token punctuation">,</span>                   <span class="token comment">-- 竞价关键词id</span>
             keyword_contect <span class="token punctuation">,</span>             <span class="token comment">-- 竞价关键词内容</span>
             sku_id                      <span class="token punctuation">,</span> <span class="token comment">-- 搜索广告商品id</span>
             is_premium                  <span class="token punctuation">,</span> <span class="token comment">-- 是否溢价</span>
             partner_id                  <span class="token punctuation">,</span>
             front_time
      <span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_tracker_ad_click_dt_de
      <span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;v_dt&#125;'</span> <span class="token operator">and</span> partner_id <span class="token operator">&lt;></span> <span class="token number">3</span>
  <span class="token punctuation">)</span> t2
    <span class="token keyword">on</span> t1<span class="token punctuation">.</span>partner_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>partner_id
 <span class="token keyword">where</span> to_unix_timestamp<span class="token punctuation">(</span>t1<span class="token punctuation">.</span>ftrade_gen_time<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1000</span> <span class="token operator">></span> t2<span class="token punctuation">.</span>front_time

 <span class="token keyword">union</span> <span class="token keyword">all</span>

  <span class="token keyword">select</span>
       t1<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>
       t2<span class="token punctuation">.</span>ad_type<span class="token punctuation">,</span><span class="token comment">-- 广告类型</span>
       t2<span class="token punctuation">.</span>ad_id<span class="token punctuation">,</span><span class="token comment">-- 广告id</span>
       t2<span class="token punctuation">.</span>keyword_id<span class="token punctuation">,</span><span class="token comment">-- 竞价关键词id</span>
       t2<span class="token punctuation">.</span>keyword_contect <span class="token punctuation">,</span><span class="token comment">-- 竞价关键词内容</span>
       t2<span class="token punctuation">.</span>sku_id <span class="token keyword">as</span> search_ad_sku_id  <span class="token punctuation">,</span><span class="token comment">-- 搜索广告商品id</span>
       t2<span class="token punctuation">.</span>is_premium                  <span class="token punctuation">,</span><span class="token comment">-- 是否溢价</span>
       front_time
  <span class="token keyword">from</span> <span class="token punctuation">(</span>
    <span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token keyword">as</span> rand_num   <span class="token comment">--数据倾斜，使用随机数重新关联</span>
    <span class="token keyword">from</span> tmp<span class="token punctuation">.</span>tmp_adm_tracker_order_dt_de_1
    <span class="token keyword">where</span> partner_id <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>  t1
  <span class="token keyword">left</span> <span class="token keyword">join</span> <span class="token punctuation">(</span>
      <span class="token keyword">select</span> ad_type<span class="token punctuation">,</span>                      <span class="token comment">-- 广告类型</span>
             ad_id<span class="token punctuation">,</span>                        <span class="token comment">-- 广告id</span>
             keyword_id<span class="token punctuation">,</span>                   <span class="token comment">-- 竞价关键词id</span>
             keyword_contect <span class="token punctuation">,</span>             <span class="token comment">-- 竞价关键词内容</span>
             sku_id                      <span class="token punctuation">,</span> <span class="token comment">-- 搜索广告商品id</span>
             is_premium                  <span class="token punctuation">,</span> <span class="token comment">-- 是否溢价</span>
             partner_id                  <span class="token punctuation">,</span>
             front_time<span class="token punctuation">,</span>
             <span class="token punctuation">(</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token number">1</span> <span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token keyword">as</span> rand_num  <span class="token comment">--数据倾斜，使用随机数重新关联</span>
      <span class="token keyword">from</span> adm<span class="token punctuation">.</span>adm_tracker_ad_click_dt_de
      <span class="token keyword">where</span> dt <span class="token operator">=</span> <span class="token string">'$&#123;v_dt&#125;'</span> <span class="token operator">and</span> partner_id <span class="token operator">=</span> <span class="token number">3</span>
  <span class="token punctuation">)</span> t2
    <span class="token keyword">on</span> t1<span class="token punctuation">.</span>partner_id <span class="token operator">=</span> t2<span class="token punctuation">.</span>partner_id
    <span class="token operator">and</span> t1<span class="token punctuation">.</span>rand_num <span class="token operator">=</span> t2<span class="token punctuation">.</span>rand_num
 <span class="token keyword">where</span> to_unix_timestamp<span class="token punctuation">(</span>t1<span class="token punctuation">.</span>ftrade_gen_time<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1000</span> <span class="token operator">></span> t2<span class="token punctuation">.</span>front_time
 <span class="token punctuation">)</span> t <span class="token punctuation">)</span> tt
 <span class="token keyword">where</span> rank <span class="token operator">=</span> <span class="token number">1</span>
<span class="token punctuation">;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="Hive优化技巧"><a href="#Hive优化技巧" class="headerlink" title="Hive优化技巧"></a>Hive优化技巧</h2><h3 id="控制reducer数量"><a href="#控制reducer数量" class="headerlink" title="控制reducer数量"></a>控制reducer数量</h3><p>控制hive中reducer的数量由三种方式，分别是：</p>
<pre class="line-numbers language-shell" data-language="shell"><div class="caption"><span>script</span></div><code class="language-shell">set hive.exec.reducers.bytes.per.reducer&#x3D;&lt;number&gt; 
set hive.exec.reducers.max&#x3D;&lt;number&gt;
set mapreduce.job.reduces&#x3D;&lt;number&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>其中<code>set mapreduce.job.reduces=&lt;number&gt;</code>的方式优先级最高，<br><code>set hive.exec.reducers.max=&lt;number&gt;</code>优先级次之，<br><code>set hive.exec.reducers.bytes.per.reducer=&lt;number&gt; </code>优先级最低。<br>从hive0.14开始，一个reducer处理文件的大小的默认值是256M。<br>reducer的数量并不是越多越好，我们知道有多少个reducer就会生成多少个文件，小文件过多在hdfs中就会占用大量的空间，造成资源的浪费。<br>如果reducer数量过小，导致某个reducer处理大量的数据（数据倾斜就会出现这样的现象），没有利用hadoop的分而治之功能，甚至会产生OOM内存溢出的错误。<br>使用多少个reducer处理数据和业务场景相关，不同的业务场景处理的办法不同。</p>
<h3 id="使用Map-join"><a href="#使用Map-join" class="headerlink" title="使用Map join"></a>使用Map join</h3><p>set hive.auto.convert.join = true<br>或者使用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token comment">/*+ MAPJOIN(table_a)*/</span><span class="token punctuation">,</span>
       a<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span>
       b<span class="token punctuation">.</span><span class="token operator">*</span> 
<span class="token keyword">from</span> table_a a 
<span class="token keyword">join</span> table_b b 
<span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="使用distinct-union-all代替union"><a href="#使用distinct-union-all代替union" class="headerlink" title="使用distinct + union all代替union"></a>使用distinct + union all代替union</h3><p>使用</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token keyword">distinct</span> <span class="token operator">*</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span> <span class="token punctuation">(</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'0'</span> <span class="token keyword">union</span> <span class="token keyword">all</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'1'</span> <span class="token keyword">union</span> <span class="token keyword">all</span> 
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'1'</span>
<span class="token punctuation">)</span>a<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>代替</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span><span class="token punctuation">(</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'0'</span> <span class="token keyword">union</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'0'</span> <span class="token keyword">union</span>
<span class="token keyword">select</span> order_id<span class="token punctuation">,</span>user_id<span class="token punctuation">,</span>order_type <span class="token keyword">from</span> orders <span class="token keyword">where</span> order_type<span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">)</span>t<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="解决数据倾斜的通用办法"><a href="#解决数据倾斜的通用办法" class="headerlink" title="解决数据倾斜的通用办法"></a>解决数据倾斜的通用办法</h3><p>数据倾斜的现象：任务进度长时间维持在99%，只有少量reducer任务完成，未完成任务数据读写量非常大，超过10G。在聚合操作是经常发生。<br>通用解决方法：<code>set hive.groupby.skewindata=true;</code><br>将一个map reduce拆分成两个map reduce。</p>
<p>最常用的是，把key设置一个随机数值。保证所有数据平均的分配到所有的reducer中处理</p>
<h3 id="通过group-by代替count-distinct-使用"><a href="#通过group-by代替count-distinct-使用" class="headerlink" title="通过group by代替count(distinct)使用"></a>通过group by代替count(distinct)使用</h3><h3 id="left-semi-join替代in-exsits"><a href="#left-semi-join替代in-exsits" class="headerlink" title="left semi join替代in/exsits"></a>left semi join替代in/exsits</h3><h2 id="Hive-Join的实现原理"><a href="#Hive-Join的实现原理" class="headerlink" title="Hive Join的实现原理"></a>Hive Join的实现原理</h2><p>hive执行引擎会将HQL“翻译”成为map-reduce任务，如果多张表使用同一列做join则将被翻译成一个reduce，否则将被翻译成多个map-reduce任务<br>例如：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> a<span class="token punctuation">.</span>val<span class="token punctuation">,</span> 
       b<span class="token punctuation">.</span>val<span class="token punctuation">,</span> 
       c<span class="token punctuation">.</span>val 
<span class="token keyword">FROM</span> a 
<span class="token keyword">JOIN</span> b 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key1<span class="token punctuation">)</span> 
<span class="token keyword">JOIN</span> c 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>c<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key1<span class="token punctuation">)</span>
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>将被翻译成1个map-reduce任务</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> a<span class="token punctuation">.</span>val<span class="token punctuation">,</span> 
       b<span class="token punctuation">.</span>val<span class="token punctuation">,</span>
       c<span class="token punctuation">.</span>val 
<span class="token keyword">FROM</span> a 
<span class="token keyword">JOIN</span> b 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>a<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key1<span class="token punctuation">)</span> 
<span class="token keyword">JOIN</span> c 
<span class="token keyword">ON</span> <span class="token punctuation">(</span>c<span class="token punctuation">.</span><span class="token keyword">key</span> <span class="token operator">=</span> b<span class="token punctuation">.</span>key2<span class="token punctuation">)</span>
<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>将被翻译成2个map-reduce任务</p>
<p>Hive中的Join可分为Common Join（Reduce阶段完成join）和Map Join（Map阶段完成join）</p>
<h3 id="Common-Join"><a href="#Common-Join" class="headerlink" title="Common Join"></a>Common Join</h3><ul>
<li><p>Map阶段<br>读取源表的数据，Map输出时候以Join on条件中的列为key，如果Join有多个关联键，则以这些关联键的组合作为key;<br>Map输出的value为join之后所关心的(select或者where中需要用到的)列；同时在value中还会包含表的Tag信息，用于标明此value对应哪个表；<br>按照key进行排序</p>
</li>
<li><p>Shuffle阶段<br>根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中</p>
</li>
<li><p>Reduce阶段<br>根据key的值完成join操作，期间通过Tag来识别不同表中的数据。</p>
</li>
</ul>
<h3 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h3><ul>
<li>首先是Task A，它是一个Local Task（在客户端本地执行的Task），负责扫描小表b的数据，将其转换成一个HashTable的数据结构，并写入本地的文件中，之后将该文件加载到DistributeCache中</li>
<li>接下来是Task B，该任务是一个没有Reduce的MR，启动MapTasks扫描大表a,在Map阶段，根据a的每一条记录去和DistributeCache中b表对应的HashTable关联，并直接输出结果。<br>由于MapJoin没有Reduce，所以由Map直接输出结果文件，有多少个Map Task，就有多少个结果文件。</li>
</ul>
<p>具体可以参考<a href="https://www.hadoopdoc.com/hive/hive-join">Hive Join 的原理与机制</a></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>hudi和iceberg测试比较</title>
    <url>/2022/02/28/hudi%E5%92%8Ciceberg%E6%B5%8B%E8%AF%95%E6%AF%94%E8%BE%83/</url>
    <content><![CDATA[<p>本文主要包括：</p>
<ul>
<li>hudi和iceberg测试比较</li>
</ul>
<a id="more"></a>

<h1 id="背景和需求"><a href="#背景和需求" class="headerlink" title="背景和需求"></a>背景和需求</h1><p>当前采集系统分为实时采集、定时采集，实时采集当天数据存在Hbase中，当天以前的数据存在Hive中。定时采集只有当天以前的数据。随着业务的要求越来越高，T+1的延时已经无法满足业务的的使用场景，数据实时性是采集系统亟需改善的一个地方。<br>我们也尝试使用了Kudu来解决这个问题，Kudu是一个列式存储的存储引擎，不兼容Hdfs，其次孩子王Kudu系统也不稳定，所以没有把整个表的数据写入Kudu，而是使用Kudu替代了Hbase，解决了Hbase批量查询的性能问题，但还是没有通过一个组件解决采集的实时性问题。<br>总结下来就是，采集系统需要将原系统数据实时采入单个组件，可以达到分钟级的延迟。同时提供高性能的查询方式给业务查询。数据湖很早就进入我们的视野，目前主流的就是Iceberg和Hudi，本文就是从原理、特性、性能上对比两个数据湖组件。</p>
<h1 id="Hudi介绍"><a href="#Hudi介绍" class="headerlink" title="Hudi介绍"></a>Hudi介绍</h1><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>Hudi使用Hadoop FileSystem API与湖存储交互，Hudi充分利用了像HDFS之类的存储模式所支持的“append”特性。这有助于Hudi提供流时写入，而不会导致文件计数/表元数据激增。</p>
<h2 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h2><p>Hudi是围绕基本文件和增量日志文件的概念设计的，它们将更新 / 增量数据存储到给定的基本文件（称为文件片，file slice）。基本文件格式包括 Parquet（列访问）和 HFile（索引访问），增量日志以 Avro（面向行）。<br><img src="/uploads/202203/hudi%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F.png" alt="hudi文件格式"></p>
<h2 id="表格式"><a href="#表格式" class="headerlink" title="表格式"></a>表格式</h2><p>表格式包括表的文件布局、表的schema、表变更的元数据跟踪。Hudi使用Avro模式来存储、管理和演进表的schema。Hudi有意识地将表/分区中的文件分组，并维护记录的键与所有文件组之间的映射，所有更新都记录到特定于文件组的增量日志文件中，Hudi的设计理念基于键的快速upserts/deletes，并且只需要在每个文件组中合并delta日志<br><img src="/uploads/202203/hudi%E8%A1%A8%E6%A0%BC%E5%BC%8F.png" alt="hudi表格式"></p>
<h2 id="表类型和查询"><a href="#表类型和查询" class="headerlink" title="表类型和查询"></a>表类型和查询</h2><p>Hudi支持两种类型的表，COW（Copy-On-Write），MOR（Merge-On-Read），COW表的写放大问题严重，MOR提供了低延迟、更高效地实时写入，但读取的时候需要更高的延迟</p>
<table>
<thead>
<tr>
<th></th>
<th>COW</th>
<th>MOR</th>
</tr>
</thead>
<tbody><tr>
<td>数据延迟</td>
<td>高</td>
<td>低</td>
</tr>
<tr>
<td>查询延迟</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>更新成本</td>
<td>高（重写整个parquet）</td>
<td>低（添加到delta日志大小）</td>
</tr>
<tr>
<td>Parquet文件大小</td>
<td>小</td>
<td>大</td>
</tr>
<tr>
<td>写放大</td>
<td>高</td>
<td>低</td>
</tr>
</tbody></table>
<p>Hudi支持三种类型的查询，快照查询（能够查询到表的最新快照数据，如果是MOR表，会将基本文件和增量文件合并后再提供数据）、增量查询（增量查询只能查看到写入表的新数据）、读优化查询（可以查询到表的最新快照数据，它近查询最新的基本列文件，可以保证查询性能，这种方式保证了性能，但数据可能会有延迟）</p>
<table>
<thead>
<tr>
<th>表类型</th>
<th>支持的查询类型</th>
</tr>
</thead>
<tbody><tr>
<td>COW</td>
<td>快照查询、增量查询</td>
</tr>
<tr>
<td>MOR</td>
<td>快照查询、增量查询、读优化查询</td>
</tr>
</tbody></table>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>Hudi支持不同的基于主键的索引方案，以快速将采集的记录键映射到他们所在的文件组中。Hudi会自动强制执行文件大小，这有助于降低从Parquet页脚读取统计信息所需的时间。</p>
<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><p>定义了不同的写入器/读取器如何协调对表的访问。Hudi确保原子写入，通过将提交原子地发布到时间线，并标记一个即时时间（instant），以标记该操作具体发生的时间。Hudi明确区分了写入进程（执行用户的更新、插入、删除）、表服务（写入数据、元数据以优化执行所需的信息）和读取器（执行查询），Hudi在所有三种类型的进程之间提供快照隔离，他们都对表的一致快照进行操作。</p>
<h2 id="写入器"><a href="#写入器" class="headerlink" title="写入器"></a>写入器</h2><p>Hudi表可以用作Spark/Flink管道的接收器，upsert、delete操作都会自动处理输入流中具有相同键的记录的预合并，然后查找索引，最后调用二进制打包算法将数据打包到文件中，同时遵循预配置的目标文件大小。</p>
<h2 id="读取器"><a href="#读取器" class="headerlink" title="读取器"></a>读取器</h2><p>Hudi在写入器和读取器之间提供了快照隔离，并允许所有主流的湖查询引擎（Spark、Hive、Presto）在任何表快照上进行一致的查询，每当Hudi必须为查询合并基础文件和日志文件时，Hudi都会进行控制并采用多种机制来提高合并性能，同时还提供对数据的读优化查询，以权衡数据新鲜度与查询性能。<br>hudi支持建表、写入时将数据同步到hive元数据，生成ro、rt表，支持hive查询，支持presto使用presto连接器查询</p>
<h2 id="表服务"><a href="#表服务" class="headerlink" title="表服务"></a>表服务</h2><p>为了让Hudi能作为增量数据管道的状态存储，为其设计了内置的表服务和自我管理运行时，可以编排/触发这些服务并在内部优化一切，Hudi有几个内置的表服务，目标都是确保高性能的表存储布局和元数据管理，他们在每次写入操作后同步自动调用，或者作为单独的后台作业异步调用。</p>
<ul>
<li>归档服务：一旦事件从时间线上过期，归档服务就会清除湖缓存的任何副作用。</li>
<li>清理服务：以增量的方式，删除超过保留期限的用于增量查询的文件切片</li>
<li>压缩服务：将基本文件与一组增量日志文件合并以生成新的基本文件，同时允许对文件组进行并发写入</li>
<li>聚簇服务：用户可以通过排序键将经常查询的记录组合在一起，或者通过将较小的基本文件合并为较大的文件来控制文件大小</li>
</ul>
<h2 id="数据服务"><a href="#数据服务" class="headerlink" title="数据服务"></a>数据服务</h2><p>Hudi能对常见的端到端用例做到开箱即用，最重要的是DeltaStreamer实用程序，可以轻松基于Kafka流以及在湖存储之上的不同格式的文件来构建数据湖。支持检查点的自动管理、跟踪源检查点作为Hudi表元数据的一部分</p>
<h1 id="Iceberg介绍"><a href="#Iceberg介绍" class="headerlink" title="Iceberg介绍"></a>Iceberg介绍</h1><h2 id="存储-1"><a href="#存储-1" class="headerlink" title="存储"></a>存储</h2><p>Iceberg支持使用Hadoop FileSystem API与湖存储交互，Iceberg需要文件系统支持写、读、删除操作，比如S3。Iceberg不需要随机写，一旦写入，数据文件和元数据文件在被删除之前是不可变的。</p>
<h2 id="文件格式-1"><a href="#文件格式-1" class="headerlink" title="文件格式"></a>文件格式</h2><p>Iceberg是围绕数据文件和元数据文件的概念设计的，数据文件格式支持parquet, avro, orc，数据文件可以设置大小，减少数据文件重写成本，元数据文件格式支持Json</p>
<h2 id="表格式-1"><a href="#表格式-1" class="headerlink" title="表格式"></a>表格式</h2><p>Iceerg支持创建表、删除表、修改表名、修改表属性、添加列、修改列名、修改列大小、修改列的顺序、删除列等操作。Iceberg的schema更新是元数据修改，数据文件不需要重写。<br>Iceberg分区每次都正确地生成分区值，并总是在可能的情况下用于加速查询。最重要的是，查询不再依赖于表的物理布局。通过物理和逻辑之间的分离，Iceberg表可以随着数据量的变化而发展分区方案。分区修改是一个元数据操作且不需要重写文件。<br>Iceberg排序顺序也可以在现有表中更新，在修改排序顺序时，使用较早顺序写入的旧数据将保持不变，引擎总是可以选择以最新的排序顺序。<br>快照文件列出清单列表文件。清单列表文件列出组成表快照的清单文件，以及每个分区的范围。清单文件列出组成表快照的数据文件，以及数据文件分区数据和列级别统计信息。Iceberg首先使用清单列表文件分区的范围，然后使用清单文件获取数据文件。通过这种模式，清单列表文件作为清单文件的索引，不需要扫描所有的清单文件。</p>
<p><img src="/uploads/202203/Iceberg%E8%A1%A8%E6%A0%BC%E5%BC%8F.png" alt="Iceberg表格式"></p>
<h2 id="并发控制-1"><a href="#并发控制-1" class="headerlink" title="并发控制"></a>并发控制</h2><p>一个表的元数据文件与另一个元数据文件的原子交换为可序列化隔离提供了基础。读取器在加载表元数据时使用当前的快照，并且在刷新元数据位置之前不会受到更改的影响。写入器乐观地创建表元数据文件，假设当前版本不会在写入器提交之前更改，一旦写入器创建了更新，它就通过将表的元数据文件指针从基本版本交换到新版本来提交。</p>
<h2 id="写入器-1"><a href="#写入器-1" class="headerlink" title="写入器"></a>写入器</h2><p>批量写入：</p>
<ul>
<li>insert into：向表中添加新数据</li>
<li>merge into：实现行级更新，包含更新行的数据文件会被重写</li>
<li>insert overwrite，分区数据文件会被重写<br>流式写入：Iceberg支持append和complete输出模式</li>
<li>append：将每个少量的批处理的行追加到表中</li>
<li>complete：每个少量的批处理替换表内容<br>Iceberg对分区表进行写操作之前，需要对每个任务的数据按照分区进行排序。对于批处理，鼓励执行显示排序来满足需求，但是这种方法会带来额外的延迟，因为排序被认为是流工作负载的繁重操作。为了避免额外的延迟，可以启用fanout写入器来消除这个需求<br>流式写入会快速创建新的表版本，从而创建大量的表元数据来跟踪这些版本。建议通过调优提交速率、过期旧快照和自动清理元数据文件来维护元数据</li>
</ul>
<h2 id="读取器-1"><a href="#读取器-1" class="headerlink" title="读取器"></a>读取器</h2><p>Iceberg查询不需要指定分区值查询，支持快照查询，支持表历史元数据、快照元数据、文件元数据、清单元数据查询<br>Iceber查询扫描计划会根据快照文件、清单列表文件、清单文件找出查询需要的数据文件，扫描计划能够在单节点上运行，因此任何一个客户端都可以低延迟的查询<br>Iceberg支持hive表，元数据保存在Iceberg中，支持hive查询，支持presto使用Iceberg链接起查询</p>
<h2 id="表服务-1"><a href="#表服务-1" class="headerlink" title="表服务"></a>表服务</h2><ul>
<li>过期快照：Iceberg每次写入会产生一个新的快照，快照可以被用来做时间快照查询，或者回滚，快照会聚集直到过期快照动作执行，推荐定期执行过期快照来删除不再需要数据文件，来保持较小的表元数据</li>
<li>删除旧的元数据文件：Iceberg使用Json文件跟踪表元数据，对表的每次更改都会生成一个新的元数据文件，以提供原子性，默认情况下，将保留旧的元数据文件作为历史记录。经常提交的表，比如流式任务，需要定期地清除元数据文件。</li>
<li>删除孤儿文件：在Spark或者其他分布式处理引擎中，任务或作业失败可能会留下不被表元数据引用的文件，而且在某些情况下，正常快照过期可能无法确定某个文件不再需要并删除它</li>
<li>压缩数据文件：Iceberg在一个表中跟踪每个数据文件，更多的数据文件导致清单文件中存储更多的元数据，而小的数据文件导致不必要的元数据量和文件打开成本的低效率查询，Iceberg可以并行压缩数据文件，这将把小文件合并成大文件，以减少元数据开销和运行时文件打开成本。</li>
<li>重写清单文件：Iceberg使用清单列表文件和清单文件元数据加快查询计划，并过滤不必要的数据文件，当表写的模式和查询模式不一致，元数据可以被重写。</li>
</ul>
<h1 id="Hudi和Iceberg特性对比"><a href="#Hudi和Iceberg特性对比" class="headerlink" title="Hudi和Iceberg特性对比"></a>Hudi和Iceberg特性对比</h1><table>
<thead>
<tr>
<th></th>
<th></th>
<th>Iceberg</th>
<th>Hudi</th>
</tr>
</thead>
<tbody><tr>
<td>ACID和隔离级别</td>
<td>ACID</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>隔离级别</td>
<td>多个写必须严格串行化，读和写可以同时跑</td>
<td>多个写的数据无交集，可以并发执行，读和写可以同时跑</td>
<td></td>
</tr>
<tr>
<td>并发多写</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>时间快照查询</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>表格式</td>
<td>支持schema变更</td>
<td>支持，添加字段、删除字段、修改字段名称、修改字段长度</td>
<td>支持，添加、删除</td>
</tr>
<tr>
<td>自定义schema</td>
<td>有自己的schema，不绑定任何计算引擎层面的schema</td>
<td>不支持，绑定了spark的schema</td>
<td></td>
</tr>
<tr>
<td>文件格式</td>
<td>文件格式</td>
<td>Parquet, ORC</td>
<td>Parquet, Avro</td>
</tr>
<tr>
<td>流批接口支持</td>
<td>批量读</td>
<td>支持（spark、Hive、presto）</td>
<td>支持（spark、Hive、presto）</td>
</tr>
<tr>
<td>批量写</td>
<td>支持（spark）</td>
<td>支持（spark）</td>
<td></td>
</tr>
<tr>
<td>流式读</td>
<td>开发中</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>流式写</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>Upserts/Delete/Merge/Update</td>
<td>不支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>查询性能</td>
<td>查询不需要指定分区</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>元数据花费</td>
<td>低</td>
<td>低</td>
<td></td>
</tr>
<tr>
<td>分区内索引</td>
<td>支持</td>
<td>不支持</td>
<td></td>
</tr>
<tr>
<td>CopyOnWrite</td>
<td>支持</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>MergeOnRead</td>
<td>开发中</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>自动压缩</td>
<td>不支持（需手动调用压缩方法）</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>自动清除</td>
<td>不支持（需手动调用清除方法）</td>
<td>支持</td>
<td></td>
</tr>
<tr>
<td>社区现状</td>
<td>开源时间</td>
<td>2018.11.6</td>
<td>2019.1.17</td>
</tr>
<tr>
<td>Github watch</td>
<td>118</td>
<td>1.2k</td>
<td></td>
</tr>
<tr>
<td>Github star</td>
<td>1.9k</td>
<td>2.2k</td>
<td></td>
</tr>
<tr>
<td>Github fork</td>
<td>710</td>
<td>979</td>
<td></td>
</tr>
<tr>
<td>Github Issue</td>
<td>477</td>
<td>73</td>
<td></td>
</tr>
<tr>
<td>Github pull request</td>
<td>161</td>
<td>119</td>
<td></td>
</tr>
<tr>
<td>Commits</td>
<td>1822</td>
<td>1864</td>
<td></td>
</tr>
<tr>
<td>Contributors</td>
<td>167</td>
<td>193</td>
<td></td>
</tr>
</tbody></table>
<ol>
<li><h1 id="Hudi和Iceberg性能对比"><a href="#Hudi和Iceberg性能对比" class="headerlink" title="Hudi和Iceberg性能对比"></a>Hudi和Iceberg性能对比</h1>生产环境100万数据量对比（Hudi推hive，Iceberg是hive表）</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>初始化插入100万</th>
<th>新增插入10万条</th>
<th>插入20万条、更新10万条、删除10万条</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>无分区表</td>
<td>有分区表</td>
<td>无分区表</td>
<td>有分区表</td>
<td>无分区表</td>
<td>有分区表</td>
</tr>
<tr>
<td>Iceberg插入耗时</td>
<td>7503</td>
<td>9295</td>
<td>10787</td>
<td>7983</td>
<td>14065</td>
<td>9648</td>
</tr>
<tr>
<td>Iceberg查询总数耗时_spark</td>
<td>2952</td>
<td>5970</td>
<td>2962</td>
<td>6170</td>
<td>2906</td>
<td>6232</td>
</tr>
<tr>
<td>iceberg查询单条耗时_spark</td>
<td>1019</td>
<td>852</td>
<td>1430</td>
<td>810</td>
<td>1007</td>
<td>831</td>
</tr>
<tr>
<td>Iceberg查询总数耗时_hive</td>
<td>10137</td>
<td>10581</td>
<td>13729</td>
<td>8753</td>
<td>9950</td>
<td>7553</td>
</tr>
<tr>
<td>Iceberg查询单条耗时_hive</td>
<td>934</td>
<td>239</td>
<td>183</td>
<td>160</td>
<td>170</td>
<td>168</td>
</tr>
<tr>
<td>Iceberg查询总数耗时_presto</td>
<td>生产上trino中的iceberg版本很低，查询报错，侧重hudi，所以跳过此测试</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Iceberg查询单条耗时_presto</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Hudi插入耗时</td>
<td>60255</td>
<td>59835</td>
<td>21868</td>
<td>29383</td>
<td>155586(96611+155586)</td>
<td>172115(69477+102638)</td>
</tr>
<tr>
<td>Hudi查询创建视图耗时_spark</td>
<td>3539</td>
<td>5213</td>
<td>3283</td>
<td>5606</td>
<td>3169</td>
<td>4803</td>
</tr>
<tr>
<td>Hudi查询总数耗时_spark</td>
<td>2660</td>
<td>2437</td>
<td>3639</td>
<td>2003</td>
<td>5234</td>
<td>3978</td>
</tr>
<tr>
<td>Hudi查询单条耗时_spark</td>
<td>4665</td>
<td>910</td>
<td>1048</td>
<td>2758</td>
<td>2323</td>
<td>2125</td>
</tr>
<tr>
<td>Hudi查询总数耗时_hive</td>
<td>11933</td>
<td>6569</td>
<td>6390</td>
<td>10721</td>
<td>5129</td>
<td>12573</td>
</tr>
<tr>
<td>Hudi查询单条耗时_hive</td>
<td>185</td>
<td>129</td>
<td>201</td>
<td>216</td>
<td>104</td>
<td>150</td>
</tr>
<tr>
<td>Hudi查询总数耗时_presto</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
<tr>
<td>Hudi查询单条耗时_presto</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
</tbody></table>
<h1 id="Hudi和Iceberg总结"><a href="#Hudi和Iceberg总结" class="headerlink" title="Hudi和Iceberg总结"></a>Hudi和Iceberg总结</h1><p>Hudi的最大的特色就是upsert和delete，upsert和delete写入增量文件，一定时间后可以将增量文件合并到基本文件中，通过这种方式可以实现行更新和流式写。<br>Iceberge的最大特色就是查询，通过快照、清单文件列表、清单实现快速过滤，Iceberg通过merge into也可以实现行更新，Iceberg也提供了流式写的接口，但是无论是行更新和流式写都是需要更新行的数据文件，并产生一个快照，这会大大增加元数据量。Iceberge的merge into也有诸多限制，原表和更新表join要有交集，否则会失败；Iceberg的更新表不能出现既更新也删除的同一条记录，否则会失败。<br>虽然在性能对比章节，Iceberg性能比Hudi好很多，但是从原理上分析，Hudi耗时高是有原因的，并且带来的是较少的IO，在Hudi更新时会根据主键合并更新数据，比如一条记录先新增后删除，合并后只留下删除的记录，然后根据主键定位到记录所在的分片，如果没有找到则插入记录，如果找到则添加到增量文件中，如果使用Hbase索引，相信性能会好一些。<br>Iceberg耗时低从原理来看，Iceberg只是将两个表join，然后原表修改的数据所在的数据文件会被重写，这种方式会在某些场景下导致大量的IO和内存消耗，在流式写测场景下支持时间旅行会产生很多文件。Iceberg的行删除目前在开发中。<br>个人觉得Hudi更适合作为采集系统的数据湖组件。Hudi最大的特色upsert和delete就已经是很大的亮点，这个功能和Kudu很相似。此外，目前Hudi功能已经完善，社区反馈的问题也比较少，已经在很多大厂应用，社区比较活跃。Iceberg很多功能还在开发中，社区反馈的问题比较多。</p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>采集</category>
      </categories>
      <tags>
        <tag>hudi</tag>
        <tag>iceberg</tag>
      </tags>
  </entry>
</search>
